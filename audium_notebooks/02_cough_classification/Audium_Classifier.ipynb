{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fgVWTMK9SNz"
      },
      "source": [
        "# Classifying sounds with HeAR and Wiki Commons Cough Data\n",
        "\n",
        "This Colab notebook demonstrates how to use the HeAR (Health Acoustic Representations) model, directly from Hugging Face, to create and utilize embeddings from health-related audio. The notebook focuses on building a data-efficient cough classifier system using a small [Wikimedia Commons](https://commons.wikimedia.org/wiki/Commons:Welcome) dataset of relevant sounds.\n",
        "\n",
        "Embeddings are compact, numerical representations of audio data that capture important features, making them suitable for training machine learning models with limited data and computational resources. Learn more about embeddings and their benefits at [this page](https://developers.google.com/health-ai-developer-foundations/hear).\n",
        "\n",
        "#### Here's a breakdown of the notebook's steps:\n",
        "\n",
        "1.  **Model Loading:** The HeAR model is loaded from the Hugging Face Hub (requires authentication with your Hugging Face account).\n",
        "\n",
        "2.  **Dataset Creation:**\n",
        "    *   **Wikimedia Commons Audio:** A small set of audio files is downloaded from Wikimedia Commons. This dataset includes examples of coughing, as well as other sounds like sneezing, breathing, laughter, and door knocking. The files are all publicly available under various Creative Commons licenses (details are available on Wikimedia Commons).\n",
        "    *   **Microphone Recording:** The notebook provides functionality to record audio directly within Colab using your microphone. This allows you to add your own recordings to the dataset.\n",
        "\n",
        "3.  **Embedding Generation:**\n",
        "    *   **Preprocessing:** The downloaded and recorded audio files are loaded and processed using `librosa`. They are resampled to 16kHz (required by the HeAR model) and segmented into 2-second clips.\n",
        "    *   **Inference:** The preprocessed 2-second audio clips are fed to the HeAR model to generate embeddings. Each clip produces a 512-dimensional HeAR embedding vector.\n",
        "    *   **Visualization (Optional):** The notebook includes functions to display the audio waveform, Mel spectrogram, and an audio player for each file and its individual clips.\n",
        "\n",
        "4.  **Classifier Training:**\n",
        "    *   **Labeling:** A set of labels is manually created, associating each audio file with whether it contains a cough or not. For example, `Cough_1.ogg` is labeled as `True`, while `Laughter.ogg` is labeled as `False`.\n",
        "    *   **Model Selection:** Several scikit-learn classifiers are used and can easily be expanded, including:\n",
        "        *   Support Vector Machine (linear kernel)\n",
        "        *   Logistic Regression\n",
        "        *   Gradient Boosting\n",
        "        *   Random Forest\n",
        "        *   Multi-layer Perceptron (MLP)\n",
        "    *   **Training:** Each classifier is trained using the generated HeAR embeddings and the corresponding cough labels. This demonstrates the data efficiency of using embeddings \u2013 these models train quickly with very little data.\n",
        "\n",
        "5.  **Cough Classification:**\n",
        "    *   **Test on New Example:** Test the classfier on held out cough or non-cough sound examples.\n",
        "    *   **Test on New Recording:** The microphone recording function is used again to capture a new audio clip (presumably of the user coughing or not coughing).\n",
        "    *   **Prediction:** The new clip is preprocessed, its embedding is generated using the HeAR model, and then each of the trained classifiers is used to predict whether the clip contains a cough.\n",
        "\n",
        "6.  **Embedding Visualization:**\n",
        "    *   **PCA Plot:** A plot visualizing the data points in a PCA space is presented to show how similar sounds are grouped together, as they have similar embeddings.\n",
        "    *   **Barcode Visualization:** The embeddings are visualized as \"barcodes\". Each embedding is displayed as a row in a heatmap, showing the magnitude of each dimension after subtracting the global mean. This provides a visual representation of the embedding's structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "all_files = os.listdir(\"audios\")\n",
        "\n",
        "# Count .webm files\n",
        "webm_files = [f for f in all_files if f.endswith('.webm')]\n",
        "num_webm = len(webm_files)\n",
        "\n",
        "# Search for the CSV\n",
        "csv_files = [f for f in os.listdir() if f.endswith('.csv')]\n",
        "num_csv = len(csv_files)\n",
        "\n",
        "print(f\"Total de archivos .webm: {num_webm}\")\n",
        "print(f\"Total de archivos .csv: {num_csv}\")\n",
        "print(f\"Archivo CSV encontrado: {csv_files[0] if csv_files else 'No encontrado'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ElrkiWYDfnQ",
        "outputId": "7a6d8bf8-8077-4069-ab8a-534791a70615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de archivos .webm: 1445\n",
            "Total de archivos .csv: 1\n",
            "Archivo CSV encontrado: Audium_Multilab_Covid_Master.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uZFXCSuqr1V"
      },
      "source": [
        "## Authenticate with HuggingFace, skip if you have a HF_TOKEN secret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-5Tj0uqS3dI"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub.utils import HfFolder\n",
        "\n",
        "if HfFolder.get_token() is None:\n",
        "    from huggingface_hub import notebook_login\n",
        "    notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40C0ubVPS3dI"
      },
      "source": [
        "## Setup HeAR Hugging Face Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section loads the **HeAR (Holistic Embeddings for Audio Representations)** model directly from Hugging Face using the `from_pretrained_keras` function. The model is used to convert audio clips into dense vector embeddings suitable for downstream classification.\n",
        "\n",
        "- `SAMPLE_RATE`: Sampling rate of the audio input (16kHz).\n",
        "- `CLIP_DURATION`: Duration of each audio clip to process (2 seconds).\n",
        "- `CLIP_LENGTH`: Total number of audio samples per clip (32,000).\n",
        "\n",
        "The loaded model exposes a `serving_default` signature that enables embedding generation via inference."
      ],
      "metadata": {
        "id": "dyXHdtpSVPBJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889,
          "referenced_widgets": [
            "ab695cfe824d4d04bec3432ad38e94cf",
            "3c1925c3178b49c386a9e91562444a23",
            "58fa6b71479f43a9804333d2d09af993",
            "fe4eba1fa0cc48219f53bdd6410d603f",
            "f7052d36cb054a11b8f6f03a544e0f97",
            "4aad741741c74a8c9f19d787cd5d53e0",
            "2f54d0c750f7485dac6a9a10b77cadac",
            "273964d2c9cd479a867fdddd4b20f6e6",
            "d5e239cb2e1442ef8d2aca4c117465b4",
            "07f1352aeb7e4b80a77119ef3838e686",
            "19ba2fc5dcaa4108b3f64fa073f434cf",
            "d30a35955ef04f799c5ae7bfbf9aed80",
            "fd98606f7a5d42d98bf270055de670dd",
            "773dce5f1d444da8bace8b113e9c1b24",
            "49364e28a6b14926b9d29968cfc64ad5",
            "dd5d15f3261e4604b46d6b9e585e280a",
            "1d51ad0da6ad474ca4d2551e8a7e27f7",
            "1c3ed3cfe946461bb6f7e7c6a31cb23c",
            "9cac1914373d4cc78eb616981bf1369e",
            "5ebafed421fa4ee8a6e821038fe06072",
            "b3ab2c414d714aa5a062f973b767e78c",
            "b0e8118516e04f04af10f50ac00f01f1",
            "1b049f4d777741f3af6da3c299b29587",
            "b27ddcd654ee441cab1caf96712c0e83",
            "7ef5b2665e8046258df498be234fb9e7",
            "d15e1d5738ef4b8c98575a39066c480b",
            "1b8c248e87f248569448bbbbbd3d8971",
            "c901bf4ad95b475a95d2318fead3c077",
            "87cc323a06f44dacabfb1c2db16316dd",
            "9f13de01183d49dd96d8a0d13f2cbafc",
            "1be3fd11334b473b82a7be98f4530f11",
            "af5aa28a3c60471987897765ac675dee",
            "3b366a2f82334470a6aa6b1e6772895f",
            "de6d9a4cce0b45a99caa0f5db76e077a",
            "33888d210e8845499bf7217da6f5cada",
            "c26161317b8847d1852289395b07221e",
            "0c65e9526ae44299b68b0c45da37723b",
            "da49ae7443f342008cd0e154e0c3fdb3",
            "6ac92b9e726544b59e5ee3cfa0e85aed",
            "a9588ceb41634c51b492db47dd7c108b",
            "1189db934b9d4130b7a6f7cc442bf00e",
            "c22d7bb2e6364809ba2c3e491050b0be",
            "02fdf1ede0bb4efeae143fb13e5c3f10",
            "11343b63a94e40e481f34cea6e3d1197",
            "21db9c1399b6413f8f2d13af9ab2464f",
            "7aa902cd514249beb1782a4ce7dd5252",
            "29e8891cde284149aae9fc6ebd647f06",
            "c559b75e6a284504b2810459afdd7d56",
            "e4007d30fc48404abe169e596dc7b12a",
            "d3e87eb7195541a4998d0c787c906b0a",
            "c93f766fc4594a44bb43d0c1135a9e00",
            "f0d43177f0944f32a122f36dbf8c280d",
            "73bbe9aa071b4b62b6b78b2ffcdca6d9",
            "511fc5a03f614319b0f0900a381a79e9",
            "04a8e2a9428a4759b91e9f3e0b46bdb6",
            "b1270b2c941b44deaa820aa0f7111b75",
            "1cc90383582143948b6bfba9978c1244",
            "be1c924ca9e5407db5c90c699a55be36",
            "eae88f12d78d44f0a01a411c804fba95",
            "f1676a5f3f824e5e979ef0ad4db7bb77",
            "dc878f7061ea44c8bd028011a8976b63",
            "92a1a5a2e160497ab03a7ea6935c41aa",
            "58338466d9f14a2fa8f7bdfe0f9babe9",
            "b48ef212898f481c86ef25a66cc95065",
            "f05b1c7fce0b49c4aaa485d460c44847",
            "e30f9a035b6d45f79431635f72aa4887",
            "2d6d0288108f492da5f3cc53d61dc7c9",
            "dcbde5ee597141d0b54e5c8bb0d86724",
            "c18ecc3ac43d44f4a91be07f3485de71",
            "4985f42ccc444d89b738421312d25c57",
            "ff1c40dec64845f9ae79d5f4d5fa6f27",
            "eb21f36da3c34ee3b5c5cf14e72ff701",
            "3028f13533c24c02b1d2a720d2a54dd5",
            "cb26a0a37e274aa0921839545c4d431e",
            "231c8367e7a84e3b96495d370f55378d",
            "7893235e20184659891373e41891b092",
            "7808aa11eada4688844ff50e115a2865",
            "f065d63063c84705bf351c8e769c86e7",
            "acca8d2b877146aaab7eb599398e6789",
            "03ac67467a9a4896897c3ed2845c7bd1",
            "fcd6fc69473549b98532618efc132700",
            "49cdeb33a5df4df498de694400f36980",
            "d835b1976e1848d58523f9bbc3f8d6c5",
            "53ccafb250d34741aeecd1bd2c06fa28",
            "778a3de09d6d45fea2f9a46dda7f05fd",
            "79c7488af1df41e49145b1940669deb0",
            "c69eecb4130d4f7d8e06b38a5f6befb1",
            "b286ad0be802488aab09337efbcd5a8a",
            "374276840bfd4bb292e27009ab475dfa",
            "ec46411b2b0c4cd9bd435b8e0b03164f",
            "d8ac94ce6c7845108596f49e872766c5",
            "10a68c316d8943d7836961fb88cb2d61",
            "38488f0de8cf4fd1a6a554c917dae116",
            "8da6338646f548da90f33adccd2533eb",
            "d4b04f6bda4a4c68a04694c90f8fe45d",
            "054c102a800d493f86b0a5afdc9c1cbc",
            "1108865724c04b8c834f92386b456feb",
            "80c63421baa941c38250073c626f4ef2",
            "ddc62a1fef27471d8aae810849fda7bf",
            "b12a212b9df543d7abc75aa45646786c",
            "a94bc687be1f467c8e3a51ea4dc7bbe4",
            "430d26806a7c43aeabdef89d556dc0e9",
            "1195daf85aeb4a45b0215c44cf17b667",
            "08d747a647da465a99984d93982d8408",
            "d3d0dcd2ec894e8d9dcbd6a7193afe66",
            "784f5f8f2aa04c0db590125a5f3e1bfb",
            "0d7d2fab2cf146b9bfae42b28fb231c0",
            "ecdf50ef6cb745c192de565a2a3e60ed",
            "7cfc79467a8e4403a8d39bcf5acff201",
            "d988899649214898924547ef25e66db2",
            "46cfb63b29c04ed6bb797c7a0b1ae095",
            "079090b4ab714e73b1003437595e9e35",
            "2e8d26274854481894d6c4ba6c517943",
            "8c03a8e385bb4c23ae3a51e473badf3a",
            "989fd4145aab45b7ab36ab62f35a8ed3",
            "796282f1dc3a46eaae9d1dd2cb161f1c",
            "0f0fc2e3829942c18e7b776752b52671",
            "1cea2a10d6fd4359ad7e26b551b99644",
            "503e9de35caa48f38078bf9af90e1679",
            "baff46c75dac4c808f5ebd3df43830e3",
            "921d3b5649174d238e8e48dc819b5e7e",
            "244c5f7ec52d4da6a3270d55e041bcf4",
            "6596a56a44ba4fdd8da1d4d6ea6a8555",
            "08298afaedde4c899d6c672a8058bacf",
            "8f78409880e244e2b3cab04b5a52ef46",
            "dab6cd16332a484c821c457cca06e082",
            "bf7d9e9c57cd4371a4fbd0b39f24e613",
            "ac11fd3d2f604f79944312a36fb8feb6",
            "536384fb91d6480d87a07bacc840f0ac",
            "728e66d11466489fa7523de34a38c0ca",
            "a32c4d7602024cc8ae197ce3966aeb8e",
            "9d5cb1902508431eb1ba9c5462943d63",
            "620297496a4b4e22b1fcb9466c3f4a7e",
            "a3b709b9c7774378ba12aa53cfb315f3",
            "1e813d4163bd46cdb5ffb960745c3a0b",
            "0334d213a70a4eceb61e60a999f986f0",
            "2a90e013cc244a90bad715e1b3ca1888",
            "31944190f90e420eaac43ab473860a85",
            "d3edb541b0924fa1868095895034ffc2",
            "f2bdd2dd13b646c7ab6061607daca5cd",
            "53717466d8564974833edf549e154ac0",
            "1e33e2d289954ec5afb98d4908f78e23",
            "b10e403fdaf14a6fb6c64bb96b6ed053",
            "5e28f4a8c4884514911499d0171900ff",
            "24b09c61b99548778c19a4b6b1ae8ea2",
            "6cfdd1b614e14b41a8b98e30ca482343",
            "a41cf648c3c649638f42c3251147557f",
            "82aff41d867847f6b62d85107eea62ab",
            "522b8b827b414700a22a72006d393b1a",
            "f857c66330b042aeaa1e486cabac0536",
            "3e0e4deb1dd44853b73254f12b3232ca",
            "3f5b3c4550ee4812bf7925dbdac516f0",
            "90d430e4cd0c4c0abc1ad24048254df2",
            "ee3ee8ab8b6646b884859f4b45e13bdf",
            "fdfd92829542415c9d8be746fba57dbd",
            "e1a925678bc249a1869db6d249f391e4",
            "2311b4ef0da0498ebf3af8d8782d0b93",
            "807dc11257824eceb8870210679c605e",
            "d601a3cfada04e02b8893f3b50419c2e",
            "88d8d64ce4f2442486a513af60ee5a5f",
            "7d4ee1b6c44044528980aa59f93f0af1",
            "dcdb7cbf4a514f5cae347942d43a489a",
            "5a57145c9ffb48f49e2fb9ffebf1a92b",
            "b2bab728d9c34fd68bdf581ee462bde1",
            "75c8a37a99a648aea32a344d434f4606",
            "62e1308372074f5cbf5855938f8141dd",
            "7af77e029c4e4f44b54e6cfbb0b92bc0",
            "28c16c00500e457ebc8788a895a4a476",
            "fc7b350a4fa741d7b19b9cacb84f9c2d",
            "2c0c3e778b384071aedcf69d22e5ac94",
            "0336c993df014f599ec290aca45bd725",
            "f3d02494c2c0474a916d5147b2598cde",
            "d68bc38125744bb9bae0133ef329cab8",
            "e13f57cda9584a95949cdce9dbfffa17",
            "cc7d625e86c44913a1c58ea224057294",
            "b6db9489c3c94a57b0eb33e6ba481401",
            "4a5e6591650246d4a55bbf736e1ad370",
            "546dec9cea2246c1a4da104b5b977b67",
            "9e329f9614c74681a9a8528f00992a66",
            "81dda9f63abd4de798e125694476cb79",
            "a2ba2edf90294db1aa1120ec9f180c89",
            "9d134fb8c906436abb1ed8752e59e321",
            "c9012cc225bd436ebb2ff49518533483",
            "27a51bd918fe42dfbfae2e604a6386e8",
            "47628522e1d2419db3b284b80c6bd267",
            "86656895db9743ed9d453c35015292cd",
            "4d32a7659ac74e3aa8278cd80890c91a",
            "a3764145e75d48c8b912dd4322215fb2",
            "edfea30ac45e49edb18327a61d201e9a",
            "6b9b6047ee3940158395359725956f39",
            "d43eed7b1c91490793f00fd2ac6b11b0",
            "933b7788b5214f87971a9f8945232426",
            "d3b3aed10c834b05b5910c0c7e8b2958",
            "0d7f44d10bd24958ac76ac47c40023dd",
            "76ff648091f54cbd855a0facc378f54b",
            "ec31296836424ee197b328fcd605f22b",
            "7367330f59444327bd1276835734de10",
            "a6657b92c2884897b9fc2cad9e620aac",
            "d1ea45401a6b4aa4a4a7ab7840485a7d",
            "82824dac5c3b45e38b0cd8e86287dac9",
            "b6ae42f6abe34a249218b2eb5e7f6388",
            "eea641039c464f1daad44a65546de35e",
            "c1064cd4a9bd47eabac1f8e751c27a05",
            "1ffc1a56174d442f9b991b76455ca2eb",
            "3e8857f6696c4ca7814f1be3d0324f01",
            "ca60d69b2a5349f7b50779f0803d363d",
            "a157a0db04bd4bcc9d695ba6ec218331",
            "97f85bdae8af46afbf2e44e0f5991e1c",
            "ebed5106957c4af98b0d663d27e1eae1",
            "e57af1620bcd48968398de6ea2b76efd",
            "d3a2a9f2af7342979d3475fc45347d8c",
            "8f7a2cc5ab96416f9be039900a7b3449",
            "ee1376af2c164e20ac907a6606eedcfb",
            "95a72cdfea0f4913951b76c9cb73bfbc",
            "d92c48d215b74a72a3d77b6ad719c3d1",
            "90ed9af1dcac4892a0db9140e4d8290c",
            "37d0262b8e6d43818f9bdebc62b592ad",
            "443483054efd41f1800518c9401aac25",
            "69a6bb0be1274682868dfebb96f96162",
            "58c1a386c643417bb48010443b4a695d",
            "a6b997fb009d4c28a1702f07ca25a7c8",
            "8c8f37e6e06b45f480d1917d5fdefb66",
            "da376135967f46fb9ee80c4fdd54a0b3",
            "8251af94e711495dab257714a3814246",
            "4cd6d58567dc4350b22a6ce3171b0350",
            "54adb39b27d44028bf439945cc6a8f94",
            "13dc4a6027144c18bd9875a02d56d056",
            "957704fa6edc434695f31e53a37711e7",
            "0ea805cf5a6a4277a28f64d9ba2baab9",
            "e95069e882f34a1cb20ced4c2ef7e756",
            "eee136ae6e76464390c67b1f5a9eca67",
            "21ef6cd7f93140f8ad670f3a9c82ad5c",
            "bb03faa60b614131804e934970a461c7",
            "2ef7b7af0dd44d379ab2dd62916284f7",
            "3e3e3ec3adca42bfb32073a3d7623de3",
            "51e0981338f24b4b838a10ea4d40ed52",
            "3092e4a9003a4c09b0a4dfe2349294c3",
            "04d02374695347efabee14e878dba819",
            "1965ab7c3b4a40318b75c982442d28ed",
            "2b70c8c8aff7466591076a9d2a7c3f47",
            "0d309dd317b24fc8a78a048a08ceaae7",
            "5b06cd6d5d0b4a89a0e5fabc38aab9ab",
            "e30ba9794aab48ac8ea3a0064776cfbe",
            "059daa9e2bfa4b2b994eced5566faa4e",
            "9c612675c5164f3dae01ec523ff5c00b",
            "ebfc982da3fc4528a881e89a714c5336",
            "36691816838f4e0ba70b04a0ba72c0bc",
            "7b44273e928548c8b064cc41224ce723",
            "3a3f5181ff0143159de1acd38de73687",
            "2c96b25bf6db4b788ca839a603a76ab8",
            "445d9d629b384cda8b03244d658188cd",
            "206711a2d59043cbb4fcc5ca0efcda28",
            "43592f9c567441f7b1cd0664efc80843",
            "02539085db3144be9aeeda9e2fdb4e79",
            "937867b94c8f438589b91bacf9d64ab8",
            "e8e0ecbacf92433294edc61e133315fd",
            "94f40dd5f4894675b321809e119911d9",
            "72ed8a28185c4174b841d84a2e9d82b8",
            "fdaee05f761947a1b4b82bce7e54709c",
            "26f8805829f64a4ab1780df56a23930a",
            "df705a88008e49359ed7408f954073bd",
            "37424a3582df4b9787c6badb6fa99d27",
            "81de07af82514444a2849d45414e708c",
            "f80dbd298ef64149974f30a42856dd25",
            "26363c2ee1c44957b028d761fa229826",
            "fbbe889b153c4633b06f48494bdfb917",
            "5b05ce5f6c594c478b1bada9cc505cb6",
            "677b5a6bb97f445badd6590fe78567ca",
            "379431e85f4e4341b85889419f4c48a3",
            "eec7f3957366496c902555183610cb46",
            "d7a0a70165b0447db35f44d2aaed2c02",
            "aca8f687720f412a82e413f773805438",
            "a61f84e75ade45e09e465cef16601d59",
            "5e85518f2415480e8a8c0c8fdec343aa",
            "2c91ee3110e741d5bd2735f2b710259c"
          ]
        },
        "collapsed": true,
        "id": "hqB4-dSUeQKe",
        "outputId": "499753d1-4781-486e-965c-1e2bcc23aa95"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 24 files:   0%|          | 0/24 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab695cfe824d4d04bec3432ad38e94cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/3.24k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d30a35955ef04f799c5ae7bfbf9aed80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".DS_Store:   0%|          | 0.00/6.15k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b049f4d777741f3af6da3c299b29587"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/11.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de6d9a4cce0b45a99caa0f5db76e077a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.82k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21db9c1399b6413f8f2d13af9ab2464f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "keras_metadata.pb:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1270b2c941b44deaa820aa0f7111b75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "variables.data-00000-of-00001:   0%|          | 0.00/12.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d6d0288108f492da5f3cc53d61dc7c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fingerprint.pb:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f065d63063c84705bf351c8e769c86e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "variables.index:   0%|          | 0.00/5.08k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "374276840bfd4bb292e27009ab475dfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "saved_model.pb:   0%|          | 0.00/4.89M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b12a212b9df543d7abc75aa45646786c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fingerprint.pb:   0%|          | 0.00/76.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46cfb63b29c04ed6bb797c7a0b1ae095"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "saved_model.pb:   0%|          | 0.00/4.01M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "244c5f7ec52d4da6a3270d55e041bcf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "keras_metadata.pb:   0%|          | 0.00/644k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "620297496a4b4e22b1fcb9466c3f4a7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "variables.index:   0%|          | 0.00/4.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e28f4a8c4884514911499d0171900ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "variables.data-00000-of-00001:   0%|          | 0.00/3.95M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdfd92829542415c9d8be746fba57dbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fingerprint.pb:   0%|          | 0.00/55.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62e1308372074f5cbf5855938f8141dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "keras_metadata.pb:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a5e6591650246d4a55bbf736e1ad370"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "saved_model.pb:   0%|          | 0.00/340k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3764145e75d48c8b912dd4322215fb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "variables.index:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1ea45401a6b4aa4a4a7ab7840485a7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "variables.data-00000-of-00001:   0%|          | 0.00/24.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e57af1620bcd48968398de6ea2b76efd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "gitattributes:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6b997fb009d4c28a1702f07ca25a7c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "variables.data-00000-of-00001:   0%|          | 0.00/1.21G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21ef6cd7f93140f8ad670f3a9c82ad5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fingerprint.pb:   0%|          | 0.00/78.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e30ba9794aab48ac8ea3a0064776cfbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "saved_model.pb:   0%|          | 0.00/3.98M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02539085db3144be9aeeda9e2fdb4e79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "variables.index:   0%|          | 0.00/6.57k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26363c2ee1c44957b028d761fa229826"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_21425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_17891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import from_pretrained_keras\n",
        "\n",
        "# Load the model directly from Hugging Face Hub\n",
        "loaded_model = from_pretrained_keras(\"google/hear\")\n",
        "# Inference function for embedding generation\n",
        "infer = loaded_model.signatures[\"serving_default\"]\n",
        "\n",
        "# HeAR Parameters\n",
        "SAMPLE_RATE = 16000  # Samples per second (Hz)\n",
        "CLIP_DURATION = 2    # Duration of the audio clip in seconds\n",
        "CLIP_LENGTH = SAMPLE_RATE * CLIP_DURATION  # Total number of samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model Inference on Random Input\n",
        "This block tests the HeAR model inference using **synthetic audio data** (random noise). It is useful for verifying that the embedding pipeline is working before using real audio clips.\n",
        "\n",
        "- Generates `NUM_EXAMPLES` random audio clips of duration `CLIP_DURATION`.\n",
        "- Each clip has shape `(CLIP_LENGTH,)` matching the expected input format.\n",
        "- Passes the batch of audio clips to the HeAR model to extract embeddings.\n",
        "- Outputs the shape and data type of the resulting embedding array.\n",
        "\n",
        "This is a dry run to confirm that the model produces meaningful embeddings without requiring labeled data."
      ],
      "metadata": {
        "id": "29KuJzk0Vx1l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "z1KzmL_kqbRz",
        "outputId": "46f8d128-64d8-4671-cedb-3fb5577d8341"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CLIP_DURATION' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3452515320>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Generate Random Input Audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mNUM_EXAMPLES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m  \u001b[0;31m# number of random audio examples to generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Generating {NUM_EXAMPLES} {CLIP_DURATION}s raw audio examples.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mraw_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EXAMPLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Raw audio shape: {raw_audio.shape}, data type: {raw_audio.dtype}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CLIP_DURATION' is not defined"
          ]
        }
      ],
      "source": [
        "# %%time\n",
        "import numpy as np\n",
        "\n",
        "# Generate Random Input Audio\n",
        "NUM_EXAMPLES = 4  # number of random audio examples to generate\n",
        "print(f\"Generating {NUM_EXAMPLES} {CLIP_DURATION}s raw audio examples.\")\n",
        "raw_audio = np.random.normal(size=(NUM_EXAMPLES, CLIP_LENGTH))\n",
        "print(f\"Raw audio shape: {raw_audio.shape}, data type: {raw_audio.dtype}\\n\")\n",
        "\n",
        "# Perform Inference Extract and Process the Embedding\n",
        "print(f'Running HeAR model to produce {NUM_EXAMPLES} embeddings.')\n",
        "output_dict = infer(x=raw_audio)\n",
        "embedding = output_dict['output_0'].numpy()  # directly unpack as a NumPy array\n",
        "print(f\"Embedding shape: {embedding.shape}, data type: {embedding.dtype}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO-Z5BOtj3D1"
      },
      "source": [
        "## Download and Record Audio Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBZnJwzzj3D1"
      },
      "source": [
        " Wiki Commons\n",
        "https://commons.wikimedia.org/wiki/Category:Coughing_audio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bzpu88BhonqO"
      },
      "outputs": [],
      "source": [
        "files_map = {}  # file name to file path map\n",
        "file_embeddings = {} # embedding cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz5Z4BOlGVHm"
      },
      "source": [
        "## Model Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section defines utility functions for **visualizing audio waveforms and spectrograms** using `librosa` and `matplotlib`. These visual tools help in understanding the structure of the audio signals being processed.\n",
        "\n",
        "- `plot_waveform(...)`: Plots the raw waveform of an audio clip.\n",
        "- `plot_spectrogram(...)`: Plots the **Mel spectrogram**, a frequency representation commonly used in audio analysis.\n",
        "\n",
        "Warnings from specific audio libraries are suppressed for cleaner outputs."
      ],
      "metadata": {
        "id": "gp2EsHAgWLzg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33G4zKJHjGGc"
      },
      "outputs": [],
      "source": [
        "# @title Plot Helpers\n",
        "import os\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "import matplotlib.cm as cm\n",
        "import warnings\n",
        "\n",
        "# Suppress the specific warning\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"soundfile\")\n",
        "warnings.filterwarnings(\"ignore\", module=\"librosa\")\n",
        "\n",
        "\n",
        "def plot_waveform(sound, sr, title, figsize=(12, 4), color='blue', alpha=0.7):\n",
        "  \"\"\"Plots the waveform of the audio using librosa.display.\"\"\"\n",
        "  plt.figure(figsize=figsize)\n",
        "  librosa.display.waveshow(sound, sr=sr, color=color, alpha=alpha)\n",
        "  plt.title(f\"{title}\\nshape={sound.shape}, sr={sr}, dtype={sound.dtype}\")\n",
        "  plt.xlabel(\"Time (s)\")\n",
        "  plt.ylabel(\"Amplitude\")\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_spectrogram(sound, sr, title, figsize=(12, 4), n_fft=2048, hop_length=256, n_mels=128, cmap='nipy_spectral'):\n",
        "  \"\"\"Plots the Mel spectrogram of the audio using librosa.\"\"\"\n",
        "  plt.figure(figsize=figsize)\n",
        "  mel_spectrogram = librosa.feature.melspectrogram(y=sound, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "  log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "  librosa.display.specshow(log_mel_spectrogram, sr=sr, hop_length=hop_length, x_axis='time', y_axis='mel', cmap=cmap)\n",
        "  plt.title(f\"{title} - Mel Spectrogram\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Unique File Identifiers from Metadata\n",
        "\n",
        "This cell reads the master CSV file containing metadata for the audio samples and filters only those marked as **valid** (`Valid == \"Yes\"`). For each valid entry, it generates a **unique identifier** (used for matching with `.webm` files) by combining:\n",
        "\n",
        "- the date (`YYYYMMDD`),\n",
        "- the time (`HHMMSS`),\n",
        "- the subject code,\n",
        "- and the original filename.\n",
        "\n",
        "Spaces are replaced with `%20` to ensure filename compatibility."
      ],
      "metadata": {
        "id": "s1glge-kWeso"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhd5Xd4dyWSp",
        "outputId": "a4c45d17-ec74-4ddd-d18c-9b6b14a59be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  Generated_Code\n",
            "0            20230424140556_GB%20fe-1_vocal.webm\n",
            "1        20230424140556_GB%20fe-1_lungfront.webm\n",
            "2         20230424140556_GB%20fe-1_lungback.webm\n",
            "3            20230424140045_GA%20fe-1_vocal.webm\n",
            "4        20230424140045_GA%20fe-1_lungfront.webm\n",
            "...                                          ...\n",
            "1627  20211202103821_Mcp-02-12-D2_lungfront.webm\n",
            "1628   20211202103821_Mcp-02-12-D2_lungback.webm\n",
            "1629      20211202103721_Mcp-02-12-D1_vocal.webm\n",
            "1630  20211202103721_Mcp-02-12-D1_lungfront.webm\n",
            "1631   20211202103721_Mcp-02-12-D1_lungback.webm\n",
            "\n",
            "[1210 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(\"Audium_Multilab_Covid_Master.csv\")  # Cambiar por la ruta de tu archivo CSV\n",
        "\n",
        "# Filter rows where Valid == \"Yes\"\n",
        "valid_rows = df[df[\"Valid\"] == \"Yes\"].copy()\n",
        "\n",
        "# Function to generate the unique code\n",
        "def generate_code(row):\n",
        "    # Convert and format date and time, tolerant to different formats\n",
        "    date_str = pd.to_datetime(row[\"Date\"]).strftime(\"%Y%m%d\")\n",
        "    time_str = pd.to_datetime(row[\"Time\"]).strftime(\"%H%M%S\")\n",
        "    code = row[\"Code\"]\n",
        "    filename = row[\"Filename\"]\n",
        "    return f\"{date_str}{time_str}_{code}{filename}\".replace(\" \", \"%20\")\n",
        "\n",
        "# Generate the codes\n",
        "valid_rows[\"Generated_Code\"] = valid_rows.apply(generate_code, axis=1)\n",
        "\n",
        "# Display or export the result\n",
        "print(valid_rows[[\"Generated_Code\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Match Valid Audio Files\n",
        "\n",
        "This section scans all `.webm` files in the current working directory and cross-references them against the list of valid entries generated from the metadata CSV. It builds a dictionary (`files_map`) containing only the filenames that are confirmed as valid, ensuring that subsequent processing is performed exclusively on approved and verified data samples."
      ],
      "metadata": {
        "id": "QFc-POq6XSb1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "yiakAX5h0VWD",
        "outputId": "148a20a9-5b46-42bb-b237-b08a828cd607"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1245393725>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfiles_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"audios\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.webm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresultado\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_rows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_rows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Generated_Code\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "files_map = {}\n",
        "\n",
        "for filename in os.listdir(\"audios\"):\n",
        "  if filename.endswith('.webm'):\n",
        "    resultado = valid_rows[valid_rows[\"Generated_Code\"] == filename]\n",
        "    if len(resultado) > 0:\n",
        "      files_map[filename] = filename\n",
        "\n",
        "# # Mostrar solo los nombres de archivos que fueron validados exitosamente\n",
        "# print(\"Archivos .webm validados encontrados:\\n\")\n",
        "# for filename in files_map:\n",
        "#     print(f\"- {filename}\")\n",
        "\n",
        "print(f\"\\nTotal de archivos validados: {len(files_map)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Audio and Generate HeAR Embeddings\n",
        "\n",
        "This section loads each validated .webm audio file, segments it into overlapping clips, filters out silent ones, and generates embeddings using the HeAR model.\n",
        "\n",
        "Adjustable parameters:\n",
        "- `CLIP_DURATION`: Length (in seconds) of each audio clip. Affects how much context each embedding captures.\n",
        "- `CLIP_OVERLAP_PERCENT`: Percentage of overlap between consecutive clips. Higher values increase redundancy, useful for smoother transitions.\n",
        "- `CLIP_IGNORE_SILENT_CLIPS`: Whether to skip clips that are too quiet (boolean).\n",
        "- `SILENCE_RMS_THRESHOLD_DB`: Silence threshold in decibels. Clips below this average loudness are ignored if CLIP_IGNORE_SILENT_CLIPS is True.\n",
        "- `SHOW_WAVEFORM`, `SHOW_SPECTROGRAM`, `SHOW_PLAYER`, `SHOW_CLIPS`: Toggle options for waveform plots, spectrograms, audio players, and clip previews.\n",
        "\n"
      ],
      "metadata": {
        "id": "eGOmAghOYUJQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KYbz904QXio2",
        "outputId": "ab922a7b-e98f-45ef-9b58-3be54a3e7d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading file: 20220212082327_Mmm%2024-1_lungback.webm from audios/20220212082327_Mmm%2024-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220212082327_Mmm%2024-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20220212082327_Mmm%2024-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 3 from 20220212082327_Mmm%2024-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 4 from 20220212082327_Mmm%2024-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 5 from 20220212082327_Mmm%2024-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 6 from 20220212082327_Mmm%2024-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220212082327_Mmm%2024-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 8 from 20220212082327_Mmm%2024-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 9 from 20220212082327_Mmm%2024-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230419115012_LA%20fe-1_lungfront.webm from audios/20230419115012_LA%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419115012_LA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230419115012_LA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230419115012_LA%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230419115012_LA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230419115012_LA%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230419115012_LA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20230419115012_LA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20230419115012_LA%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20230419115012_LA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20230419115012_LA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125112846_DAKP%20fe_vocal.webm from audios/20220125112846_DAKP%20fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220125112846_DAKP%20fe_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220125112846_DAKP%20fe_vocal.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220125112846_DAKP%20fe_vocal.webm [loudness: -8 dB]\n",
            "  Clip 4 from 20220125112846_DAKP%20fe_vocal.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212070508_Jmt%2017-1_lungfront.webm from audios/20220212070508_Jmt%2017-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 13 2s clips\n",
            "  Clip 1 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 2 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 3 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 4 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 5 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 6 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -42 dB]\n",
            "  Clip 7 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 8 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -42 dB]\n",
            "  Clip 9 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 10 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 11 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 12 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 13 from 20220212070508_Jmt%2017-1_lungfront.webm [loudness: -48 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303082932_ACH%20fe%203-1_vocal.webm from audios/20220303082932_ACH%20fe%203-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220303082932_ACH%20fe%203-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220303082932_ACH%20fe%203-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220303082932_ACH%20fe%203-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220303082932_ACH%20fe%203-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127153448_RAJL%20es_vocal.webm from audios/20220127153448_RAJL%20es_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220127153448_RAJL%20es_vocal.webm [loudness: -50 dB]\n",
            "  Clip 2 from 20220127153448_RAJL%20es_vocal.webm [loudness: -42 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220111120259_RARN_lungback.webm from audios/20220111120259_RARN_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220111120259_RARN_lungback.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20220111120259_RARN_lungback.webm [loudness: -82 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -82 dB]\n",
            "  Clip 3 from 20220111120259_RARN_lungback.webm [loudness: -80 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 4 from 20220111120259_RARN_lungback.webm [loudness: -86 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 5 from 20220111120259_RARN_lungback.webm [loudness: -78 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -78 dB]\n",
            "  Clip 6 from 20220111120259_RARN_lungback.webm [loudness: -78 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -78 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220503163043_Jonathan%202_vocal.webm from audios/20220503163043_Jonathan%202_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220503163043_Jonathan%202_vocal.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220503163043_Jonathan%202_vocal.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220503163043_Jonathan%202_vocal.webm [loudness: -29 dB]\n",
            "  Clip 4 from 20220503163043_Jonathan%202_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126113139_BMY%20es_vocal.webm from audios/20220126113139_BMY%20es_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220126113139_BMY%20es_vocal.webm [loudness: -49 dB]\n",
            "  Clip 2 from 20220126113139_BMY%20es_vocal.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220126113139_BMY%20es_vocal.webm [loudness: -39 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709054715_CNE%20fe-1_lungfront.webm from audios/20220709054715_CNE%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709054715_CNE%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220709054715_CNE%20fe-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 3 from 20220709054715_CNE%20fe-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220709054715_CNE%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220709054715_CNE%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220709054715_CNE%20fe-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 7 from 20220709054715_CNE%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220709054715_CNE%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20220709054715_CNE%20fe-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120153840_GCNF_lungfront.webm from audios/20220120153840_GCNF_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220120153840_GCNF_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220120153840_GCNF_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220120153840_GCNF_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220120153840_GCNF_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220120153840_GCNF_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220120153840_GCNF_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219084905_MGCH%2030-1_vocal.webm from audios/20220219084905_MGCH%2030-1_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220219084905_MGCH%2030-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220219084905_MGCH%2030-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420094226_GCH%20fe-1_lungback.webm from audios/20230420094226_GCH%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230420094226_GCH%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230420094226_GCH%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230420094226_GCH%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20230420094226_GCH%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20230420094226_GCH%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20230420094226_GCH%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230420094226_GCH%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230420094226_GCH%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230420094226_GCH%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 10 from 20230420094226_GCH%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220121165452_STDCP_vocal.webm from audios/20220121165452_STDCP_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220121165452_STDCP_vocal.webm [loudness: -45 dB]\n",
            "  Clip 2 from 20220121165452_STDCP_vocal.webm [loudness: -39 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220111120259_RARN_lungfront.webm from audios/20220111120259_RARN_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220111120259_RARN_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220111120259_RARN_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 3 from 20220111120259_RARN_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 4 from 20220111120259_RARN_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 5 from 20220111120259_RARN_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 6 from 20220111120259_RARN_lungfront.webm [loudness: -76 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 7 from 20220111120259_RARN_lungfront.webm [loudness: -82 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -82 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302092223_CCP%20fe%202-1_vocal.webm from audios/20220302092223_CCP%20fe%202-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302092223_CCP%20fe%202-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220302092223_CCP%20fe%202-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220302092223_CCP%20fe%202-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220302092223_CCP%20fe%202-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128110857_MCFF%20FE_lungback.webm from audios/20220128110857_MCFF%20FE_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128110857_MCFF%20FE_lungback.webm [loudness: -50 dB]\n",
            "  Clip 2 from 20220128110857_MCFF%20FE_lungback.webm [loudness: -50 dB]\n",
            "  Clip 3 from 20220128110857_MCFF%20FE_lungback.webm [loudness: -50 dB]\n",
            "  Clip 4 from 20220128110857_MCFF%20FE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220128110857_MCFF%20FE_lungback.webm [loudness: -63 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212063005_Ach%2014-2_lungfront.webm from audios/20220212063005_Ach%2014-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 2 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 3 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -34 dB]\n",
            "  Clip 4 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 5 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 6 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 7 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 8 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 9 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -38 dB]\n",
            "  Clip 10 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 11 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -40 dB]\n",
            "  Clip 12 from 20220212063005_Ach%2014-2_lungfront.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122153938_MSVC%20es_lungfront.webm from audios/20220122153938_MSVC%20es_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122153938_MSVC%20es_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220122153938_MSVC%20es_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220122153938_MSVC%20es_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220122153938_MSVC%20es_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220122153938_MSVC%20es_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418114816_TE%20fe-1_lungfront.webm from audios/20230418114816_TE%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230418114816_TE%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230418114816_TE%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20230418114816_TE%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20230418114816_TE%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20230418114816_TE%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20230418114816_TE%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20230418114816_TE%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20230418114816_TE%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20230418114816_TE%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230418114816_TE%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20221223095759_Fe-2%20GB_lungfront.webm from audios/20221223095759_Fe-2%20GB_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221223095759_Fe-2%20GB_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20221223095759_Fe-2%20GB_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20221223095759_Fe-2%20GB_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20221223095759_Fe-2%20GB_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20221223095759_Fe-2%20GB_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20221223095759_Fe-2%20GB_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20221223095759_Fe-2%20GB_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20221223095759_Fe-2%20GB_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20221223095759_Fe-2%20GB_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303091025_JAR%20fe%203-1_lungfront.webm from audios/20220303091025_JAR%20fe%203-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220303091025_JAR%20fe%203-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220303091025_JAR%20fe%203-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220303091025_JAR%20fe%203-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 4 from 20220303091025_JAR%20fe%203-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220303091025_JAR%20fe%203-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220303091025_JAR%20fe%203-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220303091025_JAR%20fe%203-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220303091025_JAR%20fe%203-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516145612_Leco1-16-5_lungback.webm from audios/20220516145612_Leco1-16-5_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220516145612_Leco1-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220516145612_Leco1-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220516145612_Leco1-16-5_lungback.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220516145612_Leco1-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220516145612_Leco1-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220516145612_Leco1-16-5_lungback.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220516145612_Leco1-16-5_lungback.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220516145612_Leco1-16-5_lungback.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20220516145612_Leco1-16-5_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119161535_SNPC_lungfront.webm from audios/20220119161535_SNPC_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220119161535_SNPC_lungfront.webm [loudness: -97 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -97 dB]\n",
            "  Clip 2 from 20220119161535_SNPC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220119161535_SNPC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220119161535_SNPC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220119161535_SNPC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220506051857_Abemn%206-5-22_lungfront.webm from audios/20220506051857_Abemn%206-5-22_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220506051857_Abemn%206-5-22_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220506051857_Abemn%206-5-22_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220506051857_Abemn%206-5-22_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220506051857_Abemn%206-5-22_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220506051857_Abemn%206-5-22_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20220506051857_Abemn%206-5-22_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220506051857_Abemn%206-5-22_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220506051857_Abemn%206-5-22_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220506051857_Abemn%206-5-22_lungfront.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212071122_Tvs%2018-2_lungfront.webm from audios/20220212071122_Tvs%2018-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220212071122_Tvs%2018-2_lungfront.webm [loudness: -38 dB]\n",
            "  Clip 2 from 20220212071122_Tvs%2018-2_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 3 from 20220212071122_Tvs%2018-2_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 4 from 20220212071122_Tvs%2018-2_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 5 from 20220212071122_Tvs%2018-2_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 6 from 20220212071122_Tvs%2018-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 7 from 20220212071122_Tvs%2018-2_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 8 from 20220212071122_Tvs%2018-2_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 9 from 20220212071122_Tvs%2018-2_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 10 from 20220212071122_Tvs%2018-2_lungfront.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128124525_SCSHR%20fE_vocal.webm from audios/20220128124525_SCSHR%20fE_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220128124525_SCSHR%20fE_vocal.webm [loudness: -49 dB]\n",
            "  Clip 2 from 20220128124525_SCSHR%20fE_vocal.webm [loudness: -47 dB]\n",
            "  Clip 3 from 20220128124525_SCSHR%20fE_vocal.webm [loudness: -47 dB]\n",
            "  Clip 4 from 20220128124525_SCSHR%20fE_vocal.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20221118094140_Fe-1%20JG_lungback.webm from audios/20221118094140_Fe-1%20JG_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221118094140_Fe-1%20JG_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20221118094140_Fe-1%20JG_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20221118094140_Fe-1%20JG_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20221118094140_Fe-1%20JG_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20221118094140_Fe-1%20JG_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20221118094140_Fe-1%20JG_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20221118094140_Fe-1%20JG_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20221118094140_Fe-1%20JG_lungback.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20221118094140_Fe-1%20JG_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215080924_MME%2028-1_lungback.webm from audios/20220215080924_MME%2028-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220215080924_MME%2028-1_lungback.webm [loudness: -52 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 2 from 20220215080924_MME%2028-1_lungback.webm [loudness: -54 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 3 from 20220215080924_MME%2028-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 4 from 20220215080924_MME%2028-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 5 from 20220215080924_MME%2028-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 6 from 20220215080924_MME%2028-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 7 from 20220215080924_MME%2028-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220215080924_MME%2028-1_lungback.webm [loudness: -41 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516150924_Mfyc1-16-5_lungback.webm from audios/20220516150924_Mfyc1-16-5_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516150924_Mfyc1-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220516150924_Mfyc1-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220516150924_Mfyc1-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220516150924_Mfyc1-16-5_lungback.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220516150924_Mfyc1-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220516150924_Mfyc1-16-5_lungback.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20220516150924_Mfyc1-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127103801_CHLA%20es_vocal.webm from audios/20220127103801_CHLA%20es_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220127103801_CHLA%20es_vocal.webm [loudness: -44 dB]\n",
            "  Clip 2 from 20220127103801_CHLA%20es_vocal.webm [loudness: -49 dB]\n",
            "  Clip 3 from 20220127103801_CHLA%20es_vocal.webm [loudness: -41 dB]\n",
            "  Clip 4 from 20220127103801_CHLA%20es_vocal.webm [loudness: -46 dB]\n",
            "  Clip 5 from 20220127103801_CHLA%20es_vocal.webm [loudness: -47 dB]\n",
            "  Clip 6 from 20220127103801_CHLA%20es_vocal.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516145612_Leco1-16-5_vocal.webm from audios/20220516145612_Leco1-16-5_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220516145612_Leco1-16-5_vocal.webm [loudness: -71 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 2 from 20220516145612_Leco1-16-5_vocal.webm [loudness: -76 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 3 from 20220516145612_Leco1-16-5_vocal.webm [loudness: -75 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 4 from 20220516145612_Leco1-16-5_vocal.webm [loudness: -70 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 5 from 20220516145612_Leco1-16-5_vocal.webm [loudness: -69 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -69 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220127113235_NRJJ%20Fe_lungfront.webm from audios/20220127113235_NRJJ%20Fe_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220127113235_NRJJ%20Fe_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220127113235_NRJJ%20Fe_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220127113235_NRJJ%20Fe_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220127113235_NRJJ%20Fe_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220127113235_NRJJ%20Fe_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220127113235_NRJJ%20Fe_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20220127113235_NRJJ%20Fe_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303081659_RRA%20fe%203-1_vocal.webm from audios/20220303081659_RRA%20fe%203-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220303081659_RRA%20fe%203-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220303081659_RRA%20fe%203-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220303081659_RRA%20fe%203-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220303081659_RRA%20fe%203-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220303081659_RRA%20fe%203-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115122413_RRB_lungback.webm from audios/20220115122413_RRB_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115122413_RRB_lungback.webm [loudness: -61 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 2 from 20220115122413_RRB_lungback.webm [loudness: -71 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 3 from 20220115122413_RRB_lungback.webm [loudness: -104 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -104 dB]\n",
            "  Clip 4 from 20220115122413_RRB_lungback.webm [loudness: -49 dB]\n",
            "  Clip 5 from 20220115122413_RRB_lungback.webm [loudness: -46 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212065052_ATC%2017-1_lungfront.webm from audios/20220212065052_ATC%2017-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 14 2s clips\n",
            "  Clip 1 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 2 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 3 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 4 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 5 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 6 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 7 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 8 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 9 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 10 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 11 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 12 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 13 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 13 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 14 from 20220212065052_ATC%2017-1_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 14 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220224135946_ARD%2033-2_lungfront.webm from audios/20220224135946_ARD%2033-2_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220224135946_ARD%2033-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220224135946_ARD%2033-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220224135946_ARD%2033-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220224135946_ARD%2033-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220224135946_ARD%2033-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220224135946_ARD%2033-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220224135946_ARD%2033-2_lungfront.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319095643_MAR%20fe%2019-1_vocal.webm from audios/20220319095643_MAR%20fe%2019-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220319095643_MAR%20fe%2019-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220319095643_MAR%20fe%2019-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220319095643_MAR%20fe%2019-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220319095643_MAR%20fe%2019-1_vocal.webm [loudness: -41 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319073711_PRC%20fe%2019-1_lungback.webm from audios/20220319073711_PRC%20fe%2019-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319073711_PRC%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220319073711_PRC%20fe%2019-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220319073711_PRC%20fe%2019-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220319073711_PRC%20fe%2019-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220319073711_PRC%20fe%2019-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220319073711_PRC%20fe%2019-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220319073711_PRC%20fe%2019-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220319073711_PRC%20fe%2019-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220319073711_PRC%20fe%2019-1_lungback.webm [loudness: -31 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124102435_ARJA%20es_lungfront.webm from audios/20220124102435_ARJA%20es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124102435_ARJA%20es_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20220124102435_ARJA%20es_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 3 from 20220124102435_ARJA%20es_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 4 from 20220124102435_ARJA%20es_lungfront.webm [loudness: -80 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 5 from 20220124102435_ARJA%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20211209064137_JMT-P_vocal.webm from audios/20211209064137_JMT-P_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20211209064137_JMT-P_vocal.webm [loudness: -30 dB]\n",
            "  Clip 2 from 20211209064137_JMT-P_vocal.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20211209064137_JMT-P_vocal.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20211209064137_JMT-P_vocal.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212063501_Acb%2015-1_lungfront.webm from audios/20220212063501_Acb%2015-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 13 2s clips\n",
            "  Clip 1 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 2 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 3 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 4 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 5 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 6 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 8 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 9 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -71 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 10 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 11 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -38 dB]\n",
            "  Clip 12 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 13 from 20220212063501_Acb%2015-1_lungfront.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424134952_LY%20fe-1_lungfront.webm from audios/20230424134952_LY%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230424134952_LY%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230424134952_LY%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20230424134952_LY%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20230424134952_LY%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20230424134952_LY%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20230424134952_LY%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20230424134952_LY%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230424134952_LY%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 9 from 20230424134952_LY%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122140243_MRGM%20fe_lungback.webm from audios/20220122140243_MRGM%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122140243_MRGM%20fe_lungback.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220122140243_MRGM%20fe_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220122140243_MRGM%20fe_lungback.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220122140243_MRGM%20fe_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220122140243_MRGM%20fe_lungback.webm [loudness: -10 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107152508_RCET_lungback.webm from audios/20220107152508_RCET_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220107152508_RCET_lungback.webm [loudness: -70 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 2 from 20220107152508_RCET_lungback.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220107152508_RCET_lungback.webm [loudness: -64 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 4 from 20220107152508_RCET_lungback.webm [loudness: -64 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 5 from 20220107152508_RCET_lungback.webm [loudness: -66 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 6 from 20220107152508_RCET_lungback.webm [loudness: -65 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -65 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516151109_Mfyc2-16-5_vocal.webm from audios/20220516151109_Mfyc2-16-5_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220516151109_Mfyc2-16-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220516151109_Mfyc2-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220516151109_Mfyc2-16-5_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128124349_SCSHR%20Fe_lungback.webm from audios/20220128124349_SCSHR%20Fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128124349_SCSHR%20Fe_lungback.webm [loudness: -90 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -90 dB]\n",
            "  Clip 2 from 20220128124349_SCSHR%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220128124349_SCSHR%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220128124349_SCSHR%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220128124349_SCSHR%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20221118094140_Fe-1%20JG_vocal.webm from audios/20221118094140_Fe-1%20JG_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20221118094140_Fe-1%20JG_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20221118094140_Fe-1%20JG_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20221118094140_Fe-1%20JG_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20221118094140_Fe-1%20JG_vocal.webm [loudness: -42 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220715101331_RFC%20fe-3_lungback.webm from audios/20220715101331_RFC%20fe-3_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220715101331_RFC%20fe-3_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220715101331_RFC%20fe-3_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220715101331_RFC%20fe-3_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220715101331_RFC%20fe-3_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220715101331_RFC%20fe-3_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220715101331_RFC%20fe-3_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220715101331_RFC%20fe-3_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220715101331_RFC%20fe-3_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220715101331_RFC%20fe-3_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064407_JMT-P3_lungback.webm from audios/20211209064407_JMT-P3_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211209064407_JMT-P3_lungback.webm [loudness: -36 dB]\n",
            "  Clip 2 from 20211209064407_JMT-P3_lungback.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20211209064407_JMT-P3_lungback.webm [loudness: -35 dB]\n",
            "  Clip 4 from 20211209064407_JMT-P3_lungback.webm [loudness: -40 dB]\n",
            "  Clip 5 from 20211209064407_JMT-P3_lungback.webm [loudness: -43 dB]\n",
            "  Clip 6 from 20211209064407_JMT-P3_lungback.webm [loudness: -28 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604055424_JFC%20fe-1_lungfront.webm from audios/20220604055424_JFC%20fe-1_lungfront.webm\n",
            "Error loading 20220604055424_JFC%20fe-1_lungfront.webm: . Removing from files_map.\n",
            "\n",
            "Loading file: 20230418102811_LR%20fe-1_lungfront.webm from audios/20230418102811_LR%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230418102811_LR%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20230418102811_LR%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230418102811_LR%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230418102811_LR%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20230418102811_LR%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20230418102811_LR%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20230418102811_LR%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20230418102811_LR%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20230418102811_LR%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 10 from 20230418102811_LR%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304082514_SAC%20fe%204-1_vocal.webm from audios/20220304082514_SAC%20fe%204-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220304082514_SAC%20fe%204-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220304082514_SAC%20fe%204-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220304082514_SAC%20fe%204-1_vocal.webm [loudness: -60 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 4 from 20220304082514_SAC%20fe%204-1_vocal.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207100112_Fe-1%20WC_vocal.webm from audios/20221207100112_Fe-1%20WC_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221207100112_Fe-1%20WC_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20221207100112_Fe-1%20WC_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20221207100112_Fe-1%20WC_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20221207100112_Fe-1%20WC_vocal.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20221207100112_Fe-1%20WC_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709073837_RCM%20fe-3_lungback.webm from audios/20220709073837_RCM%20fe-3_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709073837_RCM%20fe-3_lungback.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220709073837_RCM%20fe-3_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220709073837_RCM%20fe-3_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220709073837_RCM%20fe-3_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220709073837_RCM%20fe-3_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220709073837_RCM%20fe-3_lungback.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220709073837_RCM%20fe-3_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220709073837_RCM%20fe-3_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220709073837_RCM%20fe-3_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124160502_RALL%20es_lungfront.webm from audios/20220124160502_RALL%20es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124160502_RALL%20es_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220124160502_RALL%20es_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220124160502_RALL%20es_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220124160502_RALL%20es_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220124160502_RALL%20es_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220718073538_RM%20fe-1_vocal.webm from audios/20220718073538_RM%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220718073538_RM%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220718073538_RM%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220718073538_RM%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220718073538_RM%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220718073538_RM%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128110857_MCFF%20FE_lungfront.webm from audios/20220128110857_MCFF%20FE_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128110857_MCFF%20FE_lungfront.webm [loudness: -76 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 2 from 20220128110857_MCFF%20FE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220128110857_MCFF%20FE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220128110857_MCFF%20FE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220128110857_MCFF%20FE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20221223095536_Fe-1%20GB_lungback.webm from audios/20221223095536_Fe-1%20GB_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221223095536_Fe-1%20GB_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20221223095536_Fe-1%20GB_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20221223095536_Fe-1%20GB_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20221223095536_Fe-1%20GB_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20221223095536_Fe-1%20GB_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20221223095536_Fe-1%20GB_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20221223095536_Fe-1%20GB_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20221223095536_Fe-1%20GB_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20221223095536_Fe-1%20GB_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165919_ETA%204-5_lungback.webm from audios/20220504165919_ETA%204-5_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220504165919_ETA%204-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220504165919_ETA%204-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220504165919_ETA%204-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220504165919_ETA%204-5_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220504165919_ETA%204-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424133743_JA%20fe-1_lungback.webm from audios/20230424133743_JA%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 11 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 12 from 20230424133743_JA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (12, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075741_SYV%2027-1_lungback.webm from audios/20220215075741_SYV%2027-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220215075741_SYV%2027-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220215075741_SYV%2027-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220215075741_SYV%2027-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 4 from 20220215075741_SYV%2027-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220215075741_SYV%2027-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220215075741_SYV%2027-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 7 from 20220215075741_SYV%2027-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220215075741_SYV%2027-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 9 from 20220215075741_SYV%2027-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220721062840_ICR%20fe-1_lungfront.webm from audios/20220721062840_ICR%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220721062840_ICR%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220721062840_ICR%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220721062840_ICR%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220721062840_ICR%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220721062840_ICR%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220721062840_ICR%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220721062840_ICR%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 8 from 20220721062840_ICR%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 9 from 20220721062840_ICR%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124151015_JAYG%20es_lungfront.webm from audios/20220124151015_JAYG%20es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124151015_JAYG%20es_lungfront.webm [loudness: -79 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 2 from 20220124151015_JAYG%20es_lungfront.webm [loudness: -120 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -120 dB]\n",
            "  Clip 3 from 20220124151015_JAYG%20es_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220124151015_JAYG%20es_lungfront.webm [loudness: -85 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -85 dB]\n",
            "  Clip 5 from 20220124151015_JAYG%20es_lungfront.webm [loudness: -85 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -85 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220319061032_ECO%20fe%2019-1_vocal.webm from audios/20220319061032_ECO%20fe%2019-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220319061032_ECO%20fe%2019-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220319061032_ECO%20fe%2019-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220319061032_ECO%20fe%2019-1_vocal.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220319061032_ECO%20fe%2019-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220319061032_ECO%20fe%2019-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212072243_Lml%2020-1_lungback.webm from audios/20220212072243_Lml%2020-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -46 dB]\n",
            "  Clip 2 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -48 dB]\n",
            "  Clip 3 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -48 dB]\n",
            "  Clip 5 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -43 dB]\n",
            "  Clip 6 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -67 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 7 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -61 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 8 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -44 dB]\n",
            "  Clip 9 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 10 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 11 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -38 dB]\n",
            "  Clip 12 from 20220212072243_Lml%2020-1_lungback.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127130655_RPY%20Es_lungfront.webm from audios/20220127130655_RPY%20Es_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220127130655_RPY%20Es_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220127130655_RPY%20Es_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220127130655_RPY%20Es_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220127130655_RPY%20Es_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 5 from 20220127130655_RPY%20Es_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220127130655_RPY%20Es_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128104342_AASE%20fe%201_lungfront.webm from audios/20220128104342_AASE%20fe%201_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128104342_AASE%20fe%201_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220128104342_AASE%20fe%201_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220128104342_AASE%20fe%201_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220128104342_AASE%20fe%201_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220128104342_AASE%20fe%201_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303082932_ACH%20fe%203-1_lungback.webm from audios/20220303082932_ACH%20fe%203-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303082932_ACH%20fe%203-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220303082932_ACH%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220303082932_ACH%20fe%203-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220303082932_ACH%20fe%203-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220303082932_ACH%20fe%203-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220303082932_ACH%20fe%203-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220303082932_ACH%20fe%203-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220303082932_ACH%20fe%203-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220303082932_ACH%20fe%203-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063621_JMT-D3_lungfront.webm from audios/20211209063621_JMT-D3_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20211209063621_JMT-D3_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 2 from 20211209063621_JMT-D3_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 3 from 20211209063621_JMT-D3_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 4 from 20211209063621_JMT-D3_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 5 from 20211209063621_JMT-D3_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 6 from 20211209063621_JMT-D3_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 7 from 20211209063621_JMT-D3_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 8 from 20211209063621_JMT-D3_lungfront.webm [loudness: -49 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424140556_GB%20fe-1_lungback.webm from audios/20230424140556_GB%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424140556_GB%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20230424140556_GB%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230424140556_GB%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20230424140556_GB%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20230424140556_GB%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20230424140556_GB%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20230424140556_GB%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20230424140556_GB%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20230424140556_GB%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20230424140556_GB%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20221118053800_Fe-1%20SD_lungback.webm from audios/20221118053800_Fe-1%20SD_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221118053800_Fe-1%20SD_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20221118053800_Fe-1%20SD_lungback.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20221118053800_Fe-1%20SD_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20221118053800_Fe-1%20SD_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20221118053800_Fe-1%20SD_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20221118053800_Fe-1%20SD_lungback.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20221118053800_Fe-1%20SD_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20221118053800_Fe-1%20SD_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20221118053800_Fe-1%20SD_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202103821_Mcp-02-12-D2_lungback.webm from audios/20211202103821_Mcp-02-12-D2_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211202103821_Mcp-02-12-D2_lungback.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20211202103821_Mcp-02-12-D2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20211202103821_Mcp-02-12-D2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20211202103821_Mcp-02-12-D2_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20211202103821_Mcp-02-12-D2_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20211202103821_Mcp-02-12-D2_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708093145_ARB%20fe-4_lungfront.webm from audios/20220708093145_ARB%20fe-4_lungfront.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 4 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 10 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 11 from 20220708093145_ARB%20fe-4_lungfront.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105133843_YH%20sin_lungback.webm from audios/20220105133843_YH%20sin_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220105133843_YH%20sin_lungback.webm [loudness: -81 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -81 dB]\n",
            "  Clip 2 from 20220105133843_YH%20sin_lungback.webm [loudness: -77 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -77 dB]\n",
            "  Clip 3 from 20220105133843_YH%20sin_lungback.webm [loudness: -83 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 4 from 20220105133843_YH%20sin_lungback.webm [loudness: -84 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -84 dB]\n",
            "  Clip 5 from 20220105133843_YH%20sin_lungback.webm [loudness: -83 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 6 from 20220105133843_YH%20sin_lungback.webm [loudness: -83 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 7 from 20220105133843_YH%20sin_lungback.webm [loudness: -83 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 8 from 20220105133843_YH%20sin_lungback.webm [loudness: -81 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -81 dB]\n",
            "  Clip 9 from 20220105133843_YH%20sin_lungback.webm [loudness: -82 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -82 dB]\n",
            "  Clip 10 from 20220105133843_YH%20sin_lungback.webm [loudness: -81 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -81 dB]\n",
            "  Clip 11 from 20220105133843_YH%20sin_lungback.webm [loudness: -82 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -82 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220124102547_ARJA%20fe_lungfront.webm from audios/20220124102547_ARJA%20fe_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220124102547_ARJA%20fe_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 2 from 20220124102547_ARJA%20fe_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 3 from 20220124102547_ARJA%20fe_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 4 from 20220124102547_ARJA%20fe_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 5 from 20220124102547_ARJA%20fe_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 6 from 20220124102547_ARJA%20fe_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105152805_GUF%20con_vocal.webm from audios/20220105152805_GUF%20con_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 13 2s clips\n",
            "  Clip 1 from 20220105152805_GUF%20con_vocal.webm [loudness: -33 dB]\n",
            "  Clip 2 from 20220105152805_GUF%20con_vocal.webm [loudness: -40 dB]\n",
            "  Clip 3 from 20220105152805_GUF%20con_vocal.webm [loudness: -45 dB]\n",
            "  Clip 4 from 20220105152805_GUF%20con_vocal.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220105152805_GUF%20con_vocal.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220105152805_GUF%20con_vocal.webm [loudness: -27 dB]\n",
            "  Clip 7 from 20220105152805_GUF%20con_vocal.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220105152805_GUF%20con_vocal.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220105152805_GUF%20con_vocal.webm [loudness: -25 dB]\n",
            "  Clip 10 from 20220105152805_GUF%20con_vocal.webm [loudness: -39 dB]\n",
            "  Clip 11 from 20220105152805_GUF%20con_vocal.webm [loudness: -25 dB]\n",
            "  Clip 12 from 20220105152805_GUF%20con_vocal.webm [loudness: -22 dB]\n",
            "  Clip 13 from 20220105152805_GUF%20con_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (13, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516152711_Lsma1-16-5_lungfront.webm from audios/20220516152711_Lsma1-16-5_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220516152711_Lsma1-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220516152711_Lsma1-16-5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220516152711_Lsma1-16-5_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220516152711_Lsma1-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220516152711_Lsma1-16-5_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220516152711_Lsma1-16-5_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107144605_VYFS_lungback.webm from audios/20220107144605_VYFS_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220107144605_VYFS_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220107144605_VYFS_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220107144605_VYFS_lungback.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220107144605_VYFS_lungback.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20220107144605_VYFS_lungback.webm [loudness: -29 dB]\n",
            "  Clip 6 from 20220107144605_VYFS_lungback.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220107144605_VYFS_lungback.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124102547_ARJA%20fe_lungback.webm from audios/20220124102547_ARJA%20fe_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124102547_ARJA%20fe_lungback.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20220124102547_ARJA%20fe_lungback.webm [loudness: -48 dB]\n",
            "  Clip 3 from 20220124102547_ARJA%20fe_lungback.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220124102547_ARJA%20fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220124102547_ARJA%20fe_lungback.webm [loudness: -56 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219081530_TRC%2029-2_vocal.webm from audios/20220219081530_TRC%2029-2_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220219081530_TRC%2029-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220219081530_TRC%2029-2_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220219081530_TRC%2029-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119141214_MAAR_lungfront.webm from audios/20220119141214_MAAR_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220119141214_MAAR_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220119141214_MAAR_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220119141214_MAAR_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220119141214_MAAR_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220119141214_MAAR_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220119141214_MAAR_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220715104234_CBP%20fe-2_lungback.webm from audios/20220715104234_CBP%20fe-2_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220715104234_CBP%20fe-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220715104234_CBP%20fe-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220715104234_CBP%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220715104234_CBP%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220715104234_CBP%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220715104234_CBP%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220715104234_CBP%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220715104234_CBP%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220715104234_CBP%20fe-2_lungback.webm [loudness: -29 dB]\n",
            "  Clip 10 from 20220715104234_CBP%20fe-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165035_Aves%204-5_vocal.webm from audios/20220504165035_Aves%204-5_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220504165035_Aves%204-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220504165035_Aves%204-5_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220504165035_Aves%204-5_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220506072041_Vmpr%206_5_22_lungback.webm from audios/20220506072041_Vmpr%206_5_22_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220506072041_Vmpr%206_5_22_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220506072041_Vmpr%206_5_22_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220506072041_Vmpr%206_5_22_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220506072041_Vmpr%206_5_22_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220506072041_Vmpr%206_5_22_lungback.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220506072041_Vmpr%206_5_22_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054333_ACW-D3_lungfront.webm from audios/20211207054333_ACW-D3_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207054333_ACW-D3_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20211207054333_ACW-D3_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20211207054333_ACW-D3_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20211207054333_ACW-D3_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20211207054333_ACW-D3_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20211207054333_ACW-D3_lungfront.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212082523_Lmm24-2_lungback.webm from audios/20220212082523_Lmm24-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220212082523_Lmm24-2_lungback.webm [loudness: -50 dB]\n",
            "  Clip 2 from 20220212082523_Lmm24-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220212082523_Lmm24-2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 4 from 20220212082523_Lmm24-2_lungback.webm [loudness: -48 dB]\n",
            "  Clip 5 from 20220212082523_Lmm24-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220212082523_Lmm24-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 7 from 20220212082523_Lmm24-2_lungback.webm [loudness: -54 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 8 from 20220212082523_Lmm24-2_lungback.webm [loudness: -54 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220804101609_MHC%20fe-3_lungback.webm from audios/20220804101609_MHC%20fe-3_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220804101609_MHC%20fe-3_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220804101609_MHC%20fe-3_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220804101609_MHC%20fe-3_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220804101609_MHC%20fe-3_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220804101609_MHC%20fe-3_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220804101609_MHC%20fe-3_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220804101609_MHC%20fe-3_lungback.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220804101609_MHC%20fe-3_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220804101609_MHC%20fe-3_lungback.webm [loudness: -24 dB]\n",
            "  Clip 10 from 20220804101609_MHC%20fe-3_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708104228_FDV%20fe-2_lungfront.webm from audios/20220708104228_FDV%20fe-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220708104228_FDV%20fe-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220708104228_FDV%20fe-2_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220708104228_FDV%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220708104228_FDV%20fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220708104228_FDV%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220708104228_FDV%20fe-2_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220708104228_FDV%20fe-2_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 8 from 20220708104228_FDV%20fe-2_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220708104228_FDV%20fe-2_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 10 from 20220708104228_FDV%20fe-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709050338_BUM%20fe-2_lungfront.webm from audios/20220709050338_BUM%20fe-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709050338_BUM%20fe-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220709050338_BUM%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220709050338_BUM%20fe-2_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220709050338_BUM%20fe-2_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20220709050338_BUM%20fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220709050338_BUM%20fe-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220709050338_BUM%20fe-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220709050338_BUM%20fe-2_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20220709050338_BUM%20fe-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128111148_MTSK%20Fe_vocal.webm from audios/20220128111148_MTSK%20Fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220128111148_MTSK%20Fe_vocal.webm [loudness: -41 dB]\n",
            "  Clip 2 from 20220128111148_MTSK%20Fe_vocal.webm [loudness: -37 dB]\n",
            "  Clip 3 from 20220128111148_MTSK%20Fe_vocal.webm [loudness: -37 dB]\n",
            "  Clip 4 from 20220128111148_MTSK%20Fe_vocal.webm [loudness: -39 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220519070721_KRRS%2019-05-22_lungfront.webm from audios/20220519070721_KRRS%2019-05-22_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220519070721_KRRS%2019-05-22_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220519070721_KRRS%2019-05-22_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220519070721_KRRS%2019-05-22_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220519070721_KRRS%2019-05-22_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220519070721_KRRS%2019-05-22_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220519070721_KRRS%2019-05-22_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220519070721_KRRS%2019-05-22_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215074418_Zmg%2025-1_lungfront.webm from audios/20220215074418_Zmg%2025-1_lungfront.webm\n",
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 4 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 5 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 7 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 8 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 9 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 10 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 11 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 12 from 20220215074418_Zmg%2025-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -55 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220708103953_FDV%20fe-1_lungfront.webm from audios/20220708103953_FDV%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220708103953_FDV%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220708103953_FDV%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220708103953_FDV%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220708103953_FDV%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220708103953_FDV%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220708103953_FDV%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220708103953_FDV%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220708103953_FDV%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220708103953_FDV%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420093811_GY%20fe-1_lungback.webm from audios/20230420093811_GY%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230420093811_GY%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20230420093811_GY%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20230420093811_GY%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230420093811_GY%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20230420093811_GY%20fe-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20230420093811_GY%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20230420093811_GY%20fe-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 8 from 20230420093811_GY%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20230420093811_GY%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 10 from 20230420093811_GY%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516153445_Jasr1-1605_lungfront.webm from audios/20220516153445_Jasr1-1605_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220516153445_Jasr1-1605_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220516153445_Jasr1-1605_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220516153445_Jasr1-1605_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220516153445_Jasr1-1605_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220516153445_Jasr1-1605_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220516153445_Jasr1-1605_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212070508_Jmt%2017-1_lungback.webm from audios/20220212070508_Jmt%2017-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 13 2s clips\n",
            "  Clip 1 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -45 dB]\n",
            "  Clip 2 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -51 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 4 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -45 dB]\n",
            "  Clip 5 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -52 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 6 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -50 dB]\n",
            "  Clip 7 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -47 dB]\n",
            "  Clip 8 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -47 dB]\n",
            "  Clip 9 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -54 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 10 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -46 dB]\n",
            "  Clip 11 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -49 dB]\n",
            "  Clip 12 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -48 dB]\n",
            "  Clip 13 from 20220212070508_Jmt%2017-1_lungback.webm [loudness: -54 dB]\n",
            "  Clip 13 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105133643_YE_lungback.webm from audios/20220105133643_YE_lungback.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220105133643_YE_lungback.webm [loudness: -78 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -78 dB]\n",
            "  Clip 2 from 20220105133643_YE_lungback.webm [loudness: -62 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 3 from 20220105133643_YE_lungback.webm [loudness: -75 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 4 from 20220105133643_YE_lungback.webm [loudness: -83 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 5 from 20220105133643_YE_lungback.webm [loudness: -76 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 6 from 20220105133643_YE_lungback.webm [loudness: -76 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 7 from 20220105133643_YE_lungback.webm [loudness: -60 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 8 from 20220105133643_YE_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220105133643_YE_lungback.webm [loudness: -40 dB]\n",
            "  Clip 10 from 20220105133643_YE_lungback.webm [loudness: -82 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -82 dB]\n",
            "  Clip 11 from 20220105133643_YE_lungback.webm [loudness: -77 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -77 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302091650_EAR%20fe%202-1_vocal.webm from audios/20220302091650_EAR%20fe%202-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302091650_EAR%20fe%202-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220302091650_EAR%20fe%202-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220302091650_EAR%20fe%202-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220302091650_EAR%20fe%202-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123121132_Fe-1%20RC_lungfront.webm from audios/20221123121132_Fe-1%20RC_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123121132_Fe-1%20RC_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20221123121132_Fe-1%20RC_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20221123121132_Fe-1%20RC_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20221123121132_Fe-1%20RC_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 5 from 20221123121132_Fe-1%20RC_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20221123121132_Fe-1%20RC_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20221123121132_Fe-1%20RC_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20221123121132_Fe-1%20RC_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20221123121132_Fe-1%20RC_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211216131859_JSR-scp_lungback.webm from audios/20211216131859_JSR-scp_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211216131859_JSR-scp_lungback.webm [loudness: -47 dB]\n",
            "  Clip 2 from 20211216131859_JSR-scp_lungback.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20211216131859_JSR-scp_lungback.webm [loudness: -60 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 4 from 20211216131859_JSR-scp_lungback.webm [loudness: -52 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 5 from 20211216131859_JSR-scp_lungback.webm [loudness: -53 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 6 from 20211216131859_JSR-scp_lungback.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424140045_GA%20fe-1_vocal.webm from audios/20230424140045_GA%20fe-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20230424140045_GA%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20230424140045_GA%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20230424140045_GA%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419094918_MF%20fe-1_lungback.webm from audios/20230419094918_MF%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419094918_MF%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20230419094918_MF%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230419094918_MF%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230419094918_MF%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20230419094918_MF%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230419094918_MF%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20230419094918_MF%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20230419094918_MF%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230419094918_MF%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230419094918_MF%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075741_SYV%2027-1_lungfront.webm from audios/20220215075741_SYV%2027-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220215075741_SYV%2027-1_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 2 from 20220215075741_SYV%2027-1_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220215075741_SYV%2027-1_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 4 from 20220215075741_SYV%2027-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220215075741_SYV%2027-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 6 from 20220215075741_SYV%2027-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220215075741_SYV%2027-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 8 from 20220215075741_SYV%2027-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 9 from 20220215075741_SYV%2027-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516151109_Mfyc2-16-5_lungback.webm from audios/20220516151109_Mfyc2-16-5_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220516151109_Mfyc2-16-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220516151109_Mfyc2-16-5_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220516151109_Mfyc2-16-5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220516151109_Mfyc2-16-5_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220516151109_Mfyc2-16-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220516151109_Mfyc2-16-5_lungback.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128135337_PCSN%20fE_lungfront.webm from audios/20220128135337_PCSN%20fE_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128135337_PCSN%20fE_lungfront.webm [loudness: -99 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -99 dB]\n",
            "  Clip 2 from 20220128135337_PCSN%20fE_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 3 from 20220128135337_PCSN%20fE_lungfront.webm [loudness: -83 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 4 from 20220128135337_PCSN%20fE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220128135337_PCSN%20fE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220122140243_MRGM%20fe_lungfront.webm from audios/20220122140243_MRGM%20fe_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220122140243_MRGM%20fe_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220122140243_MRGM%20fe_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220122140243_MRGM%20fe_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220122140243_MRGM%20fe_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220122140243_MRGM%20fe_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220122140243_MRGM%20fe_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220122140243_MRGM%20fe_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114142427_AJTN_vocal.webm from audios/20220114142427_AJTN_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220114142427_AJTN_vocal.webm [loudness: -37 dB]\n",
            "  Clip 2 from 20220114142427_AJTN_vocal.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20220114142427_AJTN_vocal.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202104033_Mcp-02-12-D3_lungback.webm from audios/20211202104033_Mcp-02-12-D3_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211202104033_Mcp-02-12-D3_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20211202104033_Mcp-02-12-D3_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20211202104033_Mcp-02-12-D3_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20211202104033_Mcp-02-12-D3_lungback.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20211202104033_Mcp-02-12-D3_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20211202104033_Mcp-02-12-D3_lungback.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219083953_SYV%2030-1_lungback.webm from audios/20220219083953_SYV%2030-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220219083953_SYV%2030-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220219083953_SYV%2030-1_lungback.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220219083953_SYV%2030-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220219083953_SYV%2030-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220219083953_SYV%2030-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220219083953_SYV%2030-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220219083953_SYV%2030-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220219083953_SYV%2030-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118162724_SAA_lungfront.webm from audios/20220118162724_SAA_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118162724_SAA_lungfront.webm [loudness: -96 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -96 dB]\n",
            "  Clip 2 from 20220118162724_SAA_lungfront.webm [loudness: -94 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -94 dB]\n",
            "  Clip 3 from 20220118162724_SAA_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 4 from 20220118162724_SAA_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 5 from 20220118162724_SAA_lungfront.webm [loudness: -88 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -88 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220215075741_SYV%2027-1_vocal.webm from audios/20220215075741_SYV%2027-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220215075741_SYV%2027-1_vocal.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220215075741_SYV%2027-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220215075741_SYV%2027-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20211216131725_NSR-CD_vocal.webm from audios/20211216131725_NSR-CD_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20211216131725_NSR-CD_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20211216131725_NSR-CD_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20211216131725_NSR-CD_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20211216131725_NSR-CD_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202103821_Mcp-02-12-D2_lungfront.webm from audios/20211202103821_Mcp-02-12-D2_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211202103821_Mcp-02-12-D2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20211202103821_Mcp-02-12-D2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20211202103821_Mcp-02-12-D2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20211202103821_Mcp-02-12-D2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20211202103821_Mcp-02-12-D2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20211202103821_Mcp-02-12-D2_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303082548_AAC%20fe%203-1_lungfront.webm from audios/20220303082548_AAC%20fe%203-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303082548_AAC%20fe%203-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220303082548_AAC%20fe%203-1_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 3 from 20220303082548_AAC%20fe%203-1_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 4 from 20220303082548_AAC%20fe%203-1_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 5 from 20220303082548_AAC%20fe%203-1_lungfront.webm [loudness: -34 dB]\n",
            "  Clip 6 from 20220303082548_AAC%20fe%203-1_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 7 from 20220303082548_AAC%20fe%203-1_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 8 from 20220303082548_AAC%20fe%203-1_lungfront.webm [loudness: -38 dB]\n",
            "  Clip 9 from 20220303082548_AAC%20fe%203-1_lungfront.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304062221_DSC%20fe%204-1_lungfront.webm from audios/20220304062221_DSC%20fe%204-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304062221_DSC%20fe%204-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220304062221_DSC%20fe%204-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220304062221_DSC%20fe%204-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220304062221_DSC%20fe%204-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220304062221_DSC%20fe%204-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220304062221_DSC%20fe%204-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 7 from 20220304062221_DSC%20fe%204-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220304062221_DSC%20fe%204-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424140045_GA%20fe-1_lungfront.webm from audios/20230424140045_GA%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424140045_GA%20fe-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 2 from 20230424140045_GA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20230424140045_GA%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230424140045_GA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20230424140045_GA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20230424140045_GA%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20230424140045_GA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20230424140045_GA%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20230424140045_GA%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20230424140045_GA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212065239_ATC%2017-2_vocal.webm from audios/20220212065239_ATC%2017-2_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212065239_ATC%2017-2_vocal.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220212065239_ATC%2017-2_vocal.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220212065239_ATC%2017-2_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126113139_BMY%20es_lungback.webm from audios/20220126113139_BMY%20es_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220126113139_BMY%20es_lungback.webm [loudness: -53 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 2 from 20220126113139_BMY%20es_lungback.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220126113139_BMY%20es_lungback.webm [loudness: -53 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 4 from 20220126113139_BMY%20es_lungback.webm [loudness: -46 dB]\n",
            "  Clip 5 from 20220126113139_BMY%20es_lungback.webm [loudness: -60 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 6 from 20220126113139_BMY%20es_lungback.webm [loudness: -56 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516145759_Leco2-16-5_lungfront.webm from audios/20220516145759_Leco2-16-5_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516145759_Leco2-16-5_lungfront.webm [loudness: -71 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 2 from 20220516145759_Leco2-16-5_lungfront.webm [loudness: -76 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 3 from 20220516145759_Leco2-16-5_lungfront.webm [loudness: -76 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 4 from 20220516145759_Leco2-16-5_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 5 from 20220516145759_Leco2-16-5_lungfront.webm [loudness: -74 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 6 from 20220516145759_Leco2-16-5_lungfront.webm [loudness: -74 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 7 from 20220516145759_Leco2-16-5_lungfront.webm [loudness: -74 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 8 from 20220516145759_Leco2-16-5_lungfront.webm [loudness: -74 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -74 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20211207054534_ACD-D4_lungback.webm from audios/20211207054534_ACD-D4_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20211207054534_ACD-D4_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20211207054534_ACD-D4_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20211207054534_ACD-D4_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20211207054534_ACD-D4_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20211207054534_ACD-D4_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20211207054534_ACD-D4_lungback.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20211207054534_ACD-D4_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20211207054534_ACD-D4_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220211114254_OCF%20fe%2012-1_lungfront.webm from audios/20220211114254_OCF%20fe%2012-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -38 dB]\n",
            "  Clip 2 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 3 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 4 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 5 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 7 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 10 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 11 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 12 from 20220211114254_OCF%20fe%2012-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (12, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127153613_RAJL%20fe_vocal.webm from audios/20220127153613_RAJL%20fe_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220127153613_RAJL%20fe_vocal.webm [loudness: -42 dB]\n",
            "  Clip 2 from 20220127153613_RAJL%20fe_vocal.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220127153613_RAJL%20fe_vocal.webm [loudness: -36 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108164635_OQFR_lungfront.webm from audios/20220108164635_OQFR_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220108164635_OQFR_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 2 from 20220108164635_OQFR_lungfront.webm [loudness: -107 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -107 dB]\n",
            "  Clip 3 from 20220108164635_OQFR_lungfront.webm [loudness: -83 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 4 from 20220108164635_OQFR_lungfront.webm [loudness: -83 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 5 from 20220108164635_OQFR_lungfront.webm [loudness: -102 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -102 dB]\n",
            "  Clip 6 from 20220108164635_OQFR_lungfront.webm [loudness: -97 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -97 dB]\n",
            "  Clip 7 from 20220108164635_OQFR_lungfront.webm [loudness: -98 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -98 dB]\n",
            "  Clip 8 from 20220108164635_OQFR_lungfront.webm [loudness: -98 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -98 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516110622_Ahj-16-5_vocal.webm from audios/20220516110622_Ahj-16-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516110622_Ahj-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220516110622_Ahj-16-5_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220516110622_Ahj-16-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220516110622_Ahj-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305054143_MST%20fe%205-1_lungfront.webm from audios/20220305054143_MST%20fe%205-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305054143_MST%20fe%205-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220305054143_MST%20fe%205-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220305054143_MST%20fe%205-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220305054143_MST%20fe%205-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220305054143_MST%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220305054143_MST%20fe%205-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220305054143_MST%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220305054143_MST%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220305054143_MST%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516153654_Jasr2-16-05_lungfront.webm from audios/20220516153654_Jasr2-16-05_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516153654_Jasr2-16-05_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220516153654_Jasr2-16-05_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220516153654_Jasr2-16-05_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220516153654_Jasr2-16-05_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220516153654_Jasr2-16-05_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220516153654_Jasr2-16-05_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20220516153654_Jasr2-16-05_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419124122_LG%20fe-1_vocal.webm from audios/20230419124122_LG%20fe-1_vocal.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419124122_LG%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20230419124122_LG%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230419124122_LG%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230419124122_LG%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20230419124122_LG%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20230419124122_LG%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20230419124122_LG%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230419124122_LG%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20230419124122_LG%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 10 from 20230419124122_LG%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115122413_RRB_lungfront.webm from audios/20220115122413_RRB_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115122413_RRB_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 2 from 20220115122413_RRB_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 3 from 20220115122413_RRB_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 4 from 20220115122413_RRB_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 5 from 20220115122413_RRB_lungfront.webm [loudness: -44 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105152805_GUF%20con_lungfront.webm from audios/20220105152805_GUF%20con_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220105152805_GUF%20con_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220105152805_GUF%20con_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20220105152805_GUF%20con_lungfront.webm [loudness: -81 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -81 dB]\n",
            "  Clip 4 from 20220105152805_GUF%20con_lungfront.webm [loudness: -76 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 5 from 20220105152805_GUF%20con_lungfront.webm [loudness: -80 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 6 from 20220105152805_GUF%20con_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 7 from 20220105152805_GUF%20con_lungfront.webm [loudness: -71 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 8 from 20220105152805_GUF%20con_lungfront.webm [loudness: -72 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212071632_Gbc%2019-1_vocal.webm from audios/20220212071632_Gbc%2019-1_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220212071632_Gbc%2019-1_vocal.webm [loudness: -27 dB]\n",
            "  Clip 2 from 20220212071632_Gbc%2019-1_vocal.webm [loudness: -30 dB]\n",
            "  Clip 3 from 20220212071632_Gbc%2019-1_vocal.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220212071632_Gbc%2019-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220212071632_Gbc%2019-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220212071632_Gbc%2019-1_vocal.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424111937_JH%20fe-1_lungback.webm from audios/20230424111937_JH%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424111937_JH%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230424111937_JH%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20230424111937_JH%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20230424111937_JH%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20230424111937_JH%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20230424111937_JH%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20230424111937_JH%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20230424111937_JH%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20230424111937_JH%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 10 from 20230424111937_JH%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302060619_PRC%20fe%202-2_lungback.webm from audios/20220302060619_PRC%20fe%202-2_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302060619_PRC%20fe%202-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220302060619_PRC%20fe%202-2_lungback.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220302060619_PRC%20fe%202-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220302060619_PRC%20fe%202-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220302060619_PRC%20fe%202-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220302060619_PRC%20fe%202-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220302060619_PRC%20fe%202-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220302060619_PRC%20fe%202-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220302060619_PRC%20fe%202-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127134714_JAYG%20Fe_lungfront.webm from audios/20220127134714_JAYG%20Fe_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220127134714_JAYG%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220127134714_JAYG%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220127134714_JAYG%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220127134714_JAYG%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220127134714_JAYG%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220127134714_JAYG%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220125122955_RPY%20fe_vocal.webm from audios/20220125122955_RPY%20fe_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220125122955_RPY%20fe_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220125122955_RPY%20fe_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20220125122955_RPY%20fe_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220125122955_RPY%20fe_vocal.webm [loudness: -11 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421090956_AH%20fe-1_lungback.webm from audios/20230421090956_AH%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 11 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 12 from 20230421090956_AH%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (12, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604055709_JFC%20fe-2_lungfront.webm from audios/20220604055709_JFC%20fe-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220604055709_JFC%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220604055709_JFC%20fe-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220604055709_JFC%20fe-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220604055709_JFC%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220604055709_JFC%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220604055709_JFC%20fe-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220604055709_JFC%20fe-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 8 from 20220604055709_JFC%20fe-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 9 from 20220604055709_JFC%20fe-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20220604055709_JFC%20fe-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709054937_CNE%20fe-2_lungback.webm from audios/20220709054937_CNE%20fe-2_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709054937_CNE%20fe-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220709054937_CNE%20fe-2_lungback.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20220709054937_CNE%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220709054937_CNE%20fe-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220709054937_CNE%20fe-2_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220709054937_CNE%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220709054937_CNE%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220709054937_CNE%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220709054937_CNE%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516145759_Leco2-16-5_lungback.webm from audios/20220516145759_Leco2-16-5_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516145759_Leco2-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220516145759_Leco2-16-5_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220516145759_Leco2-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220516145759_Leco2-16-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220516145759_Leco2-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220516145759_Leco2-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220516145759_Leco2-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220516145759_Leco2-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120143633_SBDS_lungfront.webm from audios/20220120143633_SBDS_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220120143633_SBDS_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220120143633_SBDS_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220120143633_SBDS_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220120143633_SBDS_lungfront.webm [loudness: -8 dB]\n",
            "  Clip 5 from 20220120143633_SBDS_lungfront.webm [loudness: -7 dB]\n",
            "  Clip 6 from 20220120143633_SBDS_lungfront.webm [loudness: -6 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516145759_Leco2-16-5_vocal.webm from audios/20220516145759_Leco2-16-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516145759_Leco2-16-5_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220516145759_Leco2-16-5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220516145759_Leco2-16-5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220516145759_Leco2-16-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304081704_MHR%20fe%204-1_vocal.webm from audios/20220304081704_MHR%20fe%204-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220304081704_MHR%20fe%204-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220304081704_MHR%20fe%204-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220304081704_MHR%20fe%204-1_vocal.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220304081704_MHR%20fe%204-1_vocal.webm [loudness: -53 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063858_JMT-D4_vocal.webm from audios/20211209063858_JMT-D4_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20211209063858_JMT-D4_vocal.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20211209063858_JMT-D4_vocal.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20211209063858_JMT-D4_vocal.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20211209063858_JMT-D4_vocal.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20211209063858_JMT-D4_vocal.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219083953_SYV%2030-1_lungfront.webm from audios/20220219083953_SYV%2030-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220219083953_SYV%2030-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220219083953_SYV%2030-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20220219083953_SYV%2030-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220219083953_SYV%2030-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220219083953_SYV%2030-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220219083953_SYV%2030-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220219083953_SYV%2030-1_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 8 from 20220219083953_SYV%2030-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421114407_JF%20fe-1_vocal.webm from audios/20230421114407_JF%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230421114407_JF%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20230421114407_JF%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20230421114407_JF%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230421114407_JF%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105162835_CGT%20con_lungfront.webm from audios/20220105162835_CGT%20con_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220105162835_CGT%20con_lungfront.webm [loudness: -80 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 2 from 20220105162835_CGT%20con_lungfront.webm [loudness: -86 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 3 from 20220105162835_CGT%20con_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 4 from 20220105162835_CGT%20con_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20220105162835_CGT%20con_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 6 from 20220105162835_CGT%20con_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 7 from 20220105162835_CGT%20con_lungfront.webm [loudness: -87 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -87 dB]\n",
            "  Clip 8 from 20220105162835_CGT%20con_lungfront.webm [loudness: -83 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 9 from 20220105162835_CGT%20con_lungfront.webm [loudness: -83 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305090421_LCC%20fe%205-1_vocal.webm from audios/20220305090421_LCC%20fe%205-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220305090421_LCC%20fe%205-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220305090421_LCC%20fe%205-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220305090421_LCC%20fe%205-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220305090421_LCC%20fe%205-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115130617_RVPP_lungback.webm from audios/20220115130617_RVPP_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220115130617_RVPP_lungback.webm [loudness: -75 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 2 from 20220115130617_RVPP_lungback.webm [loudness: -91 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -91 dB]\n",
            "  Clip 3 from 20220115130617_RVPP_lungback.webm [loudness: -100 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -100 dB]\n",
            "  Clip 4 from 20220115130617_RVPP_lungback.webm [loudness: -83 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 5 from 20220115130617_RVPP_lungback.webm [loudness: -61 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 6 from 20220115130617_RVPP_lungback.webm [loudness: -59 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 7 from 20220115130617_RVPP_lungback.webm [loudness: -55 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -55 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220111120259_RARN_vocal.webm from audios/20220111120259_RARN_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220111120259_RARN_vocal.webm [loudness: -35 dB]\n",
            "  Clip 2 from 20220111120259_RARN_vocal.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20220111120259_RARN_vocal.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220111120259_RARN_vocal.webm [loudness: -31 dB]\n",
            "  Clip 5 from 20220111120259_RARN_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108152718_PMAD_vocal.webm from audios/20220108152718_PMAD_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220108152718_PMAD_vocal.webm [loudness: -90 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -90 dB]\n",
            "  Clip 2 from 20220108152718_PMAD_vocal.webm [loudness: -93 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -93 dB]\n",
            "  Clip 3 from 20220108152718_PMAD_vocal.webm [loudness: -93 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -93 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516110622_Ahj-16-5_lungback.webm from audios/20220516110622_Ahj-16-5_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516110622_Ahj-16-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220516110622_Ahj-16-5_lungback.webm [loudness: -53 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 3 from 20220516110622_Ahj-16-5_lungback.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220516110622_Ahj-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220516110622_Ahj-16-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220516110622_Ahj-16-5_lungback.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20220516110622_Ahj-16-5_lungback.webm [loudness: -27 dB]\n",
            "  Clip 8 from 20220516110622_Ahj-16-5_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125122955_RPY%20fe_lungback.webm from audios/20220125122955_RPY%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125122955_RPY%20fe_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220125122955_RPY%20fe_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220125122955_RPY%20fe_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220125122955_RPY%20fe_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220125122955_RPY%20fe_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419114613_AR%20fe-1_lungfront.webm from audios/20230419114613_AR%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 11 from 20230419114613_AR%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421091258_MH%20fe-1_lungfront.webm from audios/20230421091258_MH%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230421091258_MH%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230421091258_MH%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20230421091258_MH%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230421091258_MH%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20230421091258_MH%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20230421091258_MH%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230421091258_MH%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20230421091258_MH%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230421091258_MH%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 10 from 20230421091258_MH%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122140109_MRGM%20es_vocal.webm from audios/20220122140109_MRGM%20es_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122140109_MRGM%20es_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220122140109_MRGM%20es_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220122140109_MRGM%20es_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220122140109_MRGM%20es_vocal.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220122140109_MRGM%20es_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212082327_Mmm%2024-1_vocal.webm from audios/20220212082327_Mmm%2024-1_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220212082327_Mmm%2024-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220212082327_Mmm%2024-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054534_ACD-D4_vocal.webm from audios/20211207054534_ACD-D4_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207054534_ACD-D4_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20211207054534_ACD-D4_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20211207054534_ACD-D4_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20211207054534_ACD-D4_vocal.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20211207054534_ACD-D4_vocal.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20211207054534_ACD-D4_vocal.webm [loudness: -34 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419130616_MO%20fe-1_lungfront.webm from audios/20230419130616_MO%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230419130616_MO%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230419130616_MO%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20230419130616_MO%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20230419130616_MO%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20230419130616_MO%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20230419130616_MO%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20230419130616_MO%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230419130616_MO%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20230419130616_MO%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20221119112228_Fe-1%20GN_lungfront.webm from audios/20221119112228_Fe-1%20GN_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221119112228_Fe-1%20GN_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20221119112228_Fe-1%20GN_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20221119112228_Fe-1%20GN_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20221119112228_Fe-1%20GN_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221119112228_Fe-1%20GN_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20221119112228_Fe-1%20GN_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20221119112228_Fe-1%20GN_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20221119112228_Fe-1%20GN_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20221119112228_Fe-1%20GN_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212071632_Gbc%2019-1_lungback.webm from audios/20220212071632_Gbc%2019-1_lungback.webm\n",
            " Segmenting into 1 2s clips\n",
            "  Clip 1 from 20220212071632_Gbc%2019-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105153039_GUF%20SIN_lungback.webm from audios/20220105153039_GUF%20SIN_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220105153039_GUF%20SIN_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220105153039_GUF%20SIN_lungback.webm [loudness: -73 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 3 from 20220105153039_GUF%20SIN_lungback.webm [loudness: -86 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 4 from 20220105153039_GUF%20SIN_lungback.webm [loudness: -83 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 5 from 20220105153039_GUF%20SIN_lungback.webm [loudness: -78 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -78 dB]\n",
            "  Clip 6 from 20220105153039_GUF%20SIN_lungback.webm [loudness: -79 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 7 from 20220105153039_GUF%20SIN_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220105153039_GUF%20SIN_lungback.webm [loudness: -80 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 9 from 20220105153039_GUF%20SIN_lungback.webm [loudness: -84 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -84 dB]\n",
            "  Clip 10 from 20220105153039_GUF%20SIN_lungback.webm [loudness: -35 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124160502_RALL%20es_lungback.webm from audios/20220124160502_RALL%20es_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124160502_RALL%20es_lungback.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220124160502_RALL%20es_lungback.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220124160502_RALL%20es_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220124160502_RALL%20es_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220124160502_RALL%20es_lungback.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165658_Avrd_vocal.webm from audios/20220504165658_Avrd_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220504165658_Avrd_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220504165658_Avrd_vocal.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220504165658_Avrd_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220504165658_Avrd_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107155508_GHR_lungback.webm from audios/20220107155508_GHR_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220107155508_GHR_lungback.webm [loudness: -61 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 2 from 20220107155508_GHR_lungback.webm [loudness: -52 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 3 from 20220107155508_GHR_lungback.webm [loudness: -46 dB]\n",
            "  Clip 4 from 20220107155508_GHR_lungback.webm [loudness: -66 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 5 from 20220107155508_GHR_lungback.webm [loudness: -62 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 6 from 20220107155508_GHR_lungback.webm [loudness: -74 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421090611_LS%20fe-1_lungback.webm from audios/20230421090611_LS%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230421090611_LS%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20230421090611_LS%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230421090611_LS%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20230421090611_LS%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230421090611_LS%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230421090611_LS%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20230421090611_LS%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230421090611_LS%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20230421090611_LS%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419115012_LA%20fe-1_lungback.webm from audios/20230419115012_LA%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 10 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 11 from 20230419115012_LA%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302090631_WOM%20fe%202-1_lungfront.webm from audios/20220302090631_WOM%20fe%202-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302090631_WOM%20fe%202-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220302090631_WOM%20fe%202-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220302090631_WOM%20fe%202-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220302090631_WOM%20fe%202-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220302090631_WOM%20fe%202-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220302090631_WOM%20fe%202-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220302090631_WOM%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20220302090631_WOM%20fe%202-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220302090631_WOM%20fe%202-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418103221_Av%20fe-1_lungback.webm from audios/20230418103221_Av%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230418103221_Av%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20230418103221_Av%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20230418103221_Av%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20230418103221_Av%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20230418103221_Av%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20230418103221_Av%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230418103221_Av%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20230418103221_Av%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20230418103221_Av%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20230418103221_Av%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107152508_RCET_vocal.webm from audios/20220107152508_RCET_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220107152508_RCET_vocal.webm [loudness: -32 dB]\n",
            "  Clip 2 from 20220107152508_RCET_vocal.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220107152508_RCET_vocal.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220107152508_RCET_vocal.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220107152508_RCET_vocal.webm [loudness: -61 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 6 from 20220107152508_RCET_vocal.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220107152508_RCET_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220211122728_OCF%2013_lungback.webm from audios/20220211122728_OCF%2013_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220211122728_OCF%2013_lungback.webm [loudness: -49 dB]\n",
            "  Clip 2 from 20220211122728_OCF%2013_lungback.webm [loudness: -52 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 3 from 20220211122728_OCF%2013_lungback.webm [loudness: -48 dB]\n",
            "  Clip 4 from 20220211122728_OCF%2013_lungback.webm [loudness: -42 dB]\n",
            "  Clip 5 from 20220211122728_OCF%2013_lungback.webm [loudness: -48 dB]\n",
            "  Clip 6 from 20220211122728_OCF%2013_lungback.webm [loudness: -46 dB]\n",
            "  Clip 7 from 20220211122728_OCF%2013_lungback.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516150340_Wgyv2-16-5_lungfront.webm from audios/20220516150340_Wgyv2-16-5_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220516150340_Wgyv2-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220516150340_Wgyv2-16-5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220516150340_Wgyv2-16-5_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220516150340_Wgyv2-16-5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220516150340_Wgyv2-16-5_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220516150340_Wgyv2-16-5_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302081528_EGDC%20fe%202-1_lungback.webm from audios/20220302081528_EGDC%20fe%202-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302081528_EGDC%20fe%202-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220302081528_EGDC%20fe%202-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220302081528_EGDC%20fe%202-1_lungback.webm [loudness: -32 dB]\n",
            "  Clip 4 from 20220302081528_EGDC%20fe%202-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20220302081528_EGDC%20fe%202-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220302081528_EGDC%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220302081528_EGDC%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220302081528_EGDC%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220302081528_EGDC%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20221213121136_Fe-1%20GM_lungfront.webm from audios/20221213121136_Fe-1%20GM_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20221213121136_Fe-1%20GM_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20221213121136_Fe-1%20GM_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20221213121136_Fe-1%20GM_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20221213121136_Fe-1%20GM_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20221213121136_Fe-1%20GM_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20221213121136_Fe-1%20GM_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20221213121136_Fe-1%20GM_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20221213121136_Fe-1%20GM_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075217_TRC%2026-2_lungfront.webm from audios/20220215075217_TRC%2026-2_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220215075217_TRC%2026-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20220215075217_TRC%2026-2_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 3 from 20220215075217_TRC%2026-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 4 from 20220215075217_TRC%2026-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 5 from 20220215075217_TRC%2026-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 6 from 20220215075217_TRC%2026-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220215075217_TRC%2026-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220215075217_TRC%2026-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -57 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20211209064522_JMT-P4_lungfront.webm from audios/20211209064522_JMT-P4_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20211209064522_JMT-P4_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20211209064522_JMT-P4_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 3 from 20211209064522_JMT-P4_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 4 from 20211209064522_JMT-P4_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 5 from 20211209064522_JMT-P4_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 6 from 20211209064522_JMT-P4_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 7 from 20211209064522_JMT-P4_lungfront.webm [loudness: -48 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302090631_WOM%20fe%202-1_lungback.webm from audios/20220302090631_WOM%20fe%202-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -30 dB]\n",
            "  Clip 4 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 9 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 10 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 11 from 20220302090631_WOM%20fe%202-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126170624_GMK%20Fe_lungback.webm from audios/20220126170624_GMK%20Fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220126170624_GMK%20Fe_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220126170624_GMK%20Fe_lungback.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220126170624_GMK%20Fe_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220126170624_GMK%20Fe_lungback.webm [loudness: -10 dB]\n",
            "  Clip 5 from 20220126170624_GMK%20Fe_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128110729_MCEE%20Fe_lungfront.webm from audios/20220128110729_MCEE%20Fe_lungfront.webm\n",
            "Error loading 20220128110729_MCEE%20Fe_lungfront.webm: . Removing from files_map.\n",
            "\n",
            "Loading file: 20220127134714_JAYG%20Fe_vocal.webm from audios/20220127134714_JAYG%20Fe_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220127134714_JAYG%20Fe_vocal.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220127134714_JAYG%20Fe_vocal.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220127134714_JAYG%20Fe_vocal.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20211202103930_Mcp-02-11-D3_lungfront.webm from audios/20211202103930_Mcp-02-11-D3_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20211202103930_Mcp-02-11-D3_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20211202103930_Mcp-02-11-D3_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20211202103930_Mcp-02-11-D3_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20211202103930_Mcp-02-11-D3_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20211202103930_Mcp-02-11-D3_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20211202103930_Mcp-02-11-D3_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20211202103930_Mcp-02-11-D3_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20211202103930_Mcp-02-11-D3_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304051252_PBZ%20fe%204-1_lungback.webm from audios/20220304051252_PBZ%20fe%204-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304051252_PBZ%20fe%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220304051252_PBZ%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220304051252_PBZ%20fe%204-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220304051252_PBZ%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220304051252_PBZ%20fe%204-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220304051252_PBZ%20fe%204-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220304051252_PBZ%20fe%204-1_lungback.webm [loudness: -34 dB]\n",
            "  Clip 8 from 20220304051252_PBZ%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220304051252_PBZ%20fe%204-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20221216093012_Fe-1%20CM_lungfront.webm from audios/20221216093012_Fe-1%20CM_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221216093012_Fe-1%20CM_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20221216093012_Fe-1%20CM_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20221216093012_Fe-1%20CM_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20221216093012_Fe-1%20CM_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20221216093012_Fe-1%20CM_lungfront.webm [loudness: -20 dB]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Clip 6 from 20221216093012_Fe-1%20CM_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20221216093012_Fe-1%20CM_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20221216093012_Fe-1%20CM_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20221216093012_Fe-1%20CM_lungfront.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105153039_GUF%20SIN_vocal.webm from audios/20220105153039_GUF%20SIN_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220105153039_GUF%20SIN_vocal.webm [loudness: -27 dB]\n",
            "  Clip 2 from 20220105153039_GUF%20SIN_vocal.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20220105153039_GUF%20SIN_vocal.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220105153039_GUF%20SIN_vocal.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220105153039_GUF%20SIN_vocal.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220105153039_GUF%20SIN_vocal.webm [loudness: -29 dB]\n",
            "  Clip 7 from 20220105153039_GUF%20SIN_vocal.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220105153039_GUF%20SIN_vocal.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220105153039_GUF%20SIN_vocal.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20220105153039_GUF%20SIN_vocal.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126125056_ABM%20fe_lungback.webm from audios/20220126125056_ABM%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220126125056_ABM%20fe_lungback.webm [loudness: -101 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -101 dB]\n",
            "  Clip 2 from 20220126125056_ABM%20fe_lungback.webm [loudness: -83 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 3 from 20220126125056_ABM%20fe_lungback.webm [loudness: -96 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -96 dB]\n",
            "  Clip 4 from 20220126125056_ABM%20fe_lungback.webm [loudness: -80 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 5 from 20220126125056_ABM%20fe_lungback.webm [loudness: -102 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -102 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220127120739_GADA%20es_vocal.webm from audios/20220127120739_GADA%20es_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220127120739_GADA%20es_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220127120739_GADA%20es_vocal.webm [loudness: -7 dB]\n",
            "  Clip 3 from 20220127120739_GADA%20es_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220127120739_GADA%20es_vocal.webm [loudness: -10 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319074246_RMC%20fe%2019-1_lungfront.webm from audios/20220319074246_RMC%20fe%2019-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319074246_RMC%20fe%2019-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220319074246_RMC%20fe%2019-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220319074246_RMC%20fe%2019-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220319074246_RMC%20fe%2019-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220319074246_RMC%20fe%2019-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20220319074246_RMC%20fe%2019-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220319074246_RMC%20fe%2019-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 8 from 20220319074246_RMC%20fe%2019-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 9 from 20220319074246_RMC%20fe%2019-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220526123751_SE%20fe-1_lungfront.webm from audios/20220526123751_SE%20fe-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220526123751_SE%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220526123751_SE%20fe-1_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220526123751_SE%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220526123751_SE%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220526123751_SE%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220526123751_SE%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220526123751_SE%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220526123751_SE%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220810095753_JLP%20fe-1_lungfront.webm from audios/20220810095753_JLP%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220810095753_JLP%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220810095753_JLP%20fe-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220810095753_JLP%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220810095753_JLP%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220810095753_JLP%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220810095753_JLP%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220810095753_JLP%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220810095753_JLP%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220810095753_JLP%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114120408_FWS_lungfront.webm from audios/20220114120408_FWS_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220114120408_FWS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220114120408_FWS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220114120408_FWS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220114120408_FWS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220114120408_FWS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220114120408_FWS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220114125553_DAYC_lungback.webm from audios/20220114125553_DAYC_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114125553_DAYC_lungback.webm [loudness: -60 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 2 from 20220114125553_DAYC_lungback.webm [loudness: -61 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 3 from 20220114125553_DAYC_lungback.webm [loudness: -75 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 4 from 20220114125553_DAYC_lungback.webm [loudness: -110 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -110 dB]\n",
            "  Clip 5 from 20220114125553_DAYC_lungback.webm [loudness: -68 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -68 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230421113844_AP%20fe-1_lungfront.webm from audios/20230421113844_AP%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230421113844_AP%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20230421113844_AP%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20230421113844_AP%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20230421113844_AP%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20230421113844_AP%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20230421113844_AP%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20230421113844_AP%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20230421113844_AP%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20230421113844_AP%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114132657_REVY_lungback.webm from audios/20220114132657_REVY_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220114132657_REVY_lungback.webm [loudness: -61 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 2 from 20220114132657_REVY_lungback.webm [loudness: -40 dB]\n",
            "  Clip 3 from 20220114132657_REVY_lungback.webm [loudness: -44 dB]\n",
            "  Clip 4 from 20220114132657_REVY_lungback.webm [loudness: -56 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 5 from 20220114132657_REVY_lungback.webm [loudness: -35 dB]\n",
            "  Clip 6 from 20220114132657_REVY_lungback.webm [loudness: -36 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063439_JMT-D2_vocal.webm from audios/20211209063439_JMT-D2_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211209063439_JMT-D2_vocal.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20211209063439_JMT-D2_vocal.webm [loudness: -34 dB]\n",
            "  Clip 3 from 20211209063439_JMT-D2_vocal.webm [loudness: -29 dB]\n",
            "  Clip 4 from 20211209063439_JMT-D2_vocal.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20211209063439_JMT-D2_vocal.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20211209063439_JMT-D2_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054733_ADW-D5_vocal.webm from audios/20211207054733_ADW-D5_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207054733_ADW-D5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20211207054733_ADW-D5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20211207054733_ADW-D5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20211207054733_ADW-D5_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20211207054733_ADW-D5_vocal.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20211207054733_ADW-D5_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122140109_MRGM%20es_lungfront.webm from audios/20220122140109_MRGM%20es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122140109_MRGM%20es_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220122140109_MRGM%20es_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220122140109_MRGM%20es_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220122140109_MRGM%20es_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220122140109_MRGM%20es_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319094727_JGA%20fe%2019-1_vocal.webm from audios/20220319094727_JGA%20fe%2019-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220319094727_JGA%20fe%2019-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220319094727_JGA%20fe%2019-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220319094727_JGA%20fe%2019-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220319094727_JGA%20fe%2019-1_vocal.webm [loudness: -45 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302054046_DAT%20fe%202-1_vocal.webm from audios/20220302054046_DAT%20fe%202-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302054046_DAT%20fe%202-1_vocal.webm [loudness: -30 dB]\n",
            "  Clip 2 from 20220302054046_DAT%20fe%202-1_vocal.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220302054046_DAT%20fe%202-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220302054046_DAT%20fe%202-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202103930_Mcp-02-11-D3_lungback.webm from audios/20211202103930_Mcp-02-11-D3_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211202103930_Mcp-02-11-D3_lungback.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20211202103930_Mcp-02-11-D3_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20211202103930_Mcp-02-11-D3_lungback.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20211202103930_Mcp-02-11-D3_lungback.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20211202103930_Mcp-02-11-D3_lungback.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20211202103930_Mcp-02-11-D3_lungback.webm [loudness: -10 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424111328_RB%20fe-1_vocal.webm from audios/20230424111328_RB%20fe-1_vocal.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20230424111328_RB%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20230424111328_RB%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230424111328_RB%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20230424111328_RB%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20230424111328_RB%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230424111328_RB%20fe-1_vocal.webm [loudness: -55 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 7 from 20230424111328_RB%20fe-1_vocal.webm [loudness: -66 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114163111_JASR_lungfront.webm from audios/20220114163111_JASR_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114163111_JASR_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220114163111_JASR_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220114163111_JASR_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220114163111_JASR_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220114163111_JASR_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128124349_SCSHR%20Fe_vocal.webm from audios/20220128124349_SCSHR%20Fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220128124349_SCSHR%20Fe_vocal.webm [loudness: -48 dB]\n",
            "  Clip 2 from 20220128124349_SCSHR%20Fe_vocal.webm [loudness: -50 dB]\n",
            "  Clip 3 from 20220128124349_SCSHR%20Fe_vocal.webm [loudness: -49 dB]\n",
            "  Clip 4 from 20220128124349_SCSHR%20Fe_vocal.webm [loudness: -50 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504102754_Seyv%204-5_vocal.webm from audios/20220504102754_Seyv%204-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220504102754_Seyv%204-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220504102754_Seyv%204-5_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20220504102754_Seyv%204-5_vocal.webm [loudness: -9 dB]\n",
            "  Clip 4 from 20220504102754_Seyv%204-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117164316_LTA_lungback.webm from audios/20220117164316_LTA_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220117164316_LTA_lungback.webm [loudness: -80 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 2 from 20220117164316_LTA_lungback.webm [loudness: -62 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 3 from 20220117164316_LTA_lungback.webm [loudness: -84 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -84 dB]\n",
            "  Clip 4 from 20220117164316_LTA_lungback.webm [loudness: -98 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -98 dB]\n",
            "  Clip 5 from 20220117164316_LTA_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220302092223_CCP%20fe%202-1_lungback.webm from audios/20220302092223_CCP%20fe%202-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -11 dB]\n",
            "  Clip 7 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 11 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 12 from 20220302092223_CCP%20fe%202-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (12, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126170624_GMK%20Fe_vocal.webm from audios/20220126170624_GMK%20Fe_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220126170624_GMK%20Fe_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220126170624_GMK%20Fe_vocal.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220126170624_GMK%20Fe_vocal.webm [loudness: -11 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114132657_REVY_vocal.webm from audios/20220114132657_REVY_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220114132657_REVY_vocal.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220114132657_REVY_vocal.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220114132657_REVY_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220114132657_REVY_vocal.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220114132657_REVY_vocal.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220114132657_REVY_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424134952_LY%20fe-1_vocal.webm from audios/20230424134952_LY%20fe-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20230424134952_LY%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20230424134952_LY%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230424134952_LY%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424140556_GB%20fe-1_vocal.webm from audios/20230424140556_GB%20fe-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20230424140556_GB%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20230424140556_GB%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20230424140556_GB%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215081101_MME%2028-2_lungback.webm from audios/20220215081101_MME%2028-2_lungback.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220215081101_MME%2028-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220215081101_MME%2028-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220215081101_MME%2028-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220215081101_MME%2028-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220215081101_MME%2028-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220215081101_MME%2028-2_lungback.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220215081101_MME%2028-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220215081101_MME%2028-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 9 from 20220215081101_MME%2028-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 10 from 20220215081101_MME%2028-2_lungback.webm [loudness: -53 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 11 from 20220215081101_MME%2028-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -56 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220121121412_EOTS_lungfront.webm from audios/20220121121412_EOTS_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220121121412_EOTS_lungfront.webm [loudness: -95 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -95 dB]\n",
            "  Clip 2 from 20220121121412_EOTS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220121121412_EOTS_lungfront.webm [loudness: -90 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -90 dB]\n",
            "  Clip 4 from 20220121121412_EOTS_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 5 from 20220121121412_EOTS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220121121412_EOTS_lungfront.webm [loudness: -88 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -88 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123051040_Fe-1%20MM_lungback.webm from audios/20221123051040_Fe-1%20MM_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123051040_Fe-1%20MM_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20221123051040_Fe-1%20MM_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20221123051040_Fe-1%20MM_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20221123051040_Fe-1%20MM_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20221123051040_Fe-1%20MM_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20221123051040_Fe-1%20MM_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20221123051040_Fe-1%20MM_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20221123051040_Fe-1%20MM_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20221123051040_Fe-1%20MM_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424135234_LM%20fe-1_lungback.webm from audios/20230424135234_LM%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424135234_LM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20230424135234_LM%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20230424135234_LM%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20230424135234_LM%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20230424135234_LM%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230424135234_LM%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230424135234_LM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20230424135234_LM%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230424135234_LM%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230424135234_LM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220129133119_DAKP%20fE_lungfront.webm from audios/20220129133119_DAKP%20fE_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220129133119_DAKP%20fE_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 2 from 20220129133119_DAKP%20fE_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 3 from 20220129133119_DAKP%20fE_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220129133119_DAKP%20fE_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 5 from 20220129133119_DAKP%20fE_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302082442_MOP%20fe%202-1_lungfront.webm from audios/20220302082442_MOP%20fe%202-1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220302082442_MOP%20fe%202-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220302082442_MOP%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220302082442_MOP%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220302082442_MOP%20fe%202-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220302082442_MOP%20fe%202-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220302082442_MOP%20fe%202-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20220302082442_MOP%20fe%202-1_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 8 from 20220302082442_MOP%20fe%202-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 9 from 20220302082442_MOP%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20220302082442_MOP%20fe%202-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424124430_RT%20fe-1_vocal.webm from audios/20230424124430_RT%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230424124430_RT%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20230424124430_RT%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20230424124430_RT%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230424124430_RT%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202103821_Mcp-02-12-D2_vocal.webm from audios/20211202103821_Mcp-02-12-D2_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20211202103821_Mcp-02-12-D2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20211202103821_Mcp-02-12-D2_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220630100058_ARB%20fe-2_lungfront.webm from audios/20220630100058_ARB%20fe-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220630100058_ARB%20fe-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220630100058_ARB%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220630100058_ARB%20fe-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220630100058_ARB%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220630100058_ARB%20fe-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220630100058_ARB%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220630100058_ARB%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220630100058_ARB%20fe-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220630100058_ARB%20fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219081410_TRC%2029-1_lungfront.webm from audios/20220219081410_TRC%2029-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220219081410_TRC%2029-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220219081410_TRC%2029-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20220219081410_TRC%2029-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220219081410_TRC%2029-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220219081410_TRC%2029-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220219081410_TRC%2029-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220219081410_TRC%2029-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220219081410_TRC%2029-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20221220075710_Fe-2%20PB_vocal.webm from audios/20221220075710_Fe-2%20PB_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20221220075710_Fe-2%20PB_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20221220075710_Fe-2%20PB_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20221220075710_Fe-2%20PB_vocal.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20221220075710_Fe-2%20PB_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124102547_ARJA%20fe_vocal.webm from audios/20220124102547_ARJA%20fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220124102547_ARJA%20fe_vocal.webm [loudness: -36 dB]\n",
            "  Clip 2 from 20220124102547_ARJA%20fe_vocal.webm [loudness: -37 dB]\n",
            "  Clip 3 from 20220124102547_ARJA%20fe_vocal.webm [loudness: -33 dB]\n",
            "  Clip 4 from 20220124102547_ARJA%20fe_vocal.webm [loudness: -28 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125140524_NRJJ%20es_lungfront.webm from audios/20220125140524_NRJJ%20es_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220125140524_NRJJ%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220125140524_NRJJ%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220125140524_NRJJ%20es_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 4 from 20220125140524_NRJJ%20es_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 5 from 20220125140524_NRJJ%20es_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 6 from 20220125140524_NRJJ%20es_lungfront.webm [loudness: -107 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -107 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220212071122_Tvs%2018-2_vocal.webm from audios/20220212071122_Tvs%2018-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212071122_Tvs%2018-2_vocal.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220212071122_Tvs%2018-2_vocal.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220212071122_Tvs%2018-2_vocal.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305090043_SFT%20fe%205-1_lungback.webm from audios/20220305090043_SFT%20fe%205-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220305090043_SFT%20fe%205-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220305090043_SFT%20fe%205-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220305090043_SFT%20fe%205-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220305090043_SFT%20fe%205-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20220305090043_SFT%20fe%205-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220305090043_SFT%20fe%205-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220305090043_SFT%20fe%205-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220305090043_SFT%20fe%205-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128111313_MCFF%20fE_lungfront.webm from audios/20220128111313_MCFF%20fE_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128111313_MCFF%20fE_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 2 from 20220128111313_MCFF%20fE_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 3 from 20220128111313_MCFF%20fE_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 4 from 20220128111313_MCFF%20fE_lungfront.webm [loudness: -72 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 5 from 20220128111313_MCFF%20fE_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120162822_OEGP_lungfront.webm from audios/20220120162822_OEGP_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220120162822_OEGP_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220120162822_OEGP_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220120162822_OEGP_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220120162822_OEGP_lungfront.webm [loudness: -9 dB]\n",
            "  Clip 5 from 20220120162822_OEGP_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127134606_JAYG%20Es_lungfront.webm from audios/20220127134606_JAYG%20Es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127134606_JAYG%20Es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220127134606_JAYG%20Es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220127134606_JAYG%20Es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220127134606_JAYG%20Es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220127134606_JAYG%20Es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230418115210_JS%20fe-1_lungfront.webm from audios/20230418115210_JS%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230418115210_JS%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20230418115210_JS%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20230418115210_JS%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230418115210_JS%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20230418115210_JS%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20230418115210_JS%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20230418115210_JS%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 8 from 20230418115210_JS%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20230418115210_JS%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220812142325_ANR%20fe-1_lungfront.webm from audios/20220812142325_ANR%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220812142325_ANR%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220812142325_ANR%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220812142325_ANR%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220812142325_ANR%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220812142325_ANR%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220812142325_ANR%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220812142325_ANR%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220812142325_ANR%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20220812142325_ANR%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128111148_MTSK%20Fe_lungback.webm from audios/20220128111148_MTSK%20Fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128111148_MTSK%20Fe_lungback.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220128111148_MTSK%20Fe_lungback.webm [loudness: -66 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 3 from 20220128111148_MTSK%20Fe_lungback.webm [loudness: -75 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 4 from 20220128111148_MTSK%20Fe_lungback.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 5 from 20220128111148_MTSK%20Fe_lungback.webm [loudness: -91 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -91 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20221123054048_Fe-1%20GCh_lungback.webm from audios/20221123054048_Fe-1%20GCh_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123054048_Fe-1%20GCh_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20221123054048_Fe-1%20GCh_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20221123054048_Fe-1%20GCh_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20221123054048_Fe-1%20GCh_lungback.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20221123054048_Fe-1%20GCh_lungback.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20221123054048_Fe-1%20GCh_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20221123054048_Fe-1%20GCh_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20221123054048_Fe-1%20GCh_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20221123054048_Fe-1%20GCh_lungback.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105152805_GUF%20con_lungback.webm from audios/20220105152805_GUF%20con_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220105152805_GUF%20con_lungback.webm [loudness: -84 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -84 dB]\n",
            "  Clip 2 from 20220105152805_GUF%20con_lungback.webm [loudness: -88 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -88 dB]\n",
            "  Clip 3 from 20220105152805_GUF%20con_lungback.webm [loudness: -86 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 4 from 20220105152805_GUF%20con_lungback.webm [loudness: -81 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -81 dB]\n",
            "  Clip 5 from 20220105152805_GUF%20con_lungback.webm [loudness: -65 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 6 from 20220105152805_GUF%20con_lungback.webm [loudness: -66 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 7 from 20220105152805_GUF%20con_lungback.webm [loudness: -76 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 8 from 20220105152805_GUF%20con_lungback.webm [loudness: -82 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -82 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220302060345_PRC%20fe%202-1_lungfront.webm from audios/20220302060345_PRC%20fe%202-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302060345_PRC%20fe%202-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220302060345_PRC%20fe%202-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220302060345_PRC%20fe%202-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220302060345_PRC%20fe%202-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220302060345_PRC%20fe%202-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220302060345_PRC%20fe%202-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 7 from 20220302060345_PRC%20fe%202-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220302060345_PRC%20fe%202-1_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 9 from 20220302060345_PRC%20fe%202-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127121029_GADA%20fe_lungback.webm from audios/20220127121029_GADA%20fe_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127121029_GADA%20fe_lungback.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220127121029_GADA%20fe_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220127121029_GADA%20fe_lungback.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220127121029_GADA%20fe_lungback.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220127121029_GADA%20fe_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123090606_Fe-1%20AM_vocal.webm from audios/20221123090606_Fe-1%20AM_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221123090606_Fe-1%20AM_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20221123090606_Fe-1%20AM_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20221123090606_Fe-1%20AM_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20221123090606_Fe-1%20AM_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20221123090606_Fe-1%20AM_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604055424_JFC%20fe-1_lungback.webm from audios/20220604055424_JFC%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220604055424_JFC%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220604055424_JFC%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220604055424_JFC%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220604055424_JFC%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220604055424_JFC%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220604055424_JFC%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220604055424_JFC%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220604055424_JFC%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220604055424_JFC%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212065052_ATC%2017-1_lungback.webm from audios/20220212065052_ATC%2017-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 17 2s clips\n",
            "  Clip 1 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -42 dB]\n",
            "  Clip 2 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -43 dB]\n",
            "  Clip 3 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -42 dB]\n",
            "  Clip 4 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -47 dB]\n",
            "  Clip 6 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -66 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 7 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -60 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 8 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -61 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 9 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -48 dB]\n",
            "  Clip 10 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -70 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 11 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -52 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 12 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -67 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 13 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -66 dB]\n",
            "  Clip 13 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 14 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -48 dB]\n",
            "  Clip 15 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 15 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 16 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -51 dB]\n",
            "  Clip 16 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 17 from 20220212065052_ATC%2017-1_lungback.webm [loudness: -42 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304065400_NAA%20fe%204-1_lungback.webm from audios/20220304065400_NAA%20fe%204-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304065400_NAA%20fe%204-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 2 from 20220304065400_NAA%20fe%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220304065400_NAA%20fe%204-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220304065400_NAA%20fe%204-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20220304065400_NAA%20fe%204-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220304065400_NAA%20fe%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220304065400_NAA%20fe%204-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220304065400_NAA%20fe%204-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20221220075710_Fe-2%20PB_lungback.webm from audios/20221220075710_Fe-2%20PB_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221220075710_Fe-2%20PB_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20221220075710_Fe-2%20PB_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20221220075710_Fe-2%20PB_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20221220075710_Fe-2%20PB_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20221220075710_Fe-2%20PB_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20221220075710_Fe-2%20PB_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20221220075710_Fe-2%20PB_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20221220075710_Fe-2%20PB_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20221220075710_Fe-2%20PB_lungback.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319073113_MLQ%20fe%2019-1_vocal.webm from audios/20220319073113_MLQ%20fe%2019-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220319073113_MLQ%20fe%2019-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220319073113_MLQ%20fe%2019-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220319073113_MLQ%20fe%2019-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220319073113_MLQ%20fe%2019-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220525092038_Pt%20fe-1_lungback.webm from audios/20220525092038_Pt%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220525092038_Pt%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220525092038_Pt%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220525092038_Pt%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220525092038_Pt%20fe-1_lungback.webm [loudness: -44 dB]\n",
            "  Clip 5 from 20220525092038_Pt%20fe-1_lungback.webm [loudness: -41 dB]\n",
            "  Clip 6 from 20220525092038_Pt%20fe-1_lungback.webm [loudness: -33 dB]\n",
            "  Clip 7 from 20220525092038_Pt%20fe-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128110857_MCFF%20FE_vocal.webm from audios/20220128110857_MCFF%20FE_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128110857_MCFF%20FE_vocal.webm [loudness: -45 dB]\n",
            "  Clip 2 from 20220128110857_MCFF%20FE_vocal.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220128110857_MCFF%20FE_vocal.webm [loudness: -30 dB]\n",
            "  Clip 4 from 20220128110857_MCFF%20FE_vocal.webm [loudness: -30 dB]\n",
            "  Clip 5 from 20220128110857_MCFF%20FE_vocal.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122153938_MSVC%20es_vocal.webm from audios/20220122153938_MSVC%20es_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220122153938_MSVC%20es_vocal.webm [loudness: -8 dB]\n",
            "  Clip 2 from 20220122153938_MSVC%20es_vocal.webm [loudness: -9 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063858_JMT-D4_lungback.webm from audios/20211209063858_JMT-D4_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211209063858_JMT-D4_lungback.webm [loudness: -37 dB]\n",
            "  Clip 2 from 20211209063858_JMT-D4_lungback.webm [loudness: -35 dB]\n",
            "  Clip 3 from 20211209063858_JMT-D4_lungback.webm [loudness: -42 dB]\n",
            "  Clip 4 from 20211209063858_JMT-D4_lungback.webm [loudness: -46 dB]\n",
            "  Clip 5 from 20211209063858_JMT-D4_lungback.webm [loudness: -47 dB]\n",
            "  Clip 6 from 20211209063858_JMT-D4_lungback.webm [loudness: -49 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421113844_AP%20fe-1_vocal.webm from audios/20230421113844_AP%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230421113844_AP%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20230421113844_AP%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230421113844_AP%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230421113844_AP%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304062932_ACR%20fe%204-1_lungback.webm from audios/20220304062932_ACR%20fe%204-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304062932_ACR%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220304062932_ACR%20fe%204-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220304062932_ACR%20fe%204-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220304062932_ACR%20fe%204-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220304062932_ACR%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220304062932_ACR%20fe%204-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220304062932_ACR%20fe%204-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220304062932_ACR%20fe%204-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604085459_CAD%20fe-1_vocal.webm from audios/20220604085459_CAD%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220604085459_CAD%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220604085459_CAD%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220604085459_CAD%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220604085459_CAD%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118162724_SAA_lungback.webm from audios/20220118162724_SAA_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118162724_SAA_lungback.webm [loudness: -94 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -94 dB]\n",
            "  Clip 2 from 20220118162724_SAA_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220118162724_SAA_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220118162724_SAA_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220118162724_SAA_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220810095753_JLP%20fe-1_lungback.webm from audios/20220810095753_JLP%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220810095753_JLP%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220810095753_JLP%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220810095753_JLP%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220810095753_JLP%20fe-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20220810095753_JLP%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220810095753_JLP%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220810095753_JLP%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220810095753_JLP%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20220810095753_JLP%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303082932_ACH%20fe%203-1_lungfront.webm from audios/20220303082932_ACH%20fe%203-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303082932_ACH%20fe%203-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220303082932_ACH%20fe%203-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220303082932_ACH%20fe%203-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220303082932_ACH%20fe%203-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220303082932_ACH%20fe%203-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20220303082932_ACH%20fe%203-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220303082932_ACH%20fe%203-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220303082932_ACH%20fe%203-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220303082932_ACH%20fe%203-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516153445_Jasr1-1605_vocal.webm from audios/20220516153445_Jasr1-1605_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516153445_Jasr1-1605_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220516153445_Jasr1-1605_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220516153445_Jasr1-1605_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220516153445_Jasr1-1605_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127104054_CHLA%20fe_lungfront.webm from audios/20220127104054_CHLA%20fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127104054_CHLA%20fe_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 2 from 20220127104054_CHLA%20fe_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220127104054_CHLA%20fe_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 4 from 20220127104054_CHLA%20fe_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 5 from 20220127104054_CHLA%20fe_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220129141239_SMALM%20FE_vocal.webm from audios/20220129141239_SMALM%20FE_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220129141239_SMALM%20FE_vocal.webm [loudness: -48 dB]\n",
            "  Clip 2 from 20220129141239_SMALM%20FE_vocal.webm [loudness: -44 dB]\n",
            "  Clip 3 from 20220129141239_SMALM%20FE_vocal.webm [loudness: -41 dB]\n",
            "  Clip 4 from 20220129141239_SMALM%20FE_vocal.webm [loudness: -52 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 5 from 20220129141239_SMALM%20FE_vocal.webm [loudness: -51 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 6 from 20220129141239_SMALM%20FE_vocal.webm [loudness: -39 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420093811_GY%20fe-1_lungfront.webm from audios/20230420093811_GY%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230420093811_GY%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20230420093811_GY%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20230420093811_GY%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230420093811_GY%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20230420093811_GY%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20230420093811_GY%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230420093811_GY%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20230420093811_GY%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20230420093811_GY%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 10 from 20230420093811_GY%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220506072041_Vmpr%206_5_22_lungfront.webm from audios/20220506072041_Vmpr%206_5_22_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220506072041_Vmpr%206_5_22_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220506072041_Vmpr%206_5_22_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20220506072041_Vmpr%206_5_22_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220506072041_Vmpr%206_5_22_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20220506072041_Vmpr%206_5_22_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220506072041_Vmpr%206_5_22_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120110747_ARSC_lungfront.webm from audios/20220120110747_ARSC_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220120110747_ARSC_lungfront.webm [loudness: -97 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -97 dB]\n",
            "  Clip 2 from 20220120110747_ARSC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220120110747_ARSC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220120110747_ARSC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220120110747_ARSC_lungfront.webm [loudness: -48 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304062932_ACR%20fe%204-1_lungfront.webm from audios/20220304062932_ACR%20fe%204-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304062932_ACR%20fe%204-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220304062932_ACR%20fe%204-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220304062932_ACR%20fe%204-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220304062932_ACR%20fe%204-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220304062932_ACR%20fe%204-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220304062932_ACR%20fe%204-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220304062932_ACR%20fe%204-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220304062932_ACR%20fe%204-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220506051857_Abemn%206-5-22_lungback.webm from audios/20220506051857_Abemn%206-5-22_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220506051857_Abemn%206-5-22_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220506051857_Abemn%206-5-22_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220506051857_Abemn%206-5-22_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220506051857_Abemn%206-5-22_lungback.webm [loudness: -31 dB]\n",
            "  Clip 5 from 20220506051857_Abemn%206-5-22_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220506051857_Abemn%206-5-22_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220506051857_Abemn%206-5-22_lungback.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220506051857_Abemn%206-5-22_lungback.webm [loudness: -29 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212080246_Afc%2021-2_lungfront.webm from audios/20220212080246_Afc%2021-2_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220212080246_Afc%2021-2_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 2 from 20220212080246_Afc%2021-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220212080246_Afc%2021-2_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 4 from 20220212080246_Afc%2021-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 5 from 20220212080246_Afc%2021-2_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 6 from 20220212080246_Afc%2021-2_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 7 from 20220212080246_Afc%2021-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420073507_NA%20fe-1_lungfront.webm from audios/20230420073507_NA%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230420073507_NA%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20230420073507_NA%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20230420073507_NA%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20230420073507_NA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230420073507_NA%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20230420073507_NA%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20230420073507_NA%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 8 from 20230420073507_NA%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20230420073507_NA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 10 from 20230420073507_NA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220721062840_ICR%20fe-1_vocal.webm from audios/20220721062840_ICR%20fe-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220721062840_ICR%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220721062840_ICR%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220721062840_ICR%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220721062840_ICR%20fe-1_vocal.webm [loudness: -79 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 5 from 20220721062840_ICR%20fe-1_vocal.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212081824_Gnf%2023-2_lungback.webm from audios/20220212081824_Gnf%2023-2_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220212081824_Gnf%2023-2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 2 from 20220212081824_Gnf%2023-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220212081824_Gnf%2023-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220212081824_Gnf%2023-2_lungback.webm [loudness: -48 dB]\n",
            "  Clip 5 from 20220212081824_Gnf%2023-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 6 from 20220212081824_Gnf%2023-2_lungback.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220212081824_Gnf%2023-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220212081824_Gnf%2023-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220121121412_EOTS_vocal.webm from audios/20220121121412_EOTS_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220121121412_EOTS_vocal.webm [loudness: -38 dB]\n",
            "  Clip 2 from 20220121121412_EOTS_vocal.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220121121412_EOTS_vocal.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114132657_REVY_lungfront.webm from audios/20220114132657_REVY_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114132657_REVY_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 2 from 20220114132657_REVY_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220114132657_REVY_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 4 from 20220114132657_REVY_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 5 from 20220114132657_REVY_lungfront.webm [loudness: -69 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117150958_EGX_lungback.webm from audios/20220117150958_EGX_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220117150958_EGX_lungback.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220117150958_EGX_lungback.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220117150958_EGX_lungback.webm [loudness: -67 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 4 from 20220117150958_EGX_lungback.webm [loudness: -53 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 5 from 20220117150958_EGX_lungback.webm [loudness: -53 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 6 from 20220117150958_EGX_lungback.webm [loudness: -74 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 7 from 20220117150958_EGX_lungback.webm [loudness: -71 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -71 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220212063658_Acb%2015-2_vocal.webm from audios/20220212063658_Acb%2015-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220212063658_Acb%2015-2_vocal.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220212063658_Acb%2015-2_vocal.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107134757_OCAD_lungback.webm from audios/20220107134757_OCAD_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220107134757_OCAD_lungback.webm [loudness: -30 dB]\n",
            "  Clip 2 from 20220107134757_OCAD_lungback.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20220107134757_OCAD_lungback.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220107134757_OCAD_lungback.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220107134757_OCAD_lungback.webm [loudness: -29 dB]\n",
            "  Clip 6 from 20220107134757_OCAD_lungback.webm [loudness: -29 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516143936_Darz1-16-5_vocal.webm from audios/20220516143936_Darz1-16-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516143936_Darz1-16-5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220516143936_Darz1-16-5_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220516143936_Darz1-16-5_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220516143936_Darz1-16-5_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127143409_MMLJ%20Es_vocal.webm from audios/20220127143409_MMLJ%20Es_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220127143409_MMLJ%20Es_vocal.webm [loudness: -34 dB]\n",
            "  Clip 2 from 20220127143409_MMLJ%20Es_vocal.webm [loudness: -34 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128124349_SCSHR%20Fe_lungfront.webm from audios/20220128124349_SCSHR%20Fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128124349_SCSHR%20Fe_lungfront.webm [loudness: -100 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -100 dB]\n",
            "  Clip 2 from 20220128124349_SCSHR%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220128124349_SCSHR%20Fe_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 4 from 20220128124349_SCSHR%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220128124349_SCSHR%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230419104420_RP%20fe-1_lungback.webm from audios/20230419104420_RP%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419104420_RP%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20230419104420_RP%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230419104420_RP%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20230419104420_RP%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230419104420_RP%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20230419104420_RP%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20230419104420_RP%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20230419104420_RP%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20230419104420_RP%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230419104420_RP%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123090606_Fe-1%20AM_lungfront.webm from audios/20221123090606_Fe-1%20AM_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123090606_Fe-1%20AM_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20221123090606_Fe-1%20AM_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20221123090606_Fe-1%20AM_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20221123090606_Fe-1%20AM_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20221123090606_Fe-1%20AM_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20221123090606_Fe-1%20AM_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20221123090606_Fe-1%20AM_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20221123090606_Fe-1%20AM_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20221123090606_Fe-1%20AM_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305090421_LCC%20fe%205-1_lungback.webm from audios/20220305090421_LCC%20fe%205-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305090421_LCC%20fe%205-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220305090421_LCC%20fe%205-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220305090421_LCC%20fe%205-1_lungback.webm [loudness: -31 dB]\n",
            "  Clip 4 from 20220305090421_LCC%20fe%205-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220305090421_LCC%20fe%205-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220305090421_LCC%20fe%205-1_lungback.webm [loudness: -37 dB]\n",
            "  Clip 7 from 20220305090421_LCC%20fe%205-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220305090421_LCC%20fe%205-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 9 from 20220305090421_LCC%20fe%205-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124160633_RALL%20fe_vocal.webm from audios/20220124160633_RALL%20fe_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220124160633_RALL%20fe_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220124160633_RALL%20fe_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220124160633_RALL%20fe_vocal.webm [loudness: -10 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202104151_Mcp-02-12-D5_vocal.webm from audios/20211202104151_Mcp-02-12-D5_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20211202104151_Mcp-02-12-D5_vocal.webm [loudness: -90 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -90 dB]\n",
            "  Clip 2 from 20211202104151_Mcp-02-12-D5_vocal.webm [loudness: -94 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -94 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220302081528_EGDC%20fe%202-1_lungfront.webm from audios/20220302081528_EGDC%20fe%202-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220302081528_EGDC%20fe%202-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220302081528_EGDC%20fe%202-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20220302081528_EGDC%20fe%202-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220302081528_EGDC%20fe%202-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220302081528_EGDC%20fe%202-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220302081528_EGDC%20fe%202-1_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 7 from 20220302081528_EGDC%20fe%202-1_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 8 from 20220302081528_EGDC%20fe%202-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125122834_RPY%20es_lungfront.webm from audios/20220125122834_RPY%20es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125122834_RPY%20es_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220125122834_RPY%20es_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220125122834_RPY%20es_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220125122834_RPY%20es_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220125122834_RPY%20es_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117141014_MACL_lungfront.webm from audios/20220117141014_MACL_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220117141014_MACL_lungfront.webm [loudness: -85 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -85 dB]\n",
            "  Clip 2 from 20220117141014_MACL_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 3 from 20220117141014_MACL_lungfront.webm [loudness: -91 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -91 dB]\n",
            "  Clip 4 from 20220117141014_MACL_lungfront.webm [loudness: -76 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 5 from 20220117141014_MACL_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 6 from 20220117141014_MACL_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708103953_FDV%20fe-1_lungback.webm from audios/20220708103953_FDV%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 10 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 11 from 20220708103953_FDV%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303082111_JFC%20fe%203-1_vocal.webm from audios/20220303082111_JFC%20fe%203-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220303082111_JFC%20fe%203-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220303082111_JFC%20fe%203-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220303082111_JFC%20fe%203-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220303082111_JFC%20fe%203-1_vocal.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219084905_MGCH%2030-1_lungback.webm from audios/20220219084905_MGCH%2030-1_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220219084905_MGCH%2030-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220219084905_MGCH%2030-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220219084905_MGCH%2030-1_lungback.webm [loudness: -40 dB]\n",
            "  Clip 4 from 20220219084905_MGCH%2030-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20220219084905_MGCH%2030-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20220219084905_MGCH%2030-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 7 from 20220219084905_MGCH%2030-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207055043_ADW-P2_vocal.webm from audios/20211207055043_ADW-P2_vocal.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20211207055043_ADW-P2_vocal.webm [loudness: -71 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 2 from 20211207055043_ADW-P2_vocal.webm [loudness: -70 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 3 from 20211207055043_ADW-P2_vocal.webm [loudness: -71 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 4 from 20211207055043_ADW-P2_vocal.webm [loudness: -71 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 5 from 20211207055043_ADW-P2_vocal.webm [loudness: -72 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 6 from 20211207055043_ADW-P2_vocal.webm [loudness: -73 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 7 from 20211207055043_ADW-P2_vocal.webm [loudness: -72 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -72 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230424124430_RT%20fe-1_lungfront.webm from audios/20230424124430_RT%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424124430_RT%20fe-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20230424124430_RT%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20230424124430_RT%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20230424124430_RT%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20230424124430_RT%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230424124430_RT%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20230424124430_RT%20fe-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20230424124430_RT%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20230424124430_RT%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 10 from 20230424124430_RT%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075914_SYV%2027-2_vocal.webm from audios/20220215075914_SYV%2027-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220215075914_SYV%2027-2_vocal.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220215075914_SYV%2027-2_vocal.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220215075914_SYV%2027-2_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128135337_PCSN%20fE_vocal.webm from audios/20220128135337_PCSN%20fE_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220128135337_PCSN%20fE_vocal.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220128135337_PCSN%20fE_vocal.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220128135337_PCSN%20fE_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220128135337_PCSN%20fE_vocal.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207055444_ACW-P3_lungback.webm from audios/20211207055444_ACW-P3_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207055444_ACW-P3_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20211207055444_ACW-P3_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20211207055444_ACW-P3_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20211207055444_ACW-P3_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20211207055444_ACW-P3_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20211207055444_ACW-P3_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107152508_RCET_lungfront.webm from audios/20220107152508_RCET_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220107152508_RCET_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 2 from 20220107152508_RCET_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220107152508_RCET_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 4 from 20220107152508_RCET_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 5 from 20220107152508_RCET_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 6 from 20220107152508_RCET_lungfront.webm [loudness: -46 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305074538_KMI%20fe%205-1_lungback.webm from audios/20220305074538_KMI%20fe%205-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305074538_KMI%20fe%205-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220305074538_KMI%20fe%205-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220305074538_KMI%20fe%205-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220305074538_KMI%20fe%205-1_lungback.webm [loudness: -11 dB]\n",
            "  Clip 5 from 20220305074538_KMI%20fe%205-1_lungback.webm [loudness: -11 dB]\n",
            "  Clip 6 from 20220305074538_KMI%20fe%205-1_lungback.webm [loudness: -11 dB]\n",
            "  Clip 7 from 20220305074538_KMI%20fe%205-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220305074538_KMI%20fe%205-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220305074538_KMI%20fe%205-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123054048_Fe-1%20GCh_lungfront.webm from audios/20221123054048_Fe-1%20GCh_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20221123054048_Fe-1%20GCh_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20221123054048_Fe-1%20GCh_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20221123054048_Fe-1%20GCh_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20221123054048_Fe-1%20GCh_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20221123054048_Fe-1%20GCh_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20221123054048_Fe-1%20GCh_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20221123054048_Fe-1%20GCh_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20221123054048_Fe-1%20GCh_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302090942_ANP%20fe%202-1_lungback.webm from audios/20220302090942_ANP%20fe%202-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220302090942_ANP%20fe%202-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220302090942_ANP%20fe%202-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220302090942_ANP%20fe%202-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220302090942_ANP%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220302090942_ANP%20fe%202-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220302090942_ANP%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220302090942_ANP%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220302090942_ANP%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220302090942_ANP%20fe%202-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20220302090942_ANP%20fe%202-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117141014_MACL_vocal.webm from audios/20220117141014_MACL_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220117141014_MACL_vocal.webm [loudness: -44 dB]\n",
            "  Clip 2 from 20220117141014_MACL_vocal.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220727094501_CCG%20fe-1_lungfront.webm from audios/20220727094501_CCG%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220727094501_CCG%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220727094501_CCG%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220727094501_CCG%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220727094501_CCG%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220727094501_CCG%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220727094501_CCG%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220727094501_CCG%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220727094501_CCG%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220727094501_CCG%20fe-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125160128_MMLJ%20fe_vocal.webm from audios/20220125160128_MMLJ%20fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220125160128_MMLJ%20fe_vocal.webm [loudness: -33 dB]\n",
            "  Clip 2 from 20220125160128_MMLJ%20fe_vocal.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220125160128_MMLJ%20fe_vocal.webm [loudness: -33 dB]\n",
            "  Clip 4 from 20220125160128_MMLJ%20fe_vocal.webm [loudness: -41 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207055653_ADW-P4_vocal.webm from audios/20211207055653_ADW-P4_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20211207055653_ADW-P4_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20211207055653_ADW-P4_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20211207055653_ADW-P4_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20211207055653_ADW-P4_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20211207055653_ADW-P4_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220630100058_ARB%20fe-2_vocal.webm from audios/20220630100058_ARB%20fe-2_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220630100058_ARB%20fe-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220630100058_ARB%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220630100058_ARB%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220630100058_ARB%20fe-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220630100058_ARB%20fe-2_vocal.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119165019_SKMT_lungback.webm from audios/20220119165019_SKMT_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220119165019_SKMT_lungback.webm [loudness: -67 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 2 from 20220119165019_SKMT_lungback.webm [loudness: -72 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 3 from 20220119165019_SKMT_lungback.webm [loudness: -67 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 4 from 20220119165019_SKMT_lungback.webm [loudness: -82 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -82 dB]\n",
            "  Clip 5 from 20220119165019_SKMT_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220119141214_MAAR_vocal.webm from audios/20220119141214_MAAR_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220119141214_MAAR_vocal.webm [loudness: -7 dB]\n",
            "  Clip 2 from 20220119141214_MAAR_vocal.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304082033_MQR%20fe%204-1_vocal.webm from audios/20220304082033_MQR%20fe%204-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220304082033_MQR%20fe%204-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220304082033_MQR%20fe%204-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220304082033_MQR%20fe%204-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220304082033_MQR%20fe%204-1_vocal.webm [loudness: -51 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212070643_Jmt%2017-2_lungfront.webm from audios/20220212070643_Jmt%2017-2_lungfront.webm\n",
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 2 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 3 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 4 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 5 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 6 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 7 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 8 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 9 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 10 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 11 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 12 from 20220212070643_Jmt%2017-2_lungfront.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319073711_PRC%20fe%2019-1_lungfront.webm from audios/20220319073711_PRC%20fe%2019-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319073711_PRC%20fe%2019-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220319073711_PRC%20fe%2019-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220319073711_PRC%20fe%2019-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220319073711_PRC%20fe%2019-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220319073711_PRC%20fe%2019-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220319073711_PRC%20fe%2019-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220319073711_PRC%20fe%2019-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 8 from 20220319073711_PRC%20fe%2019-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220319073711_PRC%20fe%2019-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107155508_GHR_vocal.webm from audios/20220107155508_GHR_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220107155508_GHR_vocal.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220107155508_GHR_vocal.webm [loudness: -41 dB]\n",
            "  Clip 3 from 20220107155508_GHR_vocal.webm [loudness: -39 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120104224_CRMT_vocal.webm from audios/20220120104224_CRMT_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220120104224_CRMT_vocal.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20220120104224_CRMT_vocal.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220120104224_CRMT_vocal.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220120104224_CRMT_vocal.webm [loudness: -42 dB]\n",
            "  Clip 5 from 20220120104224_CRMT_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419104420_RP%20fe-1_vocal.webm from audios/20230419104420_RP%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230419104420_RP%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20230419104420_RP%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230419104420_RP%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230419104420_RP%20fe-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127103801_CHLA%20es_lungback.webm from audios/20220127103801_CHLA%20es_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220127103801_CHLA%20es_lungback.webm [loudness: -86 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 2 from 20220127103801_CHLA%20es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220127103801_CHLA%20es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220127103801_CHLA%20es_lungback.webm [loudness: -47 dB]\n",
            "  Clip 5 from 20220127103801_CHLA%20es_lungback.webm [loudness: -69 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 6 from 20220127103801_CHLA%20es_lungback.webm [loudness: -102 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -102 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302081802_EPV%20fe%202-1_lungback.webm from audios/20220302081802_EPV%20fe%202-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302081802_EPV%20fe%202-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220302081802_EPV%20fe%202-1_lungback.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20220302081802_EPV%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220302081802_EPV%20fe%202-1_lungback.webm [loudness: -30 dB]\n",
            "  Clip 5 from 20220302081802_EPV%20fe%202-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20220302081802_EPV%20fe%202-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220302081802_EPV%20fe%202-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20220302081802_EPV%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220302081802_EPV%20fe%202-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304051252_PBZ%20fe%204-1_lungfront.webm from audios/20220304051252_PBZ%20fe%204-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304051252_PBZ%20fe%204-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220304051252_PBZ%20fe%204-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220304051252_PBZ%20fe%204-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220304051252_PBZ%20fe%204-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220304051252_PBZ%20fe%204-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220304051252_PBZ%20fe%204-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220304051252_PBZ%20fe%204-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220304051252_PBZ%20fe%204-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20220304051252_PBZ%20fe%204-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114152135_VRP_lungback.webm from audios/20220114152135_VRP_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220114152135_VRP_lungback.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20220114152135_VRP_lungback.webm [loudness: -51 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 3 from 20220114152135_VRP_lungback.webm [loudness: -52 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 4 from 20220114152135_VRP_lungback.webm [loudness: -52 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 5 from 20220114152135_VRP_lungback.webm [loudness: -52 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 6 from 20220114152135_VRP_lungback.webm [loudness: -52 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -52 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220303091025_JAR%20fe%203-1_vocal.webm from audios/20220303091025_JAR%20fe%203-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220303091025_JAR%20fe%203-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220303091025_JAR%20fe%203-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220303091025_JAR%20fe%203-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220303091025_JAR%20fe%203-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302092611_SLlJ%20fe%202-1_vocal.webm from audios/20220302092611_SLlJ%20fe%202-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302092611_SLlJ%20fe%202-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220302092611_SLlJ%20fe%202-1_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220302092611_SLlJ%20fe%202-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220302092611_SLlJ%20fe%202-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304053013_LRM%20fe%204-1_lungback.webm from audios/20220304053013_LRM%20fe%204-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304053013_LRM%20fe%204-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220304053013_LRM%20fe%204-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220304053013_LRM%20fe%204-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220304053013_LRM%20fe%204-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220304053013_LRM%20fe%204-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220304053013_LRM%20fe%204-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220304053013_LRM%20fe%204-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220304053013_LRM%20fe%204-1_lungback.webm [loudness: -9 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118151408_TZP_vocal.webm from audios/20220118151408_TZP_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220118151408_TZP_vocal.webm [loudness: -7 dB]\n",
            "  Clip 2 from 20220118151408_TZP_vocal.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212072243_Lml%2020-1_lungfront.webm from audios/20220212072243_Lml%2020-1_lungfront.webm\n",
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 3 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -40 dB]\n",
            "  Clip 4 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 5 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -38 dB]\n",
            "  Clip 6 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 7 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 8 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 9 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -38 dB]\n",
            "  Clip 10 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 11 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 12 from 20220212072243_Lml%2020-1_lungfront.webm [loudness: -42 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418103221_Av%20fe-1_lungfront.webm from audios/20230418103221_Av%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230418103221_Av%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20230418103221_Av%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20230418103221_Av%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230418103221_Av%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20230418103221_Av%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20230418103221_Av%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230418103221_Av%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20230418103221_Av%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 9 from 20230418103221_Av%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 10 from 20230418103221_Av%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419124433_LG%20fe-2_vocal.webm from audios/20230419124433_LG%20fe-2_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230419124433_LG%20fe-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20230419124433_LG%20fe-2_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20230419124433_LG%20fe-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20230419124433_LG%20fe-2_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604055424_JFC%20fe-1_vocal.webm from audios/20220604055424_JFC%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220604055424_JFC%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220604055424_JFC%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220604055424_JFC%20fe-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220604055424_JFC%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207131017_Fe-1%20MA_lungfront.webm from audios/20221207131017_Fe-1%20MA_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221207131017_Fe-1%20MA_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20221207131017_Fe-1%20MA_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20221207131017_Fe-1%20MA_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20221207131017_Fe-1%20MA_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20221207131017_Fe-1%20MA_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20221207131017_Fe-1%20MA_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20221207131017_Fe-1%20MA_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 8 from 20221207131017_Fe-1%20MA_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20221207131017_Fe-1%20MA_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107110951_SMAJ_lungfront.webm from audios/20220107110951_SMAJ_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220107110951_SMAJ_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20220107110951_SMAJ_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 3 from 20220107110951_SMAJ_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220107110951_SMAJ_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 5 from 20220107110951_SMAJ_lungfront.webm [loudness: -76 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 6 from 20220107110951_SMAJ_lungfront.webm [loudness: -94 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -94 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420074758_ACH%20fe-1_vocal.webm from audios/20230420074758_ACH%20fe-1_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20230420074758_ACH%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20230420074758_ACH%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20230420074758_ACH%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20230420074758_ACH%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20230420074758_ACH%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230420074758_ACH%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212070643_Jmt%2017-2_vocal.webm from audios/20220212070643_Jmt%2017-2_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212070643_Jmt%2017-2_vocal.webm [loudness: -28 dB]\n",
            "  Clip 2 from 20220212070643_Jmt%2017-2_vocal.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220212070643_Jmt%2017-2_vocal.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220625095154_DM%20fe-2_lungback.webm from audios/20220625095154_DM%20fe-2_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220625095154_DM%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220625095154_DM%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220625095154_DM%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220625095154_DM%20fe-2_lungback.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220625095154_DM%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220625095154_DM%20fe-2_lungback.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20220625095154_DM%20fe-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220625095154_DM%20fe-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220625095154_DM%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 10 from 20220625095154_DM%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418102811_LR%20fe-1_lungback.webm from audios/20230418102811_LR%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 10 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 11 from 20230418102811_LR%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709073607_RCM%20fe-2_lungback.webm from audios/20220709073607_RCM%20fe-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709073607_RCM%20fe-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220709073607_RCM%20fe-2_lungback.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220709073607_RCM%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220709073607_RCM%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220709073607_RCM%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220709073607_RCM%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220709073607_RCM%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220709073607_RCM%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220709073607_RCM%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212080851_Mmb%2022.1_lungfront.webm from audios/20220212080851_Mmb%2022.1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220212080851_Mmb%2022.1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220212080851_Mmb%2022.1_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 3 from 20220212080851_Mmb%2022.1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220212080851_Mmb%2022.1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 5 from 20220212080851_Mmb%2022.1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 6 from 20220212080851_Mmb%2022.1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220212080851_Mmb%2022.1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 8 from 20220212080851_Mmb%2022.1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 9 from 20220212080851_Mmb%2022.1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 10 from 20220212080851_Mmb%2022.1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105124255_PTR_vocal.webm from audios/20220105124255_PTR_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220105124255_PTR_vocal.webm [loudness: -41 dB]\n",
            "  Clip 2 from 20220105124255_PTR_vocal.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220105124255_PTR_vocal.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220105124255_PTR_vocal.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220105124255_PTR_vocal.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220105124255_PTR_vocal.webm [loudness: -64 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708085349_FHA%20fe-1_lungfront.webm from audios/20220708085349_FHA%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220708085349_FHA%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220708085349_FHA%20fe-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220708085349_FHA%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220708085349_FHA%20fe-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20220708085349_FHA%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20220708085349_FHA%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220708085349_FHA%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220708085349_FHA%20fe-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 9 from 20220708085349_FHA%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125155955_MMLJ%20es_vocal.webm from audios/20220125155955_MMLJ%20es_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125155955_MMLJ%20es_vocal.webm [loudness: -48 dB]\n",
            "  Clip 2 from 20220125155955_MMLJ%20es_vocal.webm [loudness: -48 dB]\n",
            "  Clip 3 from 20220125155955_MMLJ%20es_vocal.webm [loudness: -46 dB]\n",
            "  Clip 4 from 20220125155955_MMLJ%20es_vocal.webm [loudness: -43 dB]\n",
            "  Clip 5 from 20220125155955_MMLJ%20es_vocal.webm [loudness: -42 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114163111_JASR_lungback.webm from audios/20220114163111_JASR_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220114163111_JASR_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220114163111_JASR_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220114163111_JASR_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220114163111_JASR_lungback.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220114163111_JASR_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220114163111_JASR_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420074758_ACH%20fe-1_lungfront.webm from audios/20230420074758_ACH%20fe-1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230420074758_ACH%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20230420074758_ACH%20fe-1_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 3 from 20230420074758_ACH%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20230420074758_ACH%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20230420074758_ACH%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20230420074758_ACH%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20230420074758_ACH%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20230420074758_ACH%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20230420074758_ACH%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20230420074758_ACH%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215074545_Zmg%2025-2_vocal.webm from audios/20220215074545_Zmg%2025-2_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220215074545_Zmg%2025-2_vocal.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20220215074545_Zmg%2025-2_vocal.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220215074545_Zmg%2025-2_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420074758_ACH%20fe-1_lungback.webm from audios/20230420074758_ACH%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230420074758_ACH%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230420074758_ACH%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20230420074758_ACH%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20230420074758_ACH%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20230420074758_ACH%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230420074758_ACH%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20230420074758_ACH%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20230420074758_ACH%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20230420074758_ACH%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20230420074758_ACH%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302054305_DAT%20fe%202-2_lungfront.webm from audios/20220302054305_DAT%20fe%202-2_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220302054305_DAT%20fe%202-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220302054305_DAT%20fe%202-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220302054305_DAT%20fe%202-2_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 4 from 20220302054305_DAT%20fe%202-2_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 5 from 20220302054305_DAT%20fe%202-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220302054305_DAT%20fe%202-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 7 from 20220302054305_DAT%20fe%202-2_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 8 from 20220302054305_DAT%20fe%202-2_lungfront.webm [loudness: -40 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125112846_DAKP%20fe_lungfront.webm from audios/20220125112846_DAKP%20fe_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125112846_DAKP%20fe_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220125112846_DAKP%20fe_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220125112846_DAKP%20fe_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220125112846_DAKP%20fe_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220125112846_DAKP%20fe_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302060619_PRC%20fe%202-2_lungfront.webm from audios/20220302060619_PRC%20fe%202-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302060619_PRC%20fe%202-2_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220302060619_PRC%20fe%202-2_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220302060619_PRC%20fe%202-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220302060619_PRC%20fe%202-2_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20220302060619_PRC%20fe%202-2_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20220302060619_PRC%20fe%202-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220302060619_PRC%20fe%202-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220302060619_PRC%20fe%202-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220302060619_PRC%20fe%202-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212064149_Rgh%2016-1_lungback.webm from audios/20220212064149_Rgh%2016-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 14 2s clips\n",
            "  Clip 1 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -65 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 4 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -63 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 5 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -54 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 6 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 9 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -63 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 10 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 11 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -63 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 12 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -64 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 13 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 13 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 14 from 20220212064149_Rgh%2016-1_lungback.webm [loudness: -62 dB]\n",
            "  Clip 14 Skip...too quiet [loudness: -62 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220302081247_TZP%20fe%202-2_lungback.webm from audios/20220302081247_TZP%20fe%202-2_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220302081247_TZP%20fe%202-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220302081247_TZP%20fe%202-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220302081247_TZP%20fe%202-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220302081247_TZP%20fe%202-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220302081247_TZP%20fe%202-2_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220302081247_TZP%20fe%202-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220302081247_TZP%20fe%202-2_lungback.webm [loudness: -28 dB]\n",
            "  Clip 8 from 20220302081247_TZP%20fe%202-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115130617_RVPP_lungfront.webm from audios/20220115130617_RVPP_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115130617_RVPP_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 2 from 20220115130617_RVPP_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220115130617_RVPP_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 4 from 20220115130617_RVPP_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 5 from 20220115130617_RVPP_lungfront.webm [loudness: -44 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516150119_Wgyv1-16-5_lungback.webm from audios/20220516150119_Wgyv1-16-5_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516150119_Wgyv1-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220516150119_Wgyv1-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220516150119_Wgyv1-16-5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220516150119_Wgyv1-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220516150119_Wgyv1-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220516150119_Wgyv1-16-5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220516150119_Wgyv1-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220516150119_Wgyv1-16-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419104705_MG%20fe-1_lungfront.webm from audios/20230419104705_MG%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419104705_MG%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20230419104705_MG%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20230419104705_MG%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20230419104705_MG%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20230419104705_MG%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20230419104705_MG%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20230419104705_MG%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20230419104705_MG%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20230419104705_MG%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230419104705_MG%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304053013_LRM%20fe%204-1_vocal.webm from audios/20220304053013_LRM%20fe%204-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220304053013_LRM%20fe%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220304053013_LRM%20fe%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220304053013_LRM%20fe%204-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220304053013_LRM%20fe%204-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305054143_MST%20fe%205-1_lungback.webm from audios/20220305054143_MST%20fe%205-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220305054143_MST%20fe%205-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220305054143_MST%20fe%205-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220305054143_MST%20fe%205-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220305054143_MST%20fe%205-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220305054143_MST%20fe%205-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220305054143_MST%20fe%205-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220305054143_MST%20fe%205-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220305054143_MST%20fe%205-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220305054143_MST%20fe%205-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20220305054143_MST%20fe%205-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220727082823_FSM%20fe-1_vocal.webm from audios/20220727082823_FSM%20fe-1_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220727082823_FSM%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220727082823_FSM%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220727082823_FSM%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220727082823_FSM%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220727082823_FSM%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220727082823_FSM%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127104054_CHLA%20fe_lungback.webm from audios/20220127104054_CHLA%20fe_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220127104054_CHLA%20fe_lungback.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20220127104054_CHLA%20fe_lungback.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220127104054_CHLA%20fe_lungback.webm [loudness: -62 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 4 from 20220127104054_CHLA%20fe_lungback.webm [loudness: -68 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 5 from 20220127104054_CHLA%20fe_lungback.webm [loudness: -66 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 6 from 20220127104054_CHLA%20fe_lungback.webm [loudness: -64 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -64 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220319054519_XLS%20fe%2019-1_vocal.webm from audios/20220319054519_XLS%20fe%2019-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220319054519_XLS%20fe%2019-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220319054519_XLS%20fe%2019-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220319054519_XLS%20fe%2019-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220319054519_XLS%20fe%2019-1_vocal.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212071822_Gbc%2019-2_lungfront.webm from audios/20220212071822_Gbc%2019-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 13 2s clips\n",
            "  Clip 1 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 2 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 3 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 4 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 6 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -42 dB]\n",
            "  Clip 7 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 8 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 9 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -42 dB]\n",
            "  Clip 10 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 11 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 12 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 13 from 20220212071822_Gbc%2019-2_lungfront.webm [loudness: -37 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128110729_MCEE%20Fe_vocal.webm from audios/20220128110729_MCEE%20Fe_vocal.webm\n",
            "Error loading 20220128110729_MCEE%20Fe_vocal.webm: . Removing from files_map.\n",
            "\n",
            "Loading file: 20220126113139_BMY%20es_lungfront.webm from audios/20220126113139_BMY%20es_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220126113139_BMY%20es_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220126113139_BMY%20es_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 3 from 20220126113139_BMY%20es_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 4 from 20220126113139_BMY%20es_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 5 from 20220126113139_BMY%20es_lungfront.webm [loudness: -97 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -97 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220319073711_PRC%20fe%2019-1_vocal.webm from audios/20220319073711_PRC%20fe%2019-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220319073711_PRC%20fe%2019-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220319073711_PRC%20fe%2019-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220319073711_PRC%20fe%2019-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220319073711_PRC%20fe%2019-1_vocal.webm [loudness: -35 dB]\n",
            "  Clip 5 from 20220319073711_PRC%20fe%2019-1_vocal.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419130616_MO%20fe-1_lungback.webm from audios/20230419130616_MO%20fe-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230419130616_MO%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20230419130616_MO%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20230419130616_MO%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20230419130616_MO%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20230419130616_MO%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230419130616_MO%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20230419130616_MO%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20230419130616_MO%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20230419130616_MO%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302091211_APM%20fe%202-1_vocal.webm from audios/20220302091211_APM%20fe%202-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220302091211_APM%20fe%202-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220302091211_APM%20fe%202-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220302091211_APM%20fe%202-1_vocal.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220302091211_APM%20fe%202-1_vocal.webm [loudness: -43 dB]\n",
            "  Clip 5 from 20220302091211_APM%20fe%202-1_vocal.webm [loudness: -44 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20221213121136_Fe-1%20GM_lungback.webm from audios/20221213121136_Fe-1%20GM_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221213121136_Fe-1%20GM_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20221213121136_Fe-1%20GM_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20221213121136_Fe-1%20GM_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20221213121136_Fe-1%20GM_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20221213121136_Fe-1%20GM_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20221213121136_Fe-1%20GM_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20221213121136_Fe-1%20GM_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20221213121136_Fe-1%20GM_lungback.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20221213121136_Fe-1%20GM_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128104455_AASE_lungfront.webm from audios/20220128104455_AASE_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128104455_AASE_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220128104455_AASE_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220128104455_AASE_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220128104455_AASE_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220128104455_AASE_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125140524_NRJJ%20es_vocal.webm from audios/20220125140524_NRJJ%20es_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125140524_NRJJ%20es_vocal.webm [loudness: -40 dB]\n",
            "  Clip 2 from 20220125140524_NRJJ%20es_vocal.webm [loudness: -38 dB]\n",
            "  Clip 3 from 20220125140524_NRJJ%20es_vocal.webm [loudness: -35 dB]\n",
            "  Clip 4 from 20220125140524_NRJJ%20es_vocal.webm [loudness: -34 dB]\n",
            "  Clip 5 from 20220125140524_NRJJ%20es_vocal.webm [loudness: -34 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075914_SYV%2027-2_lungfront.webm from audios/20220215075914_SYV%2027-2_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220215075914_SYV%2027-2_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 2 from 20220215075914_SYV%2027-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220215075914_SYV%2027-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 4 from 20220215075914_SYV%2027-2_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 5 from 20220215075914_SYV%2027-2_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 6 from 20220215075914_SYV%2027-2_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 7 from 20220215075914_SYV%2027-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 8 from 20220215075914_SYV%2027-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709054937_CNE%20fe-2_vocal.webm from audios/20220709054937_CNE%20fe-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220709054937_CNE%20fe-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220709054937_CNE%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220709054937_CNE%20fe-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220709054937_CNE%20fe-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220709054937_CNE%20fe-2_vocal.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220709054937_CNE%20fe-2_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802083643_JQZ%20fe-2_lungback.webm from audios/20220802083643_JQZ%20fe-2_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220802083643_JQZ%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220802083643_JQZ%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220802083643_JQZ%20fe-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220802083643_JQZ%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220802083643_JQZ%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220802083643_JQZ%20fe-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220802083643_JQZ%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220802083643_JQZ%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220802083643_JQZ%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124124846_AOLR%20fe_lungback.webm from audios/20220124124846_AOLR%20fe_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220124124846_AOLR%20fe_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220124124846_AOLR%20fe_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220124124846_AOLR%20fe_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220124124846_AOLR%20fe_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220124124846_AOLR%20fe_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220124124846_AOLR%20fe_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064407_JMT-P3_lungfront.webm from audios/20211209064407_JMT-P3_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211209064407_JMT-P3_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20211209064407_JMT-P3_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20211209064407_JMT-P3_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 4 from 20211209064407_JMT-P3_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 5 from 20211209064407_JMT-P3_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 6 from 20211209064407_JMT-P3_lungfront.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212080851_Mmb%2022.1_lungback.webm from audios/20220212080851_Mmb%2022.1_lungback.webm\n",
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -35 dB]\n",
            "  Clip 2 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 4 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 8 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 9 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 10 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 11 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 12 from 20220212080851_Mmb%2022.1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119134648_MILS_lungfront.webm from audios/20220119134648_MILS_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220119134648_MILS_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220119134648_MILS_lungfront.webm [loudness: -6 dB]\n",
            "  Clip 3 from 20220119134648_MILS_lungfront.webm [loudness: -7 dB]\n",
            "  Clip 4 from 20220119134648_MILS_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 5 from 20220119134648_MILS_lungfront.webm [loudness: -8 dB]\n",
            "  Clip 6 from 20220119134648_MILS_lungfront.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122140243_MRGM%20fe_vocal.webm from audios/20220122140243_MRGM%20fe_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122140243_MRGM%20fe_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220122140243_MRGM%20fe_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220122140243_MRGM%20fe_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220122140243_MRGM%20fe_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220122140243_MRGM%20fe_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420111142_FT%20fe-1_lungfront.webm from audios/20230420111142_FT%20fe-1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230420111142_FT%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230420111142_FT%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20230420111142_FT%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230420111142_FT%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20230420111142_FT%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230420111142_FT%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20230420111142_FT%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20230420111142_FT%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230420111142_FT%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 10 from 20230420111142_FT%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302064348_RMC%20fe%202-1_lungfront.webm from audios/20220302064348_RMC%20fe%202-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 7 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 9 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 10 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 11 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 12 from 20220302064348_RMC%20fe%202-1_lungfront.webm [loudness: -39 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (12, 512), data type: float32\n",
            "\n",
            "Loading file: 20221223095536_Fe-1%20GB_vocal.webm from audios/20221223095536_Fe-1%20GB_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221223095536_Fe-1%20GB_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20221223095536_Fe-1%20GB_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20221223095536_Fe-1%20GB_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20221223095536_Fe-1%20GB_vocal.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20221223095536_Fe-1%20GB_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304083114_AMQ%20fe%204-1_lungfront.webm from audios/20220304083114_AMQ%20fe%204-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304083114_AMQ%20fe%204-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220304083114_AMQ%20fe%204-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220304083114_AMQ%20fe%204-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220304083114_AMQ%20fe%204-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220304083114_AMQ%20fe%204-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220304083114_AMQ%20fe%204-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220304083114_AMQ%20fe%204-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20220304083114_AMQ%20fe%204-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118111208_XAW_lungback.webm from audios/20220118111208_XAW_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118111208_XAW_lungback.webm [loudness: -40 dB]\n",
            "  Clip 2 from 20220118111208_XAW_lungback.webm [loudness: -30 dB]\n",
            "  Clip 3 from 20220118111208_XAW_lungback.webm [loudness: -84 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -84 dB]\n",
            "  Clip 4 from 20220118111208_XAW_lungback.webm [loudness: -50 dB]\n",
            "  Clip 5 from 20220118111208_XAW_lungback.webm [loudness: -50 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319061032_ECO%20fe%2019-1_lungfront.webm from audios/20220319061032_ECO%20fe%2019-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220319061032_ECO%20fe%2019-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220319061032_ECO%20fe%2019-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220319061032_ECO%20fe%2019-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220319061032_ECO%20fe%2019-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220319061032_ECO%20fe%2019-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220319061032_ECO%20fe%2019-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220319061032_ECO%20fe%2019-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220319061032_ECO%20fe%2019-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064253_JMT-P2_lungback.webm from audios/20211209064253_JMT-P2_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211209064253_JMT-P2_lungback.webm [loudness: -34 dB]\n",
            "  Clip 2 from 20211209064253_JMT-P2_lungback.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20211209064253_JMT-P2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 4 from 20211209064253_JMT-P2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 5 from 20211209064253_JMT-P2_lungback.webm [loudness: -60 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 6 from 20211209064253_JMT-P2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126150050_AOLR%20Fe_lungfront.webm from audios/20220126150050_AOLR%20Fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220126150050_AOLR%20Fe_lungfront.webm [loudness: -64 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 2 from 20220126150050_AOLR%20Fe_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 3 from 20220126150050_AOLR%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220126150050_AOLR%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220126150050_AOLR%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516153654_Jasr2-16-05_vocal.webm from audios/20220516153654_Jasr2-16-05_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516153654_Jasr2-16-05_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220516153654_Jasr2-16-05_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220516153654_Jasr2-16-05_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220516153654_Jasr2-16-05_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212065239_ATC%2017-2_lungfront.webm from audios/20220212065239_ATC%2017-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 2 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 11 from 20220212065239_ATC%2017-2_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708085349_FHA%20fe-1_lungback.webm from audios/20220708085349_FHA%20fe-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220708085349_FHA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220708085349_FHA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220708085349_FHA%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220708085349_FHA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220708085349_FHA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220708085349_FHA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220708085349_FHA%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220708085349_FHA%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20220708085349_FHA%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118162724_SAA_vocal.webm from audios/20220118162724_SAA_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220118162724_SAA_vocal.webm [loudness: -29 dB]\n",
            "  Clip 2 from 20220118162724_SAA_vocal.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220118162724_SAA_vocal.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220118162724_SAA_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114114719_HIRP_vocal.webm from audios/20220114114719_HIRP_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220114114719_HIRP_vocal.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20220114114719_HIRP_vocal.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220114114719_HIRP_vocal.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220525092038_Pt%20fe-1_lungfront.webm from audios/20220525092038_Pt%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220525092038_Pt%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220525092038_Pt%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220525092038_Pt%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220525092038_Pt%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220525092038_Pt%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220525092038_Pt%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220525092038_Pt%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220525092038_Pt%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220525092038_Pt%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302063901_JGA%20fe%202-1_lungfront.webm from audios/20220302063901_JGA%20fe%202-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220302063901_JGA%20fe%202-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220302063901_JGA%20fe%202-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220302063901_JGA%20fe%202-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 4 from 20220302063901_JGA%20fe%202-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220302063901_JGA%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220302063901_JGA%20fe%202-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220302063901_JGA%20fe%202-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220302063901_JGA%20fe%202-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119112335_SMAC_lungfront.webm from audios/20220119112335_SMAC_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220119112335_SMAC_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220119112335_SMAC_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220119112335_SMAC_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220119112335_SMAC_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220119112335_SMAC_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220224135946_ARD%2033-2_vocal.webm from audios/20220224135946_ARD%2033-2_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220224135946_ARD%2033-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220224135946_ARD%2033-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220224135946_ARD%2033-2_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108174158_MFRJ_lungfront.webm from audios/20220108174158_MFRJ_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220108174158_MFRJ_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 2 from 20220108174158_MFRJ_lungfront.webm [loudness: -40 dB]\n",
            "  Clip 3 from 20220108174158_MFRJ_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 4 from 20220108174158_MFRJ_lungfront.webm [loudness: -64 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 5 from 20220108174158_MFRJ_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 6 from 20220108174158_MFRJ_lungfront.webm [loudness: -103 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -103 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108135008_LSH_lungback.webm from audios/20220108135008_LSH_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220108135008_LSH_lungback.webm [loudness: -29 dB]\n",
            "  Clip 2 from 20220108135008_LSH_lungback.webm [loudness: -42 dB]\n",
            "  Clip 3 from 20220108135008_LSH_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220108135008_LSH_lungback.webm [loudness: -45 dB]\n",
            "  Clip 5 from 20220108135008_LSH_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220108135008_LSH_lungback.webm [loudness: -37 dB]\n",
            "  Clip 7 from 20220108135008_LSH_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127113235_NRJJ%20Fe_vocal.webm from audios/20220127113235_NRJJ%20Fe_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127113235_NRJJ%20Fe_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220127113235_NRJJ%20Fe_vocal.webm [loudness: -7 dB]\n",
            "  Clip 3 from 20220127113235_NRJJ%20Fe_vocal.webm [loudness: -6 dB]\n",
            "  Clip 4 from 20220127113235_NRJJ%20Fe_vocal.webm [loudness: -9 dB]\n",
            "  Clip 5 from 20220127113235_NRJJ%20Fe_vocal.webm [loudness: -10 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126125056_ABM%20fe_lungfront.webm from audios/20220126125056_ABM%20fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220126125056_ABM%20fe_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 2 from 20220126125056_ABM%20fe_lungfront.webm [loudness: -104 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -104 dB]\n",
            "  Clip 3 from 20220126125056_ABM%20fe_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220126125056_ABM%20fe_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 5 from 20220126125056_ABM%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220212064424_Rgh%2016-2_vocal.webm from audios/20220212064424_Rgh%2016-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212064424_Rgh%2016-2_vocal.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220212064424_Rgh%2016-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220212064424_Rgh%2016-2_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319054519_XLS%20fe%2019-1_lungfront.webm from audios/20220319054519_XLS%20fe%2019-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319054519_XLS%20fe%2019-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220319054519_XLS%20fe%2019-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220319054519_XLS%20fe%2019-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220319054519_XLS%20fe%2019-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220319054519_XLS%20fe%2019-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220319054519_XLS%20fe%2019-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 7 from 20220319054519_XLS%20fe%2019-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220319054519_XLS%20fe%2019-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220319054519_XLS%20fe%2019-1_lungfront.webm [loudness: -32 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304062221_DSC%20fe%204-1_lungback.webm from audios/20220304062221_DSC%20fe%204-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304062221_DSC%20fe%204-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220304062221_DSC%20fe%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220304062221_DSC%20fe%204-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220304062221_DSC%20fe%204-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20220304062221_DSC%20fe%204-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220304062221_DSC%20fe%204-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220304062221_DSC%20fe%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220304062221_DSC%20fe%204-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220304062221_DSC%20fe%204-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075217_TRC%2026-2_vocal.webm from audios/20220215075217_TRC%2026-2_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220215075217_TRC%2026-2_vocal.webm [loudness: -33 dB]\n",
            "  Clip 2 from 20220215075217_TRC%2026-2_vocal.webm [loudness: -30 dB]\n",
            "  Clip 3 from 20220215075217_TRC%2026-2_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220121145022_CHFA_lungback.webm from audios/20220121145022_CHFA_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220121145022_CHFA_lungback.webm [loudness: -51 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 2 from 20220121145022_CHFA_lungback.webm [loudness: -68 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 3 from 20220121145022_CHFA_lungback.webm [loudness: -80 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 4 from 20220121145022_CHFA_lungback.webm [loudness: -64 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 5 from 20220121145022_CHFA_lungback.webm [loudness: -42 dB]\n",
            "  Clip 6 from 20220121145022_CHFA_lungback.webm [loudness: -42 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126150050_AOLR%20Fe_lungback.webm from audios/20220126150050_AOLR%20Fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220126150050_AOLR%20Fe_lungback.webm [loudness: -100 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -100 dB]\n",
            "  Clip 2 from 20220126150050_AOLR%20Fe_lungback.webm [loudness: -97 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -97 dB]\n",
            "  Clip 3 from 20220126150050_AOLR%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220126150050_AOLR%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220126150050_AOLR%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220810095537_DLP%20fe-1_vocal.webm from audios/20220810095537_DLP%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220810095537_DLP%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220810095537_DLP%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220810095537_DLP%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220810095537_DLP%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516150119_Wgyv1-16-5_lungfront.webm from audios/20220516150119_Wgyv1-16-5_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516150119_Wgyv1-16-5_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220516150119_Wgyv1-16-5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220516150119_Wgyv1-16-5_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220516150119_Wgyv1-16-5_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220516150119_Wgyv1-16-5_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220516150119_Wgyv1-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220516150119_Wgyv1-16-5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124134054_GMK%20fe_vocal.webm from audios/20220124134054_GMK%20fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220124134054_GMK%20fe_vocal.webm [loudness: -51 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 2 from 20220124134054_GMK%20fe_vocal.webm [loudness: -40 dB]\n",
            "  Clip 3 from 20220124134054_GMK%20fe_vocal.webm [loudness: -40 dB]\n",
            "  Clip 4 from 20220124134054_GMK%20fe_vocal.webm [loudness: -41 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516153003_Lsma2-16-5_lungfront.webm from audios/20220516153003_Lsma2-16-5_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220516153003_Lsma2-16-5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220516153003_Lsma2-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220516153003_Lsma2-16-5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220516153003_Lsma2-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220516153003_Lsma2-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220516153003_Lsma2-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117155838_ABPC_lungback.webm from audios/20220117155838_ABPC_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220117155838_ABPC_lungback.webm [loudness: -105 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -105 dB]\n",
            "  Clip 2 from 20220117155838_ABPC_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220117155838_ABPC_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220117155838_ABPC_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220117155838_ABPC_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220810095753_JLP%20fe-1_vocal.webm from audios/20220810095753_JLP%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220810095753_JLP%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220810095753_JLP%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220810095753_JLP%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220810095753_JLP%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220704112246_JGA%20fe-1_vocal.webm from audios/20220704112246_JGA%20fe-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220704112246_JGA%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220704112246_JGA%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220704112246_JGA%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220704112246_JGA%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220704112246_JGA%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220715104234_CBP%20fe-2_vocal.webm from audios/20220715104234_CBP%20fe-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220715104234_CBP%20fe-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220715104234_CBP%20fe-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220715104234_CBP%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220715104234_CBP%20fe-2_vocal.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220715104234_CBP%20fe-2_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126161918_ABM%20Fe_lungback.webm from audios/20220126161918_ABM%20Fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220126161918_ABM%20Fe_lungback.webm [loudness: -65 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 2 from 20220126161918_ABM%20Fe_lungback.webm [loudness: -105 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -105 dB]\n",
            "  Clip 3 from 20220126161918_ABM%20Fe_lungback.webm [loudness: -89 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -89 dB]\n",
            "  Clip 4 from 20220126161918_ABM%20Fe_lungback.webm [loudness: -95 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -95 dB]\n",
            "  Clip 5 from 20220126161918_ABM%20Fe_lungback.webm [loudness: -108 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -108 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220212081610_Gnf%2023-1_lungback.webm from audios/20220212081610_Gnf%2023-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220212081610_Gnf%2023-1_lungback.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20220212081610_Gnf%2023-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220212081610_Gnf%2023-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220212081610_Gnf%2023-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 5 from 20220212081610_Gnf%2023-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220212081610_Gnf%2023-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 7 from 20220212081610_Gnf%2023-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220212081610_Gnf%2023-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 9 from 20220212081610_Gnf%2023-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220319073411_DAT%20fe%2019-1_lungfront.webm from audios/20220319073411_DAT%20fe%2019-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220319073411_DAT%20fe%2019-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220319073411_DAT%20fe%2019-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220319073411_DAT%20fe%2019-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220319073411_DAT%20fe%2019-1_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 5 from 20220319073411_DAT%20fe%2019-1_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 6 from 20220319073411_DAT%20fe%2019-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220319073411_DAT%20fe%2019-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220319073411_DAT%20fe%2019-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220713083652_LML%20fe-1_vocal.webm from audios/20220713083652_LML%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220713083652_LML%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220713083652_LML%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220713083652_LML%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220713083652_LML%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212080246_Afc%2021-2_lungback.webm from audios/20220212080246_Afc%2021-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220212080246_Afc%2021-2_lungback.webm [loudness: -46 dB]\n",
            "  Clip 2 from 20220212080246_Afc%2021-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220212080246_Afc%2021-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 4 from 20220212080246_Afc%2021-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 5 from 20220212080246_Afc%2021-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 6 from 20220212080246_Afc%2021-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 7 from 20220212080246_Afc%2021-2_lungback.webm [loudness: -43 dB]\n",
            "  Clip 8 from 20220212080246_Afc%2021-2_lungback.webm [loudness: -53 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220525090247_Pt_vocal.webm from audios/20220525090247_Pt_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220525090247_Pt_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220525090247_Pt_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220525090247_Pt_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220525090247_Pt_vocal.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220525090247_Pt_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419092959_AA%20fe-1_lungback.webm from audios/20230419092959_AA%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419092959_AA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20230419092959_AA%20fe-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20230419092959_AA%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230419092959_AA%20fe-1_lungback.webm [loudness: -30 dB]\n",
            "  Clip 5 from 20230419092959_AA%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20230419092959_AA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230419092959_AA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230419092959_AA%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20230419092959_AA%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20230419092959_AA%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119130925_MCNT_lungfront.webm from audios/20220119130925_MCNT_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220119130925_MCNT_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 2 from 20220119130925_MCNT_lungfront.webm [loudness: -64 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 3 from 20220119130925_MCNT_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 4 from 20220119130925_MCNT_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 5 from 20220119130925_MCNT_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 6 from 20220119130925_MCNT_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303081248_LRR%20fe%203-1_lungfront.webm from audios/20220303081248_LRR%20fe%203-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220303081248_LRR%20fe%203-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220303081248_LRR%20fe%203-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220303081248_LRR%20fe%203-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220303081248_LRR%20fe%203-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220303081248_LRR%20fe%203-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220303081248_LRR%20fe%203-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220303081248_LRR%20fe%203-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 8 from 20220303081248_LRR%20fe%203-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20220303081248_LRR%20fe%203-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 10 from 20220303081248_LRR%20fe%203-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516144655_Sdpa2-16-5_vocal.webm from audios/20220516144655_Sdpa2-16-5_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516144655_Sdpa2-16-5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220516144655_Sdpa2-16-5_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220516144655_Sdpa2-16-5_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220516144655_Sdpa2-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117155838_ABPC_vocal.webm from audios/20220117155838_ABPC_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220117155838_ABPC_vocal.webm [loudness: -48 dB]\n",
            "  Clip 2 from 20220117155838_ABPC_vocal.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220117155838_ABPC_vocal.webm [loudness: -47 dB]\n",
            "  Clip 4 from 20220117155838_ABPC_vocal.webm [loudness: -44 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215081101_MME%2028-2_lungfront.webm from audios/20220215081101_MME%2028-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220215081101_MME%2028-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220215081101_MME%2028-2_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220215081101_MME%2028-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220215081101_MME%2028-2_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 5 from 20220215081101_MME%2028-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 6 from 20220215081101_MME%2028-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 7 from 20220215081101_MME%2028-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 8 from 20220215081101_MME%2028-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 9 from 20220215081101_MME%2028-2_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -53 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220120110747_ARSC_lungback.webm from audios/20220120110747_ARSC_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220120110747_ARSC_lungback.webm [loudness: -83 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 2 from 20220120110747_ARSC_lungback.webm [loudness: -89 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -89 dB]\n",
            "  Clip 3 from 20220120110747_ARSC_lungback.webm [loudness: -75 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 4 from 20220120110747_ARSC_lungback.webm [loudness: -106 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -106 dB]\n",
            "  Clip 5 from 20220120110747_ARSC_lungback.webm [loudness: -116 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -116 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220708085349_FHA%20fe-1_vocal.webm from audios/20220708085349_FHA%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220708085349_FHA%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220708085349_FHA%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220708085349_FHA%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220708085349_FHA%20fe-1_vocal.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319053836_MMA%20fe%2019-1_vocal.webm from audios/20220319053836_MMA%20fe%2019-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220319053836_MMA%20fe%2019-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220319053836_MMA%20fe%2019-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220319053836_MMA%20fe%2019-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220319053836_MMA%20fe%2019-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220319053836_MMA%20fe%2019-1_vocal.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115111646_EMPV_lungfront.webm from audios/20220115111646_EMPV_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220115111646_EMPV_lungfront.webm [loudness: -84 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -84 dB]\n",
            "  Clip 2 from 20220115111646_EMPV_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 3 from 20220115111646_EMPV_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 4 from 20220115111646_EMPV_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 5 from 20220115111646_EMPV_lungfront.webm [loudness: -72 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 6 from 20220115111646_EMPV_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -73 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220319095643_MAR%20fe%2019-1_lungfront.webm from audios/20220319095643_MAR%20fe%2019-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319095643_MAR%20fe%2019-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220319095643_MAR%20fe%2019-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220319095643_MAR%20fe%2019-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220319095643_MAR%20fe%2019-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220319095643_MAR%20fe%2019-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220319095643_MAR%20fe%2019-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220319095643_MAR%20fe%2019-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 8 from 20220319095643_MAR%20fe%2019-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220319095643_MAR%20fe%2019-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20221220075454_Fe-1%20PB_lungback.webm from audios/20221220075454_Fe-1%20PB_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221220075454_Fe-1%20PB_lungback.webm [loudness: -19 dB]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Clip 2 from 20221220075454_Fe-1%20PB_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20221220075454_Fe-1%20PB_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20221220075454_Fe-1%20PB_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221220075454_Fe-1%20PB_lungback.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20221220075454_Fe-1%20PB_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20221220075454_Fe-1%20PB_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20221220075454_Fe-1%20PB_lungback.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20221220075454_Fe-1%20PB_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063439_JMT-D2_lungfront.webm from audios/20211209063439_JMT-D2_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211209063439_JMT-D2_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20211209063439_JMT-D2_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 3 from 20211209063439_JMT-D2_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 4 from 20211209063439_JMT-D2_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 5 from 20211209063439_JMT-D2_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 6 from 20211209063439_JMT-D2_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -61 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220111111424_CLD_vocal.webm from audios/20220111111424_CLD_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220111111424_CLD_vocal.webm [loudness: -38 dB]\n",
            "  Clip 2 from 20220111111424_CLD_vocal.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220111111424_CLD_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220111111424_CLD_vocal.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220111111424_CLD_vocal.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420094226_GCH%20fe-1_vocal.webm from audios/20230420094226_GCH%20fe-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20230420094226_GCH%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20230420094226_GCH%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230420094226_GCH%20fe-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207100112_Fe-1%20WC_lungback.webm from audios/20221207100112_Fe-1%20WC_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221207100112_Fe-1%20WC_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20221207100112_Fe-1%20WC_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20221207100112_Fe-1%20WC_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20221207100112_Fe-1%20WC_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221207100112_Fe-1%20WC_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20221207100112_Fe-1%20WC_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20221207100112_Fe-1%20WC_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20221207100112_Fe-1%20WC_lungback.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20221207100112_Fe-1%20WC_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122114315_GPOE%20fe_vocal.webm from audios/20220122114315_GPOE%20fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220122114315_GPOE%20fe_vocal.webm [loudness: -8 dB]\n",
            "  Clip 2 from 20220122114315_GPOE%20fe_vocal.webm [loudness: -5 dB]\n",
            "  Clip 3 from 20220122114315_GPOE%20fe_vocal.webm [loudness: -9 dB]\n",
            "  Clip 4 from 20220122114315_GPOE%20fe_vocal.webm [loudness: -7 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220727094501_CCG%20fe-1_vocal.webm from audios/20220727094501_CCG%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220727094501_CCG%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220727094501_CCG%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220727094501_CCG%20fe-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220727094501_CCG%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220727094501_CCG%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305073453_FFP%20fe%205-1_lungback.webm from audios/20220305073453_FFP%20fe%205-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305073453_FFP%20fe%205-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220305073453_FFP%20fe%205-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220305073453_FFP%20fe%205-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220305073453_FFP%20fe%205-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220305073453_FFP%20fe%205-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 6 from 20220305073453_FFP%20fe%205-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220305073453_FFP%20fe%205-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220305073453_FFP%20fe%205-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220305073453_FFP%20fe%205-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302081802_EPV%20fe%202-1_lungfront.webm from audios/20220302081802_EPV%20fe%202-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220302081802_EPV%20fe%202-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220302081802_EPV%20fe%202-1_lungfront.webm [loudness: -34 dB]\n",
            "  Clip 3 from 20220302081802_EPV%20fe%202-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220302081802_EPV%20fe%202-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220302081802_EPV%20fe%202-1_lungfront.webm [loudness: -38 dB]\n",
            "  Clip 6 from 20220302081802_EPV%20fe%202-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220302081802_EPV%20fe%202-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 8 from 20220302081802_EPV%20fe%202-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125122955_RPY%20fe_lungfront.webm from audios/20220125122955_RPY%20fe_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220125122955_RPY%20fe_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220125122955_RPY%20fe_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220125122955_RPY%20fe_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 4 from 20220125122955_RPY%20fe_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220125122955_RPY%20fe_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220125122955_RPY%20fe_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304083114_AMQ%20fe%204-1_vocal.webm from audios/20220304083114_AMQ%20fe%204-1_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220304083114_AMQ%20fe%204-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220304083114_AMQ%20fe%204-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220304083114_AMQ%20fe%204-1_vocal.webm [loudness: -56 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 4 from 20220304083114_AMQ%20fe%204-1_vocal.webm [loudness: -32 dB]\n",
            "  Clip 5 from 20220304083114_AMQ%20fe%204-1_vocal.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220304083114_AMQ%20fe%204-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304062932_ACR%20fe%204-1_vocal.webm from audios/20220304062932_ACR%20fe%204-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220304062932_ACR%20fe%204-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220304062932_ACR%20fe%204-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220304062932_ACR%20fe%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220304062932_ACR%20fe%204-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20221212104450_Fe-1%20KP_lungfront.webm from audios/20221212104450_Fe-1%20KP_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221212104450_Fe-1%20KP_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20221212104450_Fe-1%20KP_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20221212104450_Fe-1%20KP_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20221212104450_Fe-1%20KP_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20221212104450_Fe-1%20KP_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20221212104450_Fe-1%20KP_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20221212104450_Fe-1%20KP_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20221212104450_Fe-1%20KP_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20221212104450_Fe-1%20KP_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212063005_Ach%2014-2_lungback.webm from audios/20220212063005_Ach%2014-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 15 2s clips\n",
            "  Clip 1 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 2 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -43 dB]\n",
            "  Clip 3 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -37 dB]\n",
            "  Clip 4 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -45 dB]\n",
            "  Clip 5 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -54 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 6 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -41 dB]\n",
            "  Clip 7 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -50 dB]\n",
            "  Clip 8 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -34 dB]\n",
            "  Clip 9 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -48 dB]\n",
            "  Clip 10 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -51 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 11 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -36 dB]\n",
            "  Clip 12 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -38 dB]\n",
            "  Clip 13 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -51 dB]\n",
            "  Clip 13 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 14 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -37 dB]\n",
            "  Clip 15 from 20220212063005_Ach%2014-2_lungback.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418115210_JS%20fe-1_lungback.webm from audios/20230418115210_JS%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230418115210_JS%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20230418115210_JS%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230418115210_JS%20fe-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20230418115210_JS%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20230418115210_JS%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20230418115210_JS%20fe-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20230418115210_JS%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20230418115210_JS%20fe-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 9 from 20230418115210_JS%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20230418115210_JS%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424135234_LM%20fe-1_lungfront.webm from audios/20230424135234_LM%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424135234_LM%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20230424135234_LM%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20230424135234_LM%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20230424135234_LM%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20230424135234_LM%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20230424135234_LM%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230424135234_LM%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20230424135234_LM%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20230424135234_LM%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20230424135234_LM%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302064618_RMC%20fe%202-2_lungback.webm from audios/20220302064618_RMC%20fe%202-2_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220302064618_RMC%20fe%202-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220302064618_RMC%20fe%202-2_lungback.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220302064618_RMC%20fe%202-2_lungback.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220302064618_RMC%20fe%202-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220302064618_RMC%20fe%202-2_lungback.webm [loudness: -30 dB]\n",
            "  Clip 6 from 20220302064618_RMC%20fe%202-2_lungback.webm [loudness: -28 dB]\n",
            "  Clip 7 from 20220302064618_RMC%20fe%202-2_lungback.webm [loudness: -28 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128104342_AASE%20fe%201_lungback.webm from audios/20220128104342_AASE%20fe%201_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128104342_AASE%20fe%201_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220128104342_AASE%20fe%201_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220128104342_AASE%20fe%201_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220128104342_AASE%20fe%201_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220128104342_AASE%20fe%201_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220723121728_JMT%20fe-1_lungback.webm from audios/20220723121728_JMT%20fe-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220723121728_JMT%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220723121728_JMT%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220723121728_JMT%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220723121728_JMT%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220723121728_JMT%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220723121728_JMT%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220723121728_JMT%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220723121728_JMT%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220723121728_JMT%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114145132_AACC_vocal.webm from audios/20220114145132_AACC_vocal.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220114145132_AACC_vocal.webm [loudness: -40 dB]\n",
            "  Clip 2 from 20220114145132_AACC_vocal.webm [loudness: -36 dB]\n",
            "  Clip 3 from 20220114145132_AACC_vocal.webm [loudness: -37 dB]\n",
            "  Clip 4 from 20220114145132_AACC_vocal.webm [loudness: -33 dB]\n",
            "  Clip 5 from 20220114145132_AACC_vocal.webm [loudness: -43 dB]\n",
            "  Clip 6 from 20220114145132_AACC_vocal.webm [loudness: -45 dB]\n",
            "  Clip 7 from 20220114145132_AACC_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709054715_CNE%20fe-1_lungback.webm from audios/20220709054715_CNE%20fe-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709054715_CNE%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220709054715_CNE%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220709054715_CNE%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220709054715_CNE%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220709054715_CNE%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220709054715_CNE%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220709054715_CNE%20fe-1_lungback.webm [loudness: -36 dB]\n",
            "  Clip 8 from 20220709054715_CNE%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220709054715_CNE%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207110303_Fe-1%20YO_vocal.webm from audios/20221207110303_Fe-1%20YO_vocal.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20221207110303_Fe-1%20YO_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20221207110303_Fe-1%20YO_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20221207110303_Fe-1%20YO_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20221207110303_Fe-1%20YO_vocal.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20221207110303_Fe-1%20YO_vocal.webm [loudness: -11 dB]\n",
            "  Clip 6 from 20221207110303_Fe-1%20YO_vocal.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20221207110303_Fe-1%20YO_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302090631_WOM%20fe%202-1_vocal.webm from audios/20220302090631_WOM%20fe%202-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220302090631_WOM%20fe%202-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220302090631_WOM%20fe%202-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220302090631_WOM%20fe%202-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220302090631_WOM%20fe%202-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220302090631_WOM%20fe%202-1_vocal.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220121165452_STDCP_lungback.webm from audios/20220121165452_STDCP_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220121165452_STDCP_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220121165452_STDCP_lungback.webm [loudness: -61 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 3 from 20220121165452_STDCP_lungback.webm [loudness: -71 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 4 from 20220121165452_STDCP_lungback.webm [loudness: -71 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 5 from 20220121165452_STDCP_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220127143555_MMLJ%20Fe_vocal.webm from audios/20220127143555_MMLJ%20Fe_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220127143555_MMLJ%20Fe_vocal.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220127143555_MMLJ%20Fe_vocal.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220127143555_MMLJ%20Fe_vocal.webm [loudness: -29 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114114719_HIRP_lungfront.webm from audios/20220114114719_HIRP_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114114719_HIRP_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 2 from 20220114114719_HIRP_lungfront.webm [loudness: -118 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -118 dB]\n",
            "  Clip 3 from 20220114114719_HIRP_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220114114719_HIRP_lungfront.webm [loudness: -42 dB]\n",
            "  Clip 5 from 20220114114719_HIRP_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207110303_Fe-1%20YO_lungfront.webm from audios/20221207110303_Fe-1%20YO_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20221207110303_Fe-1%20YO_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20221207110303_Fe-1%20YO_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20221207110303_Fe-1%20YO_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20221207110303_Fe-1%20YO_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20221207110303_Fe-1%20YO_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20221207110303_Fe-1%20YO_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20221207110303_Fe-1%20YO_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20221207110303_Fe-1%20YO_lungfront.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304065400_NAA%20fe%204-1_vocal.webm from audios/20220304065400_NAA%20fe%204-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220304065400_NAA%20fe%204-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220304065400_NAA%20fe%204-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220304065400_NAA%20fe%204-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220304065400_NAA%20fe%204-1_vocal.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220304065400_NAA%20fe%204-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220804094909_JQZ%20fe-3_lungback.webm from audios/20220804094909_JQZ%20fe-3_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220804094909_JQZ%20fe-3_lungback.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220804094909_JQZ%20fe-3_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220804094909_JQZ%20fe-3_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220804094909_JQZ%20fe-3_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220804094909_JQZ%20fe-3_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220804094909_JQZ%20fe-3_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220804094909_JQZ%20fe-3_lungback.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220804094909_JQZ%20fe-3_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220804094909_JQZ%20fe-3_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516151434_Yyrg1-16-5_vocal.webm from audios/20220516151434_Yyrg1-16-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516151434_Yyrg1-16-5_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220516151434_Yyrg1-16-5_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220516151434_Yyrg1-16-5_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220516151434_Yyrg1-16-5_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20221223095759_Fe-2%20GB_vocal.webm from audios/20221223095759_Fe-2%20GB_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20221223095759_Fe-2%20GB_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20221223095759_Fe-2%20GB_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20221223095759_Fe-2%20GB_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20221223095759_Fe-2%20GB_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125140657_NRJJ%20fe_lungback.webm from audios/20220125140657_NRJJ%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125140657_NRJJ%20fe_lungback.webm [loudness: -68 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 2 from 20220125140657_NRJJ%20fe_lungback.webm [loudness: -71 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 3 from 20220125140657_NRJJ%20fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220125140657_NRJJ%20fe_lungback.webm [loudness: -62 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 5 from 20220125140657_NRJJ%20fe_lungback.webm [loudness: -62 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -62 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220107163554_PMA_lungfront.webm from audios/20220107163554_PMA_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220107163554_PMA_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 2 from 20220107163554_PMA_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220107163554_PMA_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 4 from 20220107163554_PMA_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 5 from 20220107163554_PMA_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 6 from 20220107163554_PMA_lungfront.webm [loudness: -64 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 7 from 20220107163554_PMA_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 8 from 20220107163554_PMA_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -65 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230424124430_RT%20fe-1_lungback.webm from audios/20230424124430_RT%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 11 from 20230424124430_RT%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212065239_ATC%2017-2_lungback.webm from audios/20220212065239_ATC%2017-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 10 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 11 from 20220212065239_ATC%2017-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419120707_ET%20fe-1_lungback.webm from audios/20230419120707_ET%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230419120707_ET%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230419120707_ET%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230419120707_ET%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20230419120707_ET%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20230419120707_ET%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230419120707_ET%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20230419120707_ET%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230419120707_ET%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230419120707_ET%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220704112603_JGA.%20Fe-2_lungback.webm from audios/20220704112603_JGA.%20Fe-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220704112603_JGA.%20Fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220704112603_JGA.%20Fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220704112603_JGA.%20Fe-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220704112603_JGA.%20Fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220704112603_JGA.%20Fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220704112603_JGA.%20Fe-2_lungback.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20220704112603_JGA.%20Fe-2_lungback.webm [loudness: -12 dB]\n",
            "  Clip 8 from 20220704112603_JGA.%20Fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126124939_ABM%20es_lungfront.webm from audios/20220126124939_ABM%20es_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220126124939_ABM%20es_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 2 from 20220126124939_ABM%20es_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 3 from 20220126124939_ABM%20es_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 4 from 20220126124939_ABM%20es_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 5 from 20220126124939_ABM%20es_lungfront.webm [loudness: -93 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -93 dB]\n",
            "  Clip 6 from 20220126124939_ABM%20es_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -62 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220709050025_BUM%20fe-1_lungback.webm from audios/20220709050025_BUM%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709050025_BUM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220709050025_BUM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220709050025_BUM%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220709050025_BUM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220709050025_BUM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220709050025_BUM%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220709050025_BUM%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220709050025_BUM%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220709050025_BUM%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304050722_LRM%204-1_vocal.webm from audios/20220304050722_LRM%204-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220304050722_LRM%204-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220304050722_LRM%204-1_vocal.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220304050722_LRM%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220304050722_LRM%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063216_JMT-D_vocal.webm from audios/20211209063216_JMT-D_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20211209063216_JMT-D_vocal.webm [loudness: -34 dB]\n",
            "  Clip 2 from 20211209063216_JMT-D_vocal.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20211209063216_JMT-D_vocal.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20211209063216_JMT-D_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212070643_Jmt%2017-2_lungback.webm from audios/20220212070643_Jmt%2017-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -63 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 3 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -39 dB]\n",
            "  Clip 4 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -33 dB]\n",
            "  Clip 5 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -38 dB]\n",
            "  Clip 6 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -37 dB]\n",
            "  Clip 7 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -32 dB]\n",
            "  Clip 8 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -36 dB]\n",
            "  Clip 9 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -29 dB]\n",
            "  Clip 10 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -33 dB]\n",
            "  Clip 11 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -29 dB]\n",
            "  Clip 12 from 20220212070643_Jmt%2017-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115111646_EMPV_vocal.webm from audios/20220115111646_EMPV_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115111646_EMPV_vocal.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220115111646_EMPV_vocal.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220115111646_EMPV_vocal.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220115111646_EMPV_vocal.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220115111646_EMPV_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319073113_MLQ%20fe%2019-1_lungback.webm from audios/20220319073113_MLQ%20fe%2019-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -61 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 2 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -52 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 3 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 4 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -48 dB]\n",
            "  Clip 6 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 8 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 10 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 11 from 20220319073113_MLQ%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516151615_Yyrg2-16-5_lungfront.webm from audios/20220516151615_Yyrg2-16-5_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220516151615_Yyrg2-16-5_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220516151615_Yyrg2-16-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220516151615_Yyrg2-16-5_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220516151615_Yyrg2-16-5_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220516151615_Yyrg2-16-5_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220516151615_Yyrg2-16-5_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220516151615_Yyrg2-16-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220516151615_Yyrg2-16-5_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220516151615_Yyrg2-16-5_lungfront.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115141333_RCYM_lungfront.webm from audios/20220115141333_RCYM_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115141333_RCYM_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220115141333_RCYM_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220115141333_RCYM_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220115141333_RCYM_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220115141333_RCYM_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220125122834_RPY%20es_vocal.webm from audios/20220125122834_RPY%20es_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125122834_RPY%20es_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220125122834_RPY%20es_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220125122834_RPY%20es_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220125122834_RPY%20es_vocal.webm [loudness: -9 dB]\n",
            "  Clip 5 from 20220125122834_RPY%20es_vocal.webm [loudness: -10 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124160502_RALL%20es_vocal.webm from audios/20220124160502_RALL%20es_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220124160502_RALL%20es_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220124160502_RALL%20es_vocal.webm [loudness: -7 dB]\n",
            "  Clip 3 from 20220124160502_RALL%20es_vocal.webm [loudness: -7 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220121125602_HRMM_lungback.webm from audios/20220121125602_HRMM_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220121125602_HRMM_lungback.webm [loudness: -92 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -92 dB]\n",
            "  Clip 2 from 20220121125602_HRMM_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220121125602_HRMM_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220121125602_HRMM_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220121125602_HRMM_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220121125602_HRMM_lungback.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20221123070020_Fe-1%20RF_lungfront.webm from audios/20221123070020_Fe-1%20RF_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123070020_Fe-1%20RF_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20221123070020_Fe-1%20RF_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20221123070020_Fe-1%20RF_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20221123070020_Fe-1%20RF_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221123070020_Fe-1%20RF_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20221123070020_Fe-1%20RF_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20221123070020_Fe-1%20RF_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20221123070020_Fe-1%20RF_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20221123070020_Fe-1%20RF_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063216_JMT-D_lungfront.webm from audios/20211209063216_JMT-D_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20211209063216_JMT-D_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 2 from 20211209063216_JMT-D_lungfront.webm [loudness: -42 dB]\n",
            "  Clip 3 from 20211209063216_JMT-D_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 4 from 20211209063216_JMT-D_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 5 from 20211209063216_JMT-D_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 6 from 20211209063216_JMT-D_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 7 from 20211209063216_JMT-D_lungfront.webm [loudness: -38 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127130817_RPY%20Fe_lungback.webm from audios/20220127130817_RPY%20Fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127130817_RPY%20Fe_lungback.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220127130817_RPY%20Fe_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220127130817_RPY%20Fe_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220127130817_RPY%20Fe_lungback.webm [loudness: -10 dB]\n",
            "  Clip 5 from 20220127130817_RPY%20Fe_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125162946_MCEE%20fe_vocal.webm from audios/20220125162946_MCEE%20fe_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125162946_MCEE%20fe_vocal.webm [loudness: -32 dB]\n",
            "  Clip 2 from 20220125162946_MCEE%20fe_vocal.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20220125162946_MCEE%20fe_vocal.webm [loudness: -29 dB]\n",
            "  Clip 4 from 20220125162946_MCEE%20fe_vocal.webm [loudness: -30 dB]\n",
            "  Clip 5 from 20220125162946_MCEE%20fe_vocal.webm [loudness: -34 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219085022_MGCH%2030-2_vocal.webm from audios/20220219085022_MGCH%2030-2_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220219085022_MGCH%2030-2_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220219085022_MGCH%2030-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127113104_NRJJ%20Es_lungfront.webm from audios/20220127113104_NRJJ%20Es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127113104_NRJJ%20Es_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220127113104_NRJJ%20Es_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220127113104_NRJJ%20Es_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220127113104_NRJJ%20Es_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220127113104_NRJJ%20Es_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054901_ACW-P1_vocal.webm from audios/20211207054901_ACW-P1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20211207054901_ACW-P1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20211207054901_ACW-P1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20211207054901_ACW-P1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20211207054901_ACW-P1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20211207054901_ACW-P1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20221118083614_Fe-1%20VR_vocal.webm from audios/20221118083614_Fe-1%20VR_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221118083614_Fe-1%20VR_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20221118083614_Fe-1%20VR_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20221118083614_Fe-1%20VR_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20221118083614_Fe-1%20VR_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20221118083614_Fe-1%20VR_vocal.webm [loudness: -32 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419125101_JG%20fe-1_lungback.webm from audios/20230419125101_JG%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419125101_JG%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230419125101_JG%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20230419125101_JG%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20230419125101_JG%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20230419125101_JG%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20230419125101_JG%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20230419125101_JG%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20230419125101_JG%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20230419125101_JG%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230419125101_JG%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220503092428_Jonathan_vocal.webm from audios/20220503092428_Jonathan_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220503092428_Jonathan_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220503092428_Jonathan_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220503092428_Jonathan_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220503092428_Jonathan_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304052223_CRD%20fe%204-1_lungback.webm from audios/20220304052223_CRD%20fe%204-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304052223_CRD%20fe%204-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220304052223_CRD%20fe%204-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220304052223_CRD%20fe%204-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220304052223_CRD%20fe%204-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220304052223_CRD%20fe%204-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220304052223_CRD%20fe%204-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220304052223_CRD%20fe%204-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220304052223_CRD%20fe%204-1_lungback.webm [loudness: -30 dB]\n",
            "  Clip 9 from 20220304052223_CRD%20fe%204-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118130259_DMCS_vocal.webm from audios/20220118130259_DMCS_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220118130259_DMCS_vocal.webm [loudness: -27 dB]\n",
            "  Clip 2 from 20220118130259_DMCS_vocal.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220118130259_DMCS_vocal.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424135234_LM%20fe-1_vocal.webm from audios/20230424135234_LM%20fe-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20230424135234_LM%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20230424135234_LM%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20230424135234_LM%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215074545_Zmg%2025-2_lungback.webm from audios/20220215074545_Zmg%2025-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -53 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 2 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 6 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 7 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 8 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -54 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 9 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 10 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 11 from 20220215074545_Zmg%2025-2_lungback.webm [loudness: -54 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -54 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516152059_Jayg1-16-5_lungfront.webm from audios/20220516152059_Jayg1-16-5_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516152059_Jayg1-16-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220516152059_Jayg1-16-5_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220516152059_Jayg1-16-5_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220516152059_Jayg1-16-5_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220516152059_Jayg1-16-5_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220516152059_Jayg1-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220516152059_Jayg1-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305073957_MHC%20fe%205-1_lungfront.webm from audios/20220305073957_MHC%20fe%205-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220305073957_MHC%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220305073957_MHC%20fe%205-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220305073957_MHC%20fe%205-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220305073957_MHC%20fe%205-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 5 from 20220305073957_MHC%20fe%205-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220305073957_MHC%20fe%205-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220305073957_MHC%20fe%205-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220305073957_MHC%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220713083652_LML%20fe-1_lungfront.webm from audios/20220713083652_LML%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220713083652_LML%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220713083652_LML%20fe-1_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220713083652_LML%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220713083652_LML%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220713083652_LML%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220713083652_LML%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220713083652_LML%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220713083652_LML%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220713083652_LML%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419094918_MF%20fe-1_vocal.webm from audios/20230419094918_MF%20fe-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20230419094918_MF%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20230419094918_MF%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230419094918_MF%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230419094918_MF%20fe-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20230419094918_MF%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516143936_Darz1-16-5_lungback.webm from audios/20220516143936_Darz1-16-5_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220516143936_Darz1-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220516143936_Darz1-16-5_lungback.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20220516143936_Darz1-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220516143936_Darz1-16-5_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220516143936_Darz1-16-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220516143936_Darz1-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220516143936_Darz1-16-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220516143936_Darz1-16-5_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220516143936_Darz1-16-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220804111858_TRC%20fe-2_vocal.webm from audios/20220804111858_TRC%20fe-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220804111858_TRC%20fe-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220804111858_TRC%20fe-2_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220804111858_TRC%20fe-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220804111858_TRC%20fe-2_vocal.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220804111858_TRC%20fe-2_vocal.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604055709_JFC%20fe-2_lungback.webm from audios/20220604055709_JFC%20fe-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220604055709_JFC%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220604055709_JFC%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220604055709_JFC%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220604055709_JFC%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220604055709_JFC%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220604055709_JFC%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220604055709_JFC%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220604055709_JFC%20fe-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip 9 from 20220604055709_JFC%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418104709_JC%20fe-1_vocal.webm from audios/20230418104709_JC%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230418104709_JC%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20230418104709_JC%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20230418104709_JC%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20230418104709_JC%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504102754_Seyv%204-5_lungback.webm from audios/20220504102754_Seyv%204-5_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220504102754_Seyv%204-5_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220504102754_Seyv%204-5_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220504102754_Seyv%204-5_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220504102754_Seyv%204-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220504102754_Seyv%204-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220504102754_Seyv%204-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220504102754_Seyv%204-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220526123751_SE%20fe-1_vocal.webm from audios/20220526123751_SE%20fe-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220526123751_SE%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220526123751_SE%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220526123751_SE%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220526123751_SE%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220526123751_SE%20fe-1_vocal.webm [loudness: -35 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075217_TRC%2026-2_lungback.webm from audios/20220215075217_TRC%2026-2_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220215075217_TRC%2026-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220215075217_TRC%2026-2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 3 from 20220215075217_TRC%2026-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 4 from 20220215075217_TRC%2026-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220215075217_TRC%2026-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220215075217_TRC%2026-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 7 from 20220215075217_TRC%2026-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 8 from 20220215075217_TRC%2026-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 9 from 20220215075217_TRC%2026-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -56 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230420101527_ER%20fe-1_vocal.webm from audios/20230420101527_ER%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20230420101527_ER%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20230420101527_ER%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20230420101527_ER%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230420101527_ER%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20230420101527_ER%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114145132_AACC_lungback.webm from audios/20220114145132_AACC_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220114145132_AACC_lungback.webm [loudness: -84 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -84 dB]\n",
            "  Clip 2 from 20220114145132_AACC_lungback.webm [loudness: -61 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 3 from 20220114145132_AACC_lungback.webm [loudness: -66 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 4 from 20220114145132_AACC_lungback.webm [loudness: -62 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 5 from 20220114145132_AACC_lungback.webm [loudness: -32 dB]\n",
            "  Clip 6 from 20220114145132_AACC_lungback.webm [loudness: -51 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219084119_SYV%2030-2_lungfront.webm from audios/20220219084119_SYV%2030-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220219084119_SYV%2030-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220219084119_SYV%2030-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220219084119_SYV%2030-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220219084119_SYV%2030-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220219084119_SYV%2030-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220219084119_SYV%2030-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220219084119_SYV%2030-2_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 8 from 20220219084119_SYV%2030-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220219084119_SYV%2030-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305085654_RGM%20fe%205-1_lungfront.webm from audios/20220305085654_RGM%20fe%205-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220305085654_RGM%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220305085654_RGM%20fe%205-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220305085654_RGM%20fe%205-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220305085654_RGM%20fe%205-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220305085654_RGM%20fe%205-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220305085654_RGM%20fe%205-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220305085654_RGM%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220305085654_RGM%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114163111_JASR_vocal.webm from audios/20220114163111_JASR_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220114163111_JASR_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220114163111_JASR_vocal.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220114163111_JASR_vocal.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115155641_SI_lungback.webm from audios/20220115155641_SI_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115155641_SI_lungback.webm [loudness: -105 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -105 dB]\n",
            "  Clip 2 from 20220115155641_SI_lungback.webm [loudness: -95 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -95 dB]\n",
            "  Clip 3 from 20220115155641_SI_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220115155641_SI_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220115155641_SI_lungback.webm [loudness: -70 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -70 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220303050525_LYC%20fe%203-1_vocal.webm from audios/20220303050525_LYC%20fe%203-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220303050525_LYC%20fe%203-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220303050525_LYC%20fe%203-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220303050525_LYC%20fe%203-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220303050525_LYC%20fe%203-1_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115122413_RRB_vocal.webm from audios/20220115122413_RRB_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220115122413_RRB_vocal.webm [loudness: -37 dB]\n",
            "  Clip 2 from 20220115122413_RRB_vocal.webm [loudness: -31 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119120850_DARZ_lungback.webm from audios/20220119120850_DARZ_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220119120850_DARZ_lungback.webm [loudness: -33 dB]\n",
            "  Clip 2 from 20220119120850_DARZ_lungback.webm [loudness: -117 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -117 dB]\n",
            "  Clip 3 from 20220119120850_DARZ_lungback.webm [loudness: -108 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -108 dB]\n",
            "  Clip 4 from 20220119120850_DARZ_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220119120850_DARZ_lungback.webm [loudness: -106 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -106 dB]\n",
            "  Clip 6 from 20220119120850_DARZ_lungback.webm [loudness: -106 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -106 dB]\n",
            "  Clip 7 from 20220119120850_DARZ_lungback.webm [loudness: -125 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -125 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219081530_TRC%2029-2_lungfront.webm from audios/20220219081530_TRC%2029-2_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220219081530_TRC%2029-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220219081530_TRC%2029-2_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20220219081530_TRC%2029-2_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220219081530_TRC%2029-2_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20220219081530_TRC%2029-2_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 6 from 20220219081530_TRC%2029-2_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 7 from 20220219081530_TRC%2029-2_lungfront.webm [loudness: -32 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118111537_ARE_vocal.webm from audios/20220118111537_ARE_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220118111537_ARE_vocal.webm [loudness: -79 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 2 from 20220118111537_ARE_vocal.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220118111537_ARE_vocal.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220118111537_ARE_vocal.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220125162729_MCEE%20es_lungfront.webm from audios/20220125162729_MCEE%20es_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125162729_MCEE%20es_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 2 from 20220125162729_MCEE%20es_lungfront.webm [loudness: -103 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -103 dB]\n",
            "  Clip 3 from 20220125162729_MCEE%20es_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 4 from 20220125162729_MCEE%20es_lungfront.webm [loudness: -87 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -87 dB]\n",
            "  Clip 5 from 20220125162729_MCEE%20es_lungfront.webm [loudness: -86 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -86 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220305085654_RGM%20fe%205-1_lungback.webm from audios/20220305085654_RGM%20fe%205-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305085654_RGM%20fe%205-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220305085654_RGM%20fe%205-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220305085654_RGM%20fe%205-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220305085654_RGM%20fe%205-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220305085654_RGM%20fe%205-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220305085654_RGM%20fe%205-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220305085654_RGM%20fe%205-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220305085654_RGM%20fe%205-1_lungback.webm [loudness: -30 dB]\n",
            "  Clip 9 from 20220305085654_RGM%20fe%205-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212081146_Mmb%2022-2_lungfront.webm from audios/20220212081146_Mmb%2022-2_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220212081146_Mmb%2022-2_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 2 from 20220212081146_Mmb%2022-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 3 from 20220212081146_Mmb%2022-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 4 from 20220212081146_Mmb%2022-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220212081146_Mmb%2022-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 6 from 20220212081146_Mmb%2022-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 7 from 20220212081146_Mmb%2022-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114125553_DAYC_lungfront.webm from audios/20220114125553_DAYC_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114125553_DAYC_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220114125553_DAYC_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 3 from 20220114125553_DAYC_lungfront.webm [loudness: -231 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -231 dB]\n",
            "  Clip 4 from 20220114125553_DAYC_lungfront.webm [loudness: -94 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -94 dB]\n",
            "  Clip 5 from 20220114125553_DAYC_lungfront.webm [loudness: -89 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -89 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207095803_Fe-1%20FW_vocal.webm from audios/20221207095803_Fe-1%20FW_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221207095803_Fe-1%20FW_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20221207095803_Fe-1%20FW_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20221207095803_Fe-1%20FW_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20221207095803_Fe-1%20FW_vocal.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221207095803_Fe-1%20FW_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604085459_CAD%20fe-1_lungfront.webm from audios/20220604085459_CAD%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220604085459_CAD%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220604085459_CAD%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220604085459_CAD%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220604085459_CAD%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220604085459_CAD%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220604085459_CAD%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220604085459_CAD%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220604085459_CAD%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20220604085459_CAD%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516151434_Yyrg1-16-5_lungback.webm from audios/20220516151434_Yyrg1-16-5_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516151434_Yyrg1-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220516151434_Yyrg1-16-5_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220516151434_Yyrg1-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220516151434_Yyrg1-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220516151434_Yyrg1-16-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220516151434_Yyrg1-16-5_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220516151434_Yyrg1-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220516151434_Yyrg1-16-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212081146_Mmb%2022-2_lungback.webm from audios/20220212081146_Mmb%2022-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220212081146_Mmb%2022-2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 2 from 20220212081146_Mmb%2022-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220212081146_Mmb%2022-2_lungback.webm [loudness: -53 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 4 from 20220212081146_Mmb%2022-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 5 from 20220212081146_Mmb%2022-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220212081146_Mmb%2022-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 7 from 20220212081146_Mmb%2022-2_lungback.webm [loudness: -54 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 8 from 20220212081146_Mmb%2022-2_lungback.webm [loudness: -53 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -53 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220107134757_OCAD_lungfront.webm from audios/20220107134757_OCAD_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220107134757_OCAD_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 2 from 20220107134757_OCAD_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220107134757_OCAD_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220107134757_OCAD_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220107134757_OCAD_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220107134757_OCAD_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604085705_CAD%20fe-2_lungfront.webm from audios/20220604085705_CAD%20fe-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220604085705_CAD%20fe-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220604085705_CAD%20fe-2_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20220604085705_CAD%20fe-2_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220604085705_CAD%20fe-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220604085705_CAD%20fe-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220604085705_CAD%20fe-2_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220604085705_CAD%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220604085705_CAD%20fe-2_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 9 from 20220604085705_CAD%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302090942_ANP%20fe%202-1_vocal.webm from audios/20220302090942_ANP%20fe%202-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220302090942_ANP%20fe%202-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220302090942_ANP%20fe%202-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220302090942_ANP%20fe%202-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220302090942_ANP%20fe%202-1_vocal.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20220302090942_ANP%20fe%202-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419115012_LA%20fe-1_vocal.webm from audios/20230419115012_LA%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230419115012_LA%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20230419115012_LA%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230419115012_LA%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230419115012_LA%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220211114254_OCF%20fe%2012-1_lungback.webm from audios/20220211114254_OCF%20fe%2012-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220211114254_OCF%20fe%2012-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220211114254_OCF%20fe%2012-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20220211114254_OCF%20fe%2012-1_lungback.webm [loudness: -43 dB]\n",
            "  Clip 4 from 20220211114254_OCF%20fe%2012-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 5 from 20220211114254_OCF%20fe%2012-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220211114254_OCF%20fe%2012-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220211114254_OCF%20fe%2012-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 8 from 20220211114254_OCF%20fe%2012-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220211114254_OCF%20fe%2012-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 10 from 20220211114254_OCF%20fe%2012-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302054046_DAT%20fe%202-1_lungfront.webm from audios/20220302054046_DAT%20fe%202-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220302054046_DAT%20fe%202-1_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 2 from 20220302054046_DAT%20fe%202-1_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220302054046_DAT%20fe%202-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 4 from 20220302054046_DAT%20fe%202-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220302054046_DAT%20fe%202-1_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 6 from 20220302054046_DAT%20fe%202-1_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 7 from 20220302054046_DAT%20fe%202-1_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 8 from 20220302054046_DAT%20fe%202-1_lungfront.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421091258_MH%20fe-1_lungback.webm from audios/20230421091258_MH%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230421091258_MH%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230421091258_MH%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20230421091258_MH%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230421091258_MH%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20230421091258_MH%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20230421091258_MH%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20230421091258_MH%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20230421091258_MH%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230421091258_MH%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 10 from 20230421091258_MH%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123083226_Fe-2%20VR_lungback.webm from audios/20221123083226_Fe-2%20VR_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123083226_Fe-2%20VR_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20221123083226_Fe-2%20VR_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20221123083226_Fe-2%20VR_lungback.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20221123083226_Fe-2%20VR_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20221123083226_Fe-2%20VR_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20221123083226_Fe-2%20VR_lungback.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20221123083226_Fe-2%20VR_lungback.webm [loudness: -25 dB]\n",
            "  Clip 8 from 20221123083226_Fe-2%20VR_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20221123083226_Fe-2%20VR_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802080705_MHC%20fe-2_lungfront.webm from audios/20220802080705_MHC%20fe-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220802080705_MHC%20fe-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220802080705_MHC%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220802080705_MHC%20fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220802080705_MHC%20fe-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220802080705_MHC%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220802080705_MHC%20fe-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220802080705_MHC%20fe-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220802080705_MHC%20fe-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20220802080705_MHC%20fe-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20220802080705_MHC%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118130259_DMCS_lungfront.webm from audios/20220118130259_DMCS_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220118130259_DMCS_lungfront.webm [loudness: -113 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -113 dB]\n",
            "  Clip 2 from 20220118130259_DMCS_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 3 from 20220118130259_DMCS_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 4 from 20220118130259_DMCS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220118130259_DMCS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220118130259_DMCS_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115141333_RCYM_vocal.webm from audios/20220115141333_RCYM_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220115141333_RCYM_vocal.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220115141333_RCYM_vocal.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220304081704_MHR%20fe%204-1_lungback.webm from audios/20220304081704_MHR%20fe%204-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304081704_MHR%20fe%204-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220304081704_MHR%20fe%204-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220304081704_MHR%20fe%204-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220304081704_MHR%20fe%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220304081704_MHR%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220304081704_MHR%20fe%204-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 7 from 20220304081704_MHR%20fe%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220304081704_MHR%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220304081704_MHR%20fe%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220421124920_LRR%2021-1_lungfront.webm from audios/20220421124920_LRR%2021-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220421124920_LRR%2021-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220421124920_LRR%2021-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220421124920_LRR%2021-1_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 4 from 20220421124920_LRR%2021-1_lungfront.webm [loudness: -88 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -88 dB]\n",
            "  Clip 5 from 20220421124920_LRR%2021-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220421124920_LRR%2021-1_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 7 from 20220421124920_LRR%2021-1_lungfront.webm [loudness: -88 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -88 dB]\n",
            "  Clip 8 from 20220421124920_LRR%2021-1_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 9 from 20220421124920_LRR%2021-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220723121728_JMT%20fe-1_lungfront.webm from audios/20220723121728_JMT%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220723121728_JMT%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220723121728_JMT%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220723121728_JMT%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220723121728_JMT%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220723121728_JMT%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220723121728_JMT%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220723121728_JMT%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20220723121728_JMT%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220723121728_JMT%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304065400_NAA%20fe%204-1_lungfront.webm from audios/20220304065400_NAA%20fe%204-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304065400_NAA%20fe%204-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220304065400_NAA%20fe%204-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220304065400_NAA%20fe%204-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220304065400_NAA%20fe%204-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220304065400_NAA%20fe%204-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220304065400_NAA%20fe%204-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220304065400_NAA%20fe%204-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220304065400_NAA%20fe%204-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220718073538_RM%20fe-1_lungback.webm from audios/20220718073538_RM%20fe-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220718073538_RM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220718073538_RM%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220718073538_RM%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220718073538_RM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220718073538_RM%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220718073538_RM%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220718073538_RM%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220718073538_RM%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220718073538_RM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212081610_Gnf%2023-1_lungfront.webm from audios/20220212081610_Gnf%2023-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220212081610_Gnf%2023-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20220212081610_Gnf%2023-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220212081610_Gnf%2023-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220212081610_Gnf%2023-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220212081610_Gnf%2023-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220212081610_Gnf%2023-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 7 from 20220212081610_Gnf%2023-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 8 from 20220212081610_Gnf%2023-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 9 from 20220212081610_Gnf%2023-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -57 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516110622_Ahj-16-5_lungfront.webm from audios/20220516110622_Ahj-16-5_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516110622_Ahj-16-5_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 2 from 20220516110622_Ahj-16-5_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220516110622_Ahj-16-5_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220516110622_Ahj-16-5_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220516110622_Ahj-16-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220516110622_Ahj-16-5_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20220516110622_Ahj-16-5_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 8 from 20220516110622_Ahj-16-5_lungfront.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420111142_FT%20fe-1_lungback.webm from audios/20230420111142_FT%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230420111142_FT%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230420111142_FT%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20230420111142_FT%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20230420111142_FT%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20230420111142_FT%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230420111142_FT%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20230420111142_FT%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20230420111142_FT%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20230420111142_FT%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 10 from 20230420111142_FT%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419085806_JO%20fe-1_lungfront.webm from audios/20230419085806_JO%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230419085806_JO%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20230419085806_JO%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230419085806_JO%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20230419085806_JO%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20230419085806_JO%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230419085806_JO%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20230419085806_JO%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20230419085806_JO%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230419085806_JO%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304052223_CRD%20fe%204-1_lungfront.webm from audios/20220304052223_CRD%20fe%204-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304052223_CRD%20fe%204-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220304052223_CRD%20fe%204-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220304052223_CRD%20fe%204-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220304052223_CRD%20fe%204-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220304052223_CRD%20fe%204-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220304052223_CRD%20fe%204-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220304052223_CRD%20fe%204-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220304052223_CRD%20fe%204-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709050025_BUM%20fe-1_vocal.webm from audios/20220709050025_BUM%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220709050025_BUM%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220709050025_BUM%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220709050025_BUM%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220709050025_BUM%20fe-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124160633_RALL%20fe_lungfront.webm from audios/20220124160633_RALL%20fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124160633_RALL%20fe_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220124160633_RALL%20fe_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220124160633_RALL%20fe_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220124160633_RALL%20fe_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220124160633_RALL%20fe_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20221118083614_Fe-1%20VR_lungfront.webm from audios/20221118083614_Fe-1%20VR_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20221118083614_Fe-1%20VR_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20221118083614_Fe-1%20VR_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20221118083614_Fe-1%20VR_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20221118083614_Fe-1%20VR_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20221118083614_Fe-1%20VR_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20221118083614_Fe-1%20VR_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20221118083614_Fe-1%20VR_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20221118083614_Fe-1%20VR_lungfront.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220503163043_Jonathan%202_lungfront.webm from audios/20220503163043_Jonathan%202_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220503163043_Jonathan%202_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220503163043_Jonathan%202_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220503163043_Jonathan%202_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220503163043_Jonathan%202_lungfront.webm [loudness: -34 dB]\n",
            "  Clip 5 from 20220503163043_Jonathan%202_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20220503163043_Jonathan%202_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516144505_Sdpa1-16-5_lungback.webm from audios/20220516144505_Sdpa1-16-5_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516144505_Sdpa1-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220516144505_Sdpa1-16-5_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220516144505_Sdpa1-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220516144505_Sdpa1-16-5_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220516144505_Sdpa1-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220516144505_Sdpa1-16-5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220516144505_Sdpa1-16-5_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207055653_ADW-P4_lungfront.webm from audios/20211207055653_ADW-P4_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207055653_ADW-P4_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20211207055653_ADW-P4_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20211207055653_ADW-P4_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20211207055653_ADW-P4_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20211207055653_ADW-P4_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20211207055653_ADW-P4_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516152711_Lsma1-16-5_lungback.webm from audios/20220516152711_Lsma1-16-5_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516152711_Lsma1-16-5_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220516152711_Lsma1-16-5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220516152711_Lsma1-16-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220516152711_Lsma1-16-5_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220516152711_Lsma1-16-5_lungback.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20220516152711_Lsma1-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220516152711_Lsma1-16-5_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114125553_DAYC_vocal.webm from audios/20220114125553_DAYC_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220114125553_DAYC_vocal.webm [loudness: -43 dB]\n",
            "  Clip 2 from 20220114125553_DAYC_vocal.webm [loudness: -44 dB]\n",
            "  Clip 3 from 20220114125553_DAYC_vocal.webm [loudness: -43 dB]\n",
            "  Clip 4 from 20220114125553_DAYC_vocal.webm [loudness: -50 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424111937_JH%20fe-1_vocal.webm from audios/20230424111937_JH%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230424111937_JH%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20230424111937_JH%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230424111937_JH%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230424111937_JH%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212072422_Lml%2020-2_lungfront.webm from audios/20220212072422_Lml%2020-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220212072422_Lml%2020-2_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 2 from 20220212072422_Lml%2020-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220212072422_Lml%2020-2_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 4 from 20220212072422_Lml%2020-2_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 5 from 20220212072422_Lml%2020-2_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 6 from 20220212072422_Lml%2020-2_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 7 from 20220212072422_Lml%2020-2_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 8 from 20220212072422_Lml%2020-2_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 9 from 20220212072422_Lml%2020-2_lungfront.webm [loudness: -42 dB]\n",
            "  Clip 10 from 20220212072422_Lml%2020-2_lungfront.webm [loudness: -46 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114142427_AJTN_lungfront.webm from audios/20220114142427_AJTN_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114142427_AJTN_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 2 from 20220114142427_AJTN_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 3 from 20220114142427_AJTN_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 4 from 20220114142427_AJTN_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 5 from 20220114142427_AJTN_lungfront.webm [loudness: -110 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -110 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220127103801_CHLA%20es_lungfront.webm from audios/20220127103801_CHLA%20es_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127103801_CHLA%20es_lungfront.webm [loudness: -90 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -90 dB]\n",
            "  Clip 2 from 20220127103801_CHLA%20es_lungfront.webm [loudness: -74 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 3 from 20220127103801_CHLA%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220127103801_CHLA%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220127103801_CHLA%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220804101609_MHC%20fe-3_lungfront.webm from audios/20220804101609_MHC%20fe-3_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220804101609_MHC%20fe-3_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220804101609_MHC%20fe-3_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220804101609_MHC%20fe-3_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220804101609_MHC%20fe-3_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220804101609_MHC%20fe-3_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220804101609_MHC%20fe-3_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220804101609_MHC%20fe-3_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220804101609_MHC%20fe-3_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220804101609_MHC%20fe-3_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128135220_PCSN%20fe_lungback.webm from audios/20220128135220_PCSN%20fe_lungback.webm\n",
            "Error loading 20220128135220_PCSN%20fe_lungback.webm: . Removing from files_map.\n",
            "\n",
            "Loading file: 20211207054053_ACW-%20D2_lungback.webm from audios/20211207054053_ACW-%20D2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20211207054053_ACW-%20D2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20211207054053_ACW-%20D2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20211207054053_ACW-%20D2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20211207054053_ACW-%20D2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20211207054053_ACW-%20D2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20211207054053_ACW-%20D2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20211207054053_ACW-%20D2_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305073957_MHC%20fe%205-1_vocal.webm from audios/20220305073957_MHC%20fe%205-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220305073957_MHC%20fe%205-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220305073957_MHC%20fe%205-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220305073957_MHC%20fe%205-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220305073957_MHC%20fe%205-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117164316_LTA_lungfront.webm from audios/20220117164316_LTA_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220117164316_LTA_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220117164316_LTA_lungfront.webm [loudness: -104 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -104 dB]\n",
            "  Clip 3 from 20220117164316_LTA_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220117164316_LTA_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220117164316_LTA_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220117164316_LTA_lungfront.webm [loudness: -99 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -99 dB]\n",
            "  Clip 7 from 20220117164316_LTA_lungfront.webm [loudness: -108 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -108 dB]\n",
            "  Clip 8 from 20220117164316_LTA_lungfront.webm [loudness: -114 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -114 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220124151015_JAYG%20es_vocal.webm from audios/20220124151015_JAYG%20es_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124151015_JAYG%20es_vocal.webm [loudness: -46 dB]\n",
            "  Clip 2 from 20220124151015_JAYG%20es_vocal.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220124151015_JAYG%20es_vocal.webm [loudness: -51 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 4 from 20220124151015_JAYG%20es_vocal.webm [loudness: -46 dB]\n",
            "  Clip 5 from 20220124151015_JAYG%20es_vocal.webm [loudness: -46 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207055826_ADW-P5_lungfront.webm from audios/20211207055826_ADW-P5_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207055826_ADW-P5_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20211207055826_ADW-P5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20211207055826_ADW-P5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20211207055826_ADW-P5_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20211207055826_ADW-P5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20211207055826_ADW-P5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128124025_CGJJ%20fE_lungfront.webm from audios/20220128124025_CGJJ%20fE_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128124025_CGJJ%20fE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220128124025_CGJJ%20fE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220128124025_CGJJ%20fE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220128124025_CGJJ%20fE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220128124025_CGJJ%20fE_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -65 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220219083953_SYV%2030-1_vocal.webm from audios/20220219083953_SYV%2030-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220219083953_SYV%2030-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220219083953_SYV%2030-1_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220219083953_SYV%2030-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126170624_GMK%20Fe_lungfront.webm from audios/20220126170624_GMK%20Fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220126170624_GMK%20Fe_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220126170624_GMK%20Fe_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220126170624_GMK%20Fe_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220126170624_GMK%20Fe_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 5 from 20220126170624_GMK%20Fe_lungfront.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127143409_MMLJ%20Es_lungfront.webm from audios/20220127143409_MMLJ%20Es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127143409_MMLJ%20Es_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220127143409_MMLJ%20Es_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 3 from 20220127143409_MMLJ%20Es_lungfront.webm [loudness: -134 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -134 dB]\n",
            "  Clip 4 from 20220127143409_MMLJ%20Es_lungfront.webm [loudness: -93 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -93 dB]\n",
            "  Clip 5 from 20220127143409_MMLJ%20Es_lungfront.webm [loudness: -77 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -77 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220105133843_YH%20sin_lungfront.webm from audios/20220105133843_YH%20sin_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220105133843_YH%20sin_lungfront.webm [loudness: -40 dB]\n",
            "  Clip 2 from 20220105133843_YH%20sin_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220105133843_YH%20sin_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220105133843_YH%20sin_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220105133843_YH%20sin_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 6 from 20220105133843_YH%20sin_lungfront.webm [loudness: -79 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 7 from 20220105133843_YH%20sin_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 8 from 20220105133843_YH%20sin_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516145612_Leco1-16-5_lungfront.webm from audios/20220516145612_Leco1-16-5_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516145612_Leco1-16-5_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220516145612_Leco1-16-5_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220516145612_Leco1-16-5_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220516145612_Leco1-16-5_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 5 from 20220516145612_Leco1-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220516145612_Leco1-16-5_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220516145612_Leco1-16-5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220516145612_Leco1-16-5_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212080005_Afc%2021-1_lungfront.webm from audios/20220212080005_Afc%2021-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220212080005_Afc%2021-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20220212080005_Afc%2021-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220212080005_Afc%2021-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 4 from 20220212080005_Afc%2021-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220212080005_Afc%2021-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 6 from 20220212080005_Afc%2021-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220212080005_Afc%2021-1_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 8 from 20220212080005_Afc%2021-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 9 from 20220212080005_Afc%2021-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20211209063439_JMT-D2_lungback.webm from audios/20211209063439_JMT-D2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20211209063439_JMT-D2_lungback.webm [loudness: -46 dB]\n",
            "  Clip 2 from 20211209063439_JMT-D2_lungback.webm [loudness: -41 dB]\n",
            "  Clip 3 from 20211209063439_JMT-D2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 4 from 20211209063439_JMT-D2_lungback.webm [loudness: -54 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 5 from 20211209063439_JMT-D2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 6 from 20211209063439_JMT-D2_lungback.webm [loudness: -54 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 7 from 20211209063439_JMT-D2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20211209063439_JMT-D2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 9 from 20211209063439_JMT-D2_lungback.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 10 from 20211209063439_JMT-D2_lungback.webm [loudness: -59 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 11 from 20211209063439_JMT-D2_lungback.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117114755_LTYM_lungback.webm from audios/20220117114755_LTYM_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220117114755_LTYM_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220117114755_LTYM_lungback.webm [loudness: -34 dB]\n",
            "  Clip 3 from 20220117114755_LTYM_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220117114755_LTYM_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220117114755_LTYM_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220117114755_LTYM_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418104709_JC%20fe-1_lungfront.webm from audios/20230418104709_JC%20fe-1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230418104709_JC%20fe-1_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20230418104709_JC%20fe-1_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 3 from 20230418104709_JC%20fe-1_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 4 from 20230418104709_JC%20fe-1_lungfront.webm [loudness: -34 dB]\n",
            "  Clip 5 from 20230418104709_JC%20fe-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 6 from 20230418104709_JC%20fe-1_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 7 from 20230418104709_JC%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20230418104709_JC%20fe-1_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 9 from 20230418104709_JC%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 10 from 20230418104709_JC%20fe-1_lungfront.webm [loudness: -50 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119141214_MAAR_lungback.webm from audios/20220119141214_MAAR_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220119141214_MAAR_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220119141214_MAAR_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220119141214_MAAR_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220119141214_MAAR_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220119141214_MAAR_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220119141214_MAAR_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054053_ACW-%20D2_vocal.webm from audios/20211207054053_ACW-%20D2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20211207054053_ACW-%20D2_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20211207054053_ACW-%20D2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20211207054053_ACW-%20D2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20211207054053_ACW-%20D2_vocal.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20211207054053_ACW-%20D2_vocal.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20211207054053_ACW-%20D2_vocal.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20211207054053_ACW-%20D2_vocal.webm [loudness: -29 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220723124659_AVB%20fe-1_lungfront.webm from audios/20220723124659_AVB%20fe-1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220723124659_AVB%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220723124659_AVB%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220723124659_AVB%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220723124659_AVB%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220723124659_AVB%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220723124659_AVB%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220723124659_AVB%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220723124659_AVB%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220723124659_AVB%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 10 from 20220723124659_AVB%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117114755_LTYM_vocal.webm from audios/20220117114755_LTYM_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220117114755_LTYM_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220117114755_LTYM_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20220117114755_LTYM_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220117114755_LTYM_vocal.webm [loudness: -6 dB]\n",
            "  Clip 5 from 20220117114755_LTYM_vocal.webm [loudness: -9 dB]\n",
            "  Clip 6 from 20220117114755_LTYM_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127153613_RAJL%20fe_lungback.webm from audios/20220127153613_RAJL%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127153613_RAJL%20fe_lungback.webm [loudness: -61 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 2 from 20220127153613_RAJL%20fe_lungback.webm [loudness: -60 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 3 from 20220127153613_RAJL%20fe_lungback.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220127153613_RAJL%20fe_lungback.webm [loudness: -62 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 5 from 20220127153613_RAJL%20fe_lungback.webm [loudness: -93 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -93 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220128124025_CGJJ%20fE_lungback.webm from audios/20220128124025_CGJJ%20fE_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128124025_CGJJ%20fE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220128124025_CGJJ%20fE_lungback.webm [loudness: -70 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 3 from 20220128124025_CGJJ%20fE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220128124025_CGJJ%20fE_lungback.webm [loudness: -89 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -89 dB]\n",
            "  Clip 5 from 20220128124025_CGJJ%20fE_lungback.webm [loudness: -109 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -109 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220115134035_CRAC_vocal.webm from audios/20220115134035_CRAC_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115134035_CRAC_vocal.webm [loudness: -45 dB]\n",
            "  Clip 2 from 20220115134035_CRAC_vocal.webm [loudness: -37 dB]\n",
            "  Clip 3 from 20220115134035_CRAC_vocal.webm [loudness: -35 dB]\n",
            "  Clip 4 from 20220115134035_CRAC_vocal.webm [loudness: -35 dB]\n",
            "  Clip 5 from 20220115134035_CRAC_vocal.webm [loudness: -34 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114152135_VRP_vocal.webm from audios/20220114152135_VRP_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220114152135_VRP_vocal.webm [loudness: -33 dB]\n",
            "  Clip 2 from 20220114152135_VRP_vocal.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20220114152135_VRP_vocal.webm [loudness: -28 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709073837_RCM%20fe-3_vocal.webm from audios/20220709073837_RCM%20fe-3_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220709073837_RCM%20fe-3_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220709073837_RCM%20fe-3_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220709073837_RCM%20fe-3_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220709073837_RCM%20fe-3_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302093004_WOM%20fe%202-2_vocal.webm from audios/20220302093004_WOM%20fe%202-2_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220302093004_WOM%20fe%202-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220302093004_WOM%20fe%202-2_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20220302093004_WOM%20fe%202-2_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220302093004_WOM%20fe%202-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 5 from 20220302093004_WOM%20fe%202-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212080005_Afc%2021-1_lungback.webm from audios/20220212080005_Afc%2021-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220212080005_Afc%2021-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20220212080005_Afc%2021-1_lungback.webm [loudness: -40 dB]\n",
            "  Clip 3 from 20220212080005_Afc%2021-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 4 from 20220212080005_Afc%2021-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 5 from 20220212080005_Afc%2021-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 6 from 20220212080005_Afc%2021-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220212080005_Afc%2021-1_lungback.webm [loudness: -60 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 8 from 20220212080005_Afc%2021-1_lungback.webm [loudness: -60 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 9 from 20220212080005_Afc%2021-1_lungback.webm [loudness: -60 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 10 from 20220212080005_Afc%2021-1_lungback.webm [loudness: -60 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119165019_SKMT_lungfront.webm from audios/20220119165019_SKMT_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220119165019_SKMT_lungfront.webm [loudness: -79 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 2 from 20220119165019_SKMT_lungfront.webm [loudness: -77 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -77 dB]\n",
            "  Clip 3 from 20220119165019_SKMT_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220119165019_SKMT_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 5 from 20220119165019_SKMT_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 6 from 20220119165019_SKMT_lungfront.webm [loudness: -44 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108174158_MFRJ_vocal.webm from audios/20220108174158_MFRJ_vocal.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220108174158_MFRJ_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220108174158_MFRJ_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220108174158_MFRJ_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220108174158_MFRJ_vocal.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220108174158_MFRJ_vocal.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20220108174158_MFRJ_vocal.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20220108174158_MFRJ_vocal.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220108174158_MFRJ_vocal.webm [loudness: -11 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421114407_JF%20fe-1_lungfront.webm from audios/20230421114407_JF%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230421114407_JF%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20230421114407_JF%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20230421114407_JF%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20230421114407_JF%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20230421114407_JF%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20230421114407_JF%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20230421114407_JF%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20230421114407_JF%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20230421114407_JF%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212063501_Acb%2015-1_lungback.webm from audios/20220212063501_Acb%2015-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 13 2s clips\n",
            "  Clip 1 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -61 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 2 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -73 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 3 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -64 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 4 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -60 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 5 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 6 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -45 dB]\n",
            "  Clip 7 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 8 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -63 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 9 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -65 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 10 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -62 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 11 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -67 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 12 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 13 from 20220212063501_Acb%2015-1_lungback.webm [loudness: -53 dB]\n",
            "  Clip 13 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220129133119_DAKP%20fE_vocal.webm from audios/20220129133119_DAKP%20fE_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220129133119_DAKP%20fE_vocal.webm [loudness: -33 dB]\n",
            "  Clip 2 from 20220129133119_DAKP%20fE_vocal.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220129133119_DAKP%20fE_vocal.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219081410_TRC%2029-1_vocal.webm from audios/20220219081410_TRC%2029-1_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220219081410_TRC%2029-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220219081410_TRC%2029-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802120809_TRC%20fe-1_lungback.webm from audios/20220802120809_TRC%20fe-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220802120809_TRC%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220802120809_TRC%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220802120809_TRC%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220802120809_TRC%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220802120809_TRC%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220802120809_TRC%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220802120809_TRC%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220802120809_TRC%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220802120809_TRC%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305073453_FFP%20fe%205-1_lungfront.webm from audios/20220305073453_FFP%20fe%205-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305073453_FFP%20fe%205-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220305073453_FFP%20fe%205-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220305073453_FFP%20fe%205-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220305073453_FFP%20fe%205-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220305073453_FFP%20fe%205-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220305073453_FFP%20fe%205-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220305073453_FFP%20fe%205-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220305073453_FFP%20fe%205-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 9 from 20220305073453_FFP%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708104228_FDV%20fe-2_lungback.webm from audios/20220708104228_FDV%20fe-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220708104228_FDV%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220708104228_FDV%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220708104228_FDV%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220708104228_FDV%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220708104228_FDV%20fe-2_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220708104228_FDV%20fe-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220708104228_FDV%20fe-2_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220708104228_FDV%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220708104228_FDV%20fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220421124920_LRR%2021-1_vocal.webm from audios/20220421124920_LRR%2021-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220421124920_LRR%2021-1_vocal.webm [loudness: -29 dB]\n",
            "  Clip 2 from 20220421124920_LRR%2021-1_vocal.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20220421124920_LRR%2021-1_vocal.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127130655_RPY%20Es_lungback.webm from audios/20220127130655_RPY%20Es_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127130655_RPY%20Es_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220127130655_RPY%20Es_lungback.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220127130655_RPY%20Es_lungback.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220127130655_RPY%20Es_lungback.webm [loudness: -10 dB]\n",
            "  Clip 5 from 20220127130655_RPY%20Es_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421100451_DF%20fe-1_lungback.webm from audios/20230421100451_DF%20fe-1_lungback.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 11 from 20230421100451_DF%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064253_JMT-P2_vocal.webm from audios/20211209064253_JMT-P2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20211209064253_JMT-P2_vocal.webm [loudness: -37 dB]\n",
            "  Clip 2 from 20211209064253_JMT-P2_vocal.webm [loudness: -34 dB]\n",
            "  Clip 3 from 20211209064253_JMT-P2_vocal.webm [loudness: -32 dB]\n",
            "  Clip 4 from 20211209064253_JMT-P2_vocal.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20211209064253_JMT-P2_vocal.webm [loudness: -54 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105163221_CGT%20sin_vocal.webm from audios/20220105163221_CGT%20sin_vocal.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220105163221_CGT%20sin_vocal.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220105163221_CGT%20sin_vocal.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220105163221_CGT%20sin_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220105163221_CGT%20sin_vocal.webm [loudness: -31 dB]\n",
            "  Clip 5 from 20220105163221_CGT%20sin_vocal.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220105163221_CGT%20sin_vocal.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220105163221_CGT%20sin_vocal.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220105163221_CGT%20sin_vocal.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220105163221_CGT%20sin_vocal.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20220105163221_CGT%20sin_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20221213114920_Fe-2%20BU_vocal.webm from audios/20221213114920_Fe-2%20BU_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221213114920_Fe-2%20BU_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20221213114920_Fe-2%20BU_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20221213114920_Fe-2%20BU_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20221213114920_Fe-2%20BU_vocal.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20221213114920_Fe-2%20BU_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424140045_GA%20fe-1_lungback.webm from audios/20230424140045_GA%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424140045_GA%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20230424140045_GA%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20230424140045_GA%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20230424140045_GA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20230424140045_GA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230424140045_GA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20230424140045_GA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230424140045_GA%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20230424140045_GA%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20230424140045_GA%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054733_ADW-D5_lungfront.webm from audios/20211207054733_ADW-D5_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20211207054733_ADW-D5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20211207054733_ADW-D5_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20211207054733_ADW-D5_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20211207054733_ADW-D5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20211207054733_ADW-D5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20211207054733_ADW-D5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20211207054733_ADW-D5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20211207054733_ADW-D5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105124255_PTR_lungback.webm from audios/20220105124255_PTR_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220105124255_PTR_lungback.webm [loudness: -77 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -77 dB]\n",
            "  Clip 2 from 20220105124255_PTR_lungback.webm [loudness: -79 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 3 from 20220105124255_PTR_lungback.webm [loudness: -78 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -78 dB]\n",
            "  Clip 4 from 20220105124255_PTR_lungback.webm [loudness: -79 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 5 from 20220105124255_PTR_lungback.webm [loudness: -75 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 6 from 20220105124255_PTR_lungback.webm [loudness: -32 dB]\n",
            "  Clip 7 from 20220105124255_PTR_lungback.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220105124255_PTR_lungback.webm [loudness: -25 dB]\n",
            "  Clip 9 from 20220105124255_PTR_lungback.webm [loudness: -30 dB]\n",
            "  Clip 10 from 20220105124255_PTR_lungback.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709073607_RCM%20fe-2_lungfront.webm from audios/20220709073607_RCM%20fe-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709073607_RCM%20fe-2_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220709073607_RCM%20fe-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220709073607_RCM%20fe-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220709073607_RCM%20fe-2_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220709073607_RCM%20fe-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220709073607_RCM%20fe-2_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20220709073607_RCM%20fe-2_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220709073607_RCM%20fe-2_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20220709073607_RCM%20fe-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709054937_CNE%20fe-2_lungfront.webm from audios/20220709054937_CNE%20fe-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709054937_CNE%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220709054937_CNE%20fe-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220709054937_CNE%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220709054937_CNE%20fe-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220709054937_CNE%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220709054937_CNE%20fe-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220709054937_CNE%20fe-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220709054937_CNE%20fe-2_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 9 from 20220709054937_CNE%20fe-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108112150_HCAP_vocal.webm from audios/20220108112150_HCAP_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220108112150_HCAP_vocal.webm [loudness: -42 dB]\n",
            "  Clip 2 from 20220108112150_HCAP_vocal.webm [loudness: -39 dB]\n",
            "  Clip 3 from 20220108112150_HCAP_vocal.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220108112150_HCAP_vocal.webm [loudness: -32 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220129132954_DAKP%20FE_lungback.webm from audios/20220129132954_DAKP%20FE_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220129132954_DAKP%20FE_lungback.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20220129132954_DAKP%20FE_lungback.webm [loudness: -49 dB]\n",
            "  Clip 3 from 20220129132954_DAKP%20FE_lungback.webm [loudness: -51 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 4 from 20220129132954_DAKP%20FE_lungback.webm [loudness: -55 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 5 from 20220129132954_DAKP%20FE_lungback.webm [loudness: -45 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212062243_Ach%20fe-14-1_lungback.webm from audios/20220212062243_Ach%20fe-14-1_lungback.webm\n",
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -70 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 2 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -72 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 3 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -68 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 4 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -67 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 5 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -69 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 6 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -73 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 7 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -73 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 8 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -72 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 9 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -69 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 10 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 11 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -63 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 12 from 20220212062243_Ach%20fe-14-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -56 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220120153840_GCNF_lungback.webm from audios/20220120153840_GCNF_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220120153840_GCNF_lungback.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220120153840_GCNF_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220120153840_GCNF_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220120153840_GCNF_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220120153840_GCNF_lungback.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207055043_ADW-P2_lungback.webm from audios/20211207055043_ADW-P2_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207055043_ADW-P2_lungback.webm [loudness: -68 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 2 from 20211207055043_ADW-P2_lungback.webm [loudness: -71 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 3 from 20211207055043_ADW-P2_lungback.webm [loudness: -73 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 4 from 20211207055043_ADW-P2_lungback.webm [loudness: -73 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 5 from 20211207055043_ADW-P2_lungback.webm [loudness: -72 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 6 from 20211207055043_ADW-P2_lungback.webm [loudness: -73 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -73 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220124133907_GMK%20es_lungback.webm from audios/20220124133907_GMK%20es_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124133907_GMK%20es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220124133907_GMK%20es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220124133907_GMK%20es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220124133907_GMK%20es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220124133907_GMK%20es_lungback.webm [loudness: -53 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -53 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220215080924_MME%2028-1_lungfront.webm from audios/20220215080924_MME%2028-1_lungfront.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 2 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 4 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 6 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 8 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 9 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 10 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 11 from 20220215080924_MME%2028-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220125162946_MCEE%20fe_lungfront.webm from audios/20220125162946_MCEE%20fe_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125162946_MCEE%20fe_lungfront.webm [loudness: -78 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -78 dB]\n",
            "  Clip 2 from 20220125162946_MCEE%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220125162946_MCEE%20fe_lungfront.webm [loudness: -91 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -91 dB]\n",
            "  Clip 4 from 20220125162946_MCEE%20fe_lungfront.webm [loudness: -111 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -111 dB]\n",
            "  Clip 5 from 20220125162946_MCEE%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20211207055444_ACW-P3_lungfront.webm from audios/20211207055444_ACW-P3_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20211207055444_ACW-P3_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20211207055444_ACW-P3_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20211207055444_ACW-P3_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20211207055444_ACW-P3_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20211207055444_ACW-P3_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20211207055444_ACW-P3_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20211207055444_ACW-P3_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20211207055444_ACW-P3_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20211207055444_ACW-P3_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128104455_AASE_lungback.webm from audios/20220128104455_AASE_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128104455_AASE_lungback.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220128104455_AASE_lungback.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220128104455_AASE_lungback.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220128104455_AASE_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220128104455_AASE_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220630095905_ARB%20fe-1_lungfront.webm from audios/20220630095905_ARB%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220630095905_ARB%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220630095905_ARB%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220630095905_ARB%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220630095905_ARB%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220630095905_ARB%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220630095905_ARB%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220630095905_ARB%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220630095905_ARB%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220630095905_ARB%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219084905_MGCH%2030-1_lungfront.webm from audios/20220219084905_MGCH%2030-1_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220219084905_MGCH%2030-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 2 from 20220219084905_MGCH%2030-1_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 3 from 20220219084905_MGCH%2030-1_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 4 from 20220219084905_MGCH%2030-1_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 5 from 20220219084905_MGCH%2030-1_lungfront.webm [loudness: -42 dB]\n",
            "  Clip 6 from 20220219084905_MGCH%2030-1_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 7 from 20220219084905_MGCH%2030-1_lungfront.webm [loudness: -32 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516152223_Jayg2-16-5_lungback.webm from audios/20220516152223_Jayg2-16-5_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516152223_Jayg2-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220516152223_Jayg2-16-5_lungback.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220516152223_Jayg2-16-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220516152223_Jayg2-16-5_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220516152223_Jayg2-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220516152223_Jayg2-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220516152223_Jayg2-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302054305_DAT%20fe%202-2_vocal.webm from audios/20220302054305_DAT%20fe%202-2_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302054305_DAT%20fe%202-2_vocal.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220302054305_DAT%20fe%202-2_vocal.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220302054305_DAT%20fe%202-2_vocal.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220302054305_DAT%20fe%202-2_vocal.webm [loudness: -46 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302064348_RMC%20fe%202-1_lungback.webm from audios/20220302064348_RMC%20fe%202-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302064348_RMC%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220302064348_RMC%20fe%202-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220302064348_RMC%20fe%202-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220302064348_RMC%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220302064348_RMC%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220302064348_RMC%20fe%202-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220302064348_RMC%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220302064348_RMC%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220302064348_RMC%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118112925_JCG_vocal.webm from audios/20220118112925_JCG_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220118112925_JCG_vocal.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220118112925_JCG_vocal.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220118112925_JCG_vocal.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20221123051040_Fe-1%20MM_vocal.webm from audios/20221123051040_Fe-1%20MM_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221123051040_Fe-1%20MM_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20221123051040_Fe-1%20MM_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20221123051040_Fe-1%20MM_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20221123051040_Fe-1%20MM_vocal.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20221123051040_Fe-1%20MM_vocal.webm [loudness: -68 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120104224_CRMT_lungfront.webm from audios/20220120104224_CRMT_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220120104224_CRMT_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 2 from 20220120104224_CRMT_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 3 from 20220120104224_CRMT_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 4 from 20220120104224_CRMT_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 5 from 20220120104224_CRMT_lungfront.webm [loudness: -45 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302090338_RIT%20fe%202-1_vocal.webm from audios/20220302090338_RIT%20fe%202-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302090338_RIT%20fe%202-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220302090338_RIT%20fe%202-1_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220302090338_RIT%20fe%202-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220302090338_RIT%20fe%202-1_vocal.webm [loudness: -46 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419105624_EA%20fe-1_lungback.webm from audios/20230419105624_EA%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419105624_EA%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20230419105624_EA%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20230419105624_EA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20230419105624_EA%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230419105624_EA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20230419105624_EA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230419105624_EA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230419105624_EA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230419105624_EA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230419105624_EA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304051546_GYZ%20fe%204-1_lungback.webm from audios/20220304051546_GYZ%20fe%204-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304051546_GYZ%20fe%204-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220304051546_GYZ%20fe%204-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220304051546_GYZ%20fe%204-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220304051546_GYZ%20fe%204-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220304051546_GYZ%20fe%204-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220304051546_GYZ%20fe%204-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20220304051546_GYZ%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220304051546_GYZ%20fe%204-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20220304051546_GYZ%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122114153_GPOE%20es_vocal.webm from audios/20220122114153_GPOE%20es_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220122114153_GPOE%20es_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220122114153_GPOE%20es_vocal.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220122114153_GPOE%20es_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303082111_JFC%20fe%203-1_lungfront.webm from audios/20220303082111_JFC%20fe%203-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303082111_JFC%20fe%203-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 2 from 20220303082111_JFC%20fe%203-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220303082111_JFC%20fe%203-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220303082111_JFC%20fe%203-1_lungfront.webm [loudness: -40 dB]\n",
            "  Clip 5 from 20220303082111_JFC%20fe%203-1_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 6 from 20220303082111_JFC%20fe%203-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220303082111_JFC%20fe%203-1_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 8 from 20220303082111_JFC%20fe%203-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 9 from 20220303082111_JFC%20fe%203-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220715092715_LML%20fe-2_lungback.webm from audios/20220715092715_LML%20fe-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220715092715_LML%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220715092715_LML%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220715092715_LML%20fe-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220715092715_LML%20fe-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220715092715_LML%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220715092715_LML%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220715092715_LML%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20220715092715_LML%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220715092715_LML%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202103930_Mcp-02-11-D3_vocal.webm from audios/20211202103930_Mcp-02-11-D3_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20211202103930_Mcp-02-11-D3_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20211202103930_Mcp-02-11-D3_vocal.webm [loudness: -10 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165035_Aves%204-5_lungback.webm from audios/20220504165035_Aves%204-5_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220504165035_Aves%204-5_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220504165035_Aves%204-5_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220504165035_Aves%204-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220504165035_Aves%204-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220504165035_Aves%204-5_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220504165035_Aves%204-5_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118151408_TZP_lungback.webm from audios/20220118151408_TZP_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118151408_TZP_lungback.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220118151408_TZP_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220118151408_TZP_lungback.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220118151408_TZP_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220118151408_TZP_lungback.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302081802_EPV%20fe%202-1_vocal.webm from audios/20220302081802_EPV%20fe%202-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302081802_EPV%20fe%202-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220302081802_EPV%20fe%202-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220302081802_EPV%20fe%202-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220302081802_EPV%20fe%202-1_vocal.webm [loudness: -37 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127113235_NRJJ%20Fe_lungback.webm from audios/20220127113235_NRJJ%20Fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127113235_NRJJ%20Fe_lungback.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220127113235_NRJJ%20Fe_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220127113235_NRJJ%20Fe_lungback.webm [loudness: -9 dB]\n",
            "  Clip 4 from 20220127113235_NRJJ%20Fe_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220127113235_NRJJ%20Fe_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220121125602_HRMM_vocal.webm from audios/20220121125602_HRMM_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220121125602_HRMM_vocal.webm [loudness: -51 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 2 from 20220121125602_HRMM_vocal.webm [loudness: -48 dB]\n",
            "  Clip 3 from 20220121125602_HRMM_vocal.webm [loudness: -49 dB]\n",
            "  Clip 4 from 20220121125602_HRMM_vocal.webm [loudness: -38 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420094226_GCH%20fe-1_lungfront.webm from audios/20230420094226_GCH%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230420094226_GCH%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20230420094226_GCH%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20230420094226_GCH%20fe-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 4 from 20230420094226_GCH%20fe-1_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 5 from 20230420094226_GCH%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20230420094226_GCH%20fe-1_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 7 from 20230420094226_GCH%20fe-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 8 from 20230420094226_GCH%20fe-1_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 9 from 20230420094226_GCH%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126161918_ABM%20Fe_vocal.webm from audios/20220126161918_ABM%20Fe_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220126161918_ABM%20Fe_vocal.webm [loudness: -45 dB]\n",
            "  Clip 2 from 20220126161918_ABM%20Fe_vocal.webm [loudness: -43 dB]\n",
            "  Clip 3 from 20220126161918_ABM%20Fe_vocal.webm [loudness: -38 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219084119_SYV%2030-2_lungback.webm from audios/20220219084119_SYV%2030-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220219084119_SYV%2030-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220219084119_SYV%2030-2_lungback.webm [loudness: -38 dB]\n",
            "  Clip 3 from 20220219084119_SYV%2030-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220219084119_SYV%2030-2_lungback.webm [loudness: -30 dB]\n",
            "  Clip 5 from 20220219084119_SYV%2030-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220219084119_SYV%2030-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220219084119_SYV%2030-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220219084119_SYV%2030-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117141014_MACL_lungback.webm from audios/20220117141014_MACL_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220117141014_MACL_lungback.webm [loudness: -62 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 2 from 20220117141014_MACL_lungback.webm [loudness: -69 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 3 from 20220117141014_MACL_lungback.webm [loudness: -72 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 4 from 20220117141014_MACL_lungback.webm [loudness: -91 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -91 dB]\n",
            "  Clip 5 from 20220117141014_MACL_lungback.webm [loudness: -103 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -103 dB]\n",
            "  Clip 6 from 20220117141014_MACL_lungback.webm [loudness: -119 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -119 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220304083114_AMQ%20fe%204-1_lungback.webm from audios/20220304083114_AMQ%20fe%204-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304083114_AMQ%20fe%204-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220304083114_AMQ%20fe%204-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220304083114_AMQ%20fe%204-1_lungback.webm [loudness: -31 dB]\n",
            "  Clip 4 from 20220304083114_AMQ%20fe%204-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220304083114_AMQ%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220304083114_AMQ%20fe%204-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220304083114_AMQ%20fe%204-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220304083114_AMQ%20fe%204-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20220304083114_AMQ%20fe%204-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207055826_ADW-P5_vocal.webm from audios/20211207055826_ADW-P5_vocal.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20211207055826_ADW-P5_vocal.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20211207055826_ADW-P5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20211207055826_ADW-P5_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20211207055826_ADW-P5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20211207055826_ADW-P5_vocal.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20211207055826_ADW-P5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20211207055826_ADW-P5_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114113551_HRP_lungback.webm from audios/20220114113551_HRP_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114113551_HRP_lungback.webm [loudness: -76 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 2 from 20220114113551_HRP_lungback.webm [loudness: -89 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -89 dB]\n",
            "  Clip 3 from 20220114113551_HRP_lungback.webm [loudness: -95 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -95 dB]\n",
            "  Clip 4 from 20220114113551_HRP_lungback.webm [loudness: -65 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 5 from 20220114113551_HRP_lungback.webm [loudness: -56 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -56 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220302063901_JGA%20fe%202-1_vocal.webm from audios/20220302063901_JGA%20fe%202-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220302063901_JGA%20fe%202-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220302063901_JGA%20fe%202-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220302063901_JGA%20fe%202-1_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220302063901_JGA%20fe%202-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220302063901_JGA%20fe%202-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20221223095536_Fe-1%20GB_lungfront.webm from audios/20221223095536_Fe-1%20GB_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221223095536_Fe-1%20GB_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20221223095536_Fe-1%20GB_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20221223095536_Fe-1%20GB_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20221223095536_Fe-1%20GB_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20221223095536_Fe-1%20GB_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20221223095536_Fe-1%20GB_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20221223095536_Fe-1%20GB_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20221223095536_Fe-1%20GB_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20221223095536_Fe-1%20GB_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120121711_FFP_lungfront.webm from audios/20220120121711_FFP_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220120121711_FFP_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 2 from 20220120121711_FFP_lungfront.webm [loudness: -86 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 3 from 20220120121711_FFP_lungfront.webm [loudness: -71 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 4 from 20220120121711_FFP_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 5 from 20220120121711_FFP_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -53 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230419103918_DA%20fe-1_lungback.webm from audios/20230419103918_DA%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419103918_DA%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230419103918_DA%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20230419103918_DA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20230419103918_DA%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20230419103918_DA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230419103918_DA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20230419103918_DA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230419103918_DA%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20230419103918_DA%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 10 from 20230419103918_DA%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319055023_DDCS%20fe%2019-1_lungback.webm from audios/20220319055023_DDCS%20fe%2019-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220319055023_DDCS%20fe%2019-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220319055023_DDCS%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220319055023_DDCS%20fe%2019-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220319055023_DDCS%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220319055023_DDCS%20fe%2019-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220319055023_DDCS%20fe%2019-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 7 from 20220319055023_DDCS%20fe%2019-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 8 from 20220319055023_DDCS%20fe%2019-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708085650_FHA%20fe-2_lungback.webm from audios/20220708085650_FHA%20fe-2_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220708085650_FHA%20fe-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220708085650_FHA%20fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220708085650_FHA%20fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220708085650_FHA%20fe-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220708085650_FHA%20fe-2_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220708085650_FHA%20fe-2_lungback.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220708085650_FHA%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20220708085650_FHA%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220708085650_FHA%20fe-2_lungback.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212070508_Jmt%2017-1_vocal.webm from audios/20220212070508_Jmt%2017-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212070508_Jmt%2017-1_vocal.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20220212070508_Jmt%2017-1_vocal.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220212070508_Jmt%2017-1_vocal.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120131215_DJZA_vocal.webm from audios/20220120131215_DJZA_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220120131215_DJZA_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220120131215_DJZA_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220120131215_DJZA_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220120131215_DJZA_vocal.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126125056_ABM%20fe_vocal.webm from audios/20220126125056_ABM%20fe_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220126125056_ABM%20fe_vocal.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20220126125056_ABM%20fe_vocal.webm [loudness: -42 dB]\n",
            "  Clip 3 from 20220126125056_ABM%20fe_vocal.webm [loudness: -41 dB]\n",
            "  Clip 4 from 20220126125056_ABM%20fe_vocal.webm [loudness: -41 dB]\n",
            "  Clip 5 from 20220126125056_ABM%20fe_vocal.webm [loudness: -39 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124151015_JAYG%20es_lungback.webm from audios/20220124151015_JAYG%20es_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124151015_JAYG%20es_lungback.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220124151015_JAYG%20es_lungback.webm [loudness: -49 dB]\n",
            "  Clip 3 from 20220124151015_JAYG%20es_lungback.webm [loudness: -42 dB]\n",
            "  Clip 4 from 20220124151015_JAYG%20es_lungback.webm [loudness: -49 dB]\n",
            "  Clip 5 from 20220124151015_JAYG%20es_lungback.webm [loudness: -60 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220810095537_DLP%20fe-1_lungback.webm from audios/20220810095537_DLP%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220810095537_DLP%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220810095537_DLP%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220810095537_DLP%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220810095537_DLP%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220810095537_DLP%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220810095537_DLP%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220810095537_DLP%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220810095537_DLP%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220810095537_DLP%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127143409_MMLJ%20Es_lungback.webm from audios/20220127143409_MMLJ%20Es_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127143409_MMLJ%20Es_lungback.webm [loudness: -42 dB]\n",
            "  Clip 2 from 20220127143409_MMLJ%20Es_lungback.webm [loudness: -47 dB]\n",
            "  Clip 3 from 20220127143409_MMLJ%20Es_lungback.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220127143409_MMLJ%20Es_lungback.webm [loudness: -40 dB]\n",
            "  Clip 5 from 20220127143409_MMLJ%20Es_lungback.webm [loudness: -40 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802120809_TRC%20fe-1_lungfront.webm from audios/20220802120809_TRC%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220802120809_TRC%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220802120809_TRC%20fe-1_lungfront.webm [loudness: -34 dB]\n",
            "  Clip 3 from 20220802120809_TRC%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220802120809_TRC%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220802120809_TRC%20fe-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 6 from 20220802120809_TRC%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 7 from 20220802120809_TRC%20fe-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 8 from 20220802120809_TRC%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220802120809_TRC%20fe-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802083643_JQZ%20fe-2_lungfront.webm from audios/20220802083643_JQZ%20fe-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220802083643_JQZ%20fe-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220802083643_JQZ%20fe-2_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220802083643_JQZ%20fe-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220802083643_JQZ%20fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220802083643_JQZ%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220802083643_JQZ%20fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220802083643_JQZ%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220802083643_JQZ%20fe-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20220802083643_JQZ%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604055709_JFC%20fe-2_vocal.webm from audios/20220604055709_JFC%20fe-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220604055709_JFC%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220604055709_JFC%20fe-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220604055709_JFC%20fe-2_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220604055709_JFC%20fe-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075914_SYV%2027-2_lungback.webm from audios/20220215075914_SYV%2027-2_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220215075914_SYV%2027-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20220215075914_SYV%2027-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220215075914_SYV%2027-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220215075914_SYV%2027-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220215075914_SYV%2027-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220215075914_SYV%2027-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 7 from 20220215075914_SYV%2027-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 8 from 20220215075914_SYV%2027-2_lungback.webm [loudness: -56 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -56 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220504165658_Avrd_lungback.webm from audios/20220504165658_Avrd_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220504165658_Avrd_lungback.webm [loudness: -29 dB]\n",
            "  Clip 2 from 20220504165658_Avrd_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220504165658_Avrd_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220504165658_Avrd_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220504165658_Avrd_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220504165658_Avrd_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212081610_Gnf%2023-1_vocal.webm from audios/20220212081610_Gnf%2023-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212081610_Gnf%2023-1_vocal.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220212081610_Gnf%2023-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220212081610_Gnf%2023-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20221213114920_Fe-2%20BU_lungfront.webm from audios/20221213114920_Fe-2%20BU_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20221213114920_Fe-2%20BU_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20221213114920_Fe-2%20BU_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20221213114920_Fe-2%20BU_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20221213114920_Fe-2%20BU_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20221213114920_Fe-2%20BU_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20221213114920_Fe-2%20BU_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20221213114920_Fe-2%20BU_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20221213114920_Fe-2%20BU_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516151615_Yyrg2-16-5_vocal.webm from audios/20220516151615_Yyrg2-16-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516151615_Yyrg2-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220516151615_Yyrg2-16-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220516151615_Yyrg2-16-5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220516151615_Yyrg2-16-5_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124124846_AOLR%20fe_vocal.webm from audios/20220124124846_AOLR%20fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220124124846_AOLR%20fe_vocal.webm [loudness: -8 dB]\n",
            "  Clip 2 from 20220124124846_AOLR%20fe_vocal.webm [loudness: -7 dB]\n",
            "  Clip 3 from 20220124124846_AOLR%20fe_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220124124846_AOLR%20fe_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304082033_MQR%20fe%204-1_lungback.webm from audios/20220304082033_MQR%20fe%204-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304082033_MQR%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220304082033_MQR%20fe%204-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220304082033_MQR%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220304082033_MQR%20fe%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220304082033_MQR%20fe%204-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220304082033_MQR%20fe%204-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220304082033_MQR%20fe%204-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220304082033_MQR%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220304082033_MQR%20fe%204-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20221216093012_Fe-1%20CM_lungback.webm from audios/20221216093012_Fe-1%20CM_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20221216093012_Fe-1%20CM_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20221216093012_Fe-1%20CM_lungback.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20221216093012_Fe-1%20CM_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20221216093012_Fe-1%20CM_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20221216093012_Fe-1%20CM_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20221216093012_Fe-1%20CM_lungback.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20221216093012_Fe-1%20CM_lungback.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20221216093012_Fe-1%20CM_lungback.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20221216093012_Fe-1%20CM_lungback.webm [loudness: -17 dB]\n",
            "  Clip 10 from 20221216093012_Fe-1%20CM_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709050338_BUM%20fe-2_vocal.webm from audios/20220709050338_BUM%20fe-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220709050338_BUM%20fe-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220709050338_BUM%20fe-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220709050338_BUM%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220709050338_BUM%20fe-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220709050338_BUM%20fe-2_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304052032_CRD_lungfront.webm from audios/20220304052032_CRD_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304052032_CRD_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220304052032_CRD_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 3 from 20220304052032_CRD_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220304052032_CRD_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220304052032_CRD_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220304052032_CRD_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220304052032_CRD_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220304052032_CRD_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220304052032_CRD_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516152059_Jayg1-16-5_vocal.webm from audios/20220516152059_Jayg1-16-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516152059_Jayg1-16-5_vocal.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220516152059_Jayg1-16-5_vocal.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220516152059_Jayg1-16-5_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220516152059_Jayg1-16-5_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107110348_BTMA_lungback.webm from audios/20220107110348_BTMA_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220107110348_BTMA_lungback.webm [loudness: -52 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 2 from 20220107110348_BTMA_lungback.webm [loudness: -72 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 3 from 20220107110348_BTMA_lungback.webm [loudness: -74 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 4 from 20220107110348_BTMA_lungback.webm [loudness: -47 dB]\n",
            "  Clip 5 from 20220107110348_BTMA_lungback.webm [loudness: -65 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 6 from 20220107110348_BTMA_lungback.webm [loudness: -73 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421090956_AH%20fe-1_vocal.webm from audios/20230421090956_AH%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230421090956_AH%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20230421090956_AH%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230421090956_AH%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230421090956_AH%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120110747_ARSC_vocal.webm from audios/20220120110747_ARSC_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220120110747_ARSC_vocal.webm [loudness: -45 dB]\n",
            "  Clip 2 from 20220120110747_ARSC_vocal.webm [loudness: -41 dB]\n",
            "  Clip 3 from 20220120110747_ARSC_vocal.webm [loudness: -41 dB]\n",
            "  Clip 4 from 20220120110747_ARSC_vocal.webm [loudness: -34 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212062243_Ach%20fe-14-1_lungfront.webm from audios/20220212062243_Ach%20fe-14-1_lungfront.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 2 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -69 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 3 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 4 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -71 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 5 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -69 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 6 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 7 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 8 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 9 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 10 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 11 from 20220212062243_Ach%20fe-14-1_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220525090247_Pt_lungfront.webm from audios/20220525090247_Pt_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220525090247_Pt_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220525090247_Pt_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220525090247_Pt_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220525090247_Pt_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220525090247_Pt_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220525090247_Pt_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20220525090247_Pt_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220525090247_Pt_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 9 from 20220525090247_Pt_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302064348_RMC%20fe%202-1_vocal.webm from audios/20220302064348_RMC%20fe%202-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302064348_RMC%20fe%202-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220302064348_RMC%20fe%202-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220302064348_RMC%20fe%202-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220302064348_RMC%20fe%202-1_vocal.webm [loudness: -52 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108174158_MFRJ_lungback.webm from audios/20220108174158_MFRJ_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220108174158_MFRJ_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220108174158_MFRJ_lungback.webm [loudness: -72 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 3 from 20220108174158_MFRJ_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220108174158_MFRJ_lungback.webm [loudness: -32 dB]\n",
            "  Clip 5 from 20220108174158_MFRJ_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220108174158_MFRJ_lungback.webm [loudness: -36 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516150924_Mfyc1-16-5_lungfront.webm from audios/20220516150924_Mfyc1-16-5_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516150924_Mfyc1-16-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220516150924_Mfyc1-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220516150924_Mfyc1-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220516150924_Mfyc1-16-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220516150924_Mfyc1-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220516150924_Mfyc1-16-5_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220516150924_Mfyc1-16-5_lungfront.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212072422_Lml%2020-2_lungback.webm from audios/20220212072422_Lml%2020-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -47 dB]\n",
            "  Clip 2 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -47 dB]\n",
            "  Clip 3 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -41 dB]\n",
            "  Clip 4 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -39 dB]\n",
            "  Clip 5 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -46 dB]\n",
            "  Clip 6 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -46 dB]\n",
            "  Clip 7 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -45 dB]\n",
            "  Clip 8 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -42 dB]\n",
            "  Clip 9 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -48 dB]\n",
            "  Clip 10 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -46 dB]\n",
            "  Clip 11 from 20220212072422_Lml%2020-2_lungback.webm [loudness: -45 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125162729_MCEE%20es_vocal.webm from audios/20220125162729_MCEE%20es_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220125162729_MCEE%20es_vocal.webm [loudness: -39 dB]\n",
            "  Clip 2 from 20220125162729_MCEE%20es_vocal.webm [loudness: -39 dB]\n",
            "  Clip 3 from 20220125162729_MCEE%20es_vocal.webm [loudness: -36 dB]\n",
            "  Clip 4 from 20220125162729_MCEE%20es_vocal.webm [loudness: -37 dB]\n",
            "  Clip 5 from 20220125162729_MCEE%20es_vocal.webm [loudness: -39 dB]\n",
            "  Clip 6 from 20220125162729_MCEE%20es_vocal.webm [loudness: -37 dB]\n",
            "  Clip 7 from 20220125162729_MCEE%20es_vocal.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303081248_LRR%20fe%203-1_lungback.webm from audios/20220303081248_LRR%20fe%203-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303081248_LRR%20fe%203-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220303081248_LRR%20fe%203-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220303081248_LRR%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220303081248_LRR%20fe%203-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220303081248_LRR%20fe%203-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220303081248_LRR%20fe%203-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220303081248_LRR%20fe%203-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220303081248_LRR%20fe%203-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 9 from 20220303081248_LRR%20fe%203-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802104203_TEO%20fe-1_lungback.webm from audios/20220802104203_TEO%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220802104203_TEO%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220802104203_TEO%20fe-1_lungback.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220802104203_TEO%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220802104203_TEO%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220802104203_TEO%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220802104203_TEO%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220802104203_TEO%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220802104203_TEO%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 9 from 20220802104203_TEO%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 10 from 20220802104203_TEO%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215074418_Zmg%2025-1_lungback.webm from audios/20220215074418_Zmg%2025-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 13 2s clips\n",
            "  Clip 1 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -52 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 2 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 3 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 4 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 9 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -53 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 10 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 11 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -52 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 12 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -55 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 13 from 20220215074418_Zmg%2025-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 13 Skip...too quiet [loudness: -57 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220108112150_HCAP_lungback.webm from audios/20220108112150_HCAP_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220108112150_HCAP_lungback.webm [loudness: -52 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 2 from 20220108112150_HCAP_lungback.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220108112150_HCAP_lungback.webm [loudness: -34 dB]\n",
            "  Clip 4 from 20220108112150_HCAP_lungback.webm [loudness: -45 dB]\n",
            "  Clip 5 from 20220108112150_HCAP_lungback.webm [loudness: -30 dB]\n",
            "  Clip 6 from 20220108112150_HCAP_lungback.webm [loudness: -47 dB]\n",
            "  Clip 7 from 20220108112150_HCAP_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421114407_JF%20fe-1_lungback.webm from audios/20230421114407_JF%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230421114407_JF%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230421114407_JF%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20230421114407_JF%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230421114407_JF%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20230421114407_JF%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20230421114407_JF%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20230421114407_JF%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20230421114407_JF%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20230421114407_JF%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20230421114407_JF%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708085650_FHA%20fe-2_vocal.webm from audios/20220708085650_FHA%20fe-2_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220708085650_FHA%20fe-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220708085650_FHA%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220708085650_FHA%20fe-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220708085650_FHA%20fe-2_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424140556_GB%20fe-1_lungfront.webm from audios/20230424140556_GB%20fe-1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424140556_GB%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20230424140556_GB%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230424140556_GB%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20230424140556_GB%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20230424140556_GB%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20230424140556_GB%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20230424140556_GB%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20230424140556_GB%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20230424140556_GB%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 10 from 20230424140556_GB%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20221213114920_Fe-2%20BU_lungback.webm from audios/20221213114920_Fe-2%20BU_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221213114920_Fe-2%20BU_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20221213114920_Fe-2%20BU_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20221213114920_Fe-2%20BU_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20221213114920_Fe-2%20BU_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20221213114920_Fe-2%20BU_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20221213114920_Fe-2%20BU_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20221213114920_Fe-2%20BU_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20221213114920_Fe-2%20BU_lungback.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20221213114920_Fe-2%20BU_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118130259_DMCS_lungback.webm from audios/20220118130259_DMCS_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118130259_DMCS_lungback.webm [loudness: -114 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -114 dB]\n",
            "  Clip 2 from 20220118130259_DMCS_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220118130259_DMCS_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220118130259_DMCS_lungback.webm [loudness: -109 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -109 dB]\n",
            "  Clip 5 from 20220118130259_DMCS_lungback.webm [loudness: -74 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -74 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220127153448_RAJL%20es_lungfront.webm from audios/20220127153448_RAJL%20es_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220127153448_RAJL%20es_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 2 from 20220127153448_RAJL%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220127153448_RAJL%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220127153448_RAJL%20es_lungfront.webm [loudness: -101 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -101 dB]\n",
            "  Clip 5 from 20220127153448_RAJL%20es_lungfront.webm [loudness: -93 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -93 dB]\n",
            "  Clip 6 from 20220127153448_RAJL%20es_lungfront.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802080705_MHC%20fe-2_lungback.webm from audios/20220802080705_MHC%20fe-2_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220802080705_MHC%20fe-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220802080705_MHC%20fe-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220802080705_MHC%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220802080705_MHC%20fe-2_lungback.webm [loudness: -30 dB]\n",
            "  Clip 5 from 20220802080705_MHC%20fe-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220802080705_MHC%20fe-2_lungback.webm [loudness: -34 dB]\n",
            "  Clip 7 from 20220802080705_MHC%20fe-2_lungback.webm [loudness: -25 dB]\n",
            "  Clip 8 from 20220802080705_MHC%20fe-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip 9 from 20220802080705_MHC%20fe-2_lungback.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122110541_NFGC%20es_lungfront.webm from audios/20220122110541_NFGC%20es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122110541_NFGC%20es_lungfront.webm [loudness: -72 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 2 from 20220122110541_NFGC%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220122110541_NFGC%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220122110541_NFGC%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220122110541_NFGC%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220303081659_RRA%20fe%203-1_lungfront.webm from audios/20220303081659_RRA%20fe%203-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220303081659_RRA%20fe%203-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220303081659_RRA%20fe%203-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220303081659_RRA%20fe%203-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220303081659_RRA%20fe%203-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220303081659_RRA%20fe%203-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20220303081659_RRA%20fe%203-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220303081659_RRA%20fe%203-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220303081659_RRA%20fe%203-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20220303081659_RRA%20fe%203-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 10 from 20220303081659_RRA%20fe%203-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708092832_ARB%20fe-3_lungback.webm from audios/20220708092832_ARB%20fe-3_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220708092832_ARB%20fe-3_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220708092832_ARB%20fe-3_lungback.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220708092832_ARB%20fe-3_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220708092832_ARB%20fe-3_lungback.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220708092832_ARB%20fe-3_lungback.webm [loudness: -29 dB]\n",
            "  Clip 6 from 20220708092832_ARB%20fe-3_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220708092832_ARB%20fe-3_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220708092832_ARB%20fe-3_lungback.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220708092832_ARB%20fe-3_lungback.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108164635_OQFR_lungback.webm from audios/20220108164635_OQFR_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220108164635_OQFR_lungback.webm [loudness: -60 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 2 from 20220108164635_OQFR_lungback.webm [loudness: -63 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 3 from 20220108164635_OQFR_lungback.webm [loudness: -89 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -89 dB]\n",
            "  Clip 4 from 20220108164635_OQFR_lungback.webm [loudness: -65 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 5 from 20220108164635_OQFR_lungback.webm [loudness: -102 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -102 dB]\n",
            "  Clip 6 from 20220108164635_OQFR_lungback.webm [loudness: -99 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -99 dB]\n",
            "  Clip 7 from 20220108164635_OQFR_lungback.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516150340_Wgyv2-16-5_lungback.webm from audios/20220516150340_Wgyv2-16-5_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516150340_Wgyv2-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220516150340_Wgyv2-16-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220516150340_Wgyv2-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220516150340_Wgyv2-16-5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220516150340_Wgyv2-16-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220516150340_Wgyv2-16-5_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220516150340_Wgyv2-16-5_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122154102_MSVC%20fe_lungfront.webm from audios/20220122154102_MSVC%20fe_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220122154102_MSVC%20fe_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220122154102_MSVC%20fe_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220122154102_MSVC%20fe_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220122154102_MSVC%20fe_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220122154102_MSVC%20fe_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220122154102_MSVC%20fe_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215080924_MME%2028-1_vocal.webm from audios/20220215080924_MME%2028-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220215080924_MME%2028-1_vocal.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220215080924_MME%2028-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220215080924_MME%2028-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220215080924_MME%2028-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220723124659_AVB%20fe-1_lungback.webm from audios/20220723124659_AVB%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220723124659_AVB%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220723124659_AVB%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220723124659_AVB%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220723124659_AVB%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220723124659_AVB%20fe-1_lungback.webm [loudness: -33 dB]\n",
            "  Clip 6 from 20220723124659_AVB%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220723124659_AVB%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220723124659_AVB%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220723124659_AVB%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165658_Avrd_lungfront.webm from audios/20220504165658_Avrd_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220504165658_Avrd_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220504165658_Avrd_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220504165658_Avrd_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220504165658_Avrd_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220504165658_Avrd_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220504165658_Avrd_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 7 from 20220504165658_Avrd_lungfront.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220526123937_SE%20fe-2_vocal.webm from audios/20220526123937_SE%20fe-2_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220526123937_SE%20fe-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220526123937_SE%20fe-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220526123937_SE%20fe-2_vocal.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220526123937_SE%20fe-2_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212080005_Afc%2021-1_vocal.webm from audios/20220212080005_Afc%2021-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 1 2s clips\n",
            "  Clip 1 from 20220212080005_Afc%2021-1_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122114153_GPOE%20es_lungfront.webm from audios/20220122114153_GPOE%20es_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122114153_GPOE%20es_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220122114153_GPOE%20es_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220122114153_GPOE%20es_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220122114153_GPOE%20es_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220122114153_GPOE%20es_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516144655_Sdpa2-16-5_lungfront.webm from audios/20220516144655_Sdpa2-16-5_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516144655_Sdpa2-16-5_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220516144655_Sdpa2-16-5_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220516144655_Sdpa2-16-5_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220516144655_Sdpa2-16-5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220516144655_Sdpa2-16-5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220516144655_Sdpa2-16-5_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220516144655_Sdpa2-16-5_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220516144655_Sdpa2-16-5_lungfront.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516153003_Lsma2-16-5_vocal.webm from audios/20220516153003_Lsma2-16-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516153003_Lsma2-16-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220516153003_Lsma2-16-5_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220516153003_Lsma2-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220516153003_Lsma2-16-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319073411_DAT%20fe%2019-1_vocal.webm from audios/20220319073411_DAT%20fe%2019-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220319073411_DAT%20fe%2019-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220319073411_DAT%20fe%2019-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220319073411_DAT%20fe%2019-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220319073411_DAT%20fe%2019-1_vocal.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212082523_Lmm24-2_vocal.webm from audios/20220212082523_Lmm24-2_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220212082523_Lmm24-2_vocal.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220212082523_Lmm24-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212082327_Mmm%2024-1_lungfront.webm from audios/20220212082327_Mmm%2024-1_lungfront.webm\n",
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 7 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 9 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 10 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 11 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 12 from 20220212082327_Mmm%2024-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -57 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230419124122_LG%20fe-1_lungback.webm from audios/20230419124122_LG%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419124122_LG%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20230419124122_LG%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230419124122_LG%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20230419124122_LG%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230419124122_LG%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20230419124122_LG%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20230419124122_LG%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20230419124122_LG%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20230419124122_LG%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 10 from 20230419124122_LG%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319094332_MME%20fe%2019-1_lungback.webm from audios/20220319094332_MME%20fe%2019-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220319094332_MME%20fe%2019-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220319094332_MME%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220319094332_MME%20fe%2019-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220319094332_MME%20fe%2019-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220319094332_MME%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220319094332_MME%20fe%2019-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220319094332_MME%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220319094332_MME%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127113104_NRJJ%20Es_lungback.webm from audios/20220127113104_NRJJ%20Es_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127113104_NRJJ%20Es_lungback.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220127113104_NRJJ%20Es_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220127113104_NRJJ%20Es_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220127113104_NRJJ%20Es_lungback.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220127113104_NRJJ%20Es_lungback.webm [loudness: -31 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305091432_DYC%20fe%205-1_lungfront.webm from audios/20220305091432_DYC%20fe%205-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305091432_DYC%20fe%205-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220305091432_DYC%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220305091432_DYC%20fe%205-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220305091432_DYC%20fe%205-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220305091432_DYC%20fe%205-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20220305091432_DYC%20fe%205-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220305091432_DYC%20fe%205-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220305091432_DYC%20fe%205-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20220305091432_DYC%20fe%205-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107110951_SMAJ_vocal.webm from audios/20220107110951_SMAJ_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220107110951_SMAJ_vocal.webm [loudness: -27 dB]\n",
            "  Clip 2 from 20220107110951_SMAJ_vocal.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20220107110951_SMAJ_vocal.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302064618_RMC%20fe%202-2_lungfront.webm from audios/20220302064618_RMC%20fe%202-2_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220302064618_RMC%20fe%202-2_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220302064618_RMC%20fe%202-2_lungfront.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220302064618_RMC%20fe%202-2_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220302064618_RMC%20fe%202-2_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 5 from 20220302064618_RMC%20fe%202-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220302064618_RMC%20fe%202-2_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 7 from 20220302064618_RMC%20fe%202-2_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 8 from 20220302064618_RMC%20fe%202-2_lungfront.webm [loudness: -46 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220121145022_CHFA_lungfront.webm from audios/20220121145022_CHFA_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220121145022_CHFA_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 2 from 20220121145022_CHFA_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220121145022_CHFA_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 4 from 20220121145022_CHFA_lungfront.webm [loudness: -83 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 5 from 20220121145022_CHFA_lungfront.webm [loudness: -74 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 6 from 20220121145022_CHFA_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220503163043_Jonathan%202_lungback.webm from audios/20220503163043_Jonathan%202_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220503163043_Jonathan%202_lungback.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20220503163043_Jonathan%202_lungback.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220503163043_Jonathan%202_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220503163043_Jonathan%202_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220503163043_Jonathan%202_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220503163043_Jonathan%202_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304062221_DSC%20fe%204-1_vocal.webm from audios/20220304062221_DSC%20fe%204-1_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220304062221_DSC%20fe%204-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220304062221_DSC%20fe%204-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220304062221_DSC%20fe%204-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220304062221_DSC%20fe%204-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220304062221_DSC%20fe%204-1_vocal.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220304062221_DSC%20fe%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126150050_AOLR%20Fe_vocal.webm from audios/20220126150050_AOLR%20Fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220126150050_AOLR%20Fe_vocal.webm [loudness: -41 dB]\n",
            "  Clip 2 from 20220126150050_AOLR%20Fe_vocal.webm [loudness: -41 dB]\n",
            "  Clip 3 from 20220126150050_AOLR%20Fe_vocal.webm [loudness: -39 dB]\n",
            "  Clip 4 from 20220126150050_AOLR%20Fe_vocal.webm [loudness: -66 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708085650_FHA%20fe-2_lungfront.webm from audios/20220708085650_FHA%20fe-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220708085650_FHA%20fe-2_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 2 from 20220708085650_FHA%20fe-2_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220708085650_FHA%20fe-2_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220708085650_FHA%20fe-2_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20220708085650_FHA%20fe-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220708085650_FHA%20fe-2_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 7 from 20220708085650_FHA%20fe-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220708085650_FHA%20fe-2_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 9 from 20220708085650_FHA%20fe-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220525090247_Pt_lungback.webm from audios/20220525090247_Pt_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220525090247_Pt_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220525090247_Pt_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220525090247_Pt_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220525090247_Pt_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220525090247_Pt_lungback.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220525090247_Pt_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220525090247_Pt_lungback.webm [loudness: -31 dB]\n",
            "  Clip 8 from 20220525090247_Pt_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220525090247_Pt_lungback.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516153445_Jasr1-1605_lungback.webm from audios/20220516153445_Jasr1-1605_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516153445_Jasr1-1605_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220516153445_Jasr1-1605_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220516153445_Jasr1-1605_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220516153445_Jasr1-1605_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220516153445_Jasr1-1605_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220516153445_Jasr1-1605_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220516153445_Jasr1-1605_lungback.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302060345_PRC%20fe%202-1_vocal.webm from audios/20220302060345_PRC%20fe%202-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302060345_PRC%20fe%202-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220302060345_PRC%20fe%202-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220302060345_PRC%20fe%202-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220302060345_PRC%20fe%202-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302054046_DAT%20fe%202-1_lungback.webm from audios/20220302054046_DAT%20fe%202-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302054046_DAT%20fe%202-1_lungback.webm [loudness: -35 dB]\n",
            "  Clip 2 from 20220302054046_DAT%20fe%202-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20220302054046_DAT%20fe%202-1_lungback.webm [loudness: -43 dB]\n",
            "  Clip 4 from 20220302054046_DAT%20fe%202-1_lungback.webm [loudness: -49 dB]\n",
            "  Clip 5 from 20220302054046_DAT%20fe%202-1_lungback.webm [loudness: -51 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 6 from 20220302054046_DAT%20fe%202-1_lungback.webm [loudness: -54 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 7 from 20220302054046_DAT%20fe%202-1_lungback.webm [loudness: -51 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 8 from 20220302054046_DAT%20fe%202-1_lungback.webm [loudness: -42 dB]\n",
            "  Clip 9 from 20220302054046_DAT%20fe%202-1_lungback.webm [loudness: -48 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119134648_MILS_vocal.webm from audios/20220119134648_MILS_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220119134648_MILS_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220119134648_MILS_vocal.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220119134648_MILS_vocal.webm [loudness: -8 dB]\n",
            "  Clip 4 from 20220119134648_MILS_vocal.webm [loudness: -7 dB]\n",
            "  Clip 5 from 20220119134648_MILS_vocal.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220518132744_Typ%20_lungfront.webm from audios/20220518132744_Typ%20_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 1 2s clips\n",
            "  Last clip: Padding with zeros.\n",
            "  Clip 1 from 20220518132744_Typ%20_lungfront.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120121711_FFP_lungback.webm from audios/20220120121711_FFP_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220120121711_FFP_lungback.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220120121711_FFP_lungback.webm [loudness: -50 dB]\n",
            "  Clip 3 from 20220120121711_FFP_lungback.webm [loudness: -55 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 4 from 20220120121711_FFP_lungback.webm [loudness: -54 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 5 from 20220120121711_FFP_lungback.webm [loudness: -48 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319055023_DDCS%20fe%2019-1_lungfront.webm from audios/20220319055023_DDCS%20fe%2019-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319055023_DDCS%20fe%2019-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220319055023_DDCS%20fe%2019-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220319055023_DDCS%20fe%2019-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220319055023_DDCS%20fe%2019-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220319055023_DDCS%20fe%2019-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220319055023_DDCS%20fe%2019-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220319055023_DDCS%20fe%2019-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220319055023_DDCS%20fe%2019-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 9 from 20220319055023_DDCS%20fe%2019-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202104033_Mcp-02-12-D3_vocal.webm from audios/20211202104033_Mcp-02-12-D3_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20211202104033_Mcp-02-12-D3_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20211202104033_Mcp-02-12-D3_vocal.webm [loudness: -86 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 3 from 20211202104033_Mcp-02-12-D3_vocal.webm [loudness: -92 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -92 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063216_JMT-D_lungback.webm from audios/20211209063216_JMT-D_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20211209063216_JMT-D_lungback.webm [loudness: -39 dB]\n",
            "  Clip 2 from 20211209063216_JMT-D_lungback.webm [loudness: -47 dB]\n",
            "  Clip 3 from 20211209063216_JMT-D_lungback.webm [loudness: -44 dB]\n",
            "  Clip 4 from 20211209063216_JMT-D_lungback.webm [loudness: -50 dB]\n",
            "  Clip 5 from 20211209063216_JMT-D_lungback.webm [loudness: -41 dB]\n",
            "  Clip 6 from 20211209063216_JMT-D_lungback.webm [loudness: -47 dB]\n",
            "  Clip 7 from 20211209063216_JMT-D_lungback.webm [loudness: -48 dB]\n",
            "  Clip 8 from 20211209063216_JMT-D_lungback.webm [loudness: -52 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 9 from 20211209063216_JMT-D_lungback.webm [loudness: -44 dB]\n",
            "  Clip 10 from 20211209063216_JMT-D_lungback.webm [loudness: -49 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124102435_ARJA%20es_lungback.webm from audios/20220124102435_ARJA%20es_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124102435_ARJA%20es_lungback.webm [loudness: -60 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 2 from 20220124102435_ARJA%20es_lungback.webm [loudness: -60 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 3 from 20220124102435_ARJA%20es_lungback.webm [loudness: -50 dB]\n",
            "  Clip 4 from 20220124102435_ARJA%20es_lungback.webm [loudness: -62 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 5 from 20220124102435_ARJA%20es_lungback.webm [loudness: -84 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -84 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220804111858_TRC%20fe-2_lungback.webm from audios/20220804111858_TRC%20fe-2_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220804111858_TRC%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220804111858_TRC%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220804111858_TRC%20fe-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220804111858_TRC%20fe-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220804111858_TRC%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220804111858_TRC%20fe-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220804111858_TRC%20fe-2_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220804111858_TRC%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220804111858_TRC%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 10 from 20220804111858_TRC%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117114755_LTYM_lungfront.webm from audios/20220117114755_LTYM_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220117114755_LTYM_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220117114755_LTYM_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220117114755_LTYM_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220117114755_LTYM_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220117114755_LTYM_lungfront.webm [loudness: -11 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302082442_MOP%20fe%202-1_lungback.webm from audios/20220302082442_MOP%20fe%202-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302082442_MOP%20fe%202-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220302082442_MOP%20fe%202-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220302082442_MOP%20fe%202-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220302082442_MOP%20fe%202-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220302082442_MOP%20fe%202-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220302082442_MOP%20fe%202-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220302082442_MOP%20fe%202-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220302082442_MOP%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220302082442_MOP%20fe%202-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304050722_LRM%204-1_lungfront.webm from audios/20220304050722_LRM%204-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304050722_LRM%204-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220304050722_LRM%204-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220304050722_LRM%204-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220304050722_LRM%204-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220304050722_LRM%204-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220304050722_LRM%204-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220304050722_LRM%204-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220304050722_LRM%204-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424134952_LY%20fe-1_lungback.webm from audios/20230424134952_LY%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230424134952_LY%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20230424134952_LY%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230424134952_LY%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20230424134952_LY%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20230424134952_LY%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20230424134952_LY%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230424134952_LY%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20230424134952_LY%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20230424134952_LY%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125160128_MMLJ%20fe_lungback.webm from audios/20220125160128_MMLJ%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125160128_MMLJ%20fe_lungback.webm [loudness: -68 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 2 from 20220125160128_MMLJ%20fe_lungback.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220125160128_MMLJ%20fe_lungback.webm [loudness: -58 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 4 from 20220125160128_MMLJ%20fe_lungback.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20220125160128_MMLJ%20fe_lungback.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305090043_SFT%20fe%205-1_vocal.webm from audios/20220305090043_SFT%20fe%205-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220305090043_SFT%20fe%205-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220305090043_SFT%20fe%205-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220305090043_SFT%20fe%205-1_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220305090043_SFT%20fe%205-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220305090043_SFT%20fe%205-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114113551_HRP_vocal.webm from audios/20220114113551_HRP_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220114113551_HRP_vocal.webm [loudness: -32 dB]\n",
            "  Clip 2 from 20220114113551_HRP_vocal.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220114113551_HRP_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20221118083614_Fe-1%20VR_lungback.webm from audios/20221118083614_Fe-1%20VR_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20221118083614_Fe-1%20VR_lungback.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20221118083614_Fe-1%20VR_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20221118083614_Fe-1%20VR_lungback.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20221118083614_Fe-1%20VR_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221118083614_Fe-1%20VR_lungback.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20221118083614_Fe-1%20VR_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20221118083614_Fe-1%20VR_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20221118083614_Fe-1%20VR_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20221118083614_Fe-1%20VR_lungback.webm [loudness: -13 dB]\n",
            "  Clip 10 from 20221118083614_Fe-1%20VR_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118112925_JCG_lungback.webm from audios/20220118112925_JCG_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118112925_JCG_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220118112925_JCG_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220118112925_JCG_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220118112925_JCG_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220118112925_JCG_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220526123751_SE%20fe-1_lungback.webm from audios/20220526123751_SE%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220526123751_SE%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220526123751_SE%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220526123751_SE%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220526123751_SE%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220526123751_SE%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220526123751_SE%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220526123751_SE%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220526123751_SE%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220526123751_SE%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421091258_MH%20fe-1_vocal.webm from audios/20230421091258_MH%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230421091258_MH%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20230421091258_MH%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230421091258_MH%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230421091258_MH%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305091432_DYC%20fe%205-1_vocal.webm from audios/20220305091432_DYC%20fe%205-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220305091432_DYC%20fe%205-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220305091432_DYC%20fe%205-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220305091432_DYC%20fe%205-1_vocal.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220305091432_DYC%20fe%205-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220630095905_ARB%20fe-1_lungback.webm from audios/20220630095905_ARB%20fe-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220630095905_ARB%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220630095905_ARB%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220630095905_ARB%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220630095905_ARB%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220630095905_ARB%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220630095905_ARB%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220630095905_ARB%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220630095905_ARB%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220630095905_ARB%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122110541_NFGC%20es_lungback.webm from audios/20220122110541_NFGC%20es_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122110541_NFGC%20es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220122110541_NFGC%20es_lungback.webm [loudness: -101 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -101 dB]\n",
            "  Clip 3 from 20220122110541_NFGC%20es_lungback.webm [loudness: -98 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -98 dB]\n",
            "  Clip 4 from 20220122110541_NFGC%20es_lungback.webm [loudness: -97 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -97 dB]\n",
            "  Clip 5 from 20220122110541_NFGC%20es_lungback.webm [loudness: -260 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -260 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220127130817_RPY%20Fe_lungfront.webm from audios/20220127130817_RPY%20Fe_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127130817_RPY%20Fe_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220127130817_RPY%20Fe_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220127130817_RPY%20Fe_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220127130817_RPY%20Fe_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220127130817_RPY%20Fe_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120131215_DJZA_lungfront.webm from audios/20220120131215_DJZA_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220120131215_DJZA_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220120131215_DJZA_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220120131215_DJZA_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220120131215_DJZA_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220120131215_DJZA_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 6 from 20220120131215_DJZA_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220120131215_DJZA_lungfront.webm [loudness: -10 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207095803_Fe-1%20FW_lungfront.webm from audios/20221207095803_Fe-1%20FW_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221207095803_Fe-1%20FW_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20221207095803_Fe-1%20FW_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20221207095803_Fe-1%20FW_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20221207095803_Fe-1%20FW_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20221207095803_Fe-1%20FW_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20221207095803_Fe-1%20FW_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20221207095803_Fe-1%20FW_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20221207095803_Fe-1%20FW_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20221207095803_Fe-1%20FW_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128135220_PCSN%20fe_vocal.webm from audios/20220128135220_PCSN%20fe_vocal.webm\n",
            "Error loading 20220128135220_PCSN%20fe_vocal.webm: . Removing from files_map.\n",
            "\n",
            "Loading file: 20221223095759_Fe-2%20GB_lungback.webm from audios/20221223095759_Fe-2%20GB_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20221223095759_Fe-2%20GB_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20221223095759_Fe-2%20GB_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20221223095759_Fe-2%20GB_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20221223095759_Fe-2%20GB_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221223095759_Fe-2%20GB_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20221223095759_Fe-2%20GB_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20221223095759_Fe-2%20GB_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20221223095759_Fe-2%20GB_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20221223095759_Fe-2%20GB_lungback.webm [loudness: -17 dB]\n",
            "  Clip 10 from 20221223095759_Fe-2%20GB_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107144605_VYFS_lungfront.webm from audios/20220107144605_VYFS_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220107144605_VYFS_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 2 from 20220107144605_VYFS_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220107144605_VYFS_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 4 from 20220107144605_VYFS_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 5 from 20220107144605_VYFS_lungfront.webm [loudness: -44 dB]\n",
            "  Clip 6 from 20220107144605_VYFS_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 7 from 20220107144605_VYFS_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 8 from 20220107144605_VYFS_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064253_JMT-P2_lungfront.webm from audios/20211209064253_JMT-P2_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211209064253_JMT-P2_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 2 from 20211209064253_JMT-P2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20211209064253_JMT-P2_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 4 from 20211209064253_JMT-P2_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 5 from 20211209064253_JMT-P2_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 6 from 20211209064253_JMT-P2_lungfront.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127121029_GADA%20fe_lungfront.webm from audios/20220127121029_GADA%20fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127121029_GADA%20fe_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220127121029_GADA%20fe_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220127121029_GADA%20fe_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220127121029_GADA%20fe_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220127121029_GADA%20fe_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220111111424_CLD_lungback.webm from audios/20220111111424_CLD_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220111111424_CLD_lungback.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220111111424_CLD_lungback.webm [loudness: -43 dB]\n",
            "  Clip 3 from 20220111111424_CLD_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220111111424_CLD_lungback.webm [loudness: -139 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -139 dB]\n",
            "  Clip 5 from 20220111111424_CLD_lungback.webm [loudness: -118 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -118 dB]\n",
            "  Clip 6 from 20220111111424_CLD_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220515223642_Jasr-16-5_vocal.webm from audios/20220515223642_Jasr-16-5_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220515223642_Jasr-16-5_vocal.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220515223642_Jasr-16-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220515223642_Jasr-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220515223642_Jasr-16-5_vocal.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220515223642_Jasr-16-5_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604085705_CAD%20fe-2_lungback.webm from audios/20220604085705_CAD%20fe-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220604085705_CAD%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220604085705_CAD%20fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220604085705_CAD%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220604085705_CAD%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220604085705_CAD%20fe-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220604085705_CAD%20fe-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220604085705_CAD%20fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220604085705_CAD%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220604085705_CAD%20fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212071632_Gbc%2019-1_lungfront.webm from audios/20220212071632_Gbc%2019-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 14 2s clips\n",
            "  Clip 1 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 2 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 3 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 4 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 5 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 6 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 7 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 8 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 9 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 10 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -74 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 11 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 12 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 13 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 13 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 14 from 20220212071632_Gbc%2019-1_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 14 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302063901_JGA%20fe%202-1_lungback.webm from audios/20220302063901_JGA%20fe%202-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302063901_JGA%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220302063901_JGA%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220302063901_JGA%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220302063901_JGA%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220302063901_JGA%20fe%202-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220302063901_JGA%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220302063901_JGA%20fe%202-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220302063901_JGA%20fe%202-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 9 from 20220302063901_JGA%20fe%202-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123070020_Fe-1%20RF_lungback.webm from audios/20221123070020_Fe-1%20RF_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123070020_Fe-1%20RF_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20221123070020_Fe-1%20RF_lungback.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20221123070020_Fe-1%20RF_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20221123070020_Fe-1%20RF_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20221123070020_Fe-1%20RF_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20221123070020_Fe-1%20RF_lungback.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20221123070020_Fe-1%20RF_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20221123070020_Fe-1%20RF_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20221123070020_Fe-1%20RF_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120131215_DJZA_lungback.webm from audios/20220120131215_DJZA_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220120131215_DJZA_lungback.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220120131215_DJZA_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220120131215_DJZA_lungback.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220120131215_DJZA_lungback.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220120131215_DJZA_lungback.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20220120131215_DJZA_lungback.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220804094909_JQZ%20fe-3_vocal.webm from audios/20220804094909_JQZ%20fe-3_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220804094909_JQZ%20fe-3_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220804094909_JQZ%20fe-3_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220804094909_JQZ%20fe-3_vocal.webm [loudness: -51 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 4 from 20220804094909_JQZ%20fe-3_vocal.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220804094909_JQZ%20fe-3_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114142427_AJTN_lungback.webm from audios/20220114142427_AJTN_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220114142427_AJTN_lungback.webm [loudness: -108 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -108 dB]\n",
            "  Clip 2 from 20220114142427_AJTN_lungback.webm [loudness: -69 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 3 from 20220114142427_AJTN_lungback.webm [loudness: -69 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 4 from 20220114142427_AJTN_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220114142427_AJTN_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220114142427_AJTN_lungback.webm [loudness: -70 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -70 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20211216131859_JSR-scp_vocal.webm from audios/20211216131859_JSR-scp_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20211216131859_JSR-scp_vocal.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20211216131859_JSR-scp_vocal.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20211216131859_JSR-scp_vocal.webm [loudness: -29 dB]\n",
            "  Clip 4 from 20211216131859_JSR-scp_vocal.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20211216131859_JSR-scp_vocal.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120104224_CRMT_lungback.webm from audios/20220120104224_CRMT_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220120104224_CRMT_lungback.webm [loudness: -44 dB]\n",
            "  Clip 2 from 20220120104224_CRMT_lungback.webm [loudness: -44 dB]\n",
            "  Clip 3 from 20220120104224_CRMT_lungback.webm [loudness: -44 dB]\n",
            "  Clip 4 from 20220120104224_CRMT_lungback.webm [loudness: -41 dB]\n",
            "  Clip 5 from 20220120104224_CRMT_lungback.webm [loudness: -42 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119112335_SMAC_lungback.webm from audios/20220119112335_SMAC_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220119112335_SMAC_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220119112335_SMAC_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220119112335_SMAC_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220119112335_SMAC_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220119112335_SMAC_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207110303_Fe-1%20YO_lungback.webm from audios/20221207110303_Fe-1%20YO_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20221207110303_Fe-1%20YO_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20221207110303_Fe-1%20YO_lungback.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20221207110303_Fe-1%20YO_lungback.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20221207110303_Fe-1%20YO_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20221207110303_Fe-1%20YO_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20221207110303_Fe-1%20YO_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20221207110303_Fe-1%20YO_lungback.webm [loudness: -12 dB]\n",
            "  Clip 8 from 20221207110303_Fe-1%20YO_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20221220075454_Fe-1%20PB_vocal.webm from audios/20221220075454_Fe-1%20PB_vocal.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221220075454_Fe-1%20PB_vocal.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20221220075454_Fe-1%20PB_vocal.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20221220075454_Fe-1%20PB_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20221220075454_Fe-1%20PB_vocal.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20221220075454_Fe-1%20PB_vocal.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20221220075454_Fe-1%20PB_vocal.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20221220075454_Fe-1%20PB_vocal.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20221220075454_Fe-1%20PB_vocal.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20221220075454_Fe-1%20PB_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118112925_JCG_lungfront.webm from audios/20220118112925_JCG_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118112925_JCG_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220118112925_JCG_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220118112925_JCG_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220118112925_JCG_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220118112925_JCG_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220212063658_Acb%2015-2_lungfront.webm from audios/20220212063658_Acb%2015-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 3 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 4 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 5 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 6 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 7 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 8 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 9 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 10 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 11 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 12 from 20220212063658_Acb%2015-2_lungfront.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128124525_SCSHR%20fE_lungfront.webm from audios/20220128124525_SCSHR%20fE_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128124525_SCSHR%20fE_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 2 from 20220128124525_SCSHR%20fE_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 3 from 20220128124525_SCSHR%20fE_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 4 from 20220128124525_SCSHR%20fE_lungfront.webm [loudness: -69 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 5 from 20220128124525_SCSHR%20fE_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516152059_Jayg1-16-5_lungback.webm from audios/20220516152059_Jayg1-16-5_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516152059_Jayg1-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220516152059_Jayg1-16-5_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220516152059_Jayg1-16-5_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220516152059_Jayg1-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220516152059_Jayg1-16-5_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220516152059_Jayg1-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220516152059_Jayg1-16-5_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220625095154_DM%20fe-2_vocal.webm from audios/20220625095154_DM%20fe-2_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220625095154_DM%20fe-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220625095154_DM%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220625095154_DM%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220625095154_DM%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220625095154_DM%20fe-2_vocal.webm [loudness: -65 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122154102_MSVC%20fe_vocal.webm from audios/20220122154102_MSVC%20fe_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220122154102_MSVC%20fe_vocal.webm [loudness: -8 dB]\n",
            "  Clip 2 from 20220122154102_MSVC%20fe_vocal.webm [loudness: -9 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165337_Eta_lungback.webm from audios/20220504165337_Eta_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220504165337_Eta_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220504165337_Eta_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220504165337_Eta_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220504165337_Eta_lungback.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220504165337_Eta_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220504165337_Eta_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219085022_MGCH%2030-2_lungfront.webm from audios/20220219085022_MGCH%2030-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220219085022_MGCH%2030-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220219085022_MGCH%2030-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220219085022_MGCH%2030-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220219085022_MGCH%2030-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220219085022_MGCH%2030-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220219085022_MGCH%2030-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220219085022_MGCH%2030-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220219085022_MGCH%2030-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302093004_WOM%20fe%202-2_lungback.webm from audios/20220302093004_WOM%20fe%202-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302093004_WOM%20fe%202-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220302093004_WOM%20fe%202-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220302093004_WOM%20fe%202-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220302093004_WOM%20fe%202-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220302093004_WOM%20fe%202-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220302093004_WOM%20fe%202-2_lungback.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220302093004_WOM%20fe%202-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220302093004_WOM%20fe%202-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220302093004_WOM%20fe%202-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064026_JMT-D5_vocal.webm from audios/20211209064026_JMT-D5_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20211209064026_JMT-D5_vocal.webm [loudness: -27 dB]\n",
            "  Clip 2 from 20211209064026_JMT-D5_vocal.webm [loudness: -28 dB]\n",
            "  Clip 3 from 20211209064026_JMT-D5_vocal.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20211209064026_JMT-D5_vocal.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20211209064026_JMT-D5_vocal.webm [loudness: -37 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165919_ETA%204-5_vocal.webm from audios/20220504165919_ETA%204-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220504165919_ETA%204-5_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220504165919_ETA%204-5_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220504165919_ETA%204-5_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220504165919_ETA%204-5_vocal.webm [loudness: -11 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220715101331_RFC%20fe-3_vocal.webm from audios/20220715101331_RFC%20fe-3_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220715101331_RFC%20fe-3_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220715101331_RFC%20fe-3_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220715101331_RFC%20fe-3_vocal.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220715101331_RFC%20fe-3_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128104455_AASE_vocal.webm from audios/20220128104455_AASE_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220128104455_AASE_vocal.webm [loudness: -8 dB]\n",
            "  Clip 2 from 20220128104455_AASE_vocal.webm [loudness: -9 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420101527_ER%20fe-1_lungback.webm from audios/20230420101527_ER%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230420101527_ER%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20230420101527_ER%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20230420101527_ER%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20230420101527_ER%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20230420101527_ER%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20230420101527_ER%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20230420101527_ER%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20230420101527_ER%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20230420101527_ER%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 10 from 20230420101527_ER%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802120809_TRC%20fe-1_vocal.webm from audios/20220802120809_TRC%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220802120809_TRC%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220802120809_TRC%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220802120809_TRC%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220802120809_TRC%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418102811_LR%20fe-1_vocal.webm from audios/20230418102811_LR%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230418102811_LR%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20230418102811_LR%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230418102811_LR%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230418102811_LR%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127130817_RPY%20Fe_vocal.webm from audios/20220127130817_RPY%20Fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220127130817_RPY%20Fe_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220127130817_RPY%20Fe_vocal.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220127130817_RPY%20Fe_vocal.webm [loudness: -9 dB]\n",
            "  Clip 4 from 20220127130817_RPY%20Fe_vocal.webm [loudness: -9 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105133843_YH%20sin_vocal.webm from audios/20220105133843_YH%20sin_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220105133843_YH%20sin_vocal.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220105133843_YH%20sin_vocal.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220105133843_YH%20sin_vocal.webm [loudness: -78 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -78 dB]\n",
            "  Clip 4 from 20220105133843_YH%20sin_vocal.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220105133843_YH%20sin_vocal.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220105133843_YH%20sin_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220704112246_JGA%20fe-1_lungfront.webm from audios/20220704112246_JGA%20fe-1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220704112246_JGA%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220704112246_JGA%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220704112246_JGA%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220704112246_JGA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220704112246_JGA%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220704112246_JGA%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20220704112246_JGA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20220704112246_JGA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220704112246_JGA%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 10 from 20220704112246_JGA%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419104705_MG%20fe-1_vocal.webm from audios/20230419104705_MG%20fe-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20230419104705_MG%20fe-1_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20230419104705_MG%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20230419104705_MG%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115134035_CRAC_lungfront.webm from audios/20220115134035_CRAC_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220115134035_CRAC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220115134035_CRAC_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 3 from 20220115134035_CRAC_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 4 from 20220115134035_CRAC_lungfront.webm [loudness: -111 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -111 dB]\n",
            "  Clip 5 from 20220115134035_CRAC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220115134035_CRAC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212081824_Gnf%2023-2_vocal.webm from audios/20220212081824_Gnf%2023-2_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212081824_Gnf%2023-2_vocal.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220212081824_Gnf%2023-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220212081824_Gnf%2023-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319073113_MLQ%20fe%2019-1_lungfront.webm from audios/20220319073113_MLQ%20fe%2019-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319073113_MLQ%20fe%2019-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220319073113_MLQ%20fe%2019-1_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220319073113_MLQ%20fe%2019-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220319073113_MLQ%20fe%2019-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220319073113_MLQ%20fe%2019-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220319073113_MLQ%20fe%2019-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220319073113_MLQ%20fe%2019-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220319073113_MLQ%20fe%2019-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20220319073113_MLQ%20fe%2019-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122114315_GPOE%20fe_lungfront.webm from audios/20220122114315_GPOE%20fe_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122114315_GPOE%20fe_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220122114315_GPOE%20fe_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220122114315_GPOE%20fe_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220122114315_GPOE%20fe_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220122114315_GPOE%20fe_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119130925_MCNT_vocal.webm from audios/20220119130925_MCNT_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220119130925_MCNT_vocal.webm [loudness: -33 dB]\n",
            "  Clip 2 from 20220119130925_MCNT_vocal.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220119130925_MCNT_vocal.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220129124418_GADA%20fE_lungback.webm from audios/20220129124418_GADA%20fE_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220129124418_GADA%20fE_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220129124418_GADA%20fE_lungback.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220129124418_GADA%20fE_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220129124418_GADA%20fE_lungback.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220129124418_GADA%20fE_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220129124418_GADA%20fE_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212064424_Rgh%2016-2_lungback.webm from audios/20220212064424_Rgh%2016-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 13 2s clips\n",
            "  Clip 1 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -37 dB]\n",
            "  Clip 2 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -35 dB]\n",
            "  Clip 3 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -44 dB]\n",
            "  Clip 5 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -40 dB]\n",
            "  Clip 6 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -31 dB]\n",
            "  Clip 7 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -41 dB]\n",
            "  Clip 8 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -35 dB]\n",
            "  Clip 9 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -28 dB]\n",
            "  Clip 10 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -28 dB]\n",
            "  Clip 11 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip 12 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -38 dB]\n",
            "  Clip 13 from 20220212064424_Rgh%2016-2_lungback.webm [loudness: -34 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (13, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054534_ACD-D4_lungfront.webm from audios/20211207054534_ACD-D4_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20211207054534_ACD-D4_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20211207054534_ACD-D4_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20211207054534_ACD-D4_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20211207054534_ACD-D4_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20211207054534_ACD-D4_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20211207054534_ACD-D4_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20211207054534_ACD-D4_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20211207054534_ACD-D4_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165337_Eta_lungfront.webm from audios/20220504165337_Eta_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220504165337_Eta_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220504165337_Eta_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220504165337_Eta_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220504165337_Eta_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220504165337_Eta_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220504165337_Eta_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220630095905_ARB%20fe-1_vocal.webm from audios/20220630095905_ARB%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220630095905_ARB%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220630095905_ARB%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220630095905_ARB%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220630095905_ARB%20fe-1_vocal.webm [loudness: -55 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114113551_HRP_lungfront.webm from audios/20220114113551_HRP_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114113551_HRP_lungfront.webm [loudness: -88 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -88 dB]\n",
            "  Clip 2 from 20220114113551_HRP_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220114113551_HRP_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220114113551_HRP_lungfront.webm [loudness: -69 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 5 from 20220114113551_HRP_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230424133743_JA%20fe-1_vocal.webm from audios/20230424133743_JA%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230424133743_JA%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20230424133743_JA%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230424133743_JA%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20230424133743_JA%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125112513_DAKP%20es_vocal.webm from audios/20220125112513_DAKP%20es_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125112513_DAKP%20es_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220125112513_DAKP%20es_vocal.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220125112513_DAKP%20es_vocal.webm [loudness: -9 dB]\n",
            "  Clip 4 from 20220125112513_DAKP%20es_vocal.webm [loudness: -8 dB]\n",
            "  Clip 5 from 20220125112513_DAKP%20es_vocal.webm [loudness: -7 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516150924_Mfyc1-16-5_vocal.webm from audios/20220516150924_Mfyc1-16-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516150924_Mfyc1-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220516150924_Mfyc1-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220516150924_Mfyc1-16-5_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220516150924_Mfyc1-16-5_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709050025_BUM%20fe-1_lungfront.webm from audios/20220709050025_BUM%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709050025_BUM%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220709050025_BUM%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220709050025_BUM%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220709050025_BUM%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220709050025_BUM%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220709050025_BUM%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220709050025_BUM%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220709050025_BUM%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220709050025_BUM%20fe-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207095803_Fe-1%20FW_lungback.webm from audios/20221207095803_Fe-1%20FW_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221207095803_Fe-1%20FW_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20221207095803_Fe-1%20FW_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20221207095803_Fe-1%20FW_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20221207095803_Fe-1%20FW_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221207095803_Fe-1%20FW_lungback.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20221207095803_Fe-1%20FW_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20221207095803_Fe-1%20FW_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20221207095803_Fe-1%20FW_lungback.webm [loudness: -27 dB]\n",
            "  Clip 9 from 20221207095803_Fe-1%20FW_lungback.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304081704_MHR%20fe%204-1_lungfront.webm from audios/20220304081704_MHR%20fe%204-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304081704_MHR%20fe%204-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 2 from 20220304081704_MHR%20fe%204-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 3 from 20220304081704_MHR%20fe%204-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 4 from 20220304081704_MHR%20fe%204-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 5 from 20220304081704_MHR%20fe%204-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 6 from 20220304081704_MHR%20fe%204-1_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 7 from 20220304081704_MHR%20fe%204-1_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 8 from 20220304081704_MHR%20fe%204-1_lungfront.webm [loudness: -31 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302081247_TZP%20fe%202-2_vocal.webm from audios/20220302081247_TZP%20fe%202-2_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302081247_TZP%20fe%202-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220302081247_TZP%20fe%202-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220302081247_TZP%20fe%202-2_vocal.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220302081247_TZP%20fe%202-2_vocal.webm [loudness: -51 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124160633_RALL%20fe_lungback.webm from audios/20220124160633_RALL%20fe_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124160633_RALL%20fe_lungback.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220124160633_RALL%20fe_lungback.webm [loudness: -40 dB]\n",
            "  Clip 3 from 20220124160633_RALL%20fe_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220124160633_RALL%20fe_lungback.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20220124160633_RALL%20fe_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319094332_MME%20fe%2019-1_lungfront.webm from audios/20220319094332_MME%20fe%2019-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220319094332_MME%20fe%2019-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220319094332_MME%20fe%2019-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220319094332_MME%20fe%2019-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 4 from 20220319094332_MME%20fe%2019-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220319094332_MME%20fe%2019-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220319094332_MME%20fe%2019-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220319094332_MME%20fe%2019-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220319094332_MME%20fe%2019-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207131017_Fe-1%20MA_lungback.webm from audios/20221207131017_Fe-1%20MA_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221207131017_Fe-1%20MA_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20221207131017_Fe-1%20MA_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20221207131017_Fe-1%20MA_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20221207131017_Fe-1%20MA_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20221207131017_Fe-1%20MA_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20221207131017_Fe-1%20MA_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20221207131017_Fe-1%20MA_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20221207131017_Fe-1%20MA_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20221207131017_Fe-1%20MA_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708092832_ARB%20fe-3_vocal.webm from audios/20220708092832_ARB%20fe-3_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220708092832_ARB%20fe-3_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220708092832_ARB%20fe-3_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220708092832_ARB%20fe-3_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220708092832_ARB%20fe-3_vocal.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207100112_Fe-1%20WC_lungfront.webm from audios/20221207100112_Fe-1%20WC_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221207100112_Fe-1%20WC_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20221207100112_Fe-1%20WC_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20221207100112_Fe-1%20WC_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20221207100112_Fe-1%20WC_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20221207100112_Fe-1%20WC_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20221207100112_Fe-1%20WC_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20221207100112_Fe-1%20WC_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20221207100112_Fe-1%20WC_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20221207100112_Fe-1%20WC_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305075107_MRC%20fe%205-1_lungfront.webm from audios/20220305075107_MRC%20fe%205-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220305075107_MRC%20fe%205-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220305075107_MRC%20fe%205-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220305075107_MRC%20fe%205-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220305075107_MRC%20fe%205-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220305075107_MRC%20fe%205-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220305075107_MRC%20fe%205-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220305075107_MRC%20fe%205-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220305075107_MRC%20fe%205-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128124525_SCSHR%20fE_lungback.webm from audios/20220128124525_SCSHR%20fE_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128124525_SCSHR%20fE_lungback.webm [loudness: -62 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 2 from 20220128124525_SCSHR%20fE_lungback.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220128124525_SCSHR%20fE_lungback.webm [loudness: -59 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 4 from 20220128124525_SCSHR%20fE_lungback.webm [loudness: -49 dB]\n",
            "  Clip 5 from 20220128124525_SCSHR%20fE_lungback.webm [loudness: -48 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220718073538_RM%20fe-1_lungfront.webm from audios/20220718073538_RM%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220718073538_RM%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220718073538_RM%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220718073538_RM%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220718073538_RM%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220718073538_RM%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220718073538_RM%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220718073538_RM%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220718073538_RM%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 9 from 20220718073538_RM%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302093004_WOM%20fe%202-2_lungfront.webm from audios/20220302093004_WOM%20fe%202-2_lungfront.webm\n",
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 4 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 5 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 6 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 10 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 11 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 12 from 20220302093004_WOM%20fe%202-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (12, 512), data type: float32\n",
            "\n",
            "Loading file: 20220727082823_FSM%20fe-1_lungback.webm from audios/20220727082823_FSM%20fe-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220727082823_FSM%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220727082823_FSM%20fe-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20220727082823_FSM%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220727082823_FSM%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220727082823_FSM%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220727082823_FSM%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220727082823_FSM%20fe-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 8 from 20220727082823_FSM%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220727082823_FSM%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220715101331_RFC%20fe-3_lungfront.webm from audios/20220715101331_RFC%20fe-3_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220715101331_RFC%20fe-3_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220715101331_RFC%20fe-3_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220715101331_RFC%20fe-3_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220715101331_RFC%20fe-3_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220715101331_RFC%20fe-3_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220715101331_RFC%20fe-3_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220715101331_RFC%20fe-3_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 8 from 20220715101331_RFC%20fe-3_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220715101331_RFC%20fe-3_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420111142_FT%20fe-1_vocal.webm from audios/20230420111142_FT%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230420111142_FT%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20230420111142_FT%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230420111142_FT%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230420111142_FT%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419085806_JO%20fe-1_vocal.webm from audios/20230419085806_JO%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20230419085806_JO%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20230419085806_JO%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20230419085806_JO%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20230419085806_JO%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20230419085806_JO%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230419085806_JO%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421100451_DF%20fe-1_vocal.webm from audios/20230421100451_DF%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230421100451_DF%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20230421100451_DF%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20230421100451_DF%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20230421100451_DF%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220713083652_LML%20fe-1_lungback.webm from audios/20220713083652_LML%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220713083652_LML%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220713083652_LML%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220713083652_LML%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220713083652_LML%20fe-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20220713083652_LML%20fe-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220713083652_LML%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220713083652_LML%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220713083652_LML%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220713083652_LML%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220715104234_CBP%20fe-2_lungfront.webm from audios/20220715104234_CBP%20fe-2_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220715104234_CBP%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220715104234_CBP%20fe-2_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 3 from 20220715104234_CBP%20fe-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220715104234_CBP%20fe-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220715104234_CBP%20fe-2_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220715104234_CBP%20fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220715104234_CBP%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220715104234_CBP%20fe-2_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220715104234_CBP%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 10 from 20220715104234_CBP%20fe-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708093145_ARB%20fe-4_vocal.webm from audios/20220708093145_ARB%20fe-4_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220708093145_ARB%20fe-4_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220708093145_ARB%20fe-4_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220708093145_ARB%20fe-4_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220708093145_ARB%20fe-4_vocal.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220708093145_ARB%20fe-4_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305090804_APC%20fe%205-1_lungback.webm from audios/20220305090804_APC%20fe%205-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305090804_APC%20fe%205-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220305090804_APC%20fe%205-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220305090804_APC%20fe%205-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220305090804_APC%20fe%205-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220305090804_APC%20fe%205-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220305090804_APC%20fe%205-1_lungback.webm [loudness: -31 dB]\n",
            "  Clip 7 from 20220305090804_APC%20fe%205-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220305090804_APC%20fe%205-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220305090804_APC%20fe%205-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122114153_GPOE%20es_lungback.webm from audios/20220122114153_GPOE%20es_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122114153_GPOE%20es_lungback.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220122114153_GPOE%20es_lungback.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220122114153_GPOE%20es_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220122114153_GPOE%20es_lungback.webm [loudness: -9 dB]\n",
            "  Clip 5 from 20220122114153_GPOE%20es_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122110655_NFGC%20fe_lungfront.webm from audios/20220122110655_NFGC%20fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122110655_NFGC%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220122110655_NFGC%20fe_lungfront.webm [loudness: -103 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -103 dB]\n",
            "  Clip 3 from 20220122110655_NFGC%20fe_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 4 from 20220122110655_NFGC%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220122110655_NFGC%20fe_lungfront.webm [loudness: -49 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304082514_SAC%20fe%204-1_lungback.webm from audios/20220304082514_SAC%20fe%204-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304082514_SAC%20fe%204-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220304082514_SAC%20fe%204-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220304082514_SAC%20fe%204-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220304082514_SAC%20fe%204-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220304082514_SAC%20fe%204-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20220304082514_SAC%20fe%204-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220304082514_SAC%20fe%204-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220304082514_SAC%20fe%204-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220304082514_SAC%20fe%204-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114145132_AACC_lungfront.webm from audios/20220114145132_AACC_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220114145132_AACC_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20220114145132_AACC_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 3 from 20220114145132_AACC_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 4 from 20220114145132_AACC_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 5 from 20220114145132_AACC_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 6 from 20220114145132_AACC_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424111328_RB%20fe-1_lungfront.webm from audios/20230424111328_RB%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424111328_RB%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20230424111328_RB%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20230424111328_RB%20fe-1_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 4 from 20230424111328_RB%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20230424111328_RB%20fe-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20230424111328_RB%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20230424111328_RB%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20230424111328_RB%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20230424111328_RB%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20230424111328_RB%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302091211_APM%20fe%202-1_lungback.webm from audios/20220302091211_APM%20fe%202-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302091211_APM%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220302091211_APM%20fe%202-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220302091211_APM%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220302091211_APM%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220302091211_APM%20fe%202-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220302091211_APM%20fe%202-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220302091211_APM%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220302091211_APM%20fe%202-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220302091211_APM%20fe%202-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220519070721_KRRS%2019-05-22_vocal.webm from audios/20220519070721_KRRS%2019-05-22_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220519070721_KRRS%2019-05-22_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220519070721_KRRS%2019-05-22_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220519070721_KRRS%2019-05-22_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220519070721_KRRS%2019-05-22_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212064149_Rgh%2016-1_vocal.webm from audios/20220212064149_Rgh%2016-1_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220212064149_Rgh%2016-1_vocal.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220212064149_Rgh%2016-1_vocal.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516151109_Mfyc2-16-5_lungfront.webm from audios/20220516151109_Mfyc2-16-5_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516151109_Mfyc2-16-5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220516151109_Mfyc2-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220516151109_Mfyc2-16-5_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220516151109_Mfyc2-16-5_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220516151109_Mfyc2-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220516151109_Mfyc2-16-5_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220516151109_Mfyc2-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212072422_Lml%2020-2_vocal.webm from audios/20220212072422_Lml%2020-2_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220212072422_Lml%2020-2_vocal.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220212072422_Lml%2020-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220212072422_Lml%2020-2_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220212072422_Lml%2020-2_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319074246_RMC%20fe%2019-1_vocal.webm from audios/20220319074246_RMC%20fe%2019-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220319074246_RMC%20fe%2019-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220319074246_RMC%20fe%2019-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220319074246_RMC%20fe%2019-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220319074246_RMC%20fe%2019-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212070948_Tvs%2018-1_lungback.webm from audios/20220212070948_Tvs%2018-1_lungback.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -32 dB]\n",
            "  Clip 2 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -70 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 3 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -73 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 4 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -70 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 5 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -69 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 6 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -71 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 7 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -73 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 8 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -72 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 9 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -73 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 10 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -65 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 11 from 20220212070948_Tvs%2018-1_lungback.webm [loudness: -72 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127130655_RPY%20Es_vocal.webm from audios/20220127130655_RPY%20Es_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220127130655_RPY%20Es_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220127130655_RPY%20Es_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220127130655_RPY%20Es_vocal.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220804111858_TRC%20fe-2_lungfront.webm from audios/20220804111858_TRC%20fe-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220804111858_TRC%20fe-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220804111858_TRC%20fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220804111858_TRC%20fe-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220804111858_TRC%20fe-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220804111858_TRC%20fe-2_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220804111858_TRC%20fe-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220804111858_TRC%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220804111858_TRC%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220804111858_TRC%20fe-2_lungfront.webm [loudness: -25 dB]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212070948_Tvs%2018-1_vocal.webm from audios/20220212070948_Tvs%2018-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212070948_Tvs%2018-1_vocal.webm [loudness: -28 dB]\n",
            "  Clip 2 from 20220212070948_Tvs%2018-1_vocal.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220212070948_Tvs%2018-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119165019_SKMT_vocal.webm from audios/20220119165019_SKMT_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220119165019_SKMT_vocal.webm [loudness: -35 dB]\n",
            "  Clip 2 from 20220119165019_SKMT_vocal.webm [loudness: -34 dB]\n",
            "  Clip 3 from 20220119165019_SKMT_vocal.webm [loudness: -31 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424133743_JA%20fe-1_lungfront.webm from audios/20230424133743_JA%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424133743_JA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230424133743_JA%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20230424133743_JA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20230424133743_JA%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20230424133743_JA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20230424133743_JA%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230424133743_JA%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20230424133743_JA%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20230424133743_JA%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20230424133743_JA%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419103918_DA%20fe-1_lungfront.webm from audios/20230419103918_DA%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230419103918_DA%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20230419103918_DA%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20230419103918_DA%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20230419103918_DA%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20230419103918_DA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20230419103918_DA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20230419103918_DA%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20230419103918_DA%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20230419103918_DA%20fe-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202104033_Mcp-02-12-D3_lungfront.webm from audios/20211202104033_Mcp-02-12-D3_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211202104033_Mcp-02-12-D3_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20211202104033_Mcp-02-12-D3_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20211202104033_Mcp-02-12-D3_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20211202104033_Mcp-02-12-D3_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20211202104033_Mcp-02-12-D3_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20211202104033_Mcp-02-12-D3_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125140657_NRJJ%20fe_lungfront.webm from audios/20220125140657_NRJJ%20fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125140657_NRJJ%20fe_lungfront.webm [loudness: -64 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 2 from 20220125140657_NRJJ%20fe_lungfront.webm [loudness: -82 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -82 dB]\n",
            "  Clip 3 from 20220125140657_NRJJ%20fe_lungfront.webm [loudness: -104 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -104 dB]\n",
            "  Clip 4 from 20220125140657_NRJJ%20fe_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 5 from 20220125140657_NRJJ%20fe_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -70 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516144505_Sdpa1-16-5_lungfront.webm from audios/20220516144505_Sdpa1-16-5_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516144505_Sdpa1-16-5_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220516144505_Sdpa1-16-5_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220516144505_Sdpa1-16-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220516144505_Sdpa1-16-5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220516144505_Sdpa1-16-5_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220516144505_Sdpa1-16-5_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220516144505_Sdpa1-16-5_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 8 from 20220516144505_Sdpa1-16-5_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114122836_MMGC_lungback.webm from audios/20220114122836_MMGC_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114122836_MMGC_lungback.webm [loudness: -83 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 2 from 20220114122836_MMGC_lungback.webm [loudness: -67 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 3 from 20220114122836_MMGC_lungback.webm [loudness: -83 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 4 from 20220114122836_MMGC_lungback.webm [loudness: -55 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 5 from 20220114122836_MMGC_lungback.webm [loudness: -58 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220515223642_Jasr-16-5_lungback.webm from audios/20220515223642_Jasr-16-5_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220515223642_Jasr-16-5_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220515223642_Jasr-16-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220515223642_Jasr-16-5_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220515223642_Jasr-16-5_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220515223642_Jasr-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220515223642_Jasr-16-5_lungback.webm [loudness: -37 dB]\n",
            "  Clip 7 from 20220515223642_Jasr-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220515223642_Jasr-16-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220129133119_DAKP%20fE_lungback.webm from audios/20220129133119_DAKP%20fE_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220129133119_DAKP%20fE_lungback.webm [loudness: -49 dB]\n",
            "  Clip 2 from 20220129133119_DAKP%20fE_lungback.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220129133119_DAKP%20fE_lungback.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220129133119_DAKP%20fE_lungback.webm [loudness: -33 dB]\n",
            "  Clip 5 from 20220129133119_DAKP%20fE_lungback.webm [loudness: -41 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220111111424_CLD_lungfront.webm from audios/20220111111424_CLD_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220111111424_CLD_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220111111424_CLD_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220111111424_CLD_lungfront.webm [loudness: -34 dB]\n",
            "  Clip 4 from 20220111111424_CLD_lungfront.webm [loudness: -77 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -77 dB]\n",
            "  Clip 5 from 20220111111424_CLD_lungfront.webm [loudness: -115 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -115 dB]\n",
            "  Clip 6 from 20220111111424_CLD_lungfront.webm [loudness: -115 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -115 dB]\n",
            "  Clip 7 from 20220111111424_CLD_lungfront.webm [loudness: -109 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -109 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124124846_AOLR%20fe_lungfront.webm from audios/20220124124846_AOLR%20fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124124846_AOLR%20fe_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220124124846_AOLR%20fe_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220124124846_AOLR%20fe_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220124124846_AOLR%20fe_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 5 from 20220124124846_AOLR%20fe_lungfront.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114120408_FWS_vocal.webm from audios/20220114120408_FWS_vocal.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220114120408_FWS_vocal.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220114120408_FWS_vocal.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220114120408_FWS_vocal.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220114120408_FWS_vocal.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220114120408_FWS_vocal.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220114120408_FWS_vocal.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20211216131725_NSR-CD_lungback.webm from audios/20211216131725_NSR-CD_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211216131725_NSR-CD_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20211216131725_NSR-CD_lungback.webm [loudness: -39 dB]\n",
            "  Clip 3 from 20211216131725_NSR-CD_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20211216131725_NSR-CD_lungback.webm [loudness: -32 dB]\n",
            "  Clip 5 from 20211216131725_NSR-CD_lungback.webm [loudness: -35 dB]\n",
            "  Clip 6 from 20211216131725_NSR-CD_lungback.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304052032_CRD_vocal.webm from audios/20220304052032_CRD_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220304052032_CRD_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220304052032_CRD_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220304052032_CRD_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220304052032_CRD_vocal.webm [loudness: -53 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063621_JMT-D3_lungback.webm from audios/20211209063621_JMT-D3_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20211209063621_JMT-D3_lungback.webm [loudness: -47 dB]\n",
            "  Clip 2 from 20211209063621_JMT-D3_lungback.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20211209063621_JMT-D3_lungback.webm [loudness: -64 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 4 from 20211209063621_JMT-D3_lungback.webm [loudness: -63 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 5 from 20211209063621_JMT-D3_lungback.webm [loudness: -55 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 6 from 20211209063621_JMT-D3_lungback.webm [loudness: -59 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 7 from 20211209063621_JMT-D3_lungback.webm [loudness: -61 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 8 from 20211209063621_JMT-D3_lungback.webm [loudness: -62 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 9 from 20211209063621_JMT-D3_lungback.webm [loudness: -49 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125112513_DAKP%20es_lungback.webm from audios/20220125112513_DAKP%20es_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125112513_DAKP%20es_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220125112513_DAKP%20es_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220125112513_DAKP%20es_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220125112513_DAKP%20es_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220125112513_DAKP%20es_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075038_TRC%2026-1_lungback.webm from audios/20220215075038_TRC%2026-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220215075038_TRC%2026-1_lungback.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20220215075038_TRC%2026-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220215075038_TRC%2026-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220215075038_TRC%2026-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 5 from 20220215075038_TRC%2026-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 6 from 20220215075038_TRC%2026-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 7 from 20220215075038_TRC%2026-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20220215075038_TRC%2026-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 9 from 20220215075038_TRC%2026-1_lungback.webm [loudness: -57 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 10 from 20220215075038_TRC%2026-1_lungback.webm [loudness: -58 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516152223_Jayg2-16-5_vocal.webm from audios/20220516152223_Jayg2-16-5_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220516152223_Jayg2-16-5_vocal.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220516152223_Jayg2-16-5_vocal.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220516152223_Jayg2-16-5_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220516152223_Jayg2-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220516152223_Jayg2-16-5_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303090534_CMF%20fe%203-1_lungback.webm from audios/20220303090534_CMF%20fe%203-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220303090534_CMF%20fe%203-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220303090534_CMF%20fe%203-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220303090534_CMF%20fe%203-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220303090534_CMF%20fe%203-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220303090534_CMF%20fe%203-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220303090534_CMF%20fe%203-1_lungback.webm [loudness: -30 dB]\n",
            "  Clip 7 from 20220303090534_CMF%20fe%203-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220303090534_CMF%20fe%203-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220303090534_CMF%20fe%203-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 10 from 20220303090534_CMF%20fe%203-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419114613_AR%20fe-1_lungback.webm from audios/20230419114613_AR%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419114613_AR%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230419114613_AR%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20230419114613_AR%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20230419114613_AR%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230419114613_AR%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20230419114613_AR%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230419114613_AR%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230419114613_AR%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20230419114613_AR%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230419114613_AR%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20221212104450_Fe-1%20KP_vocal.webm from audios/20221212104450_Fe-1%20KP_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20221212104450_Fe-1%20KP_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20221212104450_Fe-1%20KP_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20221212104450_Fe-1%20KP_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20221212104450_Fe-1%20KP_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20221212104450_Fe-1%20KP_vocal.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20221212104450_Fe-1%20KP_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202103721_Mcp-02-12-D1_lungfront.webm from audios/20211202103721_Mcp-02-12-D1_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20211202103721_Mcp-02-12-D1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20211202103721_Mcp-02-12-D1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20211202103721_Mcp-02-12-D1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20211202103721_Mcp-02-12-D1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20211202103721_Mcp-02-12-D1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20211202103721_Mcp-02-12-D1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20211202103721_Mcp-02-12-D1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419092959_AA%20fe-1_vocal.webm from audios/20230419092959_AA%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230419092959_AA%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20230419092959_AA%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20230419092959_AA%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230419092959_AA%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124102435_ARJA%20es_vocal.webm from audios/20220124102435_ARJA%20es_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220124102435_ARJA%20es_vocal.webm [loudness: -38 dB]\n",
            "  Clip 2 from 20220124102435_ARJA%20es_vocal.webm [loudness: -38 dB]\n",
            "  Clip 3 from 20220124102435_ARJA%20es_vocal.webm [loudness: -37 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220727094501_CCG%20fe-1_lungback.webm from audios/20220727094501_CCG%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220727094501_CCG%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220727094501_CCG%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220727094501_CCG%20fe-1_lungback.webm [loudness: -31 dB]\n",
            "  Clip 4 from 20220727094501_CCG%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220727094501_CCG%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220727094501_CCG%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220727094501_CCG%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220727094501_CCG%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220727094501_CCG%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127113104_NRJJ%20Es_vocal.webm from audios/20220127113104_NRJJ%20Es_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220127113104_NRJJ%20Es_vocal.webm [loudness: -8 dB]\n",
            "  Clip 2 from 20220127113104_NRJJ%20Es_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20220127113104_NRJJ%20Es_vocal.webm [loudness: -9 dB]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215074418_Zmg%2025-1_vocal.webm from audios/20220215074418_Zmg%2025-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220215074418_Zmg%2025-1_vocal.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20220215074418_Zmg%2025-1_vocal.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20220215074418_Zmg%2025-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319094727_JGA%20fe%2019-1_lungfront.webm from audios/20220319094727_JGA%20fe%2019-1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220319094727_JGA%20fe%2019-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220319094727_JGA%20fe%2019-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220319094727_JGA%20fe%2019-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220319094727_JGA%20fe%2019-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220319094727_JGA%20fe%2019-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220319094727_JGA%20fe%2019-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220319094727_JGA%20fe%2019-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220319094727_JGA%20fe%2019-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220319094727_JGA%20fe%2019-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 10 from 20220319094727_JGA%20fe%2019-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105133643_YE_vocal.webm from audios/20220105133643_YE_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220105133643_YE_vocal.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220105133643_YE_vocal.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220105133643_YE_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220105133643_YE_vocal.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220105133643_YE_vocal.webm [loudness: -32 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305090804_APC%20fe%205-1_lungfront.webm from audios/20220305090804_APC%20fe%205-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305090804_APC%20fe%205-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220305090804_APC%20fe%205-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220305090804_APC%20fe%205-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220305090804_APC%20fe%205-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220305090804_APC%20fe%205-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220305090804_APC%20fe%205-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220305090804_APC%20fe%205-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220305090804_APC%20fe%205-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220305090804_APC%20fe%205-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304050722_LRM%204-1_lungback.webm from audios/20220304050722_LRM%204-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304050722_LRM%204-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220304050722_LRM%204-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220304050722_LRM%204-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220304050722_LRM%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220304050722_LRM%204-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220304050722_LRM%204-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220304050722_LRM%204-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 8 from 20220304050722_LRM%204-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220304050722_LRM%204-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212071822_Gbc%2019-2_vocal.webm from audios/20220212071822_Gbc%2019-2_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220212071822_Gbc%2019-2_vocal.webm [loudness: -30 dB]\n",
            "  Clip 2 from 20220212071822_Gbc%2019-2_vocal.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125140657_NRJJ%20fe_vocal.webm from audios/20220125140657_NRJJ%20fe_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125140657_NRJJ%20fe_vocal.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20220125140657_NRJJ%20fe_vocal.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220125140657_NRJJ%20fe_vocal.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220125140657_NRJJ%20fe_vocal.webm [loudness: -34 dB]\n",
            "  Clip 5 from 20220125140657_NRJJ%20fe_vocal.webm [loudness: -37 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604085705_CAD%20fe-2_vocal.webm from audios/20220604085705_CAD%20fe-2_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220604085705_CAD%20fe-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220604085705_CAD%20fe-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220604085705_CAD%20fe-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220604085705_CAD%20fe-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220604085705_CAD%20fe-2_vocal.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516153003_Lsma2-16-5_lungback.webm from audios/20220516153003_Lsma2-16-5_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516153003_Lsma2-16-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220516153003_Lsma2-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220516153003_Lsma2-16-5_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220516153003_Lsma2-16-5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220516153003_Lsma2-16-5_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220516153003_Lsma2-16-5_lungback.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20220516153003_Lsma2-16-5_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419092959_AA%20fe-1_lungfront.webm from audios/20230419092959_AA%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230419092959_AA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20230419092959_AA%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20230419092959_AA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20230419092959_AA%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20230419092959_AA%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20230419092959_AA%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20230419092959_AA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20230419092959_AA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20230419092959_AA%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122114315_GPOE%20fe_lungback.webm from audios/20220122114315_GPOE%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122114315_GPOE%20fe_lungback.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220122114315_GPOE%20fe_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220122114315_GPOE%20fe_lungback.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220122114315_GPOE%20fe_lungback.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220122114315_GPOE%20fe_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424111328_RB%20fe-1_lungback.webm from audios/20230424111328_RB%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424111328_RB%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230424111328_RB%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230424111328_RB%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230424111328_RB%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20230424111328_RB%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20230424111328_RB%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20230424111328_RB%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20230424111328_RB%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20230424111328_RB%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 10 from 20230424111328_RB%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114122836_MMGC_vocal.webm from audios/20220114122836_MMGC_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220114122836_MMGC_vocal.webm [loudness: -43 dB]\n",
            "  Clip 2 from 20220114122836_MMGC_vocal.webm [loudness: -41 dB]\n",
            "  Clip 3 from 20220114122836_MMGC_vocal.webm [loudness: -39 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302090338_RIT%20fe%202-1_lungfront.webm from audios/20220302090338_RIT%20fe%202-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220302090338_RIT%20fe%202-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220302090338_RIT%20fe%202-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220302090338_RIT%20fe%202-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220302090338_RIT%20fe%202-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220302090338_RIT%20fe%202-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220302090338_RIT%20fe%202-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220302090338_RIT%20fe%202-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220302090338_RIT%20fe%202-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122110655_NFGC%20fe_vocal.webm from audios/20220122110655_NFGC%20fe_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220122110655_NFGC%20fe_vocal.webm [loudness: -34 dB]\n",
            "  Clip 2 from 20220122110655_NFGC%20fe_vocal.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20220122110655_NFGC%20fe_vocal.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303050525_LYC%20fe%203-1_lungback.webm from audios/20220303050525_LYC%20fe%203-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303050525_LYC%20fe%203-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220303050525_LYC%20fe%203-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220303050525_LYC%20fe%203-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220303050525_LYC%20fe%203-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220303050525_LYC%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220303050525_LYC%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220303050525_LYC%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220303050525_LYC%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220303050525_LYC%20fe%203-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202103721_Mcp-02-12-D1_lungback.webm from audios/20211202103721_Mcp-02-12-D1_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211202103721_Mcp-02-12-D1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20211202103721_Mcp-02-12-D1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20211202103721_Mcp-02-12-D1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20211202103721_Mcp-02-12-D1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20211202103721_Mcp-02-12-D1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20211202103721_Mcp-02-12-D1_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516150119_Wgyv1-16-5_vocal.webm from audios/20220516150119_Wgyv1-16-5_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516150119_Wgyv1-16-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220516150119_Wgyv1-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220516150119_Wgyv1-16-5_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220516150119_Wgyv1-16-5_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128123854_CGJJ%20Fe_lungfront.webm from audios/20220128123854_CGJJ%20Fe_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220128123854_CGJJ%20Fe_lungfront.webm [loudness: -112 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -112 dB]\n",
            "  Clip 2 from 20220128123854_CGJJ%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220128123854_CGJJ%20Fe_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 4 from 20220128123854_CGJJ%20Fe_lungfront.webm [loudness: -86 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 5 from 20220128123854_CGJJ%20Fe_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 6 from 20220128123854_CGJJ%20Fe_lungfront.webm [loudness: -106 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -106 dB]\n",
            "  Clip 7 from 20220128123854_CGJJ%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220224135946_ARD%2033-2_lungback.webm from audios/20220224135946_ARD%2033-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220224135946_ARD%2033-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220224135946_ARD%2033-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220224135946_ARD%2033-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220224135946_ARD%2033-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220224135946_ARD%2033-2_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220224135946_ARD%2033-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220224135946_ARD%2033-2_lungback.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120162822_OEGP_lungback.webm from audios/20220120162822_OEGP_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220120162822_OEGP_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220120162822_OEGP_lungback.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220120162822_OEGP_lungback.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220120162822_OEGP_lungback.webm [loudness: -9 dB]\n",
            "  Clip 5 from 20220120162822_OEGP_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220120162822_OEGP_lungback.webm [loudness: -9 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20221118111510_Fe-1%20EP_lungfront.webm from audios/20221118111510_Fe-1%20EP_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20221118111510_Fe-1%20EP_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20221118111510_Fe-1%20EP_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20221118111510_Fe-1%20EP_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20221118111510_Fe-1%20EP_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20221118111510_Fe-1%20EP_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20221118111510_Fe-1%20EP_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20221118111510_Fe-1%20EP_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20221118111510_Fe-1%20EP_lungfront.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115154844_KMI_vocal.webm from audios/20220115154844_KMI_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220115154844_KMI_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220115154844_KMI_vocal.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303091025_JAR%20fe%203-1_lungback.webm from audios/20220303091025_JAR%20fe%203-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303091025_JAR%20fe%203-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220303091025_JAR%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220303091025_JAR%20fe%203-1_lungback.webm [loudness: -30 dB]\n",
            "  Clip 4 from 20220303091025_JAR%20fe%203-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220303091025_JAR%20fe%203-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220303091025_JAR%20fe%203-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220303091025_JAR%20fe%203-1_lungback.webm [loudness: -30 dB]\n",
            "  Clip 8 from 20220303091025_JAR%20fe%203-1_lungback.webm [loudness: -35 dB]\n",
            "  Clip 9 from 20220303091025_JAR%20fe%203-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220704112603_JGA.%20Fe-2_vocal.webm from audios/20220704112603_JGA.%20Fe-2_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220704112603_JGA.%20Fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220704112603_JGA.%20Fe-2_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220704112603_JGA.%20Fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220704112603_JGA.%20Fe-2_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128135337_PCSN%20fE_lungback.webm from audios/20220128135337_PCSN%20fE_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220128135337_PCSN%20fE_lungback.webm [loudness: -76 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 2 from 20220128135337_PCSN%20fE_lungback.webm [loudness: -125 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -125 dB]\n",
            "  Clip 3 from 20220128135337_PCSN%20fE_lungback.webm [loudness: -125 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -125 dB]\n",
            "  Clip 4 from 20220128135337_PCSN%20fE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220128135337_PCSN%20fE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220128135337_PCSN%20fE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220506051857_Abemn%206-5-22_vocal.webm from audios/20220506051857_Abemn%206-5-22_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220506051857_Abemn%206-5-22_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220506051857_Abemn%206-5-22_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302053604_MLQ%20fe%202-2_lungfront.webm from audios/20220302053604_MLQ%20fe%202-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -38 dB]\n",
            "  Clip 4 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 5 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 6 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 7 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 8 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -38 dB]\n",
            "  Clip 9 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -40 dB]\n",
            "  Clip 10 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 11 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 12 from 20220302053604_MLQ%20fe%202-2_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220211122728_OCF%2013_lungfront.webm from audios/20220211122728_OCF%2013_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220211122728_OCF%2013_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220211122728_OCF%2013_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220211122728_OCF%2013_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220211122728_OCF%2013_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 5 from 20220211122728_OCF%2013_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 6 from 20220211122728_OCF%2013_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 7 from 20220211122728_OCF%2013_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 8 from 20220211122728_OCF%2013_lungfront.webm [loudness: -41 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302091650_EAR%20fe%202-1_lungfront.webm from audios/20220302091650_EAR%20fe%202-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302091650_EAR%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220302091650_EAR%20fe%202-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220302091650_EAR%20fe%202-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220302091650_EAR%20fe%202-1_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 5 from 20220302091650_EAR%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220302091650_EAR%20fe%202-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220302091650_EAR%20fe%202-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 8 from 20220302091650_EAR%20fe%202-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220302091650_EAR%20fe%202-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220129132954_DAKP%20FE_vocal.webm from audios/20220129132954_DAKP%20FE_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220129132954_DAKP%20FE_vocal.webm [loudness: -37 dB]\n",
            "  Clip 2 from 20220129132954_DAKP%20FE_vocal.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20220129132954_DAKP%20FE_vocal.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220129132954_DAKP%20FE_vocal.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516144505_Sdpa1-16-5_vocal.webm from audios/20220516144505_Sdpa1-16-5_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220516144505_Sdpa1-16-5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220516144505_Sdpa1-16-5_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220516144505_Sdpa1-16-5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220516144505_Sdpa1-16-5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220516144505_Sdpa1-16-5_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303081659_RRA%20fe%203-1_lungback.webm from audios/20220303081659_RRA%20fe%203-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303081659_RRA%20fe%203-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220303081659_RRA%20fe%203-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220303081659_RRA%20fe%203-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220303081659_RRA%20fe%203-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220303081659_RRA%20fe%203-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220303081659_RRA%20fe%203-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220303081659_RRA%20fe%203-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220303081659_RRA%20fe%203-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220303081659_RRA%20fe%203-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220810095537_DLP%20fe-1_lungfront.webm from audios/20220810095537_DLP%20fe-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220810095537_DLP%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220810095537_DLP%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220810095537_DLP%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220810095537_DLP%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220810095537_DLP%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220810095537_DLP%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220810095537_DLP%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20220810095537_DLP%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802104203_TEO%20fe-1_vocal.webm from audios/20220802104203_TEO%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220802104203_TEO%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220802104203_TEO%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220802104203_TEO%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220802104203_TEO%20fe-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063621_JMT-D3_vocal.webm from audios/20211209063621_JMT-D3_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20211209063621_JMT-D3_vocal.webm [loudness: -30 dB]\n",
            "  Clip 2 from 20211209063621_JMT-D3_vocal.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20211209063621_JMT-D3_vocal.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20211209063621_JMT-D3_vocal.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20211209063621_JMT-D3_vocal.webm [loudness: -56 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108135008_LSH_vocal.webm from audios/20220108135008_LSH_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220108135008_LSH_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220108135008_LSH_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220108135008_LSH_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118111537_ARE_lungfront.webm from audios/20220118111537_ARE_lungfront.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220118111537_ARE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220118111537_ARE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220118111537_ARE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220118111537_ARE_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220708103953_FDV%20fe-1_vocal.webm from audios/20220708103953_FDV%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220708103953_FDV%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220708103953_FDV%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220708103953_FDV%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220708103953_FDV%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064137_JMT-P_lungfront.webm from audios/20211209064137_JMT-P_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211209064137_JMT-P_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 2 from 20211209064137_JMT-P_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 3 from 20211209064137_JMT-P_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 4 from 20211209064137_JMT-P_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20211209064137_JMT-P_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20211209064137_JMT-P_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -61 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220121145022_CHFA_vocal.webm from audios/20220121145022_CHFA_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220121145022_CHFA_vocal.webm [loudness: -50 dB]\n",
            "  Clip 2 from 20220121145022_CHFA_vocal.webm [loudness: -34 dB]\n",
            "  Clip 3 from 20220121145022_CHFA_vocal.webm [loudness: -34 dB]\n",
            "  Clip 4 from 20220121145022_CHFA_vocal.webm [loudness: -31 dB]\n",
            "  Clip 5 from 20220121145022_CHFA_vocal.webm [loudness: -37 dB]\n",
            "  Clip 6 from 20220121145022_CHFA_vocal.webm [loudness: -31 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220121121412_EOTS_lungback.webm from audios/20220121121412_EOTS_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220121121412_EOTS_lungback.webm [loudness: -72 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 2 from 20220121121412_EOTS_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220121121412_EOTS_lungback.webm [loudness: -59 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 4 from 20220121121412_EOTS_lungback.webm [loudness: -66 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 5 from 20220121121412_EOTS_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220506072041_Vmpr%206_5_22_vocal.webm from audios/20220506072041_Vmpr%206_5_22_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220506072041_Vmpr%206_5_22_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220506072041_Vmpr%206_5_22_vocal.webm [loudness: -9 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20211216131859_JSR-scp_lungfront.webm from audios/20211216131859_JSR-scp_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20211216131859_JSR-scp_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 2 from 20211216131859_JSR-scp_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 3 from 20211216131859_JSR-scp_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 4 from 20211216131859_JSR-scp_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 5 from 20211216131859_JSR-scp_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 6 from 20211216131859_JSR-scp_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 7 from 20211216131859_JSR-scp_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 8 from 20211216131859_JSR-scp_lungfront.webm [loudness: -48 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207055043_ADW-P2_lungfront.webm from audios/20211207055043_ADW-P2_lungfront.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20211207055043_ADW-P2_lungfront.webm [loudness: -69 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 2 from 20211207055043_ADW-P2_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 3 from 20211207055043_ADW-P2_lungfront.webm [loudness: -71 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 4 from 20211207055043_ADW-P2_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 5 from 20211207055043_ADW-P2_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 6 from 20211207055043_ADW-P2_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 7 from 20211207055043_ADW-P2_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 8 from 20211207055043_ADW-P2_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 9 from 20211207055043_ADW-P2_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 10 from 20211207055043_ADW-P2_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 11 from 20211207055043_ADW-P2_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -65 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516144141_Darz2-16-2_lungfront.webm from audios/20220516144141_Darz2-16-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220516144141_Darz2-16-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220516144141_Darz2-16-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220516144141_Darz2-16-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220516144141_Darz2-16-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220516144141_Darz2-16-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220516144141_Darz2-16-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220516144141_Darz2-16-2_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220516144141_Darz2-16-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220516144141_Darz2-16-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20220516144141_Darz2-16-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123054048_Fe-1%20GCh_vocal.webm from audios/20221123054048_Fe-1%20GCh_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221123054048_Fe-1%20GCh_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20221123054048_Fe-1%20GCh_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20221123054048_Fe-1%20GCh_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20221123054048_Fe-1%20GCh_vocal.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221123054048_Fe-1%20GCh_vocal.webm [loudness: -32 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165919_ETA%204-5_lungfront.webm from audios/20220504165919_ETA%204-5_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220504165919_ETA%204-5_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220504165919_ETA%204-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220504165919_ETA%204-5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220504165919_ETA%204-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220504165919_ETA%204-5_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105162835_CGT%20con_lungback.webm from audios/20220105162835_CGT%20con_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220105162835_CGT%20con_lungback.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220105162835_CGT%20con_lungback.webm [loudness: -69 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 3 from 20220105162835_CGT%20con_lungback.webm [loudness: -58 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 4 from 20220105162835_CGT%20con_lungback.webm [loudness: -87 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -87 dB]\n",
            "  Clip 5 from 20220105162835_CGT%20con_lungback.webm [loudness: -71 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 6 from 20220105162835_CGT%20con_lungback.webm [loudness: -85 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -85 dB]\n",
            "  Clip 7 from 20220105162835_CGT%20con_lungback.webm [loudness: -52 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 8 from 20220105162835_CGT%20con_lungback.webm [loudness: -76 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 9 from 20220105162835_CGT%20con_lungback.webm [loudness: -68 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -68 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220302091211_APM%20fe%202-1_lungfront.webm from audios/20220302091211_APM%20fe%202-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220302091211_APM%20fe%202-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220302091211_APM%20fe%202-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220302091211_APM%20fe%202-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220302091211_APM%20fe%202-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220302091211_APM%20fe%202-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220302091211_APM%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220302091211_APM%20fe%202-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220302091211_APM%20fe%202-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123083226_Fe-2%20VR_vocal.webm from audios/20221123083226_Fe-2%20VR_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221123083226_Fe-2%20VR_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20221123083226_Fe-2%20VR_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20221123083226_Fe-2%20VR_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20221123083226_Fe-2%20VR_vocal.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221123083226_Fe-2%20VR_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220625095002_DM%20fe-1_vocal.webm from audios/20220625095002_DM%20fe-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220625095002_DM%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220625095002_DM%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220625095002_DM%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220625095002_DM%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220625095002_DM%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125155955_MMLJ%20es_lungback.webm from audios/20220125155955_MMLJ%20es_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220125155955_MMLJ%20es_lungback.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220125155955_MMLJ%20es_lungback.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220125155955_MMLJ%20es_lungback.webm [loudness: -50 dB]\n",
            "  Clip 4 from 20220125155955_MMLJ%20es_lungback.webm [loudness: -51 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 5 from 20220125155955_MMLJ%20es_lungback.webm [loudness: -40 dB]\n",
            "  Clip 6 from 20220125155955_MMLJ%20es_lungback.webm [loudness: -70 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305073957_MHC%20fe%205-1_lungback.webm from audios/20220305073957_MHC%20fe%205-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305073957_MHC%20fe%205-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220305073957_MHC%20fe%205-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220305073957_MHC%20fe%205-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220305073957_MHC%20fe%205-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220305073957_MHC%20fe%205-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220305073957_MHC%20fe%205-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20220305073957_MHC%20fe%205-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220305073957_MHC%20fe%205-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220305073957_MHC%20fe%205-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165337_Eta_vocal.webm from audios/20220504165337_Eta_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220504165337_Eta_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220504165337_Eta_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220504165337_Eta_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220504165337_Eta_vocal.webm [loudness: -11 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119134648_MILS_lungback.webm from audios/20220119134648_MILS_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220119134648_MILS_lungback.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220119134648_MILS_lungback.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220119134648_MILS_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220119134648_MILS_lungback.webm [loudness: -11 dB]\n",
            "  Clip 5 from 20220119134648_MILS_lungback.webm [loudness: -7 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709073837_RCM%20fe-3_lungfront.webm from audios/20220709073837_RCM%20fe-3_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220709073837_RCM%20fe-3_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220709073837_RCM%20fe-3_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220709073837_RCM%20fe-3_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 4 from 20220709073837_RCM%20fe-3_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220709073837_RCM%20fe-3_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220709073837_RCM%20fe-3_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220709073837_RCM%20fe-3_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220709073837_RCM%20fe-3_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220709073837_RCM%20fe-3_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 10 from 20220709073837_RCM%20fe-3_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20221220075710_Fe-2%20PB_lungfront.webm from audios/20221220075710_Fe-2%20PB_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221220075710_Fe-2%20PB_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20221220075710_Fe-2%20PB_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20221220075710_Fe-2%20PB_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20221220075710_Fe-2%20PB_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221220075710_Fe-2%20PB_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20221220075710_Fe-2%20PB_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20221220075710_Fe-2%20PB_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20221220075710_Fe-2%20PB_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20221220075710_Fe-2%20PB_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504165035_Aves%204-5_lungfront.webm from audios/20220504165035_Aves%204-5_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220504165035_Aves%204-5_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220504165035_Aves%204-5_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220504165035_Aves%204-5_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220504165035_Aves%204-5_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20220504165035_Aves%204-5_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220504165035_Aves%204-5_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302082442_MOP%20fe%202-1_vocal.webm from audios/20220302082442_MOP%20fe%202-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302082442_MOP%20fe%202-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220302082442_MOP%20fe%202-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220302082442_MOP%20fe%202-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220302082442_MOP%20fe%202-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302090942_ANP%20fe%202-1_lungfront.webm from audios/20220302090942_ANP%20fe%202-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302090942_ANP%20fe%202-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220302090942_ANP%20fe%202-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20220302090942_ANP%20fe%202-1_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 4 from 20220302090942_ANP%20fe%202-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220302090942_ANP%20fe%202-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220302090942_ANP%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220302090942_ANP%20fe%202-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220302090942_ANP%20fe%202-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220302090942_ANP%20fe%202-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305075107_MRC%20fe%205-1_vocal.webm from audios/20220305075107_MRC%20fe%205-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220305075107_MRC%20fe%205-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220305075107_MRC%20fe%205-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220305075107_MRC%20fe%205-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220305075107_MRC%20fe%205-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107110951_SMAJ_lungback.webm from audios/20220107110951_SMAJ_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220107110951_SMAJ_lungback.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20220107110951_SMAJ_lungback.webm [loudness: -61 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 3 from 20220107110951_SMAJ_lungback.webm [loudness: -86 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 4 from 20220107110951_SMAJ_lungback.webm [loudness: -92 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -92 dB]\n",
            "  Clip 5 from 20220107110951_SMAJ_lungback.webm [loudness: -91 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -91 dB]\n",
            "  Clip 6 from 20220107110951_SMAJ_lungback.webm [loudness: -44 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419125101_JG%20fe-1_vocal.webm from audios/20230419125101_JG%20fe-1_vocal.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419125101_JG%20fe-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230419125101_JG%20fe-1_vocal.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20230419125101_JG%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230419125101_JG%20fe-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20230419125101_JG%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230419125101_JG%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20230419125101_JG%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20230419125101_JG%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20230419125101_JG%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 10 from 20230419125101_JG%20fe-1_vocal.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125162729_MCEE%20es_lungback.webm from audios/20220125162729_MCEE%20es_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125162729_MCEE%20es_lungback.webm [loudness: -51 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 2 from 20220125162729_MCEE%20es_lungback.webm [loudness: -116 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -116 dB]\n",
            "  Clip 3 from 20220125162729_MCEE%20es_lungback.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220125162729_MCEE%20es_lungback.webm [loudness: -48 dB]\n",
            "  Clip 5 from 20220125162729_MCEE%20es_lungback.webm [loudness: -65 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220604085459_CAD%20fe-1_lungback.webm from audios/20220604085459_CAD%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220604085459_CAD%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220604085459_CAD%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220604085459_CAD%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220604085459_CAD%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220604085459_CAD%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220604085459_CAD%20fe-1_lungback.webm [loudness: -31 dB]\n",
            "  Clip 7 from 20220604085459_CAD%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220604085459_CAD%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220604085459_CAD%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20220604085459_CAD%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303081248_LRR%20fe%203-1_vocal.webm from audios/20220303081248_LRR%20fe%203-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220303081248_LRR%20fe%203-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220303081248_LRR%20fe%203-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220303081248_LRR%20fe%203-1_vocal.webm [loudness: -39 dB]\n",
            "  Clip 4 from 20220303081248_LRR%20fe%203-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220503092428_Jonathan_lungfront.webm from audios/20220503092428_Jonathan_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220503092428_Jonathan_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 2 from 20220503092428_Jonathan_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220503092428_Jonathan_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220503092428_Jonathan_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 5 from 20220503092428_Jonathan_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220503092428_Jonathan_lungfront.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127134606_JAYG%20Es_lungback.webm from audios/20220127134606_JAYG%20Es_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220127134606_JAYG%20Es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220127134606_JAYG%20Es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220127134606_JAYG%20Es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220127134606_JAYG%20Es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220127134606_JAYG%20Es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220127134606_JAYG%20Es_lungback.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516151434_Yyrg1-16-5_lungfront.webm from audios/20220516151434_Yyrg1-16-5_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516151434_Yyrg1-16-5_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 2 from 20220516151434_Yyrg1-16-5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220516151434_Yyrg1-16-5_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220516151434_Yyrg1-16-5_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220516151434_Yyrg1-16-5_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220516151434_Yyrg1-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220516151434_Yyrg1-16-5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220516151434_Yyrg1-16-5_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302090338_RIT%20fe%202-1_lungback.webm from audios/20220302090338_RIT%20fe%202-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302090338_RIT%20fe%202-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220302090338_RIT%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220302090338_RIT%20fe%202-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220302090338_RIT%20fe%202-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20220302090338_RIT%20fe%202-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220302090338_RIT%20fe%202-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220302090338_RIT%20fe%202-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220302090338_RIT%20fe%202-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220302090338_RIT%20fe%202-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215074545_Zmg%2025-2_lungfront.webm from audios/20220215074545_Zmg%2025-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220215074545_Zmg%2025-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20220215074545_Zmg%2025-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220215074545_Zmg%2025-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220215074545_Zmg%2025-2_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 5 from 20220215074545_Zmg%2025-2_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 6 from 20220215074545_Zmg%2025-2_lungfront.webm [loudness: -50 dB]\n",
            "  Clip 7 from 20220215074545_Zmg%2025-2_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 8 from 20220215074545_Zmg%2025-2_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 9 from 20220215074545_Zmg%2025-2_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212081146_Mmb%2022-2_vocal.webm from audios/20220212081146_Mmb%2022-2_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220212081146_Mmb%2022-2_vocal.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220212081146_Mmb%2022-2_vocal.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220212081146_Mmb%2022-2_vocal.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220212081146_Mmb%2022-2_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420073507_NA%20fe-1_vocal.webm from audios/20230420073507_NA%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20230420073507_NA%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20230420073507_NA%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20230420073507_NA%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20230420073507_NA%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20230420073507_NA%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20230420073507_NA%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124134054_GMK%20fe_lungfront.webm from audios/20220124134054_GMK%20fe_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220124134054_GMK%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220124134054_GMK%20fe_lungfront.webm [loudness: -106 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -106 dB]\n",
            "  Clip 3 from 20220124134054_GMK%20fe_lungfront.webm [loudness: -83 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 4 from 20220124134054_GMK%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220124134054_GMK%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220124134054_GMK%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230419103918_DA%20fe-1_vocal.webm from audios/20230419103918_DA%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230419103918_DA%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20230419103918_DA%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230419103918_DA%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230419103918_DA%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128111313_MCFF%20fE_lungback.webm from audios/20220128111313_MCFF%20fE_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128111313_MCFF%20fE_lungback.webm [loudness: -67 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 2 from 20220128111313_MCFF%20fE_lungback.webm [loudness: -65 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 3 from 20220128111313_MCFF%20fE_lungback.webm [loudness: -80 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 4 from 20220128111313_MCFF%20fE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220128111313_MCFF%20fE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220117150958_EGX_lungfront.webm from audios/20220117150958_EGX_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220117150958_EGX_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220117150958_EGX_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 3 from 20220117150958_EGX_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 4 from 20220117150958_EGX_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 5 from 20220117150958_EGX_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 6 from 20220117150958_EGX_lungfront.webm [loudness: -44 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120121711_FFP_vocal.webm from audios/20220120121711_FFP_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220120121711_FFP_vocal.webm [loudness: -40 dB]\n",
            "  Clip 2 from 20220120121711_FFP_vocal.webm [loudness: -35 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124151143_JAYG%20fe_lungback.webm from audios/20220124151143_JAYG%20fe_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220124151143_JAYG%20fe_lungback.webm [loudness: -66 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 2 from 20220124151143_JAYG%20fe_lungback.webm [loudness: -104 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -104 dB]\n",
            "  Clip 3 from 20220124151143_JAYG%20fe_lungback.webm [loudness: -88 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -88 dB]\n",
            "  Clip 4 from 20220124151143_JAYG%20fe_lungback.webm [loudness: -88 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -88 dB]\n",
            "  Clip 5 from 20220124151143_JAYG%20fe_lungback.webm [loudness: -80 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 6 from 20220124151143_JAYG%20fe_lungback.webm [loudness: -73 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -73 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220625095002_DM%20fe-1_lungback.webm from audios/20220625095002_DM%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220625095002_DM%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220625095002_DM%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220625095002_DM%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220625095002_DM%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220625095002_DM%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220625095002_DM%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220625095002_DM%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20220625095002_DM%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20220625095002_DM%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20220625095002_DM%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303090534_CMF%20fe%203-1_vocal.webm from audios/20220303090534_CMF%20fe%203-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220303090534_CMF%20fe%203-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220303090534_CMF%20fe%203-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220303090534_CMF%20fe%203-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220303090534_CMF%20fe%203-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305075107_MRC%20fe%205-1_lungback.webm from audios/20220305075107_MRC%20fe%205-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305075107_MRC%20fe%205-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220305075107_MRC%20fe%205-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220305075107_MRC%20fe%205-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220305075107_MRC%20fe%205-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220305075107_MRC%20fe%205-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220305075107_MRC%20fe%205-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220305075107_MRC%20fe%205-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220305075107_MRC%20fe%205-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20220305075107_MRC%20fe%205-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304082033_MQR%20fe%204-1_lungfront.webm from audios/20220304082033_MQR%20fe%204-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220304082033_MQR%20fe%204-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220304082033_MQR%20fe%204-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220304082033_MQR%20fe%204-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220304082033_MQR%20fe%204-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220304082033_MQR%20fe%204-1_lungfront.webm [loudness: -9 dB]\n",
            "  Clip 6 from 20220304082033_MQR%20fe%204-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220304082033_MQR%20fe%204-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220304082033_MQR%20fe%204-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220304082033_MQR%20fe%204-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20220304082033_MQR%20fe%204-1_lungfront.webm [loudness: -46 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709073607_RCM%20fe-2_vocal.webm from audios/20220709073607_RCM%20fe-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220709073607_RCM%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220709073607_RCM%20fe-2_vocal.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220709073607_RCM%20fe-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220709073607_RCM%20fe-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107163554_PMA_vocal.webm from audios/20220107163554_PMA_vocal.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220107163554_PMA_vocal.webm [loudness: -32 dB]\n",
            "  Clip 2 from 20220107163554_PMA_vocal.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220107163554_PMA_vocal.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220107163554_PMA_vocal.webm [loudness: -34 dB]\n",
            "  Clip 5 from 20220107163554_PMA_vocal.webm [loudness: -43 dB]\n",
            "  Clip 6 from 20220107163554_PMA_vocal.webm [loudness: -64 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 7 from 20220107163554_PMA_vocal.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418103903_CA%20fe-1_vocal.webm from audios/20230418103903_CA%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20230418103903_CA%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20230418103903_CA%20fe-1_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20230418103903_CA%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20230418103903_CA%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20230418103903_CA%20fe-1_vocal.webm [loudness: -38 dB]\n",
            "  Clip 6 from 20230418103903_CA%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128111313_MCFF%20fE_vocal.webm from audios/20220128111313_MCFF%20fE_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220128111313_MCFF%20fE_vocal.webm [loudness: -41 dB]\n",
            "  Clip 2 from 20220128111313_MCFF%20fE_vocal.webm [loudness: -39 dB]\n",
            "  Clip 3 from 20220128111313_MCFF%20fE_vocal.webm [loudness: -38 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212072243_Lml%2020-1_vocal.webm from audios/20220212072243_Lml%2020-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220212072243_Lml%2020-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220212072243_Lml%2020-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220212072243_Lml%2020-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220212072243_Lml%2020-1_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120143633_SBDS_lungback.webm from audios/20220120143633_SBDS_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220120143633_SBDS_lungback.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220120143633_SBDS_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220120143633_SBDS_lungback.webm [loudness: -9 dB]\n",
            "  Clip 4 from 20220120143633_SBDS_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220120143633_SBDS_lungback.webm [loudness: -10 dB]\n",
            "  Clip 6 from 20220120143633_SBDS_lungback.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802083643_JQZ%20fe-2_vocal.webm from audios/20220802083643_JQZ%20fe-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220802083643_JQZ%20fe-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220802083643_JQZ%20fe-2_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220802083643_JQZ%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220802083643_JQZ%20fe-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220802083643_JQZ%20fe-2_vocal.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127153613_RAJL%20fe_lungfront.webm from audios/20220127153613_RAJL%20fe_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127153613_RAJL%20fe_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 2 from 20220127153613_RAJL%20fe_lungfront.webm [loudness: -82 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -82 dB]\n",
            "  Clip 3 from 20220127153613_RAJL%20fe_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 4 from 20220127153613_RAJL%20fe_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 5 from 20220127153613_RAJL%20fe_lungfront.webm [loudness: -42 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108152718_PMAD_lungback.webm from audios/20220108152718_PMAD_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220108152718_PMAD_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220108152718_PMAD_lungback.webm [loudness: -89 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -89 dB]\n",
            "  Clip 3 from 20220108152718_PMAD_lungback.webm [loudness: -94 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -94 dB]\n",
            "  Clip 4 from 20220108152718_PMAD_lungback.webm [loudness: -94 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -94 dB]\n",
            "  Clip 5 from 20220108152718_PMAD_lungback.webm [loudness: -94 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -94 dB]\n",
            "  Clip 6 from 20220108152718_PMAD_lungback.webm [loudness: -94 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -94 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212070948_Tvs%2018-1_lungfront.webm from audios/20220212070948_Tvs%2018-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 3 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 4 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -69 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 5 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 6 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 7 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 8 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -74 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 9 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 10 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -72 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 11 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -71 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 12 from 20220212070948_Tvs%2018-1_lungfront.webm [loudness: -74 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -74 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220303050525_LYC%20fe%203-1_lungfront.webm from audios/20220303050525_LYC%20fe%203-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303050525_LYC%20fe%203-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220303050525_LYC%20fe%203-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220303050525_LYC%20fe%203-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220303050525_LYC%20fe%203-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220303050525_LYC%20fe%203-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220303050525_LYC%20fe%203-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 7 from 20220303050525_LYC%20fe%203-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220303050525_LYC%20fe%203-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220303050525_LYC%20fe%203-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115134035_CRAC_lungback.webm from audios/20220115134035_CRAC_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115134035_CRAC_lungback.webm [loudness: -65 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 2 from 20220115134035_CRAC_lungback.webm [loudness: -66 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 3 from 20220115134035_CRAC_lungback.webm [loudness: -79 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 4 from 20220115134035_CRAC_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220115134035_CRAC_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220105153039_GUF%20SIN_lungfront.webm from audios/20220105153039_GUF%20SIN_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220105153039_GUF%20SIN_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 2 from 20220105153039_GUF%20SIN_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220105153039_GUF%20SIN_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 4 from 20220105153039_GUF%20SIN_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220105153039_GUF%20SIN_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 6 from 20220105153039_GUF%20SIN_lungfront.webm [loudness: -84 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -84 dB]\n",
            "  Clip 7 from 20220105153039_GUF%20SIN_lungfront.webm [loudness: -84 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -84 dB]\n",
            "  Clip 8 from 20220105153039_GUF%20SIN_lungfront.webm [loudness: -77 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -77 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220718070922_MGC%20fe-1_vocal.webm from audios/20220718070922_MGC%20fe-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220718070922_MGC%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220718070922_MGC%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220718070922_MGC%20fe-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220718070922_MGC%20fe-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220121125602_HRMM_lungfront.webm from audios/20220121125602_HRMM_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220121125602_HRMM_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220121125602_HRMM_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 3 from 20220121125602_HRMM_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220121125602_HRMM_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220121125602_HRMM_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20221118094140_Fe-1%20JG_lungfront.webm from audios/20221118094140_Fe-1%20JG_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20221118094140_Fe-1%20JG_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20221118094140_Fe-1%20JG_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20221118094140_Fe-1%20JG_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20221118094140_Fe-1%20JG_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20221118094140_Fe-1%20JG_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20221118094140_Fe-1%20JG_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 7 from 20221118094140_Fe-1%20JG_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20221118094140_Fe-1%20JG_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20221213121136_Fe-1%20GM_vocal.webm from audios/20221213121136_Fe-1%20GM_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221213121136_Fe-1%20GM_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20221213121136_Fe-1%20GM_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20221213121136_Fe-1%20GM_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20221213121136_Fe-1%20GM_vocal.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221213121136_Fe-1%20GM_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054733_ADW-D5_lungback.webm from audios/20211207054733_ADW-D5_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20211207054733_ADW-D5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20211207054733_ADW-D5_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20211207054733_ADW-D5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20211207054733_ADW-D5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20211207054733_ADW-D5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20211207054733_ADW-D5_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20211207054733_ADW-D5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 8 from 20211207054733_ADW-D5_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304052543_YH%20fe%204-1_lungback.webm from audios/20220304052543_YH%20fe%204-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304052543_YH%20fe%204-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220304052543_YH%20fe%204-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220304052543_YH%20fe%204-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220304052543_YH%20fe%204-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220304052543_YH%20fe%204-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220304052543_YH%20fe%204-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20220304052543_YH%20fe%204-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220304052543_YH%20fe%204-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212080246_Afc%2021-2_vocal.webm from audios/20220212080246_Afc%2021-2_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220212080246_Afc%2021-2_vocal.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220212080246_Afc%2021-2_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302060345_PRC%20fe%202-1_lungback.webm from audios/20220302060345_PRC%20fe%202-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302060345_PRC%20fe%202-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220302060345_PRC%20fe%202-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220302060345_PRC%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220302060345_PRC%20fe%202-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20220302060345_PRC%20fe%202-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220302060345_PRC%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220302060345_PRC%20fe%202-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220302060345_PRC%20fe%202-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220302060345_PRC%20fe%202-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421090611_LS%20fe-1_lungfront.webm from audios/20230421090611_LS%20fe-1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230421090611_LS%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20230421090611_LS%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20230421090611_LS%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20230421090611_LS%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230421090611_LS%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20230421090611_LS%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20230421090611_LS%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20230421090611_LS%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20230421090611_LS%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230421090611_LS%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107144605_VYFS_vocal.webm from audios/20220107144605_VYFS_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220107144605_VYFS_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220107144605_VYFS_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220107144605_VYFS_vocal.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220107144605_VYFS_vocal.webm [loudness: -36 dB]\n",
            "  Clip 5 from 20220107144605_VYFS_vocal.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418103903_CA%20fe-1_lungback.webm from audios/20230418103903_CA%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230418103903_CA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20230418103903_CA%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20230418103903_CA%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230418103903_CA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20230418103903_CA%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20230418103903_CA%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20230418103903_CA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20230418103903_CA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 9 from 20230418103903_CA%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 10 from 20230418103903_CA%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303082111_JFC%20fe%203-1_lungback.webm from audios/20220303082111_JFC%20fe%203-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303082111_JFC%20fe%203-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220303082111_JFC%20fe%203-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220303082111_JFC%20fe%203-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220303082111_JFC%20fe%203-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220303082111_JFC%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220303082111_JFC%20fe%203-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220303082111_JFC%20fe%203-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220303082111_JFC%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220303082111_JFC%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220723121728_JMT%20fe-1_vocal.webm from audios/20220723121728_JMT%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220723121728_JMT%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220723121728_JMT%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220723121728_JMT%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220723121728_JMT%20fe-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126161918_ABM%20Fe_lungfront.webm from audios/20220126161918_ABM%20Fe_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220126161918_ABM%20Fe_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 2 from 20220126161918_ABM%20Fe_lungfront.webm [loudness: -71 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 3 from 20220126161918_ABM%20Fe_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 4 from 20220126161918_ABM%20Fe_lungfront.webm [loudness: -107 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -107 dB]\n",
            "  Clip 5 from 20220126161918_ABM%20Fe_lungfront.webm [loudness: -109 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -109 dB]\n",
            "  Clip 6 from 20220126161918_ABM%20Fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220715092715_LML%20fe-2_lungfront.webm from audios/20220715092715_LML%20fe-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220715092715_LML%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220715092715_LML%20fe-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220715092715_LML%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220715092715_LML%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220715092715_LML%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220715092715_LML%20fe-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220715092715_LML%20fe-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220715092715_LML%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220715092715_LML%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125155955_MMLJ%20es_lungfront.webm from audios/20220125155955_MMLJ%20es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125155955_MMLJ%20es_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 2 from 20220125155955_MMLJ%20es_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 3 from 20220125155955_MMLJ%20es_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220125155955_MMLJ%20es_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 5 from 20220125155955_MMLJ%20es_lungfront.webm [loudness: -50 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115141333_RCYM_lungback.webm from audios/20220115141333_RCYM_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115141333_RCYM_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220115141333_RCYM_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220115141333_RCYM_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220115141333_RCYM_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220115141333_RCYM_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220302054305_DAT%20fe%202-2_lungback.webm from audios/20220302054305_DAT%20fe%202-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220302054305_DAT%20fe%202-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220302054305_DAT%20fe%202-2_lungback.webm [loudness: -50 dB]\n",
            "  Clip 3 from 20220302054305_DAT%20fe%202-2_lungback.webm [loudness: -53 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 4 from 20220302054305_DAT%20fe%202-2_lungback.webm [loudness: -45 dB]\n",
            "  Clip 5 from 20220302054305_DAT%20fe%202-2_lungback.webm [loudness: -45 dB]\n",
            "  Clip 6 from 20220302054305_DAT%20fe%202-2_lungback.webm [loudness: -45 dB]\n",
            "  Clip 7 from 20220302054305_DAT%20fe%202-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 8 from 20220302054305_DAT%20fe%202-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 9 from 20220302054305_DAT%20fe%202-2_lungback.webm [loudness: -43 dB]\n",
            "  Clip 10 from 20220302054305_DAT%20fe%202-2_lungback.webm [loudness: -45 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419120707_ET%20fe-1_vocal.webm from audios/20230419120707_ET%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230419120707_ET%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20230419120707_ET%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20230419120707_ET%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230419120707_ET%20fe-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516153654_Jasr2-16-05_lungback.webm from audios/20220516153654_Jasr2-16-05_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516153654_Jasr2-16-05_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220516153654_Jasr2-16-05_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220516153654_Jasr2-16-05_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220516153654_Jasr2-16-05_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220516153654_Jasr2-16-05_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220516153654_Jasr2-16-05_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220516153654_Jasr2-16-05_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708092832_ARB%20fe-3_lungfront.webm from audios/20220708092832_ARB%20fe-3_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220708092832_ARB%20fe-3_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220708092832_ARB%20fe-3_lungfront.webm [loudness: -34 dB]\n",
            "  Clip 3 from 20220708092832_ARB%20fe-3_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 4 from 20220708092832_ARB%20fe-3_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220708092832_ARB%20fe-3_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220708092832_ARB%20fe-3_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 7 from 20220708092832_ARB%20fe-3_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 8 from 20220708092832_ARB%20fe-3_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 9 from 20220708092832_ARB%20fe-3_lungfront.webm [loudness: -32 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054901_ACW-P1_lungback.webm from audios/20211207054901_ACW-P1_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207054901_ACW-P1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20211207054901_ACW-P1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20211207054901_ACW-P1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 4 from 20211207054901_ACW-P1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20211207054901_ACW-P1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20211207054901_ACW-P1_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123121132_Fe-1%20RC_lungback.webm from audios/20221123121132_Fe-1%20RC_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123121132_Fe-1%20RC_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20221123121132_Fe-1%20RC_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20221123121132_Fe-1%20RC_lungback.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20221123121132_Fe-1%20RC_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20221123121132_Fe-1%20RC_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20221123121132_Fe-1%20RC_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20221123121132_Fe-1%20RC_lungback.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20221123121132_Fe-1%20RC_lungback.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20221123121132_Fe-1%20RC_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117155838_ABPC_lungfront.webm from audios/20220117155838_ABPC_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220117155838_ABPC_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 2 from 20220117155838_ABPC_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 3 from 20220117155838_ABPC_lungfront.webm [loudness: -72 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 4 from 20220117155838_ABPC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220117155838_ABPC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 6 from 20220117155838_ABPC_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220129124418_GADA%20fE_lungfront.webm from audios/20220129124418_GADA%20fE_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220129124418_GADA%20fE_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220129124418_GADA%20fE_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220129124418_GADA%20fE_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220129124418_GADA%20fE_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220129124418_GADA%20fE_lungfront.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304052223_CRD%20fe%204-1_vocal.webm from audios/20220304052223_CRD%20fe%204-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220304052223_CRD%20fe%204-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220304052223_CRD%20fe%204-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220304052223_CRD%20fe%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220304052223_CRD%20fe%204-1_vocal.webm [loudness: -53 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20221118111510_Fe-1%20EP_lungback.webm from audios/20221118111510_Fe-1%20EP_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221118111510_Fe-1%20EP_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20221118111510_Fe-1%20EP_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20221118111510_Fe-1%20EP_lungback.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20221118111510_Fe-1%20EP_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20221118111510_Fe-1%20EP_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20221118111510_Fe-1%20EP_lungback.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20221118111510_Fe-1%20EP_lungback.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20221118111510_Fe-1%20EP_lungback.webm [loudness: -12 dB]\n",
            "  Clip 9 from 20221118111510_Fe-1%20EP_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220713092907_JFC%20fe-1_vocal.webm from audios/20220713092907_JFC%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220713092907_JFC%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220713092907_JFC%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220713092907_JFC%20fe-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220713092907_JFC%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516151615_Yyrg2-16-5_lungback.webm from audios/20220516151615_Yyrg2-16-5_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516151615_Yyrg2-16-5_lungback.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220516151615_Yyrg2-16-5_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220516151615_Yyrg2-16-5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220516151615_Yyrg2-16-5_lungback.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220516151615_Yyrg2-16-5_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220516151615_Yyrg2-16-5_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220516151615_Yyrg2-16-5_lungback.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220516151615_Yyrg2-16-5_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305085654_RGM%20fe%205-1_vocal.webm from audios/20220305085654_RGM%20fe%205-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220305085654_RGM%20fe%205-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220305085654_RGM%20fe%205-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220305085654_RGM%20fe%205-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220305085654_RGM%20fe%205-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220305085654_RGM%20fe%205-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20220305085654_RGM%20fe%205-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212080851_Mmb%2022.1_vocal.webm from audios/20220212080851_Mmb%2022.1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220212080851_Mmb%2022.1_vocal.webm [loudness: -27 dB]\n",
            "  Clip 2 from 20220212080851_Mmb%2022.1_vocal.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220212080851_Mmb%2022.1_vocal.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220212080851_Mmb%2022.1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220212080851_Mmb%2022.1_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118121138_LRLP_vocal.webm from audios/20220118121138_LRLP_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220118121138_LRLP_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220118121138_LRLP_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220118121138_LRLP_vocal.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105163221_CGT%20sin_lungback.webm from audios/20220105163221_CGT%20sin_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220105163221_CGT%20sin_lungback.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220105163221_CGT%20sin_lungback.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220105163221_CGT%20sin_lungback.webm [loudness: -40 dB]\n",
            "  Clip 4 from 20220105163221_CGT%20sin_lungback.webm [loudness: -53 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 5 from 20220105163221_CGT%20sin_lungback.webm [loudness: -73 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 6 from 20220105163221_CGT%20sin_lungback.webm [loudness: -75 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 7 from 20220105163221_CGT%20sin_lungback.webm [loudness: -79 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 8 from 20220105163221_CGT%20sin_lungback.webm [loudness: -72 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 9 from 20220105163221_CGT%20sin_lungback.webm [loudness: -79 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419104420_RP%20fe-1_lungfront.webm from audios/20230419104420_RP%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419104420_RP%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20230419104420_RP%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20230419104420_RP%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20230419104420_RP%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20230419104420_RP%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20230419104420_RP%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20230419104420_RP%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20230419104420_RP%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 9 from 20230419104420_RP%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20230419104420_RP%20fe-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105162835_CGT%20con_vocal.webm from audios/20220105162835_CGT%20con_vocal.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220105162835_CGT%20con_vocal.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220105162835_CGT%20con_vocal.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220105162835_CGT%20con_vocal.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20220105162835_CGT%20con_vocal.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220105162835_CGT%20con_vocal.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220105162835_CGT%20con_vocal.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220105162835_CGT%20con_vocal.webm [loudness: -29 dB]\n",
            "  Clip 8 from 20220105162835_CGT%20con_vocal.webm [loudness: -27 dB]\n",
            "  Clip 9 from 20220105162835_CGT%20con_vocal.webm [loudness: -21 dB]\n",
            "  Clip 10 from 20220105162835_CGT%20con_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319061032_ECO%20fe%2019-1_lungback.webm from audios/20220319061032_ECO%20fe%2019-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220319061032_ECO%20fe%2019-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220319061032_ECO%20fe%2019-1_lungback.webm [loudness: -36 dB]\n",
            "  Clip 3 from 20220319061032_ECO%20fe%2019-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220319061032_ECO%20fe%2019-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220319061032_ECO%20fe%2019-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220319061032_ECO%20fe%2019-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20220319061032_ECO%20fe%2019-1_lungback.webm [loudness: -30 dB]\n",
            "  Clip 8 from 20220319061032_ECO%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419120707_ET%20fe-1_lungfront.webm from audios/20230419120707_ET%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230419120707_ET%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20230419120707_ET%20fe-1_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 3 from 20230419120707_ET%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230419120707_ET%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20230419120707_ET%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20230419120707_ET%20fe-1_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 7 from 20230419120707_ET%20fe-1_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 8 from 20230419120707_ET%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20230419120707_ET%20fe-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127120739_GADA%20es_lungfront.webm from audios/20220127120739_GADA%20es_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220127120739_GADA%20es_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220127120739_GADA%20es_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220127120739_GADA%20es_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220127120739_GADA%20es_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220127120739_GADA%20es_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220127120739_GADA%20es_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20221118053800_Fe-1%20SD_lungfront.webm from audios/20221118053800_Fe-1%20SD_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20221118053800_Fe-1%20SD_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20221118053800_Fe-1%20SD_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20221118053800_Fe-1%20SD_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20221118053800_Fe-1%20SD_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20221118053800_Fe-1%20SD_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20221118053800_Fe-1%20SD_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20221118053800_Fe-1%20SD_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20221118053800_Fe-1%20SD_lungfront.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115154844_KMI_lungback.webm from audios/20220115154844_KMI_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115154844_KMI_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220115154844_KMI_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220115154844_KMI_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220115154844_KMI_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220115154844_KMI_lungback.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20221212104450_Fe-1%20KP_lungback.webm from audios/20221212104450_Fe-1%20KP_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221212104450_Fe-1%20KP_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20221212104450_Fe-1%20KP_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20221212104450_Fe-1%20KP_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20221212104450_Fe-1%20KP_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20221212104450_Fe-1%20KP_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20221212104450_Fe-1%20KP_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20221212104450_Fe-1%20KP_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20221212104450_Fe-1%20KP_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20221212104450_Fe-1%20KP_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212064149_Rgh%2016-1_lungfront.webm from audios/20220212064149_Rgh%2016-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 15 2s clips\n",
            "  Clip 1 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -40 dB]\n",
            "  Clip 2 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 6 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -71 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -71 dB]\n",
            "  Clip 7 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 8 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -64 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 9 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 10 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 11 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 12 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 12 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 13 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 13 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 14 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 14 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 15 from 20220212064149_Rgh%2016-1_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 15 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118111537_ARE_lungback.webm from audios/20220118111537_ARE_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118111537_ARE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220118111537_ARE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220118111537_ARE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220118111537_ARE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220118111537_ARE_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220715092715_LML%20fe-2_vocal.webm from audios/20220715092715_LML%20fe-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220715092715_LML%20fe-2_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220715092715_LML%20fe-2_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220715092715_LML%20fe-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220715092715_LML%20fe-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122140109_MRGM%20es_lungback.webm from audios/20220122140109_MRGM%20es_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122140109_MRGM%20es_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220122140109_MRGM%20es_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220122140109_MRGM%20es_lungback.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220122140109_MRGM%20es_lungback.webm [loudness: -10 dB]\n",
            "  Clip 5 from 20220122140109_MRGM%20es_lungback.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123121132_Fe-1%20RC_vocal.webm from audios/20221123121132_Fe-1%20RC_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221123121132_Fe-1%20RC_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20221123121132_Fe-1%20RC_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20221123121132_Fe-1%20RC_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20221123121132_Fe-1%20RC_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20221123121132_Fe-1%20RC_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120153840_GCNF_vocal.webm from audios/20220120153840_GCNF_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220120153840_GCNF_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220120153840_GCNF_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20220120153840_GCNF_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220120153840_GCNF_vocal.webm [loudness: -7 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064407_JMT-P3_vocal.webm from audios/20211209064407_JMT-P3_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20211209064407_JMT-P3_vocal.webm [loudness: -35 dB]\n",
            "  Clip 2 from 20211209064407_JMT-P3_vocal.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20211209064407_JMT-P3_vocal.webm [loudness: -35 dB]\n",
            "  Clip 4 from 20211209064407_JMT-P3_vocal.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20211209064407_JMT-P3_vocal.webm [loudness: -37 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304053013_LRM%20fe%204-1_lungfront.webm from audios/20220304053013_LRM%20fe%204-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304053013_LRM%20fe%204-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220304053013_LRM%20fe%204-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220304053013_LRM%20fe%204-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220304053013_LRM%20fe%204-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220304053013_LRM%20fe%204-1_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 6 from 20220304053013_LRM%20fe%204-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20220304053013_LRM%20fe%204-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220304053013_LRM%20fe%204-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220421124920_LRR%2021-1_lungback.webm from audios/20220421124920_LRR%2021-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220421124920_LRR%2021-1_lungback.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220421124920_LRR%2021-1_lungback.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20220421124920_LRR%2021-1_lungback.webm [loudness: -47 dB]\n",
            "  Clip 4 from 20220421124920_LRR%2021-1_lungback.webm [loudness: -56 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 5 from 20220421124920_LRR%2021-1_lungback.webm [loudness: -80 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 6 from 20220421124920_LRR%2021-1_lungback.webm [loudness: -79 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 7 from 20220421124920_LRR%2021-1_lungback.webm [loudness: -86 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 8 from 20220421124920_LRR%2021-1_lungback.webm [loudness: -83 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -83 dB]\n",
            "  Clip 9 from 20220421124920_LRR%2021-1_lungback.webm [loudness: -87 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -87 dB]\n",
            "  Clip 10 from 20220421124920_LRR%2021-1_lungback.webm [loudness: -52 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302092611_SLlJ%20fe%202-1_lungfront.webm from audios/20220302092611_SLlJ%20fe%202-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302092611_SLlJ%20fe%202-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220302092611_SLlJ%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220302092611_SLlJ%20fe%202-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220302092611_SLlJ%20fe%202-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220302092611_SLlJ%20fe%202-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20220302092611_SLlJ%20fe%202-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220302092611_SLlJ%20fe%202-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220302092611_SLlJ%20fe%202-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220302092611_SLlJ%20fe%202-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802104203_TEO%20fe-1_lungfront.webm from audios/20220802104203_TEO%20fe-1_lungfront.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 9 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 11 from 20220802104203_TEO%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220625095154_DM%20fe-2_lungfront.webm from audios/20220625095154_DM%20fe-2_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220625095154_DM%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220625095154_DM%20fe-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220625095154_DM%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220625095154_DM%20fe-2_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220625095154_DM%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220625095154_DM%20fe-2_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20220625095154_DM%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220625095154_DM%20fe-2_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123051040_Fe-1%20MM_lungfront.webm from audios/20221123051040_Fe-1%20MM_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123051040_Fe-1%20MM_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 2 from 20221123051040_Fe-1%20MM_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 3 from 20221123051040_Fe-1%20MM_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 4 from 20221123051040_Fe-1%20MM_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20221123051040_Fe-1%20MM_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20221123051040_Fe-1%20MM_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20221123051040_Fe-1%20MM_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20221123051040_Fe-1%20MM_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 9 from 20221123051040_Fe-1%20MM_lungfront.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215081101_MME%2028-2_vocal.webm from audios/20220215081101_MME%2028-2_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220215081101_MME%2028-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220215081101_MME%2028-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202104151_Mcp-02-12-D5_lungfront.webm from audios/20211202104151_Mcp-02-12-D5_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211202104151_Mcp-02-12-D5_lungfront.webm [loudness: -93 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -93 dB]\n",
            "  Clip 2 from 20211202104151_Mcp-02-12-D5_lungfront.webm [loudness: -93 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -93 dB]\n",
            "  Clip 3 from 20211202104151_Mcp-02-12-D5_lungfront.webm [loudness: -95 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -95 dB]\n",
            "  Clip 4 from 20211202104151_Mcp-02-12-D5_lungfront.webm [loudness: -92 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -92 dB]\n",
            "  Clip 5 from 20211202104151_Mcp-02-12-D5_lungfront.webm [loudness: -86 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -86 dB]\n",
            "  Clip 6 from 20211202104151_Mcp-02-12-D5_lungfront.webm [loudness: -89 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -89 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220129124418_GADA%20fE_vocal.webm from audios/20220129124418_GADA%20fE_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220129124418_GADA%20fE_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220129124418_GADA%20fE_vocal.webm [loudness: -8 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125112846_DAKP%20fe_lungback.webm from audios/20220125112846_DAKP%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125112846_DAKP%20fe_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220125112846_DAKP%20fe_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220125112846_DAKP%20fe_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220125112846_DAKP%20fe_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220125112846_DAKP%20fe_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418103903_CA%20fe-1_lungfront.webm from audios/20230418103903_CA%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230418103903_CA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230418103903_CA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230418103903_CA%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230418103903_CA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230418103903_CA%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20230418103903_CA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20230418103903_CA%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20230418103903_CA%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20230418103903_CA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 10 from 20230418103903_CA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305090804_APC%20fe%205-1_vocal.webm from audios/20220305090804_APC%20fe%205-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220305090804_APC%20fe%205-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220305090804_APC%20fe%205-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220305090804_APC%20fe%205-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220305090804_APC%20fe%205-1_vocal.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220804101609_MHC%20fe-3_vocal.webm from audios/20220804101609_MHC%20fe-3_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220804101609_MHC%20fe-3_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220804101609_MHC%20fe-3_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220804101609_MHC%20fe-3_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220804101609_MHC%20fe-3_vocal.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319053836_MMA%20fe%2019-1_lungfront.webm from audios/20220319053836_MMA%20fe%2019-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319053836_MMA%20fe%2019-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220319053836_MMA%20fe%2019-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220319053836_MMA%20fe%2019-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220319053836_MMA%20fe%2019-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220319053836_MMA%20fe%2019-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220319053836_MMA%20fe%2019-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220319053836_MMA%20fe%2019-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220319053836_MMA%20fe%2019-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220319053836_MMA%20fe%2019-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212062243_Ach%20fe-14-1_vocal.webm from audios/20220212062243_Ach%20fe-14-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212062243_Ach%20fe-14-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220212062243_Ach%20fe-14-1_vocal.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220212062243_Ach%20fe-14-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419125101_JG%20fe-1_lungfront.webm from audios/20230419125101_JG%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230419125101_JG%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20230419125101_JG%20fe-1_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 3 from 20230419125101_JG%20fe-1_lungfront.webm [loudness: -41 dB]\n",
            "  Clip 4 from 20230419125101_JG%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20230419125101_JG%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20230419125101_JG%20fe-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 7 from 20230419125101_JG%20fe-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 8 from 20230419125101_JG%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20230419125101_JG%20fe-1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124133907_GMK%20es_vocal.webm from audios/20220124133907_GMK%20es_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124133907_GMK%20es_vocal.webm [loudness: -45 dB]\n",
            "  Clip 2 from 20220124133907_GMK%20es_vocal.webm [loudness: -51 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 3 from 20220124133907_GMK%20es_vocal.webm [loudness: -42 dB]\n",
            "  Clip 4 from 20220124133907_GMK%20es_vocal.webm [loudness: -50 dB]\n",
            "  Clip 5 from 20220124133907_GMK%20es_vocal.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20221216093012_Fe-1%20CM_vocal.webm from audios/20221216093012_Fe-1%20CM_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20221216093012_Fe-1%20CM_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20221216093012_Fe-1%20CM_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20221216093012_Fe-1%20CM_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20221216093012_Fe-1%20CM_vocal.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305090043_SFT%20fe%205-1_lungfront.webm from audios/20220305090043_SFT%20fe%205-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305090043_SFT%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220305090043_SFT%20fe%205-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220305090043_SFT%20fe%205-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220305090043_SFT%20fe%205-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220305090043_SFT%20fe%205-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20220305090043_SFT%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220305090043_SFT%20fe%205-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220305090043_SFT%20fe%205-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220305090043_SFT%20fe%205-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230424111937_JH%20fe-1_lungfront.webm from audios/20230424111937_JH%20fe-1_lungfront.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230424111937_JH%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20230424111937_JH%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20230424111937_JH%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20230424111937_JH%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20230424111937_JH%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20230424111937_JH%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20230424111937_JH%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20230424111937_JH%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20230424111937_JH%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 10 from 20230424111937_JH%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219081530_TRC%2029-2_lungback.webm from audios/20220219081530_TRC%2029-2_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220219081530_TRC%2029-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220219081530_TRC%2029-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220219081530_TRC%2029-2_lungback.webm [loudness: -45 dB]\n",
            "  Clip 4 from 20220219081530_TRC%2029-2_lungback.webm [loudness: -33 dB]\n",
            "  Clip 5 from 20220219081530_TRC%2029-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220219081530_TRC%2029-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220219081530_TRC%2029-2_lungback.webm [loudness: -28 dB]\n",
            "  Clip 8 from 20220219081530_TRC%2029-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220219081530_TRC%2029-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115130617_RVPP_vocal.webm from audios/20220115130617_RVPP_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220115130617_RVPP_vocal.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220115130617_RVPP_vocal.webm [loudness: -53 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 3 from 20220115130617_RVPP_vocal.webm [loudness: -52 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 4 from 20220115130617_RVPP_vocal.webm [loudness: -53 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 5 from 20220115130617_RVPP_vocal.webm [loudness: -113 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -113 dB]\n",
            "  Clip 6 from 20220115130617_RVPP_vocal.webm [loudness: -37 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119112335_SMAC_vocal.webm from audios/20220119112335_SMAC_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220119112335_SMAC_vocal.webm [loudness: -8 dB]\n",
            "  Clip 2 from 20220119112335_SMAC_vocal.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220119112335_SMAC_vocal.webm [loudness: -10 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117133932_YVRM_lungback.webm from audios/20220117133932_YVRM_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220117133932_YVRM_lungback.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220117133932_YVRM_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220117133932_YVRM_lungback.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220117133932_YVRM_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220117133932_YVRM_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305074538_KMI%20fe%205-1_lungfront.webm from audios/20220305074538_KMI%20fe%205-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220305074538_KMI%20fe%205-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220305074538_KMI%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220305074538_KMI%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220305074538_KMI%20fe%205-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220305074538_KMI%20fe%205-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220305074538_KMI%20fe%205-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220305074538_KMI%20fe%205-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220305074538_KMI%20fe%205-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115155641_SI_lungfront.webm from audios/20220115155641_SI_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220115155641_SI_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 2 from 20220115155641_SI_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220115155641_SI_lungfront.webm [loudness: -79 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 4 from 20220115155641_SI_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 5 from 20220115155641_SI_lungfront.webm [loudness: -48 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123090606_Fe-1%20AM_lungback.webm from audios/20221123090606_Fe-1%20AM_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123090606_Fe-1%20AM_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20221123090606_Fe-1%20AM_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20221123090606_Fe-1%20AM_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20221123090606_Fe-1%20AM_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20221123090606_Fe-1%20AM_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20221123090606_Fe-1%20AM_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20221123090606_Fe-1%20AM_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20221123090606_Fe-1%20AM_lungback.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20221123090606_Fe-1%20AM_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219085022_MGCH%2030-2_lungback.webm from audios/20220219085022_MGCH%2030-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220219085022_MGCH%2030-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220219085022_MGCH%2030-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220219085022_MGCH%2030-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220219085022_MGCH%2030-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220219085022_MGCH%2030-2_lungback.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20220219085022_MGCH%2030-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220219085022_MGCH%2030-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419114613_AR%20fe-1_vocal.webm from audios/20230419114613_AR%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230419114613_AR%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20230419114613_AR%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20230419114613_AR%20fe-1_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20230419114613_AR%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419094918_MF%20fe-1_lungfront.webm from audios/20230419094918_MF%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20230419094918_MF%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20230419094918_MF%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230419094918_MF%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230419094918_MF%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20230419094918_MF%20fe-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20230419094918_MF%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20230419094918_MF%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20230419094918_MF%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20230419094918_MF%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302091650_EAR%20fe%202-1_lungback.webm from audios/20220302091650_EAR%20fe%202-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 6 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 9 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 10 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -33 dB]\n",
            "  Clip 11 from 20220302091650_EAR%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319054519_XLS%20fe%2019-1_lungback.webm from audios/20220319054519_XLS%20fe%2019-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319054519_XLS%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220319054519_XLS%20fe%2019-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220319054519_XLS%20fe%2019-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220319054519_XLS%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220319054519_XLS%20fe%2019-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20220319054519_XLS%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220319054519_XLS%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20220319054519_XLS%20fe%2019-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220319054519_XLS%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212063501_Acb%2015-1_vocal.webm from audios/20220212063501_Acb%2015-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212063501_Acb%2015-1_vocal.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220212063501_Acb%2015-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220212063501_Acb%2015-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212071122_Tvs%2018-2_lungback.webm from audios/20220212071122_Tvs%2018-2_lungback.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -48 dB]\n",
            "  Clip 3 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -43 dB]\n",
            "  Clip 4 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -42 dB]\n",
            "  Clip 5 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -35 dB]\n",
            "  Clip 6 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -29 dB]\n",
            "  Clip 7 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -51 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 8 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -62 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 9 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -60 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 10 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -45 dB]\n",
            "  Clip 11 from 20220212071122_Tvs%2018-2_lungback.webm [loudness: -44 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212065052_ATC%2017-1_vocal.webm from audios/20220212065052_ATC%2017-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220212065052_ATC%2017-1_vocal.webm [loudness: -37 dB]\n",
            "  Clip 2 from 20220212065052_ATC%2017-1_vocal.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20220212065052_ATC%2017-1_vocal.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220212065052_ATC%2017-1_vocal.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418104709_JC%20fe-1_lungback.webm from audios/20230418104709_JC%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230418104709_JC%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230418104709_JC%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20230418104709_JC%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20230418104709_JC%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230418104709_JC%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20230418104709_JC%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230418104709_JC%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20230418104709_JC%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20230418104709_JC%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20230418104709_JC%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119161535_SNPC_vocal.webm from audios/20220119161535_SNPC_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220119161535_SNPC_vocal.webm [loudness: -38 dB]\n",
            "  Clip 2 from 20220119161535_SNPC_vocal.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220119161535_SNPC_vocal.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220119161535_SNPC_vocal.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20220119161535_SNPC_vocal.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105124255_PTR_lungfront.webm from audios/20220105124255_PTR_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220105124255_PTR_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220105124255_PTR_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 3 from 20220105124255_PTR_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 4 from 20220105124255_PTR_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 5 from 20220105124255_PTR_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 6 from 20220105124255_PTR_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip 7 from 20220105124255_PTR_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 8 from 20220105124255_PTR_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 9 from 20220105124255_PTR_lungfront.webm [loudness: -61 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117150958_EGX_vocal.webm from audios/20220117150958_EGX_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220117150958_EGX_vocal.webm [loudness: -46 dB]\n",
            "  Clip 2 from 20220117150958_EGX_vocal.webm [loudness: -37 dB]\n",
            "  Clip 3 from 20220117150958_EGX_vocal.webm [loudness: -29 dB]\n",
            "  Clip 4 from 20220117150958_EGX_vocal.webm [loudness: -49 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122110541_NFGC%20es_vocal.webm from audios/20220122110541_NFGC%20es_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220122110541_NFGC%20es_vocal.webm [loudness: -45 dB]\n",
            "  Clip 2 from 20220122110541_NFGC%20es_vocal.webm [loudness: -42 dB]\n",
            "  Clip 3 from 20220122110541_NFGC%20es_vocal.webm [loudness: -41 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302064618_RMC%20fe%202-2_vocal.webm from audios/20220302064618_RMC%20fe%202-2_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220302064618_RMC%20fe%202-2_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220302064618_RMC%20fe%202-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220302064618_RMC%20fe%202-2_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220302064618_RMC%20fe%202-2_vocal.webm [loudness: -50 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125160128_MMLJ%20fe_lungfront.webm from audios/20220125160128_MMLJ%20fe_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220125160128_MMLJ%20fe_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 2 from 20220125160128_MMLJ%20fe_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 3 from 20220125160128_MMLJ%20fe_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 4 from 20220125160128_MMLJ%20fe_lungfront.webm [loudness: -87 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -87 dB]\n",
            "  Clip 5 from 20220125160128_MMLJ%20fe_lungfront.webm [loudness: -79 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 6 from 20220125160128_MMLJ%20fe_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -56 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220319055023_DDCS%20fe%2019-1_vocal.webm from audios/20220319055023_DDCS%20fe%2019-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220319055023_DDCS%20fe%2019-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220319055023_DDCS%20fe%2019-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220319055023_DDCS%20fe%2019-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220319055023_DDCS%20fe%2019-1_vocal.webm [loudness: -45 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118111208_XAW_lungfront.webm from audios/20220118111208_XAW_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118111208_XAW_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 2 from 20220118111208_XAW_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220118111208_XAW_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 4 from 20220118111208_XAW_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220118111208_XAW_lungfront.webm [loudness: -133 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -133 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220525092038_Pt%20fe-1_vocal.webm from audios/20220525092038_Pt%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220525092038_Pt%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220525092038_Pt%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220525092038_Pt%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220525092038_Pt%20fe-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319073411_DAT%20fe%2019-1_lungback.webm from audios/20220319073411_DAT%20fe%2019-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -30 dB]\n",
            "  Clip 9 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 11 from 20220319073411_DAT%20fe%2019-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20221217091134_Fe-1%20AR_lungback.webm from audios/20221217091134_Fe-1%20AR_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221217091134_Fe-1%20AR_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20221217091134_Fe-1%20AR_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20221217091134_Fe-1%20AR_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20221217091134_Fe-1%20AR_lungback.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20221217091134_Fe-1%20AR_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20221217091134_Fe-1%20AR_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20221217091134_Fe-1%20AR_lungback.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20221217091134_Fe-1%20AR_lungback.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20221217091134_Fe-1%20AR_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220211122728_OCF%2013_vocal.webm from audios/20220211122728_OCF%2013_vocal.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220211122728_OCF%2013_vocal.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220211122728_OCF%2013_vocal.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220211122728_OCF%2013_vocal.webm [loudness: -31 dB]\n",
            "  Clip 4 from 20220211122728_OCF%2013_vocal.webm [loudness: -31 dB]\n",
            "  Clip 5 from 20220211122728_OCF%2013_vocal.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220211122728_OCF%2013_vocal.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220211122728_OCF%2013_vocal.webm [loudness: -42 dB]\n",
            "  Clip 8 from 20220211122728_OCF%2013_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212082523_Lmm24-2_lungfront.webm from audios/20220212082523_Lmm24-2_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220212082523_Lmm24-2_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 2 from 20220212082523_Lmm24-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220212082523_Lmm24-2_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 4 from 20220212082523_Lmm24-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220212082523_Lmm24-2_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220212082523_Lmm24-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 7 from 20220212082523_Lmm24-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 8 from 20220212082523_Lmm24-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 9 from 20220212082523_Lmm24-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230420073507_NA%20fe-1_lungback.webm from audios/20230420073507_NA%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230420073507_NA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20230420073507_NA%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20230420073507_NA%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20230420073507_NA%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20230420073507_NA%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230420073507_NA%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20230420073507_NA%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20230420073507_NA%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20230420073507_NA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230420073507_NA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219084119_SYV%2030-2_vocal.webm from audios/20220219084119_SYV%2030-2_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220219084119_SYV%2030-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220219084119_SYV%2030-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220219084119_SYV%2030-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125162946_MCEE%20fe_lungback.webm from audios/20220125162946_MCEE%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125162946_MCEE%20fe_lungback.webm [loudness: -103 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -103 dB]\n",
            "  Clip 2 from 20220125162946_MCEE%20fe_lungback.webm [loudness: -60 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 3 from 20220125162946_MCEE%20fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220125162946_MCEE%20fe_lungback.webm [loudness: -60 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 5 from 20220125162946_MCEE%20fe_lungback.webm [loudness: -60 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -60 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230419104705_MG%20fe-1_lungback.webm from audios/20230419104705_MG%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419104705_MG%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230419104705_MG%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20230419104705_MG%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20230419104705_MG%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230419104705_MG%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20230419104705_MG%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20230419104705_MG%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20230419104705_MG%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20230419104705_MG%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 10 from 20230419104705_MG%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305054143_MST%20fe%205-1_vocal.webm from audios/20220305054143_MST%20fe%205-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220305054143_MST%20fe%205-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220305054143_MST%20fe%205-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220305054143_MST%20fe%205-1_vocal.webm [loudness: -31 dB]\n",
            "  Clip 4 from 20220305054143_MST%20fe%205-1_vocal.webm [loudness: -34 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212063005_Ach%2014-2_vocal.webm from audios/20220212063005_Ach%2014-2_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220212063005_Ach%2014-2_vocal.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220212063005_Ach%2014-2_vocal.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220212063005_Ach%2014-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319094727_JGA%20fe%2019-1_lungback.webm from audios/20220319094727_JGA%20fe%2019-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319094727_JGA%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220319094727_JGA%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220319094727_JGA%20fe%2019-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220319094727_JGA%20fe%2019-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220319094727_JGA%20fe%2019-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220319094727_JGA%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220319094727_JGA%20fe%2019-1_lungback.webm [loudness: -27 dB]\n",
            "  Clip 8 from 20220319094727_JGA%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220319094727_JGA%20fe%2019-1_lungback.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127134606_JAYG%20Es_vocal.webm from audios/20220127134606_JAYG%20Es_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220127134606_JAYG%20Es_vocal.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220127134606_JAYG%20Es_vocal.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220127134606_JAYG%20Es_vocal.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220303082548_AAC%20fe%203-1_lungback.webm from audios/20220303082548_AAC%20fe%203-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303082548_AAC%20fe%203-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220303082548_AAC%20fe%203-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220303082548_AAC%20fe%203-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220303082548_AAC%20fe%203-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 5 from 20220303082548_AAC%20fe%203-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 6 from 20220303082548_AAC%20fe%203-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 7 from 20220303082548_AAC%20fe%203-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220303082548_AAC%20fe%203-1_lungback.webm [loudness: -11 dB]\n",
            "  Clip 9 from 20220303082548_AAC%20fe%203-1_lungback.webm [loudness: -10 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125112513_DAKP%20es_lungfront.webm from audios/20220125112513_DAKP%20es_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125112513_DAKP%20es_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220125112513_DAKP%20es_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220125112513_DAKP%20es_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220125112513_DAKP%20es_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220125112513_DAKP%20es_lungfront.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421100451_DF%20fe-1_lungfront.webm from audios/20230421100451_DF%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230421100451_DF%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20230421100451_DF%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20230421100451_DF%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230421100451_DF%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20230421100451_DF%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20230421100451_DF%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20230421100451_DF%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20230421100451_DF%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20230421100451_DF%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 10 from 20230421100451_DF%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108152718_PMAD_lungfront.webm from audios/20220108152718_PMAD_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220108152718_PMAD_lungfront.webm [loudness: -34 dB]\n",
            "  Clip 2 from 20220108152718_PMAD_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 3 from 20220108152718_PMAD_lungfront.webm [loudness: -43 dB]\n",
            "  Clip 4 from 20220108152718_PMAD_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 5 from 20220108152718_PMAD_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 6 from 20220108152718_PMAD_lungfront.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220727082823_FSM%20fe-1_lungfront.webm from audios/20220727082823_FSM%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220727082823_FSM%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220727082823_FSM%20fe-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220727082823_FSM%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220727082823_FSM%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20220727082823_FSM%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220727082823_FSM%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220727082823_FSM%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 8 from 20220727082823_FSM%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220727082823_FSM%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128124025_CGJJ%20fE_vocal.webm from audios/20220128124025_CGJJ%20fE_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220128124025_CGJJ%20fE_vocal.webm [loudness: -53 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 2 from 20220128124025_CGJJ%20fE_vocal.webm [loudness: -51 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 3 from 20220128124025_CGJJ%20fE_vocal.webm [loudness: -51 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -51 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220114122836_MMGC_lungfront.webm from audios/20220114122836_MMGC_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114122836_MMGC_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 2 from 20220114122836_MMGC_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 3 from 20220114122836_MMGC_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 4 from 20220114122836_MMGC_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 5 from 20220114122836_MMGC_lungfront.webm [loudness: -46 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220630100058_ARB%20fe-2_lungback.webm from audios/20220630100058_ARB%20fe-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220630100058_ARB%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220630100058_ARB%20fe-2_lungback.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220630100058_ARB%20fe-2_lungback.webm [loudness: -27 dB]\n",
            "  Clip 4 from 20220630100058_ARB%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220630100058_ARB%20fe-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220630100058_ARB%20fe-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220630100058_ARB%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220630100058_ARB%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220630100058_ARB%20fe-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 10 from 20220630100058_ARB%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220704112246_JGA%20fe-1_lungback.webm from audios/20220704112246_JGA%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220704112246_JGA%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220704112246_JGA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220704112246_JGA%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220704112246_JGA%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220704112246_JGA%20fe-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220704112246_JGA%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20220704112246_JGA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220704112246_JGA%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220704112246_JGA%20fe-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220219081410_TRC%2029-1_lungback.webm from audios/20220219081410_TRC%2029-1_lungback.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220219081410_TRC%2029-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220219081410_TRC%2029-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220219081410_TRC%2029-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 4 from 20220219081410_TRC%2029-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20220219081410_TRC%2029-1_lungback.webm [loudness: -34 dB]\n",
            "  Clip 6 from 20220219081410_TRC%2029-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220219081410_TRC%2029-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 8 from 20220219081410_TRC%2029-1_lungback.webm [loudness: -41 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122110655_NFGC%20fe_lungback.webm from audios/20220122110655_NFGC%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122110655_NFGC%20fe_lungback.webm [loudness: -91 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -91 dB]\n",
            "  Clip 2 from 20220122110655_NFGC%20fe_lungback.webm [loudness: -66 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 3 from 20220122110655_NFGC%20fe_lungback.webm [loudness: -67 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -67 dB]\n",
            "  Clip 4 from 20220122110655_NFGC%20fe_lungback.webm [loudness: -100 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -100 dB]\n",
            "  Clip 5 from 20220122110655_NFGC%20fe_lungback.webm [loudness: -116 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -116 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220127120739_GADA%20es_lungback.webm from audios/20220127120739_GADA%20es_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127120739_GADA%20es_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220127120739_GADA%20es_lungback.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220127120739_GADA%20es_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220127120739_GADA%20es_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220127120739_GADA%20es_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419105624_EA%20fe-1_vocal.webm from audios/20230419105624_EA%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230419105624_EA%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20230419105624_EA%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20230419105624_EA%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230419105624_EA%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20221119112228_Fe-1%20GN_lungback.webm from audios/20221119112228_Fe-1%20GN_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221119112228_Fe-1%20GN_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20221119112228_Fe-1%20GN_lungback.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20221119112228_Fe-1%20GN_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20221119112228_Fe-1%20GN_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20221119112228_Fe-1%20GN_lungback.webm [loudness: -13 dB]\n",
            "  Clip 6 from 20221119112228_Fe-1%20GN_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20221119112228_Fe-1%20GN_lungback.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20221119112228_Fe-1%20GN_lungback.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20221119112228_Fe-1%20GN_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709050338_BUM%20fe-2_lungback.webm from audios/20220709050338_BUM%20fe-2_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220709050338_BUM%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220709050338_BUM%20fe-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 3 from 20220709050338_BUM%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220709050338_BUM%20fe-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220709050338_BUM%20fe-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220709050338_BUM%20fe-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220709050338_BUM%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220709050338_BUM%20fe-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20220709050338_BUM%20fe-2_lungback.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064137_JMT-P_lungback.webm from audios/20211209064137_JMT-P_lungback.webm\n",
            "Error loading 20211209064137_JMT-P_lungback.webm: . Removing from files_map.\n",
            "\n",
            "Loading file: 20220128111148_MTSK%20Fe_lungfront.webm from audios/20220128111148_MTSK%20Fe_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128111148_MTSK%20Fe_lungfront.webm [loudness: -76 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 2 from 20220128111148_MTSK%20Fe_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 3 from 20220128111148_MTSK%20Fe_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 4 from 20220128111148_MTSK%20Fe_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 5 from 20220128111148_MTSK%20Fe_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -57 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230418114816_TE%20fe-1_vocal.webm from audios/20230418114816_TE%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230418114816_TE%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20230418114816_TE%20fe-1_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20230418114816_TE%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20230418114816_TE%20fe-1_vocal.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126124939_ABM%20es_lungback.webm from audios/20220126124939_ABM%20es_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220126124939_ABM%20es_lungback.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20220126124939_ABM%20es_lungback.webm [loudness: -103 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -103 dB]\n",
            "  Clip 3 from 20220126124939_ABM%20es_lungback.webm [loudness: -60 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 4 from 20220126124939_ABM%20es_lungback.webm [loudness: -64 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 5 from 20220126124939_ABM%20es_lungback.webm [loudness: -62 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 6 from 20220126124939_ABM%20es_lungback.webm [loudness: -54 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -54 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220304082514_SAC%20fe%204-1_lungfront.webm from audios/20220304082514_SAC%20fe%204-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304082514_SAC%20fe%204-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220304082514_SAC%20fe%204-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220304082514_SAC%20fe%204-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220304082514_SAC%20fe%204-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220304082514_SAC%20fe%204-1_lungfront.webm [loudness: -30 dB]\n",
            "  Clip 6 from 20220304082514_SAC%20fe%204-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220304082514_SAC%20fe%204-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220304082514_SAC%20fe%204-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 9 from 20220304082514_SAC%20fe%204-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122154102_MSVC%20fe_lungback.webm from audios/20220122154102_MSVC%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220122154102_MSVC%20fe_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220122154102_MSVC%20fe_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220122154102_MSVC%20fe_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220122154102_MSVC%20fe_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220122154102_MSVC%20fe_lungback.webm [loudness: -37 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20221207131017_Fe-1%20MA_vocal.webm from audios/20221207131017_Fe-1%20MA_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20221207131017_Fe-1%20MA_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20221207131017_Fe-1%20MA_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20221207131017_Fe-1%20MA_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20221207131017_Fe-1%20MA_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108135008_LSH_lungfront.webm from audios/20220108135008_LSH_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220108135008_LSH_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220108135008_LSH_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220108135008_LSH_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 4 from 20220108135008_LSH_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220108135008_LSH_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 6 from 20220108135008_LSH_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220108135008_LSH_lungfront.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20211216131725_NSR-CD_lungfront.webm from audios/20211216131725_NSR-CD_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211216131725_NSR-CD_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20211216131725_NSR-CD_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20211216131725_NSR-CD_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20211216131725_NSR-CD_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20211216131725_NSR-CD_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20211216131725_NSR-CD_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054901_ACW-P1_lungfront.webm from audios/20211207054901_ACW-P1_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207054901_ACW-P1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20211207054901_ACW-P1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20211207054901_ACW-P1_lungfront.webm [loudness: -34 dB]\n",
            "  Clip 4 from 20211207054901_ACW-P1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 5 from 20211207054901_ACW-P1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20211207054901_ACW-P1_lungfront.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303090534_CMF%20fe%203-1_lungfront.webm from audios/20220303090534_CMF%20fe%203-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220303090534_CMF%20fe%203-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220303090534_CMF%20fe%203-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220303090534_CMF%20fe%203-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220303090534_CMF%20fe%203-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220303090534_CMF%20fe%203-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20220303090534_CMF%20fe%203-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220303090534_CMF%20fe%203-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20220303090534_CMF%20fe%203-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220303090534_CMF%20fe%203-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304052543_YH%20fe%204-1_vocal.webm from audios/20220304052543_YH%20fe%204-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220304052543_YH%20fe%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220304052543_YH%20fe%204-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220304052543_YH%20fe%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220304052543_YH%20fe%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220802080705_MHC%20fe-2_vocal.webm from audios/20220802080705_MHC%20fe-2_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220802080705_MHC%20fe-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220802080705_MHC%20fe-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220802080705_MHC%20fe-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220802080705_MHC%20fe-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220802080705_MHC%20fe-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064026_JMT-D5_lungfront.webm from audios/20211209064026_JMT-D5_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20211209064026_JMT-D5_lungfront.webm [loudness: -52 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 2 from 20211209064026_JMT-D5_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 3 from 20211209064026_JMT-D5_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 4 from 20211209064026_JMT-D5_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 5 from 20211209064026_JMT-D5_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 6 from 20211209064026_JMT-D5_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 7 from 20211209064026_JMT-D5_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 8 from 20211209064026_JMT-D5_lungfront.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064522_JMT-P4_lungback.webm from audios/20211209064522_JMT-P4_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211209064522_JMT-P4_lungback.webm [loudness: -55 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 2 from 20211209064522_JMT-P4_lungback.webm [loudness: -44 dB]\n",
            "  Clip 3 from 20211209064522_JMT-P4_lungback.webm [loudness: -44 dB]\n",
            "  Clip 4 from 20211209064522_JMT-P4_lungback.webm [loudness: -48 dB]\n",
            "  Clip 5 from 20211209064522_JMT-P4_lungback.webm [loudness: -46 dB]\n",
            "  Clip 6 from 20211209064522_JMT-P4_lungback.webm [loudness: -53 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118151408_TZP_lungfront.webm from audios/20220118151408_TZP_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220118151408_TZP_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220118151408_TZP_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220118151408_TZP_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220118151408_TZP_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 5 from 20220118151408_TZP_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220118151408_TZP_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302092611_SLlJ%20fe%202-1_lungback.webm from audios/20220302092611_SLlJ%20fe%202-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302092611_SLlJ%20fe%202-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220302092611_SLlJ%20fe%202-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 3 from 20220302092611_SLlJ%20fe%202-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220302092611_SLlJ%20fe%202-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220302092611_SLlJ%20fe%202-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220302092611_SLlJ%20fe%202-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220302092611_SLlJ%20fe%202-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220302092611_SLlJ%20fe%202-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220302092611_SLlJ%20fe%202-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117133932_YVRM_vocal.webm from audios/20220117133932_YVRM_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220117133932_YVRM_vocal.webm [loudness: -8 dB]\n",
            "  Clip 2 from 20220117133932_YVRM_vocal.webm [loudness: -7 dB]\n",
            "  Clip 3 from 20220117133932_YVRM_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220117133932_YVRM_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302053604_MLQ%20fe%202-2_vocal.webm from audios/20220302053604_MLQ%20fe%202-2_vocal.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220302053604_MLQ%20fe%202-2_vocal.webm [loudness: -34 dB]\n",
            "  Clip 2 from 20220302053604_MLQ%20fe%202-2_vocal.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220302053604_MLQ%20fe%202-2_vocal.webm [loudness: -31 dB]\n",
            "  Clip 4 from 20220302053604_MLQ%20fe%202-2_vocal.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220302053604_MLQ%20fe%202-2_vocal.webm [loudness: -34 dB]\n",
            "  Clip 6 from 20220302053604_MLQ%20fe%202-2_vocal.webm [loudness: -36 dB]\n",
            "  Clip 7 from 20220302053604_MLQ%20fe%202-2_vocal.webm [loudness: -38 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220704112603_JGA.%20Fe-2_lungfront.webm from audios/20220704112603_JGA.%20Fe-2_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220704112603_JGA.%20Fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220704112603_JGA.%20Fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220704112603_JGA.%20Fe-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220704112603_JGA.%20Fe-2_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220704112603_JGA.%20Fe-2_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 6 from 20220704112603_JGA.%20Fe-2_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220704112603_JGA.%20Fe-2_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220704112603_JGA.%20Fe-2_lungfront.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127143555_MMLJ%20Fe_lungback.webm from audios/20220127143555_MMLJ%20Fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127143555_MMLJ%20Fe_lungback.webm [loudness: -48 dB]\n",
            "  Clip 2 from 20220127143555_MMLJ%20Fe_lungback.webm [loudness: -73 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 3 from 20220127143555_MMLJ%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220127143555_MMLJ%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220127143555_MMLJ%20Fe_lungback.webm [loudness: -60 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054053_ACW-%20D2_lungfront.webm from audios/20211207054053_ACW-%20D2_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20211207054053_ACW-%20D2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20211207054053_ACW-%20D2_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 3 from 20211207054053_ACW-%20D2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20211207054053_ACW-%20D2_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20211207054053_ACW-%20D2_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20211207054053_ACW-%20D2_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20211207054053_ACW-%20D2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 8 from 20211207054053_ACW-%20D2_lungfront.webm [loudness: -29 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075038_TRC%2026-1_lungfront.webm from audios/20220215075038_TRC%2026-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220215075038_TRC%2026-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 2 from 20220215075038_TRC%2026-1_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220215075038_TRC%2026-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 4 from 20220215075038_TRC%2026-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 5 from 20220215075038_TRC%2026-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 6 from 20220215075038_TRC%2026-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 7 from 20220215075038_TRC%2026-1_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 8 from 20220215075038_TRC%2026-1_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -55 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20230419124433_LG%20fe-2_lungback.webm from audios/20230419124433_LG%20fe-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419124433_LG%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230419124433_LG%20fe-2_lungback.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20230419124433_LG%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20230419124433_LG%20fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20230419124433_LG%20fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20230419124433_LG%20fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20230419124433_LG%20fe-2_lungback.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20230419124433_LG%20fe-2_lungback.webm [loudness: -13 dB]\n",
            "  Clip 9 from 20230419124433_LG%20fe-2_lungback.webm [loudness: -13 dB]\n",
            "  Clip 10 from 20230419124433_LG%20fe-2_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127134714_JAYG%20Fe_lungback.webm from audios/20220127134714_JAYG%20Fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127134714_JAYG%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220127134714_JAYG%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220127134714_JAYG%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220127134714_JAYG%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220127134714_JAYG%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220107155508_GHR_lungfront.webm from audios/20220107155508_GHR_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220107155508_GHR_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 2 from 20220107155508_GHR_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220107155508_GHR_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 4 from 20220107155508_GHR_lungfront.webm [loudness: -69 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 5 from 20220107155508_GHR_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 6 from 20220107155508_GHR_lungfront.webm [loudness: -39 dB]\n",
            "  Clip 7 from 20220107155508_GHR_lungfront.webm [loudness: -65 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118121138_LRLP_lungfront.webm from audios/20220118121138_LRLP_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118121138_LRLP_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220118121138_LRLP_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220118121138_LRLP_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220118121138_LRLP_lungfront.webm [loudness: -11 dB]\n",
            "  Clip 5 from 20220118121138_LRLP_lungfront.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421090611_LS%20fe-1_vocal.webm from audios/20230421090611_LS%20fe-1_vocal.webm\n",
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20230421090611_LS%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20230421090611_LS%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230421090611_LS%20fe-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220718070922_MGC%20fe-1_lungfront.webm from audios/20220718070922_MGC%20fe-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220718070922_MGC%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220718070922_MGC%20fe-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220718070922_MGC%20fe-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 4 from 20220718070922_MGC%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220718070922_MGC%20fe-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220718070922_MGC%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220718070922_MGC%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220718070922_MGC%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20220718070922_MGC%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302053604_MLQ%20fe%202-2_lungback.webm from audios/20220302053604_MLQ%20fe%202-2_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302053604_MLQ%20fe%202-2_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220302053604_MLQ%20fe%202-2_lungback.webm [loudness: -31 dB]\n",
            "  Clip 3 from 20220302053604_MLQ%20fe%202-2_lungback.webm [loudness: -55 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 4 from 20220302053604_MLQ%20fe%202-2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 5 from 20220302053604_MLQ%20fe%202-2_lungback.webm [loudness: -41 dB]\n",
            "  Clip 6 from 20220302053604_MLQ%20fe%202-2_lungback.webm [loudness: -52 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 7 from 20220302053604_MLQ%20fe%202-2_lungback.webm [loudness: -51 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 8 from 20220302053604_MLQ%20fe%202-2_lungback.webm [loudness: -43 dB]\n",
            "  Clip 9 from 20220302053604_MLQ%20fe%202-2_lungback.webm [loudness: -36 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516152711_Lsma1-16-5_vocal.webm from audios/20220516152711_Lsma1-16-5_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220516152711_Lsma1-16-5_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220516152711_Lsma1-16-5_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220516152711_Lsma1-16-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220516152711_Lsma1-16-5_vocal.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220516152711_Lsma1-16-5_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127104054_CHLA%20fe_vocal.webm from audios/20220127104054_CHLA%20fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220127104054_CHLA%20fe_vocal.webm [loudness: -44 dB]\n",
            "  Clip 2 from 20220127104054_CHLA%20fe_vocal.webm [loudness: -45 dB]\n",
            "  Clip 3 from 20220127104054_CHLA%20fe_vocal.webm [loudness: -40 dB]\n",
            "  Clip 4 from 20220127104054_CHLA%20fe_vocal.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319074246_RMC%20fe%2019-1_lungback.webm from audios/20220319074246_RMC%20fe%2019-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319074246_RMC%20fe%2019-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220319074246_RMC%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220319074246_RMC%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220319074246_RMC%20fe%2019-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 5 from 20220319074246_RMC%20fe%2019-1_lungback.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20220319074246_RMC%20fe%2019-1_lungback.webm [loudness: -28 dB]\n",
            "  Clip 7 from 20220319074246_RMC%20fe%2019-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 8 from 20220319074246_RMC%20fe%2019-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 9 from 20220319074246_RMC%20fe%2019-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708104228_FDV%20fe-2_vocal.webm from audios/20220708104228_FDV%20fe-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220708104228_FDV%20fe-2_vocal.webm [loudness: -11 dB]\n",
            "  Clip 2 from 20220708104228_FDV%20fe-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220708104228_FDV%20fe-2_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220708104228_FDV%20fe-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220708104228_FDV%20fe-2_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220108112150_HCAP_lungfront.webm from audios/20220108112150_HCAP_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220108112150_HCAP_lungfront.webm [loudness: -40 dB]\n",
            "  Clip 2 from 20220108112150_HCAP_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 3 from 20220108112150_HCAP_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 4 from 20220108112150_HCAP_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 5 from 20220108112150_HCAP_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 6 from 20220108112150_HCAP_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 7 from 20220108112150_HCAP_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220503092428_Jonathan_lungback.webm from audios/20220503092428_Jonathan_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220503092428_Jonathan_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220503092428_Jonathan_lungback.webm [loudness: -30 dB]\n",
            "  Clip 3 from 20220503092428_Jonathan_lungback.webm [loudness: -36 dB]\n",
            "  Clip 4 from 20220503092428_Jonathan_lungback.webm [loudness: -40 dB]\n",
            "  Clip 5 from 20220503092428_Jonathan_lungback.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20220503092428_Jonathan_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114152135_VRP_lungfront.webm from audios/20220114152135_VRP_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114152135_VRP_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 2 from 20220114152135_VRP_lungfront.webm [loudness: -57 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 3 from 20220114152135_VRP_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220114152135_VRP_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 5 from 20220114152135_VRP_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220121165452_STDCP_lungfront.webm from audios/20220121165452_STDCP_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220121165452_STDCP_lungfront.webm [loudness: -64 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 2 from 20220121165452_STDCP_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 3 from 20220121165452_STDCP_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220121165452_STDCP_lungfront.webm [loudness: -74 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 5 from 20220121165452_STDCP_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 6 from 20220121165452_STDCP_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -70 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220107110348_BTMA_vocal.webm from audios/20220107110348_BTMA_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220107110348_BTMA_vocal.webm [loudness: -29 dB]\n",
            "  Clip 2 from 20220107110348_BTMA_vocal.webm [loudness: -27 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220122153938_MSVC%20es_lungback.webm from audios/20220122153938_MSVC%20es_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220122153938_MSVC%20es_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220122153938_MSVC%20es_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220122153938_MSVC%20es_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220122153938_MSVC%20es_lungback.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20220122153938_MSVC%20es_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220122153938_MSVC%20es_lungback.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305074538_KMI%20fe%205-1_vocal.webm from audios/20220305074538_KMI%20fe%205-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220305074538_KMI%20fe%205-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220305074538_KMI%20fe%205-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220305074538_KMI%20fe%205-1_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220305074538_KMI%20fe%205-1_vocal.webm [loudness: -39 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220804094909_JQZ%20fe-3_lungfront.webm from audios/20220804094909_JQZ%20fe-3_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220804094909_JQZ%20fe-3_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220804094909_JQZ%20fe-3_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220804094909_JQZ%20fe-3_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220804094909_JQZ%20fe-3_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220804094909_JQZ%20fe-3_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220804094909_JQZ%20fe-3_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220804094909_JQZ%20fe-3_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220804094909_JQZ%20fe-3_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220804094909_JQZ%20fe-3_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421090956_AH%20fe-1_lungfront.webm from audios/20230421090956_AH%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 6 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 9 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 11 from 20230421090956_AH%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20221217091134_Fe-1%20AR_vocal.webm from audios/20221217091134_Fe-1%20AR_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221217091134_Fe-1%20AR_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20221217091134_Fe-1%20AR_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20221217091134_Fe-1%20AR_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20221217091134_Fe-1%20AR_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20221217091134_Fe-1%20AR_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114120408_FWS_lungback.webm from audios/20220114120408_FWS_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114120408_FWS_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220114120408_FWS_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220114120408_FWS_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220114120408_FWS_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220114120408_FWS_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516143936_Darz1-16-5_lungfront.webm from audios/20220516143936_Darz1-16-5_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220516143936_Darz1-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220516143936_Darz1-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20220516143936_Darz1-16-5_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220516143936_Darz1-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220516143936_Darz1-16-5_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220516143936_Darz1-16-5_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220516143936_Darz1-16-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220516143936_Darz1-16-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119120850_DARZ_lungfront.webm from audios/20220119120850_DARZ_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220119120850_DARZ_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220119120850_DARZ_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220119120850_DARZ_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220119120850_DARZ_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220119120850_DARZ_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20211207055444_ACW-P3_vocal.webm from audios/20211207055444_ACW-P3_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20211207055444_ACW-P3_vocal.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20211207055444_ACW-P3_vocal.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20211207055444_ACW-P3_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20211207055444_ACW-P3_vocal.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20211207055444_ACW-P3_vocal.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20211207055444_ACW-P3_vocal.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20211207055444_ACW-P3_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220526123937_SE%20fe-2_lungfront.webm from audios/20220526123937_SE%20fe-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220526123937_SE%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220526123937_SE%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220526123937_SE%20fe-2_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220526123937_SE%20fe-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220526123937_SE%20fe-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220526123937_SE%20fe-2_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220526123937_SE%20fe-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220526123937_SE%20fe-2_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212071822_Gbc%2019-2_lungback.webm from audios/20220212071822_Gbc%2019-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -53 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 2 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -35 dB]\n",
            "  Clip 3 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -41 dB]\n",
            "  Clip 4 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -31 dB]\n",
            "  Clip 5 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -34 dB]\n",
            "  Clip 6 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -44 dB]\n",
            "  Clip 7 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -41 dB]\n",
            "  Clip 8 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -38 dB]\n",
            "  Clip 9 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -40 dB]\n",
            "  Clip 10 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -39 dB]\n",
            "  Clip 11 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -39 dB]\n",
            "  Clip 12 from 20220212071822_Gbc%2019-2_lungback.webm [loudness: -35 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207055653_ADW-P4_lungback.webm from audios/20211207055653_ADW-P4_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207055653_ADW-P4_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20211207055653_ADW-P4_lungback.webm [loudness: -24 dB]\n",
            "  Clip 3 from 20211207055653_ADW-P4_lungback.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20211207055653_ADW-P4_lungback.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20211207055653_ADW-P4_lungback.webm [loudness: -28 dB]\n",
            "  Clip 6 from 20211207055653_ADW-P4_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304052032_CRD_lungback.webm from audios/20220304052032_CRD_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304052032_CRD_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220304052032_CRD_lungback.webm [loudness: -27 dB]\n",
            "  Clip 3 from 20220304052032_CRD_lungback.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220304052032_CRD_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220304052032_CRD_lungback.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20220304052032_CRD_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220304052032_CRD_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220304052032_CRD_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20220304052032_CRD_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420093811_GY%20fe-1_vocal.webm from audios/20230420093811_GY%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230420093811_GY%20fe-1_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20230420093811_GY%20fe-1_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20230420093811_GY%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20230420093811_GY%20fe-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304051546_GYZ%20fe%204-1_vocal.webm from audios/20220304051546_GYZ%20fe%204-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220304051546_GYZ%20fe%204-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220304051546_GYZ%20fe%204-1_vocal.webm [loudness: -9 dB]\n",
            "  Clip 3 from 20220304051546_GYZ%20fe%204-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 4 from 20220304051546_GYZ%20fe%204-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220304051546_GYZ%20fe%204-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220721062840_ICR%20fe-1_lungback.webm from audios/20220721062840_ICR%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220721062840_ICR%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20220721062840_ICR%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220721062840_ICR%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20220721062840_ICR%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20220721062840_ICR%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220721062840_ICR%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220721062840_ICR%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 8 from 20220721062840_ICR%20fe-1_lungback.webm [loudness: -41 dB]\n",
            "  Clip 9 from 20220721062840_ICR%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 10 from 20220721062840_ICR%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20221118053800_Fe-1%20SD_vocal.webm from audios/20221118053800_Fe-1%20SD_vocal.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20221118053800_Fe-1%20SD_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20221118053800_Fe-1%20SD_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20221118053800_Fe-1%20SD_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20221118053800_Fe-1%20SD_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20221118053800_Fe-1%20SD_vocal.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20221118053800_Fe-1%20SD_vocal.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20221118053800_Fe-1%20SD_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220812142325_ANR%20fe-1_lungback.webm from audios/20220812142325_ANR%20fe-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220812142325_ANR%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220812142325_ANR%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220812142325_ANR%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220812142325_ANR%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220812142325_ANR%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220812142325_ANR%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20220812142325_ANR%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 8 from 20220812142325_ANR%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 9 from 20220812142325_ANR%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220504102754_Seyv%204-5_lungfront.webm from audios/20220504102754_Seyv%204-5_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220504102754_Seyv%204-5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220504102754_Seyv%204-5_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220504102754_Seyv%204-5_lungfront.webm [loudness: -36 dB]\n",
            "  Clip 4 from 20220504102754_Seyv%204-5_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 5 from 20220504102754_Seyv%204-5_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 6 from 20220504102754_Seyv%204-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220504102754_Seyv%204-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20221217091134_Fe-1%20AR_lungfront.webm from audios/20221217091134_Fe-1%20AR_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221217091134_Fe-1%20AR_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 2 from 20221217091134_Fe-1%20AR_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20221217091134_Fe-1%20AR_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 4 from 20221217091134_Fe-1%20AR_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20221217091134_Fe-1%20AR_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 6 from 20221217091134_Fe-1%20AR_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 7 from 20221217091134_Fe-1%20AR_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20221217091134_Fe-1%20AR_lungfront.webm [loudness: -33 dB]\n",
            "  Clip 9 from 20221217091134_Fe-1%20AR_lungfront.webm [loudness: -30 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220709054715_CNE%20fe-1_vocal.webm from audios/20220709054715_CNE%20fe-1_vocal.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220709054715_CNE%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220709054715_CNE%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20220709054715_CNE%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220709054715_CNE%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220709054715_CNE%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 6 from 20220709054715_CNE%20fe-1_vocal.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220709054715_CNE%20fe-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124134054_GMK%20fe_lungback.webm from audios/20220124134054_GMK%20fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124134054_GMK%20fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220124134054_GMK%20fe_lungback.webm [loudness: -95 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -95 dB]\n",
            "  Clip 3 from 20220124134054_GMK%20fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220124134054_GMK%20fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220124134054_GMK%20fe_lungback.webm [loudness: -63 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -63 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220625095002_DM%20fe-1_lungfront.webm from audios/20220625095002_DM%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220625095002_DM%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220625095002_DM%20fe-1_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220625095002_DM%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220625095002_DM%20fe-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20220625095002_DM%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220625095002_DM%20fe-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 7 from 20220625095002_DM%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20220625095002_DM%20fe-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 9 from 20220625095002_DM%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220129141239_SMALM%20FE_lungfront.webm from audios/20220129141239_SMALM%20FE_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220129141239_SMALM%20FE_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 2 from 20220129141239_SMALM%20FE_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220129141239_SMALM%20FE_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 4 from 20220129141239_SMALM%20FE_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 5 from 20220129141239_SMALM%20FE_lungfront.webm [loudness: -54 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 6 from 20220129141239_SMALM%20FE_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -53 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220115154844_KMI_lungfront.webm from audios/20220115154844_KMI_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220115154844_KMI_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220115154844_KMI_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220115154844_KMI_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220115154844_KMI_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220115154844_KMI_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220115154844_KMI_lungfront.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220713092907_JFC%20fe-1_lungback.webm from audios/20220713092907_JFC%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220713092907_JFC%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220713092907_JFC%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220713092907_JFC%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220713092907_JFC%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220713092907_JFC%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220713092907_JFC%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220713092907_JFC%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220713092907_JFC%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20220713092907_JFC%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105133643_YE_lungfront.webm from audios/20220105133643_YE_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220105133643_YE_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 2 from 20220105133643_YE_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 3 from 20220105133643_YE_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220105133643_YE_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220105133643_YE_lungfront.webm [loudness: -82 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -82 dB]\n",
            "  Clip 6 from 20220105133643_YE_lungfront.webm [loudness: -78 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -78 dB]\n",
            "  Clip 7 from 20220105133643_YE_lungfront.webm [loudness: -79 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 8 from 20220105133643_YE_lungfront.webm [loudness: -80 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127143555_MMLJ%20Fe_lungfront.webm from audios/20220127143555_MMLJ%20Fe_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220127143555_MMLJ%20Fe_lungfront.webm [loudness: -51 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 2 from 20220127143555_MMLJ%20Fe_lungfront.webm [loudness: -77 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -77 dB]\n",
            "  Clip 3 from 20220127143555_MMLJ%20Fe_lungfront.webm [loudness: -70 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -70 dB]\n",
            "  Clip 4 from 20220127143555_MMLJ%20Fe_lungfront.webm [loudness: -92 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -92 dB]\n",
            "  Clip 5 from 20220127143555_MMLJ%20Fe_lungfront.webm [loudness: -96 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -96 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220515223642_Jasr-16-5_lungfront.webm from audios/20220515223642_Jasr-16-5_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220515223642_Jasr-16-5_lungfront.webm [loudness: -31 dB]\n",
            "  Clip 2 from 20220515223642_Jasr-16-5_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220515223642_Jasr-16-5_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220515223642_Jasr-16-5_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220515223642_Jasr-16-5_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 6 from 20220515223642_Jasr-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220515223642_Jasr-16-5_lungfront.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128135220_PCSN%20fe_lungfront.webm from audios/20220128135220_PCSN%20fe_lungfront.webm\n",
            "Error loading 20220128135220_PCSN%20fe_lungfront.webm: . Removing from files_map.\n",
            "\n",
            "Loading file: 20230419085806_JO%20fe-1_lungback.webm from audios/20230419085806_JO%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419085806_JO%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20230419085806_JO%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20230419085806_JO%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20230419085806_JO%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20230419085806_JO%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20230419085806_JO%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20230419085806_JO%20fe-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 8 from 20230419085806_JO%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20230419085806_JO%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 10 from 20230419085806_JO%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220303082548_AAC%20fe%203-1_vocal.webm from audios/20220303082548_AAC%20fe%203-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220303082548_AAC%20fe%203-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220303082548_AAC%20fe%203-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220303082548_AAC%20fe%203-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220303082548_AAC%20fe%203-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220303082548_AAC%20fe%203-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20221118111510_Fe-1%20EP_vocal.webm from audios/20221118111510_Fe-1%20EP_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221118111510_Fe-1%20EP_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20221118111510_Fe-1%20EP_vocal.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20221118111510_Fe-1%20EP_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20221118111510_Fe-1%20EP_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20221118111510_Fe-1%20EP_vocal.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207054333_ACW-D3_vocal.webm from audios/20211207054333_ACW-D3_vocal.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20211207054333_ACW-D3_vocal.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20211207054333_ACW-D3_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20211207054333_ACW-D3_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20211207054333_ACW-D3_vocal.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20211207054333_ACW-D3_vocal.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20211207054333_ACW-D3_vocal.webm [loudness: -13 dB]\n",
            "  Clip 7 from 20211207054333_ACW-D3_vocal.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418103221_Av%20fe-1_vocal.webm from audios/20230418103221_Av%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230418103221_Av%20fe-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20230418103221_Av%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230418103221_Av%20fe-1_vocal.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20230418103221_Av%20fe-1_vocal.webm [loudness: -29 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516150340_Wgyv2-16-5_vocal.webm from audios/20220516150340_Wgyv2-16-5_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516150340_Wgyv2-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220516150340_Wgyv2-16-5_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220516150340_Wgyv2-16-5_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220516150340_Wgyv2-16-5_vocal.webm [loudness: -18 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202104151_Mcp-02-12-D5_lungback.webm from audios/20211202104151_Mcp-02-12-D5_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211202104151_Mcp-02-12-D5_lungback.webm [loudness: -88 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -88 dB]\n",
            "  Clip 2 from 20211202104151_Mcp-02-12-D5_lungback.webm [loudness: -93 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -93 dB]\n",
            "  Clip 3 from 20211202104151_Mcp-02-12-D5_lungback.webm [loudness: -95 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -95 dB]\n",
            "  Clip 4 from 20211202104151_Mcp-02-12-D5_lungback.webm [loudness: -91 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -91 dB]\n",
            "  Clip 5 from 20211202104151_Mcp-02-12-D5_lungback.webm [loudness: -95 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -95 dB]\n",
            "  Clip 6 from 20211202104151_Mcp-02-12-D5_lungback.webm [loudness: -95 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -95 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220212081824_Gnf%2023-2_lungfront.webm from audios/20220212081824_Gnf%2023-2_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220212081824_Gnf%2023-2_lungfront.webm [loudness: -49 dB]\n",
            "  Clip 2 from 20220212081824_Gnf%2023-2_lungfront.webm [loudness: -53 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 3 from 20220212081824_Gnf%2023-2_lungfront.webm [loudness: -56 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 4 from 20220212081824_Gnf%2023-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 5 from 20220212081824_Gnf%2023-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 6 from 20220212081824_Gnf%2023-2_lungfront.webm [loudness: -55 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 7 from 20220212081824_Gnf%2023-2_lungfront.webm [loudness: -58 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 8 from 20220212081824_Gnf%2023-2_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115111646_EMPV_lungback.webm from audios/20220115111646_EMPV_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220115111646_EMPV_lungback.webm [loudness: -42 dB]\n",
            "  Clip 2 from 20220115111646_EMPV_lungback.webm [loudness: -118 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -118 dB]\n",
            "  Clip 3 from 20220115111646_EMPV_lungback.webm [loudness: -72 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 4 from 20220115111646_EMPV_lungback.webm [loudness: -94 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -94 dB]\n",
            "  Clip 5 from 20220115111646_EMPV_lungback.webm [loudness: -80 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -80 dB]\n",
            "  Clip 6 from 20220115111646_EMPV_lungback.webm [loudness: -72 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125140524_NRJJ%20es_lungback.webm from audios/20220125140524_NRJJ%20es_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125140524_NRJJ%20es_lungback.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20220125140524_NRJJ%20es_lungback.webm [loudness: -66 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 3 from 20220125140524_NRJJ%20es_lungback.webm [loudness: -63 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 4 from 20220125140524_NRJJ%20es_lungback.webm [loudness: -65 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 5 from 20220125140524_NRJJ%20es_lungback.webm [loudness: -58 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220304052543_YH%20fe%204-1_lungfront.webm from audios/20220304052543_YH%20fe%204-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220304052543_YH%20fe%204-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20220304052543_YH%20fe%204-1_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220304052543_YH%20fe%204-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220304052543_YH%20fe%204-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220304052543_YH%20fe%204-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 6 from 20220304052543_YH%20fe%204-1_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 7 from 20220304052543_YH%20fe%204-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 8 from 20220304052543_YH%20fe%204-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124151143_JAYG%20fe_vocal.webm from audios/20220124151143_JAYG%20fe_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220124151143_JAYG%20fe_vocal.webm [loudness: -38 dB]\n",
            "  Clip 2 from 20220124151143_JAYG%20fe_vocal.webm [loudness: -40 dB]\n",
            "  Clip 3 from 20220124151143_JAYG%20fe_vocal.webm [loudness: -41 dB]\n",
            "  Clip 4 from 20220124151143_JAYG%20fe_vocal.webm [loudness: -42 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220126124939_ABM%20es_vocal.webm from audios/20220126124939_ABM%20es_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220126124939_ABM%20es_vocal.webm [loudness: -51 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 2 from 20220126124939_ABM%20es_vocal.webm [loudness: -49 dB]\n",
            "  Clip 3 from 20220126124939_ABM%20es_vocal.webm [loudness: -45 dB]\n",
            "  Clip 4 from 20220126124939_ABM%20es_vocal.webm [loudness: -44 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418115210_JS%20fe-1_vocal.webm from audios/20230418115210_JS%20fe-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20230418115210_JS%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20230418115210_JS%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20230418115210_JS%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20230418115210_JS%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516144141_Darz2-16-2_lungback.webm from audios/20220516144141_Darz2-16-2_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220516144141_Darz2-16-2_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220516144141_Darz2-16-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220516144141_Darz2-16-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220516144141_Darz2-16-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 5 from 20220516144141_Darz2-16-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220516144141_Darz2-16-2_lungback.webm [loudness: -19 dB]\n",
            "  Clip 7 from 20220516144141_Darz2-16-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 8 from 20220516144141_Darz2-16-2_lungback.webm [loudness: -75 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 9 from 20220516144141_Darz2-16-2_lungback.webm [loudness: -76 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip 10 from 20220516144141_Darz2-16-2_lungback.webm [loudness: -76 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -76 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20230418114816_TE%20fe-1_lungback.webm from audios/20230418114816_TE%20fe-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230418114816_TE%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20230418114816_TE%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20230418114816_TE%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20230418114816_TE%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20230418114816_TE%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20230418114816_TE%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 7 from 20230418114816_TE%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20230418114816_TE%20fe-1_lungback.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20230418114816_TE%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 10 from 20230418114816_TE%20fe-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107134757_OCAD_vocal.webm from audios/20220107134757_OCAD_vocal.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220107134757_OCAD_vocal.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220107134757_OCAD_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220107134757_OCAD_vocal.webm [loudness: -11 dB]\n",
            "  Clip 4 from 20220107134757_OCAD_vocal.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20220107134757_OCAD_vocal.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220107134757_OCAD_vocal.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220107134757_OCAD_vocal.webm [loudness: -74 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -74 dB]\n",
            "  Clip 8 from 20220107134757_OCAD_vocal.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20211202103721_Mcp-02-12-D1_vocal.webm from audios/20211202103721_Mcp-02-12-D1_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20211202103721_Mcp-02-12-D1_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20211202103721_Mcp-02-12-D1_vocal.webm [loudness: -11 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127153448_RAJL%20es_lungback.webm from audios/20220127153448_RAJL%20es_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220127153448_RAJL%20es_lungback.webm [loudness: -72 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 2 from 20220127153448_RAJL%20es_lungback.webm [loudness: -58 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip 3 from 20220127153448_RAJL%20es_lungback.webm [loudness: -69 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -69 dB]\n",
            "  Clip 4 from 20220127153448_RAJL%20es_lungback.webm [loudness: -55 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 5 from 20220127153448_RAJL%20es_lungback.webm [loudness: -55 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 6 from 20220127153448_RAJL%20es_lungback.webm [loudness: -70 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -70 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220124133907_GMK%20es_lungfront.webm from audios/20220124133907_GMK%20es_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124133907_GMK%20es_lungfront.webm [loudness: -94 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -94 dB]\n",
            "  Clip 2 from 20220124133907_GMK%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220124133907_GMK%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220124133907_GMK%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220124133907_GMK%20es_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220718070922_MGC%20fe-1_lungback.webm from audios/20220718070922_MGC%20fe-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220718070922_MGC%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 2 from 20220718070922_MGC%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220718070922_MGC%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220718070922_MGC%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220718070922_MGC%20fe-1_lungback.webm [loudness: -29 dB]\n",
            "  Clip 6 from 20220718070922_MGC%20fe-1_lungback.webm [loudness: -21 dB]\n",
            "  Clip 7 from 20220718070922_MGC%20fe-1_lungback.webm [loudness: -26 dB]\n",
            "  Clip 8 from 20220718070922_MGC%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220718070922_MGC%20fe-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220129141239_SMALM%20FE_lungback.webm from audios/20220129141239_SMALM%20FE_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220129141239_SMALM%20FE_lungback.webm [loudness: -52 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -52 dB]\n",
            "  Clip 2 from 20220129141239_SMALM%20FE_lungback.webm [loudness: -55 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 3 from 20220129141239_SMALM%20FE_lungback.webm [loudness: -55 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -55 dB]\n",
            "  Clip 4 from 20220129141239_SMALM%20FE_lungback.webm [loudness: -50 dB]\n",
            "  Clip 5 from 20220129141239_SMALM%20FE_lungback.webm [loudness: -49 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220212063658_Acb%2015-2_lungback.webm from audios/20220212063658_Acb%2015-2_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 12 2s clips\n",
            "  Clip 1 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -41 dB]\n",
            "  Clip 2 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -30 dB]\n",
            "  Clip 3 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -45 dB]\n",
            "  Clip 4 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -36 dB]\n",
            "  Clip 5 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -41 dB]\n",
            "  Clip 6 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -49 dB]\n",
            "  Clip 7 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -43 dB]\n",
            "  Clip 8 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -51 dB]\n",
            "  Clip 8 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 9 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -51 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -51 dB]\n",
            "  Clip 10 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -49 dB]\n",
            "  Clip 11 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -39 dB]\n",
            "  Clip 12 from 20220212063658_Acb%2015-2_lungback.webm [loudness: -37 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220115155641_SI_vocal.webm from audios/20220115155641_SI_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220115155641_SI_vocal.webm [loudness: -38 dB]\n",
            "  Clip 2 from 20220115155641_SI_vocal.webm [loudness: -35 dB]\n",
            "  Clip 3 from 20220115155641_SI_vocal.webm [loudness: -37 dB]\n",
            "  Clip 4 from 20220115155641_SI_vocal.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319095643_MAR%20fe%2019-1_lungback.webm from audios/20220319095643_MAR%20fe%2019-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220319095643_MAR%20fe%2019-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220319095643_MAR%20fe%2019-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220319095643_MAR%20fe%2019-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220319095643_MAR%20fe%2019-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220319095643_MAR%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 6 from 20220319095643_MAR%20fe%2019-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20220319095643_MAR%20fe%2019-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220319095643_MAR%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 9 from 20220319095643_MAR%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220304051252_PBZ%20fe%204-1_vocal.webm from audios/20220304051252_PBZ%20fe%204-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220304051252_PBZ%20fe%204-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220304051252_PBZ%20fe%204-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20220304051252_PBZ%20fe%204-1_vocal.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220304051252_PBZ%20fe%204-1_vocal.webm [loudness: -25 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220215075038_TRC%2026-1_vocal.webm from audios/20220215075038_TRC%2026-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220215075038_TRC%2026-1_vocal.webm [loudness: -36 dB]\n",
            "  Clip 2 from 20220215075038_TRC%2026-1_vocal.webm [loudness: -33 dB]\n",
            "  Clip 3 from 20220215075038_TRC%2026-1_vocal.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220215075038_TRC%2026-1_vocal.webm [loudness: -33 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319094332_MME%20fe%2019-1_vocal.webm from audios/20220319094332_MME%20fe%2019-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220319094332_MME%20fe%2019-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220319094332_MME%20fe%2019-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220319094332_MME%20fe%2019-1_vocal.webm [loudness: -19 dB]\n",
            "  Clip 4 from 20220319094332_MME%20fe%2019-1_vocal.webm [loudness: -58 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -58 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064522_JMT-P4_vocal.webm from audios/20211209064522_JMT-P4_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20211209064522_JMT-P4_vocal.webm [loudness: -35 dB]\n",
            "  Clip 2 from 20211209064522_JMT-P4_vocal.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20211209064522_JMT-P4_vocal.webm [loudness: -24 dB]\n",
            "  Clip 4 from 20211209064522_JMT-P4_vocal.webm [loudness: -22 dB]\n",
            "  Clip 5 from 20211209064522_JMT-P4_vocal.webm [loudness: -61 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419105624_EA%20fe-1_lungfront.webm from audios/20230419105624_EA%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230419105624_EA%20fe-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20230419105624_EA%20fe-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 3 from 20230419105624_EA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20230419105624_EA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20230419105624_EA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20230419105624_EA%20fe-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230419105624_EA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20230419105624_EA%20fe-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 9 from 20230419105624_EA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 10 from 20230419105624_EA%20fe-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128123854_CGJJ%20Fe_lungback.webm from audios/20220128123854_CGJJ%20Fe_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220128123854_CGJJ%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 2 from 20220128123854_CGJJ%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220128123854_CGJJ%20Fe_lungback.webm [loudness: -77 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -77 dB]\n",
            "  Clip 4 from 20220128123854_CGJJ%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220128123854_CGJJ%20Fe_lungback.webm [loudness: -inf dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -inf dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220304051546_GYZ%20fe%204-1_lungfront.webm from audios/20220304051546_GYZ%20fe%204-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220304051546_GYZ%20fe%204-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220304051546_GYZ%20fe%204-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220304051546_GYZ%20fe%204-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220304051546_GYZ%20fe%204-1_lungfront.webm [loudness: -28 dB]\n",
            "  Clip 5 from 20220304051546_GYZ%20fe%204-1_lungfront.webm [loudness: -29 dB]\n",
            "  Clip 6 from 20220304051546_GYZ%20fe%204-1_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 7 from 20220304051546_GYZ%20fe%204-1_lungfront.webm [loudness: -35 dB]\n",
            "  Clip 8 from 20220304051546_GYZ%20fe%204-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20220304051546_GYZ%20fe%204-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220118121138_LRLP_lungback.webm from audios/20220118121138_LRLP_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220118121138_LRLP_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220118121138_LRLP_lungback.webm [loudness: -11 dB]\n",
            "  Clip 3 from 20220118121138_LRLP_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220118121138_LRLP_lungback.webm [loudness: -11 dB]\n",
            "  Clip 5 from 20220118121138_LRLP_lungback.webm [loudness: -11 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20211207055826_ADW-P5_lungback.webm from audios/20211207055826_ADW-P5_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211207055826_ADW-P5_lungback.webm [loudness: -23 dB]\n",
            "  Clip 2 from 20211207055826_ADW-P5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20211207055826_ADW-P5_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20211207055826_ADW-P5_lungback.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20211207055826_ADW-P5_lungback.webm [loudness: -34 dB]\n",
            "  Clip 6 from 20211207055826_ADW-P5_lungback.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (6, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117164316_LTA_vocal.webm from audios/20220117164316_LTA_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220117164316_LTA_vocal.webm [loudness: -26 dB]\n",
            "  Clip 2 from 20220117164316_LTA_vocal.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220117164316_LTA_vocal.webm [loudness: -18 dB]\n",
            "  Clip 4 from 20220117164316_LTA_vocal.webm [loudness: -36 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220723124659_AVB%20fe-1_vocal.webm from audios/20220723124659_AVB%20fe-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220723124659_AVB%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220723124659_AVB%20fe-1_vocal.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220723124659_AVB%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220723124659_AVB%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 5 from 20220723124659_AVB%20fe-1_vocal.webm [loudness: -47 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220105163221_CGT%20sin_lungfront.webm from audios/20220105163221_CGT%20sin_lungfront.webm\n",
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -81 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -81 dB]\n",
            "  Clip 2 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -26 dB]\n",
            "  Clip 4 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 5 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 6 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -73 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -73 dB]\n",
            "  Clip 7 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -48 dB]\n",
            "  Clip 8 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 9 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -66 dB]\n",
            "  Clip 9 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 10 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -59 dB]\n",
            "  Clip 10 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 11 from 20220105163221_CGT%20sin_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 11 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209064026_JMT-D5_lungback.webm from audios/20211209064026_JMT-D5_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20211209064026_JMT-D5_lungback.webm [loudness: -45 dB]\n",
            "  Clip 2 from 20211209064026_JMT-D5_lungback.webm [loudness: -60 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 3 from 20211209064026_JMT-D5_lungback.webm [loudness: -65 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -65 dB]\n",
            "  Clip 4 from 20211209064026_JMT-D5_lungback.webm [loudness: -53 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 5 from 20211209064026_JMT-D5_lungback.webm [loudness: -61 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -61 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220812142325_ANR%20fe-1_vocal.webm from audios/20220812142325_ANR%20fe-1_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220812142325_ANR%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220812142325_ANR%20fe-1_vocal.webm [loudness: -12 dB]\n",
            "  Clip 3 from 20220812142325_ANR%20fe-1_vocal.webm [loudness: -14 dB]\n",
            "  Clip 4 from 20220812142325_ANR%20fe-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 5 from 20220812142325_ANR%20fe-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107110348_BTMA_lungfront.webm from audios/20220107110348_BTMA_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220107110348_BTMA_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 2 from 20220107110348_BTMA_lungfront.webm [loudness: -105 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -105 dB]\n",
            "  Clip 3 from 20220107110348_BTMA_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 4 from 20220107110348_BTMA_lungfront.webm [loudness: -102 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -102 dB]\n",
            "  Clip 5 from 20220107110348_BTMA_lungfront.webm [loudness: -62 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -62 dB]\n",
            "  Clip 6 from 20220107110348_BTMA_lungfront.webm [loudness: -104 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -104 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220118111208_XAW_vocal.webm from audios/20220118111208_XAW_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 3 2s clips\n",
            "  Clip 1 from 20220118111208_XAW_vocal.webm [loudness: -79 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -79 dB]\n",
            "  Clip 2 from 20220118111208_XAW_vocal.webm [loudness: -54 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 3 from 20220118111208_XAW_vocal.webm [loudness: -43 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123083226_Fe-2%20VR_lungfront.webm from audios/20221123083226_Fe-2%20VR_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20221123083226_Fe-2%20VR_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20221123083226_Fe-2%20VR_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20221123083226_Fe-2%20VR_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20221123083226_Fe-2%20VR_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20221123083226_Fe-2%20VR_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20221123083226_Fe-2%20VR_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20221123083226_Fe-2%20VR_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 8 from 20221123083226_Fe-2%20VR_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20221123083226_Fe-2%20VR_lungfront.webm [loudness: -17 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20230421113844_AP%20fe-1_lungback.webm from audios/20230421113844_AP%20fe-1_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20230421113844_AP%20fe-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 2 from 20230421113844_AP%20fe-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230421113844_AP%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20230421113844_AP%20fe-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20230421113844_AP%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20230421113844_AP%20fe-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20230421113844_AP%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 8 from 20230421113844_AP%20fe-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 9 from 20230421113844_AP%20fe-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 10 from 20230421113844_AP%20fe-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302060619_PRC%20fe%202-2_vocal.webm from audios/20220302060619_PRC%20fe%202-2_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220302060619_PRC%20fe%202-2_vocal.webm [loudness: -14 dB]\n",
            "  Clip 2 from 20220302060619_PRC%20fe%202-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220302060619_PRC%20fe%202-2_vocal.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220302060619_PRC%20fe%202-2_vocal.webm [loudness: -50 dB]\n",
            "  Clip 5 from 20220302060619_PRC%20fe%202-2_vocal.webm [loudness: -49 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305073453_FFP%20fe%205-1_vocal.webm from audios/20220305073453_FFP%20fe%205-1_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220305073453_FFP%20fe%205-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220305073453_FFP%20fe%205-1_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220305073453_FFP%20fe%205-1_vocal.webm [loudness: -54 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -54 dB]\n",
            "  Clip 4 from 20220305073453_FFP%20fe%205-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (3, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302092223_CCP%20fe%202-1_lungfront.webm from audios/20220302092223_CCP%20fe%202-1_lungfront.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220302092223_CCP%20fe%202-1_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20220302092223_CCP%20fe%202-1_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 3 from 20220302092223_CCP%20fe%202-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220302092223_CCP%20fe%202-1_lungfront.webm [loudness: -37 dB]\n",
            "  Clip 5 from 20220302092223_CCP%20fe%202-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 6 from 20220302092223_CCP%20fe%202-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 7 from 20220302092223_CCP%20fe%202-1_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 8 from 20220302092223_CCP%20fe%202-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 9 from 20220302092223_CCP%20fe%202-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20211209063858_JMT-D4_lungfront.webm from audios/20211209063858_JMT-D4_lungfront.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20211209063858_JMT-D4_lungfront.webm [loudness: -60 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 2 from 20211209063858_JMT-D4_lungfront.webm [loudness: -63 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 3 from 20211209063858_JMT-D4_lungfront.webm [loudness: -47 dB]\n",
            "  Clip 4 from 20211209063858_JMT-D4_lungfront.webm [loudness: -45 dB]\n",
            "  Clip 5 from 20211209063858_JMT-D4_lungfront.webm [loudness: -46 dB]\n",
            "  Clip 6 from 20211209063858_JMT-D4_lungfront.webm [loudness: -46 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128104342_AASE%20fe%201_vocal.webm from audios/20220128104342_AASE%20fe%201_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220128104342_AASE%20fe%201_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220128104342_AASE%20fe%201_vocal.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220120162822_OEGP_vocal.webm from audios/20220120162822_OEGP_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220120162822_OEGP_vocal.webm [loudness: -10 dB]\n",
            "  Clip 2 from 20220120162822_OEGP_vocal.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220120162822_OEGP_vocal.webm [loudness: -8 dB]\n",
            "  Clip 4 from 20220120162822_OEGP_vocal.webm [loudness: -7 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516144141_Darz2-16-2_vocal.webm from audios/20220516144141_Darz2-16-2_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20220516144141_Darz2-16-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20220516144141_Darz2-16-2_vocal.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20220516144141_Darz2-16-2_vocal.webm [loudness: -16 dB]\n",
            "  Clip 4 from 20220516144141_Darz2-16-2_vocal.webm [loudness: -15 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220319053836_MMA%20fe%2019-1_lungback.webm from audios/20220319053836_MMA%20fe%2019-1_lungback.webm\n",
            " Segmenting into 10 2s clips\n",
            "  Clip 1 from 20220319053836_MMA%20fe%2019-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 2 from 20220319053836_MMA%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220319053836_MMA%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 4 from 20220319053836_MMA%20fe%2019-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220319053836_MMA%20fe%2019-1_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220319053836_MMA%20fe%2019-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220319053836_MMA%20fe%2019-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220319053836_MMA%20fe%2019-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20220319053836_MMA%20fe%2019-1_lungback.webm [loudness: -25 dB]\n",
            "  Clip 10 from 20220319053836_MMA%20fe%2019-1_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (10, 512), data type: float32\n",
            "\n",
            "Loading file: 20220127121029_GADA%20fe_vocal.webm from audios/20220127121029_GADA%20fe_vocal.webm\n",
            " Segmenting into 2 2s clips\n",
            "  Clip 1 from 20220127121029_GADA%20fe_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220127121029_GADA%20fe_vocal.webm [loudness: -7 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305090421_LCC%20fe%205-1_lungfront.webm from audios/20220305090421_LCC%20fe%205-1_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220305090421_LCC%20fe%205-1_lungfront.webm [loudness: -19 dB]\n",
            "  Clip 2 from 20220305090421_LCC%20fe%205-1_lungfront.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20220305090421_LCC%20fe%205-1_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 4 from 20220305090421_LCC%20fe%205-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220305090421_LCC%20fe%205-1_lungfront.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220305090421_LCC%20fe%205-1_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220305090421_LCC%20fe%205-1_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220305090421_LCC%20fe%205-1_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220526123937_SE%20fe-2_lungback.webm from audios/20220526123937_SE%20fe-2_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220526123937_SE%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220526123937_SE%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 3 from 20220526123937_SE%20fe-2_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220526123937_SE%20fe-2_lungback.webm [loudness: -20 dB]\n",
            "  Clip 5 from 20220526123937_SE%20fe-2_lungback.webm [loudness: -22 dB]\n",
            "  Clip 6 from 20220526123937_SE%20fe-2_lungback.webm [loudness: -26 dB]\n",
            "  Clip 7 from 20220526123937_SE%20fe-2_lungback.webm [loudness: -28 dB]\n",
            "  Clip 8 from 20220526123937_SE%20fe-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip 9 from 20220526123937_SE%20fe-2_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119130925_MCNT_lungback.webm from audios/20220119130925_MCNT_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220119130925_MCNT_lungback.webm [loudness: -53 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 2 from 20220119130925_MCNT_lungback.webm [loudness: -53 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip 3 from 20220119130925_MCNT_lungback.webm [loudness: -66 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 4 from 20220119130925_MCNT_lungback.webm [loudness: -49 dB]\n",
            "  Clip 5 from 20220119130925_MCNT_lungback.webm [loudness: -53 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -53 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220119161535_SNPC_lungback.webm from audios/20220119161535_SNPC_lungback.webm\n",
            " Segmenting into 6 2s clips\n",
            "  Clip 1 from 20220119161535_SNPC_lungback.webm [loudness: -106 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -106 dB]\n",
            "  Clip 2 from 20220119161535_SNPC_lungback.webm [loudness: -inf dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 3 from 20220119161535_SNPC_lungback.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220119161535_SNPC_lungback.webm [loudness: -46 dB]\n",
            "  Clip 5 from 20220119161535_SNPC_lungback.webm [loudness: -44 dB]\n",
            "  Clip 6 from 20220119161535_SNPC_lungback.webm [loudness: -inf dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (2, 512), data type: float32\n",
            "\n",
            "Loading file: 20220708093145_ARB%20fe-4_lungback.webm from audios/20220708093145_ARB%20fe-4_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220708093145_ARB%20fe-4_lungback.webm [loudness: -22 dB]\n",
            "  Clip 2 from 20220708093145_ARB%20fe-4_lungback.webm [loudness: -22 dB]\n",
            "  Clip 3 from 20220708093145_ARB%20fe-4_lungback.webm [loudness: -21 dB]\n",
            "  Clip 4 from 20220708093145_ARB%20fe-4_lungback.webm [loudness: -27 dB]\n",
            "  Clip 5 from 20220708093145_ARB%20fe-4_lungback.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220708093145_ARB%20fe-4_lungback.webm [loudness: -18 dB]\n",
            "  Clip 7 from 20220708093145_ARB%20fe-4_lungback.webm [loudness: -21 dB]\n",
            "  Clip 8 from 20220708093145_ARB%20fe-4_lungback.webm [loudness: -27 dB]\n",
            "  Clip 9 from 20220708093145_ARB%20fe-4_lungback.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220516152223_Jayg2-16-5_lungfront.webm from audios/20220516152223_Jayg2-16-5_lungfront.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516152223_Jayg2-16-5_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220516152223_Jayg2-16-5_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 3 from 20220516152223_Jayg2-16-5_lungfront.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220516152223_Jayg2-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220516152223_Jayg2-16-5_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20220516152223_Jayg2-16-5_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 7 from 20220516152223_Jayg2-16-5_lungfront.webm [loudness: -21 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20220107163554_PMA_lungback.webm from audios/20220107163554_PMA_lungback.webm\n",
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220107163554_PMA_lungback.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20220107163554_PMA_lungback.webm [loudness: -63 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 3 from 20220107163554_PMA_lungback.webm [loudness: -59 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 4 from 20220107163554_PMA_lungback.webm [loudness: -60 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 5 from 20220107163554_PMA_lungback.webm [loudness: -66 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -66 dB]\n",
            "  Clip 6 from 20220107163554_PMA_lungback.webm [loudness: -59 dB]\n",
            "  Clip 6 Skip...too quiet [loudness: -59 dB]\n",
            "  Clip 7 from 20220107163554_PMA_lungback.webm [loudness: -58 dB]\n",
            "  Clip 7 Skip...too quiet [loudness: -58 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20211207054333_ACW-D3_lungback.webm from audios/20211207054333_ACW-D3_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20211207054333_ACW-D3_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20211207054333_ACW-D3_lungback.webm [loudness: -17 dB]\n",
            "  Clip 3 from 20211207054333_ACW-D3_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20211207054333_ACW-D3_lungback.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20211207054333_ACW-D3_lungback.webm [loudness: -30 dB]\n",
            "  Clip 6 from 20211207054333_ACW-D3_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20211207054333_ACW-D3_lungback.webm [loudness: -19 dB]\n",
            "  Clip 8 from 20211207054333_ACW-D3_lungback.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220125122834_RPY%20es_lungback.webm from audios/20220125122834_RPY%20es_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220125122834_RPY%20es_lungback.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20220125122834_RPY%20es_lungback.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20220125122834_RPY%20es_lungback.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220125122834_RPY%20es_lungback.webm [loudness: -44 dB]\n",
            "  Clip 5 from 20220125122834_RPY%20es_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230419124433_LG%20fe-2_lungfront.webm from audios/20230419124433_LG%20fe-2_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20230419124433_LG%20fe-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20230419124433_LG%20fe-2_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 3 from 20230419124433_LG%20fe-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 4 from 20230419124433_LG%20fe-2_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20230419124433_LG%20fe-2_lungfront.webm [loudness: -23 dB]\n",
            "  Clip 6 from 20230419124433_LG%20fe-2_lungfront.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20230419124433_LG%20fe-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20230419124433_LG%20fe-2_lungfront.webm [loudness: -13 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20220117133932_YVRM_lungfront.webm from audios/20220117133932_YVRM_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220117133932_YVRM_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220117133932_YVRM_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220117133932_YVRM_lungfront.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220117133932_YVRM_lungfront.webm [loudness: -10 dB]\n",
            "  Clip 5 from 20220117133932_YVRM_lungfront.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220124151143_JAYG%20fe_lungfront.webm from audios/20220124151143_JAYG%20fe_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220124151143_JAYG%20fe_lungfront.webm [loudness: -72 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -72 dB]\n",
            "  Clip 2 from 20220124151143_JAYG%20fe_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 3 from 20220124151143_JAYG%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 4 from 20220124151143_JAYG%20fe_lungfront.webm [loudness: -inf dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -inf dB]\n",
            "  Clip 5 from 20220124151143_JAYG%20fe_lungfront.webm [loudness: -67 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -67 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220120143633_SBDS_vocal.webm from audios/20220120143633_SBDS_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220120143633_SBDS_vocal.webm [loudness: -9 dB]\n",
            "  Clip 2 from 20220120143633_SBDS_vocal.webm [loudness: -8 dB]\n",
            "  Clip 3 from 20220120143633_SBDS_vocal.webm [loudness: -10 dB]\n",
            "  Clip 4 from 20220120143633_SBDS_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20220120143633_SBDS_vocal.webm [loudness: -6 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20230420101527_ER%20fe-1_lungfront.webm from audios/20230420101527_ER%20fe-1_lungfront.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 11 2s clips\n",
            "  Clip 1 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 2 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 3 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -15 dB]\n",
            "  Clip 5 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 6 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 7 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 9 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 10 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip 11 from 20230420101527_ER%20fe-1_lungfront.webm [loudness: -14 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (11, 512), data type: float32\n",
            "\n",
            "Loading file: 20220129132954_DAKP%20FE_lungfront.webm from audios/20220129132954_DAKP%20FE_lungfront.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220129132954_DAKP%20FE_lungfront.webm [loudness: -75 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -75 dB]\n",
            "  Clip 2 from 20220129132954_DAKP%20FE_lungfront.webm [loudness: -68 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -68 dB]\n",
            "  Clip 3 from 20220129132954_DAKP%20FE_lungfront.webm [loudness: -64 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 4 from 20220129132954_DAKP%20FE_lungfront.webm [loudness: -64 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -64 dB]\n",
            "  Clip 5 from 20220129132954_DAKP%20FE_lungfront.webm [loudness: -48 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (1, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302081247_TZP%20fe%202-2_lungfront.webm from audios/20220302081247_TZP%20fe%202-2_lungfront.webm\n",
            " Segmenting into 8 2s clips\n",
            "  Clip 1 from 20220302081247_TZP%20fe%202-2_lungfront.webm [loudness: -21 dB]\n",
            "  Clip 2 from 20220302081247_TZP%20fe%202-2_lungfront.webm [loudness: -32 dB]\n",
            "  Clip 3 from 20220302081247_TZP%20fe%202-2_lungfront.webm [loudness: -25 dB]\n",
            "  Clip 4 from 20220302081247_TZP%20fe%202-2_lungfront.webm [loudness: -17 dB]\n",
            "  Clip 5 from 20220302081247_TZP%20fe%202-2_lungfront.webm [loudness: -27 dB]\n",
            "  Clip 6 from 20220302081247_TZP%20fe%202-2_lungfront.webm [loudness: -22 dB]\n",
            "  Clip 7 from 20220302081247_TZP%20fe%202-2_lungfront.webm [loudness: -24 dB]\n",
            "  Clip 8 from 20220302081247_TZP%20fe%202-2_lungfront.webm [loudness: -26 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (8, 512), data type: float32\n",
            "\n",
            "Loading file: 20221119112228_Fe-1%20GN_vocal.webm from audios/20221119112228_Fe-1%20GN_vocal.webm\n",
            " Segmenting into 4 2s clips\n",
            "  Clip 1 from 20221119112228_Fe-1%20GN_vocal.webm [loudness: -12 dB]\n",
            "  Clip 2 from 20221119112228_Fe-1%20GN_vocal.webm [loudness: -13 dB]\n",
            "  Clip 3 from 20221119112228_Fe-1%20GN_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20221119112228_Fe-1%20GN_vocal.webm [loudness: -16 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (4, 512), data type: float32\n",
            "\n",
            "Loading file: 20220302081528_EGDC%20fe%202-1_vocal.webm from audios/20220302081528_EGDC%20fe%202-1_vocal.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220302081528_EGDC%20fe%202-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 2 from 20220302081528_EGDC%20fe%202-1_vocal.webm [loudness: -10 dB]\n",
            "  Clip 3 from 20220302081528_EGDC%20fe%202-1_vocal.webm [loudness: -13 dB]\n",
            "  Clip 4 from 20220302081528_EGDC%20fe%202-1_vocal.webm [loudness: -21 dB]\n",
            "  Clip 5 from 20220302081528_EGDC%20fe%202-1_vocal.webm [loudness: -41 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220305091432_DYC%20fe%205-1_lungback.webm from audios/20220305091432_DYC%20fe%205-1_lungback.webm\n",
            " Segmenting into 9 2s clips\n",
            "  Clip 1 from 20220305091432_DYC%20fe%205-1_lungback.webm [loudness: -16 dB]\n",
            "  Clip 2 from 20220305091432_DYC%20fe%205-1_lungback.webm [loudness: -18 dB]\n",
            "  Clip 3 from 20220305091432_DYC%20fe%205-1_lungback.webm [loudness: -20 dB]\n",
            "  Clip 4 from 20220305091432_DYC%20fe%205-1_lungback.webm [loudness: -23 dB]\n",
            "  Clip 5 from 20220305091432_DYC%20fe%205-1_lungback.webm [loudness: -15 dB]\n",
            "  Clip 6 from 20220305091432_DYC%20fe%205-1_lungback.webm [loudness: -17 dB]\n",
            "  Clip 7 from 20220305091432_DYC%20fe%205-1_lungback.webm [loudness: -14 dB]\n",
            "  Clip 8 from 20220305091432_DYC%20fe%205-1_lungback.webm [loudness: -31 dB]\n",
            "  Clip 9 from 20220305091432_DYC%20fe%205-1_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (9, 512), data type: float32\n",
            "\n",
            "Loading file: 20220114114719_HIRP_lungback.webm from audios/20220114114719_HIRP_lungback.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20220114114719_HIRP_lungback.webm [loudness: -56 dB]\n",
            "  Clip 1 Skip...too quiet [loudness: -56 dB]\n",
            "  Clip 2 from 20220114114719_HIRP_lungback.webm [loudness: -63 dB]\n",
            "  Clip 2 Skip...too quiet [loudness: -63 dB]\n",
            "  Clip 3 from 20220114114719_HIRP_lungback.webm [loudness: -60 dB]\n",
            "  Clip 3 Skip...too quiet [loudness: -60 dB]\n",
            "  Clip 4 from 20220114114719_HIRP_lungback.webm [loudness: -57 dB]\n",
            "  Clip 4 Skip...too quiet [loudness: -57 dB]\n",
            "  Clip 5 from 20220114114719_HIRP_lungback.webm [loudness: -62 dB]\n",
            "  Clip 5 Skip...too quiet [loudness: -62 dB]\n",
            "  No valid clips found after silence filtering. Skipping inference.\n",
            "\n",
            "Loading file: 20220516144655_Sdpa2-16-5_lungback.webm from audios/20220516144655_Sdpa2-16-5_lungback.webm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Segmenting into 7 2s clips\n",
            "  Clip 1 from 20220516144655_Sdpa2-16-5_lungback.webm [loudness: -17 dB]\n",
            "  Clip 2 from 20220516144655_Sdpa2-16-5_lungback.webm [loudness: -26 dB]\n",
            "  Clip 3 from 20220516144655_Sdpa2-16-5_lungback.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20220516144655_Sdpa2-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 5 from 20220516144655_Sdpa2-16-5_lungback.webm [loudness: -18 dB]\n",
            "  Clip 6 from 20220516144655_Sdpa2-16-5_lungback.webm [loudness: -12 dB]\n",
            "  Clip 7 from 20220516144655_Sdpa2-16-5_lungback.webm [loudness: -24 dB]\n",
            "  Clip not in cache, performing inference...\n",
            "  Embedding batch shape: (7, 512), data type: float32\n",
            "\n",
            "Loading file: 20221123070020_Fe-1%20RF_vocal.webm from audios/20221123070020_Fe-1%20RF_vocal.webm\n",
            " Segmenting into 5 2s clips\n",
            "  Clip 1 from 20221123070020_Fe-1%20RF_vocal.webm [loudness: -18 dB]\n",
            "  Clip 2 from 20221123070020_Fe-1%20RF_vocal.webm [loudness: -16 dB]\n",
            "  Clip 3 from 20221123070020_Fe-1%20RF_vocal.webm [loudness: -15 dB]\n",
            "  Clip 4 from 20221123070020_Fe-1%20RF_vocal.webm [loudness: -13 dB]\n",
            "  Clip 5 from 20221123070020_Fe-1%20RF_vocal.webm [loudness: -12 dB]\n",
            "  Clip not in cache, performing inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Embedding batch shape: (5, 512), data type: float32\n",
            "\n",
            "Loading file: 20220128110729_MCEE%20Fe_lungback.webm from audios/20220128110729_MCEE%20Fe_lungback.webm\n",
            "Error loading 20220128110729_MCEE%20Fe_lungback.webm: . Removing from files_map.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-83cc9b4ca661>:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n"
          ]
        }
      ],
      "source": [
        "# %%time\n",
        "# Audio display options\n",
        "SHOW_WAVEFORM = False\n",
        "SHOW_SPECTROGRAM = False\n",
        "SHOW_PLAYER = False\n",
        "SHOW_CLIPS = False\n",
        "\n",
        "# Clips of length CLIP_DURATION seconds are extracted from the audio file\n",
        "# using a sliding window. Adjecent clips are overlapped by CLIP_OVERLAP_PERCENT.\n",
        "CLIP_OVERLAP_PERCENT = 10\n",
        "\n",
        "# When True, if a clip extracted from the file is quieter than\n",
        "# the SILENCE_RMS_THRESHOLD_DB it is not sent to the HeAR model.\n",
        "CLIP_IGNORE_SILENT_CLIPS = True\n",
        "# Maximum average amplitude of a frame to be considered silence.\n",
        "SILENCE_RMS_THRESHOLD_DB = -50\n",
        "\n",
        "# Inicializar contadores globales\n",
        "total_files_processed = 0\n",
        "total_clips_seen = 0\n",
        "total_clips_kept = 0\n",
        "\n",
        "for file_key, file_url in files_map.items():\n",
        "  try:\n",
        "      full_path = os.path.join(\"audios\", file_key)\n",
        "      print(f\"\\nLoading file: {file_key} from {full_path}\")\n",
        "      audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
        "  except Exception as e:\n",
        "      print(f\"Error loading {file_key}: {e}. Removing from files_map.\")\n",
        "      files_map[file_key] = \"error\"\n",
        "      continue\n",
        "\n",
        "\n",
        "  # Display audio file (optional)\n",
        "  if SHOW_WAVEFORM:\n",
        "    plot_waveform(audio, sample_rate, title=file_key, color='blue')\n",
        "  if SHOW_SPECTROGRAM:\n",
        "    plot_spectrogram(audio, sample_rate, file_key,  n_fft=2*1024, hop_length=64, n_mels=256, cmap='Blues')\n",
        "  if SHOW_PLAYER:\n",
        "    display(Audio(data=audio, rate=sample_rate))\n",
        "\n",
        "  # This code segments an audio array into overlapping clips.\n",
        "  # It calculates the number of clips, iterates through them,\n",
        "  # and handles potential padding with zeros for the last clip if needed.\n",
        "  clip_batch = []\n",
        "  overlap_samples = int(CLIP_LENGTH * (CLIP_OVERLAP_PERCENT / 100))\n",
        "  step_size = CLIP_LENGTH - overlap_samples\n",
        "  num_clips = max(1, (len(audio) - overlap_samples) // step_size)\n",
        "  print(f\" Segmenting into {num_clips} {CLIP_DURATION}s clips\")\n",
        "\n",
        "  total_files_processed += 1\n",
        "  total_clips_seen += num_clips\n",
        "\n",
        "  for i in range(num_clips):\n",
        "    start_sample = i * step_size\n",
        "    end_sample = start_sample + CLIP_LENGTH\n",
        "    clip = audio[start_sample:end_sample]\n",
        "    # Pad clip with zeros if less than the required CLIP_LENGTH.\n",
        "    if end_sample > len(audio):\n",
        "        print(\"  Last clip: Padding with zeros.\")\n",
        "        clip = np.pad(clip, (0, CLIP_LENGTH - len(clip)), 'constant')\n",
        "    # Average Loudness of the clip(in dB)\n",
        "    power = np.mean(clip**2)\n",
        "    if power == 0:\n",
        "        rms_loudness = -np.inf\n",
        "    else:\n",
        "        rms_loudness = round(20 * np.log10(np.sqrt(power)))\n",
        "    # rms_loudness =  round(20 * np.log10(np.sqrt(np.mean(clip**2))))\n",
        "\n",
        "    # Display clip info (optional)\n",
        "    clip_str = f\"Clip {i+1} from {file_key} [loudness: {rms_loudness} dB]\"\n",
        "    print(f\"  {clip_str}\")\n",
        "    if SHOW_CLIPS:\n",
        "      if SHOW_WAVEFORM:\n",
        "        plot_waveform(clip, sample_rate, title=clip_str, figsize=(8, 3), color=cm.rainbow(i /num_clips))\n",
        "      if SHOW_PLAYER:\n",
        "        display(Audio(data=clip, rate=sample_rate))\n",
        "\n",
        "    # Skip if clip is too quiet\n",
        "    if CLIP_IGNORE_SILENT_CLIPS and rms_loudness < SILENCE_RMS_THRESHOLD_DB:\n",
        "      print(f\"  Clip {i+1} Skip...too quiet [loudness: {rms_loudness} dB]\")\n",
        "      continue\n",
        "\n",
        "    # Add clip to batch\n",
        "    clip_batch.append(clip)\n",
        "    total_clips_kept += 1\n",
        "\n",
        "\n",
        "  # Perform HeAR Batch inference to extract the associated clip embedding.\n",
        "  # Only run inference if embedding not already in file_embedding cache.\n",
        "  if len(clip_batch) == 0:\n",
        "    print(\"  No valid clips found after silence filtering. Skipping inference.\")\n",
        "    continue\n",
        "  clip_batch = np.asarray(clip_batch)\n",
        "  if file_key not in file_embeddings:\n",
        "    print(\"  Clip not in cache, performing inference...\")\n",
        "    embedding_batch = infer(x=clip_batch)['output_0'].numpy()\n",
        "    file_embeddings[file_key] = embedding_batch\n",
        "  else:\n",
        "    embedding_batch = file_embeddings[file_key]\n",
        "  print(f\"  Embedding batch shape: {embedding_batch.shape}, data type: {embedding_batch.dtype}\")\n",
        "\n",
        "# \ud83d\udd1a Mostrar resumen al final del proceso\n",
        "print(\"\\n RESUMEN FINAL:\")\n",
        "print(f\"Archivos procesados: {total_files_processed}\")\n",
        "print(f\"Clips generados (antes de filtrar): {total_clips_seen}\")\n",
        "print(f\"Clips \u00fatiles (post-filtrado): {total_clips_kept}\")\n",
        "print(f\"Clips descartados por silencio: {total_clips_seen - total_clips_kept}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# Par\u00e1metros\n",
        "SAMPLE_RATE = 16000\n",
        "CLIP_DURATION = 2\n",
        "CLIP_LENGTH = SAMPLE_RATE * CLIP_DURATION\n",
        "CLIP_OVERLAP_PERCENT = 10\n",
        "SILENCE_RMS_THRESHOLD_DB = -50\n",
        "\n",
        "# Inicializar contadores\n",
        "total_files_processed = 0\n",
        "total_clips_seen = 0\n",
        "total_clips_kept = 0\n",
        "\n",
        "# Reconstruir files_map desde los nombres ya procesados\n",
        "files_map = {fname: fname for fname in file_embeddings.keys()}\n",
        "\n",
        "# Procesar archivos\n",
        "for file_key, _ in files_map.items():\n",
        "    full_path = os.path.join(\"audios\", file_key)\n",
        "\n",
        "    try:\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "            audio, sample_rate = librosa.load(full_path, sr=SAMPLE_RATE, mono=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al cargar {file_key}: {e}\")\n",
        "        continue\n",
        "\n",
        "    total_files_processed += 1\n",
        "    overlap_samples = int(CLIP_LENGTH * (CLIP_OVERLAP_PERCENT / 100))\n",
        "    step_size = CLIP_LENGTH - overlap_samples\n",
        "    num_clips = max(1, (len(audio) - overlap_samples) // step_size)\n",
        "    total_clips_seen += num_clips\n",
        "\n",
        "    for i in range(num_clips):\n",
        "        start_sample = i * step_size\n",
        "        end_sample = start_sample + CLIP_LENGTH\n",
        "        clip = audio[start_sample:end_sample]\n",
        "\n",
        "        if end_sample > len(audio):\n",
        "            clip = np.pad(clip, (0, CLIP_LENGTH - len(clip)), 'constant')\n",
        "\n",
        "        power = np.mean(clip**2)\n",
        "        rms_loudness = -np.inf if power == 0 else round(20 * np.log10(np.sqrt(power)))\n",
        "\n",
        "        if rms_loudness >= SILENCE_RMS_THRESHOLD_DB:\n",
        "            total_clips_kept += 1\n",
        "\n",
        "# Show summary\n",
        "print(\"\\n\ud83d\udcca Summary:\")\n",
        "print(f\"Processed files: {total_files_processed}\")\n",
        "print(f\"Generated clips (before filtering): {total_clips_seen}\")\n",
        "print(f\"Useful clips (post-filtering): {total_clips_kept}\")\n",
        "print(f\"Discarded clips (silence threshold): {total_clips_seen - total_clips_kept}\")\n",
        "\n",
        "# Store variables\n",
        "resumen_stats = {\n",
        "    \"total_files_processed\": total_files_processed,\n",
        "    \"total_clips_seen\": total_clips_seen,\n",
        "    \"total_clips_kept\": total_clips_kept,\n",
        "    \"clips_descartados\": total_clips_seen - total_clips_kept\n",
        "}"
      ],
      "metadata": {
        "id": "_M9cYzgmRKiC",
        "outputId": "16af9a2d-23e4-4712-c906-967a12225ddc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udcca Summary:\n",
            "Processed files: 1055\n",
            "Generated clips (before filtering): 7077\n",
            "Useful clips (post-filtering): 6366\n",
            "Discarded clips (silence threshold): 711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backups\n",
        "Para cargar nuevamente el cuaderno sin la necesidad de subir la informacion que ya se proceso (audios, variables)\n"
      ],
      "metadata": {
        "id": "XI-kumJDQdwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from google.colab import files\n",
        "\n",
        "# Agrupar todo lo importante para no repetir trabajo\n",
        "backup_data = {\n",
        "    \"file_embeddings\": file_embeddings,\n",
        "    \"resumen_stats\": resumen_stats\n",
        "}\n",
        "\n",
        "# Guardar a disco\n",
        "backup_filename = \"../shared_data/embeddings/audium.pkl\"\n",
        "with open(backup_filename, \"wb\") as f:\n",
        "    pickle.dump(backup_data, f)\n",
        "\n",
        "# Descargar archivo a tu m\u00e1quina (opcional)\n",
        "files.download(backup_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vpGNhsSDhToc",
        "outputId": "18cea26d-872c-4ee6-a737-ab338e760d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f97b2697-a422-45d2-803b-88631a911685\", \"audium.pkl\", 13120222)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load embeddings"
      ],
      "metadata": {
        "id": "bzOXoT_uRExT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resume the notebook without doing the embeddings again."
      ],
      "metadata": {
        "id": "-T-34-lZWk1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load when you open collab again\n",
        "import pickle\n",
        "\n",
        "# Load embeddings from file\n",
        "with open(\"audium_embeddings.pkl\", \"rb\") as f:\n",
        "    backup_data = pickle.load(f)\n",
        "\n",
        "# Extraer las variables desde el diccionario\n",
        "file_embeddings = backup_data\n",
        "files_map = file_embeddings\n",
        "\n",
        "print(f\"{len(file_embeddings)} archivos ya procesados y cargados.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IcZV_pvi-uU",
        "outputId": "168acbb1-91ee-4f39-9259-7cb0235c9ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1055 archivos ya procesados y cargados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXu7LdZIudy9",
        "outputId": "be437a0a-793f-47a3-c62d-9a89505575e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train embeddings have shape: (5070, 512), data type: float32\n",
            "Train Embeddings are from 844 unique files: {'20230418103903_CA%20fe-1_lungfront.webm', '20220120110747_ARSC_vocal.webm', '20220118130259_DMCS_lungfront.webm', '20220117150958_EGX_vocal.webm', '20220802080705_MHC%20fe-2_lungfront.webm', '20220305090804_APC%20fe%205-1_lungfront.webm', '20220119112335_SMAC_lungfront.webm', '20220124134054_GMK%20fe_vocal.webm', '20220630095905_ARB%20fe-1_lungback.webm', '20220319074246_RMC%20fe%2019-1_lungback.webm', '20220304050722_LRM%204-1_lungfront.webm', '20220121125602_HRMM_vocal.webm', '20220124102547_ARJA%20fe_lungfront.webm', '20220304062221_DSC%20fe%204-1_vocal.webm', '20220118111208_XAW_lungback.webm', '20220219084905_MGCH%2030-1_lungback.webm', '20221207095803_Fe-1%20FW_lungback.webm', '20220212062243_Ach%20fe-14-1_vocal.webm', '20220219085022_MGCH%2030-2_vocal.webm', '20220119141214_MAAR_vocal.webm', '20220114152135_VRP_lungfront.webm', '20220302092611_SLlJ%20fe%202-1_lungback.webm', '20211207054053_ACW-%20D2_vocal.webm', '20220305073453_FFP%20fe%205-1_lungfront.webm', '20220125112513_DAKP%20es_lungback.webm', '20220718073538_RM%20fe-1_lungback.webm', '20220128104455_AASE_lungback.webm', '20220604055709_JFC%20fe-2_vocal.webm', '20230419092959_AA%20fe-1_lungfront.webm', '20220319094332_MME%20fe%2019-1_vocal.webm', '20220708093145_ARB%20fe-4_vocal.webm', '20220127130655_RPY%20Es_vocal.webm', '20220804101609_MHC%20fe-3_vocal.webm', '20220303082548_AAC%20fe%203-1_lungfront.webm', '20230418103221_Av%20fe-1_lungback.webm', '20220503163043_Jonathan%202_vocal.webm', '20230420101527_ER%20fe-1_lungback.webm', '20230421114407_JF%20fe-1_vocal.webm', '20220516153654_Jasr2-16-05_vocal.webm', '20230419120707_ET%20fe-1_lungfront.webm', '20220516152223_Jayg2-16-5_vocal.webm', '20220128124525_SCSHR%20fE_lungback.webm', '20211209064253_JMT-P2_lungfront.webm', '20220302091211_APM%20fe%202-1_lungback.webm', '20220120153840_GCNF_lungfront.webm', '20220526123751_SE%20fe-1_lungback.webm', '20211202103930_Mcp-02-11-D3_lungback.webm', '20220304052223_CRD%20fe%204-1_lungfront.webm', '20220303081659_RRA%20fe%203-1_vocal.webm', '20211202103821_Mcp-02-12-D2_lungfront.webm', '20220125160128_MMLJ%20fe_lungback.webm', '20230419104420_RP%20fe-1_vocal.webm', '20220515223642_Jasr-16-5_lungback.webm', '20230419094918_MF%20fe-1_lungback.webm', '20221217091134_Fe-1%20AR_lungfront.webm', '20220506051857_Abemn%206-5-22_lungfront.webm', '20220516152711_Lsma1-16-5_lungback.webm', '20220713083652_LML%20fe-1_lungback.webm', '20220212082523_Lmm24-2_lungback.webm', '20220305073453_FFP%20fe%205-1_vocal.webm', '20230424140045_GA%20fe-1_lungback.webm', '20220516150924_Mfyc1-16-5_lungfront.webm', '20230419124122_LG%20fe-1_vocal.webm', '20220516143936_Darz1-16-5_vocal.webm', '20220212071822_Gbc%2019-2_lungfront.webm', '20220127130655_RPY%20Es_lungback.webm', '20220516144141_Darz2-16-2_lungfront.webm', '20220118151408_TZP_lungfront.webm', '20220526123937_SE%20fe-2_vocal.webm', '20220219081530_TRC%2029-2_lungfront.webm', '20221123054048_Fe-1%20GCh_vocal.webm', '20220107110951_SMAJ_lungback.webm', '20220319074246_RMC%20fe%2019-1_vocal.webm', '20220302054305_DAT%20fe%202-2_vocal.webm', '20220111111424_CLD_lungfront.webm', '20230421091258_MH%20fe-1_lungfront.webm', '20220812142325_ANR%20fe-1_lungback.webm', '20220128110857_MCFF%20FE_vocal.webm', '20220516150119_Wgyv1-16-5_vocal.webm', '20220108174158_MFRJ_lungfront.webm', '20220708085650_FHA%20fe-2_lungback.webm', '20220114113551_HRP_vocal.webm', '20230421091258_MH%20fe-1_vocal.webm', '20220124160633_RALL%20fe_lungback.webm', '20220305091432_DYC%20fe%205-1_lungback.webm', '20230420111142_FT%20fe-1_vocal.webm', '20220630095905_ARB%20fe-1_vocal.webm', '20220810095753_JLP%20fe-1_vocal.webm', '20220302053604_MLQ%20fe%202-2_lungfront.webm', '20220810095537_DLP%20fe-1_lungback.webm', '20220625095002_DM%20fe-1_vocal.webm', '20220127103801_CHLA%20es_vocal.webm', '20220117155838_ABPC_vocal.webm', '20220212081824_Gnf%2023-2_vocal.webm', '20220122140243_MRGM%20fe_lungback.webm', '20220302093004_WOM%20fe%202-2_vocal.webm', '20220721062840_ICR%20fe-1_lungback.webm', '20220125112846_DAKP%20fe_lungfront.webm', '20220516110622_Ahj-16-5_vocal.webm', '20230419103918_DA%20fe-1_lungback.webm', '20220124124846_AOLR%20fe_vocal.webm', '20220125112513_DAKP%20es_vocal.webm', '20220107152508_RCET_lungfront.webm', '20220107110348_BTMA_vocal.webm', '20220708103953_FDV%20fe-1_vocal.webm', '20230424135234_LM%20fe-1_vocal.webm', '20211202104033_Mcp-02-12-D3_vocal.webm', '20220506072041_Vmpr%206_5_22_lungback.webm', '20220604085705_CAD%20fe-2_lungback.webm', '20220504102754_Seyv%204-5_lungfront.webm', '20220303091025_JAR%20fe%203-1_lungfront.webm', '20221212104450_Fe-1%20KP_lungback.webm', '20220122154102_MSVC%20fe_lungback.webm', '20220107155508_GHR_vocal.webm', '20220117164316_LTA_vocal.webm', '20220215074545_Zmg%2025-2_vocal.webm', '20230424111937_JH%20fe-1_lungback.webm', '20220630100058_ARB%20fe-2_vocal.webm', '20220305073957_MHC%20fe%205-1_vocal.webm', '20220302090631_WOM%20fe%202-1_vocal.webm', '20220120104224_CRMT_vocal.webm', '20220105153039_GUF%20SIN_vocal.webm', '20230418103903_CA%20fe-1_lungback.webm', '20220126150050_AOLR%20Fe_vocal.webm', '20220127121029_GADA%20fe_lungback.webm', '20221220075710_Fe-2%20PB_lungback.webm', '20220122140243_MRGM%20fe_vocal.webm', '20220107155508_GHR_lungback.webm', '20230424111328_RB%20fe-1_vocal.webm', '20220126113139_BMY%20es_lungback.webm', '20220302091211_APM%20fe%202-1_vocal.webm', '20220302060619_PRC%20fe%202-2_lungfront.webm', '20220211122728_OCF%2013_lungback.webm', '20220804101609_MHC%20fe-3_lungfront.webm', '20220709050025_BUM%20fe-1_lungfront.webm', '20221223095536_Fe-1%20GB_lungback.webm', '20220723124659_AVB%20fe-1_lungback.webm', '20220107144605_VYFS_lungfront.webm', '20230419120707_ET%20fe-1_vocal.webm', '20230424111937_JH%20fe-1_lungfront.webm', '20220120131215_DJZA_vocal.webm', '20220516144141_Darz2-16-2_lungback.webm', '20220212081824_Gnf%2023-2_lungback.webm', '20220704112246_JGA%20fe-1_lungback.webm', '20220219081410_TRC%2029-1_vocal.webm', '20220630095905_ARB%20fe-1_lungfront.webm', '20220120121711_FFP_vocal.webm', '20221207131017_Fe-1%20MA_lungback.webm', '20220124151143_JAYG%20fe_vocal.webm', '20230420094226_GCH%20fe-1_lungfront.webm', '20220302081528_EGDC%20fe%202-1_vocal.webm', '20220625095154_DM%20fe-2_lungback.webm', '20220117114755_LTYM_vocal.webm', '20230419085806_JO%20fe-1_vocal.webm', '20220212080246_Afc%2021-2_vocal.webm', '20220212071122_Tvs%2018-2_vocal.webm', '20220119134648_MILS_vocal.webm', '20220718070922_MGC%20fe-1_lungfront.webm', '20220212081610_Gnf%2023-1_vocal.webm', '20220127113235_NRJJ%20Fe_lungback.webm', '20220302054305_DAT%20fe%202-2_lungback.webm', '20220302053604_MLQ%20fe%202-2_lungback.webm', '20221118053800_Fe-1%20SD_lungfront.webm', '20230418114816_TE%20fe-1_lungback.webm', '20220303081248_LRR%20fe%203-1_lungback.webm', '20230424133743_JA%20fe-1_vocal.webm', '20220802083643_JQZ%20fe-2_lungback.webm', '20220129133119_DAKP%20fE_lungfront.webm', '20220129133119_DAKP%20fE_vocal.webm', '20220105153039_GUF%20SIN_lungback.webm', '20220516151434_Yyrg1-16-5_lungback.webm', '20220713083652_LML%20fe-1_vocal.webm', '20221123090606_Fe-1%20AM_vocal.webm', '20220122140243_MRGM%20fe_lungfront.webm', '20220302081802_EPV%20fe%202-1_vocal.webm', '20220516151615_Yyrg2-16-5_vocal.webm', '20230419114613_AR%20fe-1_vocal.webm', '20211207055653_ADW-P4_lungback.webm', '20220105162835_CGT%20con_vocal.webm', '20230418115210_JS%20fe-1_lungback.webm', '20220305085654_RGM%20fe%205-1_lungfront.webm', '20230419125101_JG%20fe-1_vocal.webm', '20221118094140_Fe-1%20JG_vocal.webm', '20220304062221_DSC%20fe%204-1_lungback.webm', '20221220075454_Fe-1%20PB_vocal.webm', '20220105152805_GUF%20con_vocal.webm', '20220128124525_SCSHR%20fE_vocal.webm', '20220212071632_Gbc%2019-1_lungback.webm', '20220126170624_GMK%20Fe_lungback.webm', '20221223095536_Fe-1%20GB_lungfront.webm', '20220802083643_JQZ%20fe-2_vocal.webm', '20220704112603_JGA.%20Fe-2_lungfront.webm', '20220117141014_MACL_lungfront.webm', '20230420111142_FT%20fe-1_lungback.webm', '20220302054046_DAT%20fe%202-1_lungfront.webm', '20221118111510_Fe-1%20EP_vocal.webm', '20220305075107_MRC%20fe%205-1_vocal.webm', '20220723121728_JMT%20fe-1_vocal.webm', '20220224135946_ARD%2033-2_lungfront.webm', '20211209063621_JMT-D3_lungfront.webm', '20220119112335_SMAC_lungback.webm', '20220709073607_RCM%20fe-2_lungback.webm', '20221123083226_Fe-2%20VR_vocal.webm', '20220219084119_SYV%2030-2_vocal.webm', '20220516151615_Yyrg2-16-5_lungfront.webm', '20220115130617_RVPP_vocal.webm', '20221217091134_Fe-1%20AR_vocal.webm', '20220108112150_HCAP_lungback.webm', '20230424135234_LM%20fe-1_lungfront.webm', '20221220075710_Fe-2%20PB_lungfront.webm', '20220212070508_Jmt%2017-1_vocal.webm', '20220302064348_RMC%20fe%202-1_vocal.webm', '20220105153039_GUF%20SIN_lungfront.webm', '20211209063439_JMT-D2_lungback.webm', '20221213114920_Fe-2%20BU_lungback.webm', '20220125122834_RPY%20es_vocal.webm', '20220304052223_CRD%20fe%204-1_lungback.webm', '20220129124418_GADA%20fE_lungfront.webm', '20220516143936_Darz1-16-5_lungfront.webm', '20220118111208_XAW_vocal.webm', '20230420101527_ER%20fe-1_lungfront.webm', '20220302081802_EPV%20fe%202-1_lungback.webm', '20220212063501_Acb%2015-1_vocal.webm', '20220506051857_Abemn%206-5-22_lungback.webm', '20230419085806_JO%20fe-1_lungfront.webm', '20230421114407_JF%20fe-1_lungback.webm', '20220128104455_AASE_vocal.webm', '20220212080851_Mmb%2022.1_vocal.webm', '20220212063005_Ach%2014-2_vocal.webm', '20220516152711_Lsma1-16-5_lungfront.webm', '20220727082823_FSM%20fe-1_lungfront.webm', '20220804111858_TRC%20fe-2_lungfront.webm', '20220212064149_Rgh%2016-1_vocal.webm', '20220108164635_OQFR_lungfront.webm', '20220302091211_APM%20fe%202-1_lungfront.webm', '20220115130617_RVPP_lungfront.webm', '20220212080851_Mmb%2022.1_lungback.webm', '20220305085654_RGM%20fe%205-1_vocal.webm', '20220302064618_RMC%20fe%202-2_lungfront.webm', '20220319074246_RMC%20fe%2019-1_lungfront.webm', '20230424135234_LM%20fe-1_lungback.webm', '20220212081146_Mmb%2022-2_vocal.webm', '20220708103953_FDV%20fe-1_lungback.webm', '20220127120739_GADA%20es_vocal.webm', '20220304062221_DSC%20fe%204-1_lungfront.webm', '20220125140657_NRJJ%20fe_vocal.webm', '20220122110655_NFGC%20fe_vocal.webm', '20220111111424_CLD_vocal.webm', '20220122154102_MSVC%20fe_vocal.webm', '20230418104709_JC%20fe-1_lungfront.webm', '20220115122413_RRB_lungback.webm', '20220215075914_SYV%2027-2_lungfront.webm', '20221213121136_Fe-1%20GM_vocal.webm', '20220302060619_PRC%20fe%202-2_vocal.webm', '20220120153840_GCNF_lungback.webm', '20220212082327_Mmm%2024-1_vocal.webm', '20220715092715_LML%20fe-2_lungfront.webm', '20220516144505_Sdpa1-16-5_vocal.webm', '20220709054715_CNE%20fe-1_lungfront.webm', '20220305074538_KMI%20fe%205-1_lungback.webm', '20220114114719_HIRP_lungfront.webm', '20220810095753_JLP%20fe-1_lungback.webm', '20220120104224_CRMT_lungfront.webm', '20220504165658_Avrd_vocal.webm', '20220304082033_MQR%20fe%204-1_vocal.webm', '20220127103801_CHLA%20es_lungback.webm', '20220121121412_EOTS_lungfront.webm', '20220304053013_LRM%20fe%204-1_vocal.webm', '20220115154844_KMI_vocal.webm', '20220303050525_LYC%20fe%203-1_lungback.webm', '20220718073538_RM%20fe-1_lungfront.webm', '20220120104224_CRMT_lungback.webm', '20220604085459_CAD%20fe-1_lungfront.webm', '20220713092907_JFC%20fe-1_vocal.webm', '20220718070922_MGC%20fe-1_lungback.webm', '20220715104234_CBP%20fe-2_vocal.webm', '20220708104228_FDV%20fe-2_lungfront.webm', '20220516143936_Darz1-16-5_lungback.webm', '20220516150340_Wgyv2-16-5_lungback.webm', '20220302064348_RMC%20fe%202-1_lungback.webm', '20230421091258_MH%20fe-1_lungback.webm', '20220125122955_RPY%20fe_lungfront.webm', '20220715092715_LML%20fe-2_lungback.webm', '20220516144655_Sdpa2-16-5_vocal.webm', '20211209064253_JMT-P2_vocal.webm', '20220129124418_GADA%20fE_lungback.webm', '20221213121136_Fe-1%20GM_lungfront.webm', '20230424133743_JA%20fe-1_lungfront.webm', '20230419114613_AR%20fe-1_lungfront.webm', '20220516144505_Sdpa1-16-5_lungfront.webm', '20220504165337_Eta_lungback.webm', '20220708085650_FHA%20fe-2_vocal.webm', '20220212080246_Afc%2021-2_lungback.webm', '20211209063439_JMT-D2_vocal.webm', '20211207054053_ACW-%20D2_lungfront.webm', '20211207054901_ACW-P1_lungback.webm', '20211207054901_ACW-P1_vocal.webm', '20220319054519_XLS%20fe%2019-1_lungback.webm', '20211209064407_JMT-P3_vocal.webm', '20220715101331_RFC%20fe-3_vocal.webm', '20220303091025_JAR%20fe%203-1_lungback.webm', '20220219081530_TRC%2029-2_lungback.webm', '20230419104420_RP%20fe-1_lungfront.webm', '20220727094501_CCG%20fe-1_vocal.webm', '20220516153654_Jasr2-16-05_lungfront.webm', '20220812142325_ANR%20fe-1_vocal.webm', '20220504165035_Aves%204-5_vocal.webm', '20220125122834_RPY%20es_lungback.webm', '20220115134035_CRAC_vocal.webm', '20220708085650_FHA%20fe-2_lungfront.webm', '20220304051252_PBZ%20fe%204-1_lungback.webm', '20220122114315_GPOE%20fe_lungback.webm', '20220302064618_RMC%20fe%202-2_lungback.webm', '20220319053836_MMA%20fe%2019-1_vocal.webm', '20230418114816_TE%20fe-1_lungfront.webm', '20230421100451_DF%20fe-1_lungfront.webm', '20220114122836_MMGC_lungfront.webm', '20220304051546_GYZ%20fe%204-1_vocal.webm', '20220128111148_MTSK%20Fe_vocal.webm', '20220721062840_ICR%20fe-1_lungfront.webm', '20220604085705_CAD%20fe-2_vocal.webm', '20211207054333_ACW-D3_lungfront.webm', '20220525090247_Pt_lungback.webm', '20220319055023_DDCS%20fe%2019-1_lungback.webm', '20220119130925_MCNT_lungback.webm', '20211207055826_ADW-P5_lungback.webm', '20220802104203_TEO%20fe-1_lungfront.webm', '20230418102811_LR%20fe-1_lungback.webm', '20220421124920_LRR%2021-1_lungback.webm', '20220516151109_Mfyc2-16-5_lungback.webm', '20220708104228_FDV%20fe-2_lungback.webm', '20220122153938_MSVC%20es_lungback.webm', '20220516110622_Ahj-16-5_lungback.webm', '20220709073607_RCM%20fe-2_lungfront.webm', '20220302092611_SLlJ%20fe%202-1_vocal.webm', '20220303082111_JFC%20fe%203-1_lungback.webm', '20221207110303_Fe-1%20YO_lungfront.webm', '20220302060345_PRC%20fe%202-1_vocal.webm', '20220302063901_JGA%20fe%202-1_lungback.webm', '20221123051040_Fe-1%20MM_lungback.webm', '20230419125101_JG%20fe-1_lungback.webm', '20220119165019_SKMT_lungfront.webm', '20220723121728_JMT%20fe-1_lungfront.webm', '20220504165658_Avrd_lungback.webm', '20221118083614_Fe-1%20VR_lungfront.webm', '20220119130925_MCNT_vocal.webm', '20211209063621_JMT-D3_vocal.webm', '20211209064253_JMT-P2_lungback.webm', '20220305073453_FFP%20fe%205-1_lungback.webm', '20220304053013_LRM%20fe%204-1_lungback.webm', '20220124160633_RALL%20fe_lungfront.webm', '20220212065239_ATC%2017-2_lungback.webm', '20220304062932_ACR%20fe%204-1_vocal.webm', '20220516144655_Sdpa2-16-5_lungfront.webm', '20220117150958_EGX_lungfront.webm', '20230424140556_GB%20fe-1_vocal.webm', '20220125160128_MMLJ%20fe_vocal.webm', '20220303082932_ACH%20fe%203-1_lungfront.webm', '20230419115012_LA%20fe-1_vocal.webm', '20220212071122_Tvs%2018-2_lungfront.webm', '20220212063005_Ach%2014-2_lungfront.webm', '20220126161918_ABM%20Fe_vocal.webm', '20220118121138_LRLP_lungfront.webm', '20220215075217_TRC%2026-2_vocal.webm', '20220302082442_MOP%20fe%202-1_lungfront.webm', '20220127121029_GADA%20fe_vocal.webm', '20220219084905_MGCH%2030-1_vocal.webm', '20211207055653_ADW-P4_vocal.webm', '20230421100451_DF%20fe-1_lungback.webm', '20211209064137_JMT-P_vocal.webm', '20220119134648_MILS_lungback.webm', '20220516144655_Sdpa2-16-5_lungback.webm', '20220303081659_RRA%20fe%203-1_lungback.webm', '20221123054048_Fe-1%20GCh_lungfront.webm', '20230420074758_ACH%20fe-1_vocal.webm', '20220120162822_OEGP_vocal.webm', '20220122114315_GPOE%20fe_lungfront.webm', '20220304081704_MHR%20fe%204-1_lungback.webm', '20211202103930_Mcp-02-11-D3_lungfront.webm', '20220127143409_MMLJ%20Es_vocal.webm', '20220305090043_SFT%20fe%205-1_lungback.webm', '20220516145612_Leco1-16-5_lungback.webm', '20220114163111_JASR_vocal.webm', '20220302090942_ANP%20fe%202-1_lungfront.webm', '20220303081248_LRR%20fe%203-1_vocal.webm', '20220713083652_LML%20fe-1_lungfront.webm', '20220302090338_RIT%20fe%202-1_lungback.webm', '20220304082033_MQR%20fe%204-1_lungback.webm', '20220319073113_MLQ%20fe%2019-1_lungback.webm', '20220122114153_GPOE%20es_lungfront.webm', '20220129132954_DAKP%20FE_lungback.webm', '20220516153445_Jasr1-1605_lungfront.webm', '20220212072243_Lml%2020-1_lungback.webm', '20211209064522_JMT-P4_lungfront.webm', '20220516153003_Lsma2-16-5_lungfront.webm', '20220516151434_Yyrg1-16-5_vocal.webm', '20220105133843_YH%20sin_lungfront.webm', '20230419092959_AA%20fe-1_lungback.webm', '20220219085022_MGCH%2030-2_lungfront.webm', '20220122114153_GPOE%20es_vocal.webm', '20220105133643_YE_lungfront.webm', '20221119112228_Fe-1%20GN_vocal.webm', '20211207054534_ACD-D4_vocal.webm', '20211207055444_ACW-P3_lungback.webm', '20220107152508_RCET_vocal.webm', '20220319073411_DAT%20fe%2019-1_vocal.webm', '20220304062932_ACR%20fe%204-1_lungfront.webm', '20230419130616_MO%20fe-1_lungfront.webm', '20230420101527_ER%20fe-1_vocal.webm', '20220715101331_RFC%20fe-3_lungback.webm', '20220128124349_SCSHR%20Fe_vocal.webm', '20220515223642_Jasr-16-5_lungfront.webm', '20220709054937_CNE%20fe-2_vocal.webm', '20230421090611_LS%20fe-1_lungback.webm', '20220129141239_SMALM%20FE_vocal.webm', '20220124160502_RALL%20es_lungback.webm', '20220127120739_GADA%20es_lungfront.webm', '20220304062932_ACR%20fe%204-1_lungback.webm', '20220304065400_NAA%20fe%204-1_lungfront.webm', '20220128111313_MCFF%20fE_vocal.webm', '20211207054333_ACW-D3_vocal.webm', '20220723121728_JMT%20fe-1_lungback.webm', '20220709073837_RCM%20fe-3_lungback.webm', '20220802120809_TRC%20fe-1_lungback.webm', '20220526123937_SE%20fe-2_lungback.webm', '20220804101609_MHC%20fe-3_lungback.webm', '20220302081528_EGDC%20fe%202-1_lungfront.webm', '20221123121132_Fe-1%20RC_lungback.webm', '20220219085022_MGCH%2030-2_lungback.webm', '20230421090956_AH%20fe-1_vocal.webm', '20220302081247_TZP%20fe%202-2_vocal.webm', '20211207054333_ACW-D3_lungback.webm', '20220319073411_DAT%20fe%2019-1_lungfront.webm', '20220107163554_PMA_vocal.webm', '20220127113235_NRJJ%20Fe_vocal.webm', '20220304050722_LRM%204-1_vocal.webm', '20221118094140_Fe-1%20JG_lungback.webm', '20220105124255_PTR_lungback.webm', '20220516152223_Jayg2-16-5_lungfront.webm', '20220421124920_LRR%2021-1_lungfront.webm', '20220125162946_MCEE%20fe_vocal.webm', '20221123090606_Fe-1%20AM_lungfront.webm', '20220319073113_MLQ%20fe%2019-1_lungfront.webm', '20220304050722_LRM%204-1_lungback.webm', '20220211122728_OCF%2013_vocal.webm', '20220305074538_KMI%20fe%205-1_vocal.webm', '20220119165019_SKMT_vocal.webm', '20220304052543_YH%20fe%204-1_vocal.webm', '20230420093811_GY%20fe-1_lungfront.webm', '20220114142427_AJTN_vocal.webm', '20220105124255_PTR_vocal.webm', '20220215080924_MME%2028-1_lungback.webm', '20220215074418_Zmg%2025-1_vocal.webm', '20211209063858_JMT-D4_lungfront.webm', '20230418104709_JC%20fe-1_lungback.webm', '20220516153003_Lsma2-16-5_lungback.webm', '20230419085806_JO%20fe-1_lungback.webm', '20220302063901_JGA%20fe%202-1_vocal.webm', '20220304052543_YH%20fe%204-1_lungback.webm', '20220727094501_CCG%20fe-1_lungback.webm', '20221119112228_Fe-1%20GN_lungback.webm', '20230424111328_RB%20fe-1_lungback.webm', '20220713092907_JFC%20fe-1_lungback.webm', '20221123083226_Fe-2%20VR_lungfront.webm', '20220124160502_RALL%20es_vocal.webm', '20220802083643_JQZ%20fe-2_lungfront.webm', '20220304052223_CRD%20fe%204-1_vocal.webm', '20220516144505_Sdpa1-16-5_lungback.webm', '20220127143409_MMLJ%20Es_lungback.webm', '20220128135337_PCSN%20fE_vocal.webm', '20220212070948_Tvs%2018-1_lungback.webm', '20220127153448_RAJL%20es_vocal.webm', '20220516150340_Wgyv2-16-5_vocal.webm', '20211202103821_Mcp-02-12-D2_vocal.webm', '20220302092223_CCP%20fe%202-1_vocal.webm', '20230420073507_NA%20fe-1_lungfront.webm', '20220304082514_SAC%20fe%204-1_lungfront.webm', '20230421113844_AP%20fe-1_vocal.webm', '20220503163043_Jonathan%202_lungfront.webm', '20220212081824_Gnf%2023-2_lungfront.webm', '20220304083114_AMQ%20fe%204-1_vocal.webm', '20220810095753_JLP%20fe-1_lungfront.webm', '20211209064522_JMT-P4_lungback.webm', '20220119130925_MCNT_lungfront.webm', '20220127143555_MMLJ%20Fe_lungback.webm', '20220630100058_ARB%20fe-2_lungfront.webm', '20220211114254_OCF%20fe%2012-1_lungback.webm', '20220128123854_CGJJ%20Fe_lungfront.webm', '20220302092223_CCP%20fe%202-1_lungfront.webm', '20211207054733_ADW-D5_vocal.webm', '20211202103721_Mcp-02-12-D1_vocal.webm', '20220128110857_MCFF%20FE_lungback.webm', '20220120162822_OEGP_lungfront.webm', '20220319061032_ECO%20fe%2019-1_lungback.webm', '20220526123751_SE%20fe-1_vocal.webm', '20220108112150_HCAP_vocal.webm', '20220124102435_ARJA%20es_vocal.webm', '20220129141239_SMALM%20FE_lungback.webm', '20230424134952_LY%20fe-1_lungfront.webm', '20220708085349_FHA%20fe-1_vocal.webm', '20230421090611_LS%20fe-1_vocal.webm', '20220119120850_DARZ_lungback.webm', '20220516151615_Yyrg2-16-5_lungback.webm', '20220319053836_MMA%20fe%2019-1_lungback.webm', '20230418103221_Av%20fe-1_vocal.webm', '20220215075914_SYV%2027-2_vocal.webm', '20211207055653_ADW-P4_lungfront.webm', '20220304065400_NAA%20fe%204-1_vocal.webm', '20220503092428_Jonathan_vocal.webm', '20211209063216_JMT-D_lungfront.webm', '20220302092223_CCP%20fe%202-1_lungback.webm', '20220516151109_Mfyc2-16-5_lungfront.webm', '20230419103918_DA%20fe-1_lungfront.webm', '20221123070020_Fe-1%20RF_lungfront.webm', '20230418102811_LR%20fe-1_vocal.webm', '20220212065052_ATC%2017-1_lungback.webm', '20220122140109_MRGM%20es_lungback.webm', '20220212080005_Afc%2021-1_lungback.webm', '20220305085654_RGM%20fe%205-1_lungback.webm', '20220305090421_LCC%20fe%205-1_lungback.webm', '20221207110303_Fe-1%20YO_vocal.webm', '20220129132954_DAKP%20FE_lungfront.webm', '20220709073837_RCM%20fe-3_vocal.webm', '20211209064026_JMT-D5_vocal.webm', '20221119112228_Fe-1%20GN_lungfront.webm', '20211209063858_JMT-D4_lungback.webm', '20220708103953_FDV%20fe-1_lungfront.webm', '20220715092715_LML%20fe-2_vocal.webm', '20220812142325_ANR%20fe-1_lungfront.webm', '20220304051546_GYZ%20fe%204-1_lungfront.webm', '20220121121412_EOTS_vocal.webm', '20220704112603_JGA.%20Fe-2_vocal.webm', '20220212072422_Lml%2020-2_vocal.webm', '20220305091432_DYC%20fe%205-1_lungfront.webm', '20220118121138_LRLP_vocal.webm', '20220516152059_Jayg1-16-5_vocal.webm', '20221118083614_Fe-1%20VR_vocal.webm', '20220212072243_Lml%2020-1_vocal.webm', '20220129132954_DAKP%20FE_vocal.webm', '20220708092832_ARB%20fe-3_vocal.webm', '20220115154844_KMI_lungback.webm', '20211207054534_ACD-D4_lungfront.webm', '20220125155955_MMLJ%20es_lungfront.webm', '20220120131215_DJZA_lungback.webm', '20220319073711_PRC%20fe%2019-1_lungback.webm', '20220120121711_FFP_lungback.webm', '20220125122955_RPY%20fe_vocal.webm', '20220709050338_BUM%20fe-2_lungback.webm', '20220303050525_LYC%20fe%203-1_vocal.webm', '20221207095803_Fe-1%20FW_lungfront.webm', '20221207095803_Fe-1%20FW_vocal.webm', '20220804111858_TRC%20fe-2_vocal.webm', '20220604055709_JFC%20fe-2_lungback.webm', '20220118111208_XAW_lungfront.webm', '20211216131859_JSR-scp_lungback.webm', '20230419124433_LG%20fe-2_vocal.webm', '20220526123751_SE%20fe-1_lungfront.webm', '20220302090942_ANP%20fe%202-1_vocal.webm', '20211209064026_JMT-D5_lungback.webm', '20220107144605_VYFS_lungback.webm', '20220303091025_JAR%20fe%203-1_vocal.webm', '20220219083953_SYV%2030-1_lungfront.webm', '20220604085459_CAD%20fe-1_lungback.webm', '20220708093145_ARB%20fe-4_lungfront.webm', '20220516150340_Wgyv2-16-5_lungfront.webm', '20220305073957_MHC%20fe%205-1_lungback.webm', '20220303081659_RRA%20fe%203-1_lungfront.webm', '20220302063901_JGA%20fe%202-1_lungfront.webm', '20220516145759_Leco2-16-5_vocal.webm', '20220504165337_Eta_lungfront.webm', '20220802080705_MHC%20fe-2_vocal.webm', '20220127113235_NRJJ%20Fe_lungfront.webm', '20211209064407_JMT-P3_lungback.webm', '20220126170624_GMK%20Fe_lungfront.webm', '20220304051546_GYZ%20fe%204-1_lungback.webm', '20221213114920_Fe-2%20BU_vocal.webm', '20211216131725_NSR-CD_vocal.webm', '20220304052032_CRD_lungfront.webm', '20211216131725_NSR-CD_lungback.webm', '20220122154102_MSVC%20fe_lungfront.webm', '20220115134035_CRAC_lungfront.webm', '20220212082523_Lmm24-2_vocal.webm', '20220319095643_MAR%20fe%2019-1_vocal.webm', '20220219083953_SYV%2030-1_vocal.webm', '20230421090611_LS%20fe-1_lungfront.webm', '20211202103721_Mcp-02-12-D1_lungfront.webm', '20220119161535_SNPC_vocal.webm', '20220105152805_GUF%20con_lungfront.webm', '20230419103918_DA%20fe-1_vocal.webm', '20220718073538_RM%20fe-1_vocal.webm', '20220224135946_ARD%2033-2_vocal.webm', '20220122140109_MRGM%20es_vocal.webm', '20221118053800_Fe-1%20SD_lungback.webm', '20220504102754_Seyv%204-5_vocal.webm', '20230418114816_TE%20fe-1_vocal.webm', '20220212071822_Gbc%2019-2_vocal.webm', '20220212070643_Jmt%2017-2_lungback.webm', '20220127113104_NRJJ%20Es_lungfront.webm', '20220302090338_RIT%20fe%202-1_lungfront.webm', '20211207054733_ADW-D5_lungfront.webm', '20220124102435_ARJA%20es_lungback.webm', '20220519070721_KRRS%2019-05-22_lungfront.webm', '20220305054143_MST%20fe%205-1_lungfront.webm', '20221207110303_Fe-1%20YO_lungback.webm', '20220302093004_WOM%20fe%202-2_lungfront.webm', '20220212070508_Jmt%2017-1_lungfront.webm', '20220124124846_AOLR%20fe_lungback.webm', '20220127120739_GADA%20es_lungback.webm', '20220114114719_HIRP_vocal.webm', '20211216131859_JSR-scp_lungfront.webm', '20220127104054_CHLA%20fe_vocal.webm', '20230419124433_LG%20fe-2_lungfront.webm', '20220212080005_Afc%2021-1_vocal.webm', '20220303082548_AAC%20fe%203-1_vocal.webm', '20220515223642_Jasr-16-5_vocal.webm', '20230418102811_LR%20fe-1_lungfront.webm', '20220304052543_YH%20fe%204-1_lungfront.webm', '20220506072041_Vmpr%206_5_22_lungfront.webm', '20220516145759_Leco2-16-5_lungback.webm', '20220114132657_REVY_lungfront.webm', '20220115111646_EMPV_lungback.webm', '20220120143633_SBDS_vocal.webm', '20220303082932_ACH%20fe%203-1_vocal.webm', '20220709050338_BUM%20fe-2_lungfront.webm', '20220108152718_PMAD_lungback.webm', '20221223095759_Fe-2%20GB_vocal.webm', '20220319053836_MMA%20fe%2019-1_lungfront.webm', '20220504165919_ETA%204-5_vocal.webm', '20220117133932_YVRM_lungfront.webm', '20230419115012_LA%20fe-1_lungfront.webm', '20220715104234_CBP%20fe-2_lungback.webm', '20220117114755_LTYM_lungback.webm', '20220126125056_ABM%20fe_vocal.webm', '20220305090421_LCC%20fe%205-1_vocal.webm', '20220516153654_Jasr2-16-05_lungback.webm', '20220127121029_GADA%20fe_lungfront.webm', '20220302081528_EGDC%20fe%202-1_lungback.webm', '20220212063501_Acb%2015-1_lungback.webm', '20220122114153_GPOE%20es_lungback.webm', '20220124160502_RALL%20es_lungfront.webm', '20221123070020_Fe-1%20RF_lungback.webm', '20220124102547_ARJA%20fe_vocal.webm', '20220118162724_SAA_vocal.webm', '20220118130259_DMCS_vocal.webm', '20220121145022_CHFA_vocal.webm', '20220212072422_Lml%2020-2_lungback.webm', '20220305090421_LCC%20fe%205-1_lungfront.webm', '20220219084119_SYV%2030-2_lungfront.webm', '20220105163221_CGT%20sin_lungfront.webm', '20220302091650_EAR%20fe%202-1_vocal.webm', '20220503163043_Jonathan%202_lungback.webm', '20211207055444_ACW-P3_lungfront.webm', '20220118121138_LRLP_lungback.webm', '20220604085705_CAD%20fe-2_lungfront.webm', '20220108135008_LSH_lungback.webm', '20220108164635_OQFR_lungback.webm', '20220727082823_FSM%20fe-1_vocal.webm', '20220215075741_SYV%2027-1_vocal.webm', '20220303090534_CMF%20fe%203-1_vocal.webm', '20220302060345_PRC%20fe%202-1_lungback.webm', '20220128104342_AASE%20fe%201_lungback.webm', '20230420093811_GY%20fe-1_vocal.webm', '20220120143633_SBDS_lungfront.webm', '20221123083226_Fe-2%20VR_lungback.webm', '20220125122834_RPY%20es_lungfront.webm', '20220319095643_MAR%20fe%2019-1_lungback.webm', '20220211122728_OCF%2013_lungfront.webm', '20221118111510_Fe-1%20EP_lungfront.webm', '20220107134757_OCAD_lungfront.webm', '20220303050525_LYC%20fe%203-1_lungfront.webm', '20211209063858_JMT-D4_vocal.webm', '20221220075454_Fe-1%20PB_lungback.webm', '20220516153445_Jasr1-1605_vocal.webm', '20220124151015_JAYG%20es_lungback.webm', '20211209064026_JMT-D5_lungfront.webm', '20220304081704_MHR%20fe%204-1_vocal.webm', '20220114145132_AACC_lungback.webm', '20220709050338_BUM%20fe-2_vocal.webm', '20220305090804_APC%20fe%205-1_lungback.webm', '20220111111424_CLD_lungback.webm', '20220119141214_MAAR_lungback.webm', '20220303082111_JFC%20fe%203-1_vocal.webm', '20220105162835_CGT%20con_lungfront.webm', '20220115122413_RRB_vocal.webm', '20220117133932_YVRM_vocal.webm', '20220127153613_RAJL%20fe_vocal.webm', '20230419130616_MO%20fe-1_lungback.webm', '20220303082548_AAC%20fe%203-1_lungback.webm', '20230421090956_AH%20fe-1_lungback.webm', '20220802120809_TRC%20fe-1_lungfront.webm', '20230421113844_AP%20fe-1_lungback.webm', '20220302081247_TZP%20fe%202-2_lungfront.webm', '20220302091650_EAR%20fe%202-1_lungback.webm', '20221207100112_Fe-1%20WC_lungback.webm', '20221213114920_Fe-2%20BU_lungfront.webm', '20220219081410_TRC%2029-1_lungback.webm', '20220302081247_TZP%20fe%202-2_lungback.webm', '20211207055826_ADW-P5_vocal.webm', '20220120110747_ARSC_lungfront.webm', '20220212063658_Acb%2015-2_vocal.webm', '20220516150924_Mfyc1-16-5_vocal.webm', '20220302092611_SLlJ%20fe%202-1_lungfront.webm', '20220125112513_DAKP%20es_lungfront.webm', '20220212063005_Ach%2014-2_lungback.webm', '20220516153003_Lsma2-16-5_vocal.webm', '20220625095154_DM%20fe-2_vocal.webm', '20220305090804_APC%20fe%205-1_vocal.webm', '20220516152059_Jayg1-16-5_lungfront.webm', '20220114152135_VRP_vocal.webm', '20230419094918_MF%20fe-1_vocal.webm', '20220111120259_RARN_vocal.webm', '20221216093012_Fe-1%20CM_lungback.webm', '20220304082514_SAC%20fe%204-1_lungback.webm', '20220504165035_Aves%204-5_lungfront.webm', '20220212081146_Mmb%2022-2_lungfront.webm', '20220319094727_JGA%20fe%2019-1_lungfront.webm', '20220302054046_DAT%20fe%202-1_lungback.webm', '20220128111313_MCFF%20fE_lungfront.webm', '20230420074758_ACH%20fe-1_lungback.webm', '20230424124430_RT%20fe-1_lungback.webm', '20220212064424_Rgh%2016-2_lungback.webm', '20220129124418_GADA%20fE_vocal.webm', '20220319094727_JGA%20fe%2019-1_vocal.webm', '20220708092832_ARB%20fe-3_lungfront.webm', '20220119161535_SNPC_lungback.webm', '20220302090942_ANP%20fe%202-1_lungback.webm', '20220121165452_STDCP_vocal.webm', '20220504165337_Eta_vocal.webm', '20230420073507_NA%20fe-1_vocal.webm', '20220525092038_Pt%20fe-1_vocal.webm', '20220504165658_Avrd_lungfront.webm', '20220305090043_SFT%20fe%205-1_lungfront.webm', '20220122110541_NFGC%20es_vocal.webm', '20211207054733_ADW-D5_lungback.webm', '20230424124430_RT%20fe-1_vocal.webm', '20220212070948_Tvs%2018-1_vocal.webm', '20220704112603_JGA.%20Fe-2_lungback.webm', '20220319095643_MAR%20fe%2019-1_lungfront.webm', '20220516150924_Mfyc1-16-5_lungback.webm', '20220114145132_AACC_vocal.webm', '20220526123937_SE%20fe-2_lungfront.webm', '20220212065052_ATC%2017-1_lungfront.webm', '20220212063501_Acb%2015-1_lungfront.webm', '20220212080851_Mmb%2022.1_lungfront.webm', '20220212070643_Jmt%2017-2_vocal.webm', '20211202103930_Mcp-02-11-D3_vocal.webm', '20230424124430_RT%20fe-1_lungfront.webm', '20220302090631_WOM%20fe%202-1_lungback.webm', '20220319054519_XLS%20fe%2019-1_lungfront.webm', '20220804094909_JQZ%20fe-3_vocal.webm', '20220715101331_RFC%20fe-3_lungfront.webm', '20220117133932_YVRM_lungback.webm', '20220708104228_FDV%20fe-2_vocal.webm', '20220302060619_PRC%20fe%202-2_lungback.webm', '20220122140109_MRGM%20es_lungfront.webm', '20211207055826_ADW-P5_lungfront.webm', '20230420073507_NA%20fe-1_lungback.webm', '20230419124433_LG%20fe-2_lungback.webm', '20220114132657_REVY_vocal.webm', '20220127143555_MMLJ%20Fe_vocal.webm', '20221123070020_Fe-1%20RF_vocal.webm', '20220127130817_RPY%20Fe_lungback.webm', '20220125112846_DAKP%20fe_lungback.webm', '20230419114613_AR%20fe-1_lungback.webm', '20220212071122_Tvs%2018-2_lungback.webm', '20220709073837_RCM%20fe-3_lungfront.webm', '20220302082442_MOP%20fe%202-1_lungback.webm', '20220127130655_RPY%20Es_lungfront.webm', '20220516150119_Wgyv1-16-5_lungfront.webm', '20211209063216_JMT-D_vocal.webm', '20220516144141_Darz2-16-2_vocal.webm', '20220302093004_WOM%20fe%202-2_lungback.webm', '20220127104054_CHLA%20fe_lungfront.webm', '20220107110951_SMAJ_lungfront.webm', '20220108174158_MFRJ_lungback.webm', '20220516151109_Mfyc2-16-5_vocal.webm', '20220504165919_ETA%204-5_lungfront.webm', '20220709073607_RCM%20fe-2_vocal.webm', '20230421113844_AP%20fe-1_lungfront.webm', '20230419104705_MG%20fe-1_lungfront.webm', '20230420094226_GCH%20fe-1_vocal.webm', '20220128104455_AASE_lungfront.webm', '20220219084119_SYV%2030-2_lungback.webm', '20220211114254_OCF%20fe%2012-1_lungfront.webm', '20220119134648_MILS_lungfront.webm', '20220212070643_Jmt%2017-2_lungfront.webm', '20220212072422_Lml%2020-2_lungfront.webm', '20221118111510_Fe-1%20EP_lungback.webm', '20220128104342_AASE%20fe%201_vocal.webm', '20220708085349_FHA%20fe-1_lungfront.webm', '20221123121132_Fe-1%20RC_lungfront.webm', '20220107110348_BTMA_lungback.webm', '20220708092832_ARB%20fe-3_lungback.webm', '20221223095759_Fe-2%20GB_lungback.webm', '20220303081248_LRR%20fe%203-1_lungfront.webm', '20230424140045_GA%20fe-1_lungfront.webm', '20220516152711_Lsma1-16-5_vocal.webm', '20230419094918_MF%20fe-1_lungfront.webm', '20220105163221_CGT%20sin_lungback.webm', '20220304081704_MHR%20fe%204-1_lungfront.webm', '20220212072243_Lml%2020-1_lungfront.webm', '20230420074758_ACH%20fe-1_lungfront.webm', '20220108174158_MFRJ_vocal.webm', '20230418115210_JS%20fe-1_lungfront.webm', '20220421124920_LRR%2021-1_vocal.webm', '20230424140556_GB%20fe-1_lungback.webm', '20220304083114_AMQ%20fe%204-1_lungfront.webm', '20211209063216_JMT-D_lungback.webm', '20220107110951_SMAJ_vocal.webm', '20220516145612_Leco1-16-5_lungfront.webm', '20211202103721_Mcp-02-12-D1_lungback.webm', '20221123090606_Fe-1%20AM_lungback.webm', '20220114145132_AACC_lungfront.webm', '20221207131017_Fe-1%20MA_lungfront.webm', '20211209064522_JMT-P4_vocal.webm', '20220122110655_NFGC%20fe_lungfront.webm', '20220125122955_RPY%20fe_lungback.webm', '20230420093811_GY%20fe-1_lungback.webm', '20220114125553_DAYC_lungfront.webm', '20220319094332_MME%20fe%2019-1_lungback.webm', '20230424134952_LY%20fe-1_lungback.webm', '20230424140045_GA%20fe-1_vocal.webm', '20220108135008_LSH_vocal.webm', '20220802104203_TEO%20fe-1_lungback.webm', '20220709050025_BUM%20fe-1_lungback.webm', '20220126113139_BMY%20es_vocal.webm', '20220107144605_VYFS_vocal.webm', '20220305054143_MST%20fe%205-1_vocal.webm', '20220105133643_YE_lungback.webm', '20220709054937_CNE%20fe-2_lungback.webm', '20220604085459_CAD%20fe-1_vocal.webm', '20220704112246_JGA%20fe-1_vocal.webm', '20220305073957_MHC%20fe%205-1_lungfront.webm', '20221223095759_Fe-2%20GB_lungfront.webm', '20220127113104_NRJJ%20Es_vocal.webm', '20221217091134_Fe-1%20AR_lungback.webm', '20211202103821_Mcp-02-12-D2_lungback.webm', '20230418115210_JS%20fe-1_vocal.webm', '20220525092038_Pt%20fe-1_lungback.webm', '20220212064424_Rgh%2016-2_vocal.webm', '20220319073711_PRC%20fe%2019-1_vocal.webm', '20220219081410_TRC%2029-1_lungfront.webm', '20230419120707_ET%20fe-1_lungback.webm', '20220120162822_OEGP_lungback.webm'}\n",
            "Test Embeddings are from 211 unique files: {'20220121145022_CHFA_lungback.webm', '20220810095537_DLP%20fe-1_vocal.webm', '20220319061032_ECO%20fe%2019-1_lungfront.webm', '20220303090534_CMF%20fe%203-1_lungback.webm', '20220709054715_CNE%20fe-1_lungback.webm', '20220105124255_PTR_lungfront.webm', '20220212065052_ATC%2017-1_vocal.webm', '20220519070721_KRRS%2019-05-22_vocal.webm', '20230424133743_JA%20fe-1_lungback.webm', '20220212065239_ATC%2017-2_lungfront.webm', '20220215080924_MME%2028-1_vocal.webm', '20220625095154_DM%20fe-2_lungfront.webm', '20220304051252_PBZ%20fe%204-1_lungfront.webm', '20220304065400_NAA%20fe%204-1_lungback.webm', '20220630100058_ARB%20fe-2_lungback.webm', '20220303090534_CMF%20fe%203-1_lungfront.webm', '20220215081101_MME%2028-2_vocal.webm', '20220319094332_MME%20fe%2019-1_lungfront.webm', '20220302064618_RMC%20fe%202-2_vocal.webm', '20220802104203_TEO%20fe-1_vocal.webm', '20220303082932_ACH%20fe%203-1_lungback.webm', '20220212063658_Acb%2015-2_lungfront.webm', '20220319061032_ECO%20fe%2019-1_vocal.webm', '20220715104234_CBP%20fe-2_lungfront.webm', '20220125155955_MMLJ%20es_lungback.webm', '20220124133907_GMK%20es_vocal.webm', '20220107134757_OCAD_vocal.webm', '20230419105624_EA%20fe-1_lungback.webm', '20221212104450_Fe-1%20KP_vocal.webm', '20220304082033_MQR%20fe%204-1_lungfront.webm', '20211207054053_ACW-%20D2_lungback.webm', '20211216131859_JSR-scp_vocal.webm', '20220127153448_RAJL%20es_lungfront.webm', '20220810095537_DLP%20fe-1_lungfront.webm', '20220219083953_SYV%2030-1_lungback.webm', '20220625095002_DM%20fe-1_lungfront.webm', '20220107134757_OCAD_lungback.webm', '20220127130817_RPY%20Fe_vocal.webm', '20220503092428_Jonathan_lungfront.webm', '20220125162729_MCEE%20es_lungback.webm', '20220302090338_RIT%20fe%202-1_vocal.webm', '20220125112846_DAKP%20fe_vocal.webm', '20220516150119_Wgyv1-16-5_lungback.webm', '20220114125553_DAYC_vocal.webm', '20220704112246_JGA%20fe-1_lungfront.webm', '20230424111937_JH%20fe-1_vocal.webm', '20220125162729_MCEE%20es_vocal.webm', '20230419125101_JG%20fe-1_lungfront.webm', '20220115154844_KMI_lungfront.webm', '20220804111858_TRC%20fe-2_lungback.webm', '20220124124846_AOLR%20fe_lungfront.webm', '20221118094140_Fe-1%20JG_lungfront.webm', '20220302082442_MOP%20fe%202-1_vocal.webm', '20211216131725_NSR-CD_lungfront.webm', '20230419104705_MG%20fe-1_vocal.webm', '20220127153613_RAJL%20fe_lungfront.webm', '20220504102754_Seyv%204-5_lungback.webm', '20220120131215_DJZA_lungfront.webm', '20220219081530_TRC%2029-2_vocal.webm', '20220114132657_REVY_lungback.webm', '20220718070922_MGC%20fe-1_vocal.webm', '20220212070508_Jmt%2017-1_lungback.webm', '20220319073411_DAT%20fe%2019-1_lungback.webm', '20220108135008_LSH_lungfront.webm', '20220304052032_CRD_lungback.webm', '20221123051040_Fe-1%20MM_vocal.webm', '20220114163111_JASR_lungback.webm', '20211207055444_ACW-P3_vocal.webm', '20220302090631_WOM%20fe%202-1_lungfront.webm', '20220117141014_MACL_vocal.webm', '20221118053800_Fe-1%20SD_vocal.webm', '20230419105624_EA%20fe-1_lungfront.webm', '20220516152223_Jayg2-16-5_lungback.webm', '20221123121132_Fe-1%20RC_vocal.webm', '20220114163111_JASR_lungfront.webm', '20220304052032_CRD_vocal.webm', '20220115155641_SI_lungfront.webm', '20230421114407_JF%20fe-1_lungfront.webm', '20230424111328_RB%20fe-1_lungfront.webm', '20230418103903_CA%20fe-1_vocal.webm', '20220723124659_AVB%20fe-1_lungfront.webm', '20220303082111_JFC%20fe%203-1_lungfront.webm', '20220319055023_DDCS%20fe%2019-1_lungfront.webm', '20220516153445_Jasr1-1605_lungback.webm', '20220127113104_NRJJ%20Es_lungback.webm', '20220126170624_GMK%20Fe_vocal.webm', '20220105133843_YH%20sin_vocal.webm', '20220804094909_JQZ%20fe-3_lungback.webm', '20220119112335_SMAC_vocal.webm', '20220304051252_PBZ%20fe%204-1_vocal.webm', '20220302060345_PRC%20fe%202-1_lungfront.webm', '20220506051857_Abemn%206-5-22_vocal.webm', '20220114122836_MMGC_vocal.webm', '20220120143633_SBDS_lungback.webm', '20220525090247_Pt_lungfront.webm', '20220212064149_Rgh%2016-1_lungfront.webm', '20220709054937_CNE%20fe-2_lungfront.webm', '20221123054048_Fe-1%20GCh_lungback.webm', '20220305075107_MRC%20fe%205-1_lungfront.webm', '20220212080246_Afc%2021-2_lungfront.webm', '20220119141214_MAAR_lungfront.webm', '20220504165919_ETA%204-5_lungback.webm', '20220319054519_XLS%20fe%2019-1_vocal.webm', '20220120153840_GCNF_vocal.webm', '20220219084905_MGCH%2030-1_lungfront.webm', '20220215074545_Zmg%2025-2_lungfront.webm', '20230419104705_MG%20fe-1_lungback.webm', '20220107155508_GHR_lungfront.webm', '20230420094226_GCH%20fe-1_lungback.webm', '20220525092038_Pt%20fe-1_lungfront.webm', '20220115111646_EMPV_vocal.webm', '20220708085349_FHA%20fe-1_lungback.webm', '20220212071632_Gbc%2019-1_vocal.webm', '20220516151434_Yyrg1-16-5_lungfront.webm', '20220128104342_AASE%20fe%201_lungfront.webm', '20220126124939_ABM%20es_vocal.webm', '20220302054046_DAT%20fe%202-1_vocal.webm', '20220708093145_ARB%20fe-4_lungback.webm', '20220727082823_FSM%20fe-1_lungback.webm', '20211209063621_JMT-D3_lungback.webm', '20220709050025_BUM%20fe-1_vocal.webm', '20221118083614_Fe-1%20VR_lungback.webm', '20230420111142_FT%20fe-1_lungfront.webm', '20221213121136_Fe-1%20GM_lungback.webm', '20220212071822_Gbc%2019-2_lungback.webm', '20220124102547_ARJA%20fe_lungback.webm', '20220212071632_Gbc%2019-1_lungfront.webm', '20220125155955_MMLJ%20es_vocal.webm', '20221123051040_Fe-1%20MM_lungfront.webm', '20211207054901_ACW-P1_lungfront.webm', '20220115122413_RRB_lungfront.webm', '20211209064407_JMT-P3_lungfront.webm', '20220212062243_Ach%20fe-14-1_lungfront.webm', '20211202104033_Mcp-02-12-D3_lungback.webm', '20220525090247_Pt_vocal.webm', '20220212065239_ATC%2017-2_vocal.webm', '20220319055023_DDCS%20fe%2019-1_vocal.webm', '20220124151015_JAYG%20es_vocal.webm', '20230419115012_LA%20fe-1_lungback.webm', '20220302053604_MLQ%20fe%202-2_vocal.webm', '20221207100112_Fe-1%20WC_lungfront.webm', '20221207131017_Fe-1%20MA_vocal.webm', '20220108112150_HCAP_lungfront.webm', '20230424140556_GB%20fe-1_lungfront.webm', '20221223095536_Fe-1%20GB_vocal.webm', '20221212104450_Fe-1%20KP_lungfront.webm', '20220709054715_CNE%20fe-1_vocal.webm', '20220111120259_RARN_lungfront.webm', '20220319073113_MLQ%20fe%2019-1_vocal.webm', '20220122153938_MSVC%20es_vocal.webm', '20220124160633_RALL%20fe_vocal.webm', '20230418103221_Av%20fe-1_lungfront.webm', '20220302091650_EAR%20fe%202-1_lungfront.webm', '20220127130817_RPY%20Fe_lungfront.webm', '20211202104033_Mcp-02-12-D3_lungfront.webm', '20220304053013_LRM%20fe%204-1_lungfront.webm', '20220108152718_PMAD_lungfront.webm', '20220118151408_TZP_lungback.webm', '20220503092428_Jonathan_lungback.webm', '20220504165035_Aves%204-5_lungback.webm', '20220304082514_SAC%20fe%204-1_vocal.webm', '20230421090956_AH%20fe-1_lungfront.webm', '20230419124122_LG%20fe-1_lungback.webm', '20220516110622_Ahj-16-5_lungfront.webm', '20230421100451_DF%20fe-1_vocal.webm', '20230419105624_EA%20fe-1_vocal.webm', '20220802120809_TRC%20fe-1_vocal.webm', '20220305074538_KMI%20fe%205-1_lungfront.webm', '20220212063658_Acb%2015-2_lungback.webm', '20220302054305_DAT%20fe%202-2_lungfront.webm', '20220125140524_NRJJ%20es_vocal.webm', '20220604055424_JFC%20fe-1_vocal.webm', '20220224135946_ARD%2033-2_lungback.webm', '20230424134952_LY%20fe-1_vocal.webm', '20220117114755_LTYM_lungfront.webm', '20220516152059_Jayg1-16-5_lungback.webm', '20221207100112_Fe-1%20WC_vocal.webm', '20220105133643_YE_vocal.webm', '20220302064348_RMC%20fe%202-1_lungfront.webm', '20221216093012_Fe-1%20CM_lungfront.webm', '20220518132744_Typ%20_lungfront.webm', '20220305075107_MRC%20fe%205-1_lungback.webm', '20220319073711_PRC%20fe%2019-1_lungfront.webm', '20230419092959_AA%20fe-1_vocal.webm', '20220122114315_GPOE%20fe_vocal.webm', '20220304083114_AMQ%20fe%204-1_lungback.webm', '20221216093012_Fe-1%20CM_vocal.webm', '20220129133119_DAKP%20fE_lungback.webm', '20211207054534_ACD-D4_lungback.webm', '20220302081802_EPV%20fe%202-1_lungfront.webm', '20220727094501_CCG%20fe-1_lungfront.webm', '20230419104420_RP%20fe-1_lungback.webm', '20220804094909_JQZ%20fe-3_lungfront.webm', '20220802080705_MHC%20fe-2_lungback.webm', '20220506072041_Vmpr%206_5_22_vocal.webm', '20220105163221_CGT%20sin_vocal.webm', '20220122153938_MSVC%20es_lungfront.webm', '20220305091432_DYC%20fe%205-1_vocal.webm', '20220604055709_JFC%20fe-2_lungfront.webm', '20220305090043_SFT%20fe%205-1_vocal.webm', '20220721062840_ICR%20fe-1_vocal.webm', '20220305054143_MST%20fe%205-1_lungback.webm', '20220604055424_JFC%20fe-1_lungback.webm', '20220115155641_SI_vocal.webm', '20230418104709_JC%20fe-1_vocal.webm', '20220118151408_TZP_vocal.webm', '20220215075038_TRC%2026-1_vocal.webm', '20220723124659_AVB%20fe-1_vocal.webm', '20220319094727_JGA%20fe%2019-1_lungback.webm', '20221220075710_Fe-2%20PB_vocal.webm', '20220625095002_DM%20fe-1_lungback.webm'}\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Get a list of all available files\n",
        "all_files = list(files_map.keys())\n",
        "\n",
        "# Randomly select 20% of them for the test set\n",
        "test_size = max(1, int(0.2 * len(all_files)))\n",
        "test_files = random.sample(all_files, test_size)\n",
        "\n",
        "# Ensure test files exist in the file map\n",
        "for tf in test_files:\n",
        "    assert tf in files_map, f\"Test file '{tf}' not found in files_map.\"\n",
        "\n",
        "# Initialize datasets\n",
        "test_embeddings, test_file_names = [], []\n",
        "train_embeddings, train_file_names = [], []\n",
        "\n",
        "# Collect embeddings for train and test\n",
        "for file_key, embedding_batch in file_embeddings.items():\n",
        "    for embedding in embedding_batch:\n",
        "        if file_key in test_files:\n",
        "            test_embeddings.append(embedding)\n",
        "            test_file_names.append(file_key)\n",
        "        else:\n",
        "            train_embeddings.append(embedding)\n",
        "            train_file_names.append(file_key)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "train_embeddings = np.array(train_embeddings)\n",
        "test_embeddings = np.array(test_embeddings)\n",
        "\n",
        "# Create sets of unique file names\n",
        "train_file_set = set(train_file_names)\n",
        "test_file_set = set(test_file_names)\n",
        "\n",
        "# Report results\n",
        "print(f\"Train embeddings have shape: {train_embeddings.shape}, data type: {train_embeddings.dtype}\")\n",
        "print(f\"Train Embeddings are from {len(train_file_set)} unique files: {train_file_set}\")\n",
        "print(f\"Test Embeddings are from {len(test_file_set)} unique files: {test_file_set}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHej280on_N0"
      },
      "outputs": [],
      "source": [
        "file_cough_labels = {}\n",
        "for file in all_files:\n",
        "    if \"vocal\" in file:\n",
        "        file_cough_labels[file] = \"vocal\"\n",
        "    elif \"lung\" in file:\n",
        "        file_cough_labels[file] = \"lung\"\n",
        "    else:\n",
        "        print(f\"[WARN] No se pudo clasificar: {file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average vectors for each test file\n",
        "from collections import defaultdict\n",
        "\n",
        "# Group embeddings by file name\n",
        "file_to_embeddings_test = defaultdict(list)\n",
        "for embedding, fname in zip(test_embeddings, test_file_names):\n",
        "    file_to_embeddings_test[fname].append(embedding)\n",
        "\n",
        "# Sort test files to keep consistent order\n",
        "ordered_test_files = sorted(file_to_embeddings_test.keys())\n",
        "\n",
        "# Retrieve true labels for ordered test files\n",
        "true_labels = [file_cough_labels[f] for f in ordered_test_files]\n",
        "\n",
        "# Compute average embedding per file\n",
        "test_embeddings_avg = []\n",
        "for fname in ordered_test_files:\n",
        "    embeddings = np.array(file_to_embeddings_test[fname])\n",
        "    test_embeddings_avg.append(np.mean(embeddings, axis=0))\n",
        "\n",
        "# Convert to NumPy array\n",
        "test_embeddings_avg = np.array(test_embeddings_avg)"
      ],
      "metadata": {
        "id": "PEiSWf-59ff1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkr8EXfOGgHm"
      },
      "source": [
        "## Use Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizaci\u00f3n exploratoria de los embeddings del conjunto de entrenamiento en 2D usando PCA.\n",
        "Cada punto representa un segmento de audio, coloreado seg\u00fan el archivo original.\n",
        "Los marcadores en forma de estrella muestran el embedding promedio (centroide) por archivo.\n",
        "Esta gr\u00e1fica permite analizar la cohesi\u00f3n interna por archivo, detectar dispersiones y outliers."
      ],
      "metadata": {
        "id": "QMopPR-hSwzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener archivos con embeddings y etiquetas v\u00e1lidas\n",
        "train_file_names = []\n",
        "train_embeddings = []\n",
        "train_labels = []\n",
        "\n",
        "for file_name, embedding_array in file_embeddings.items():\n",
        "    if file_name in file_cough_labels:\n",
        "        train_file_names.append(file_name)\n",
        "        train_embeddings.append(embedding_array)\n",
        "        train_labels.append(file_cough_labels[file_name])\n",
        "    else:\n",
        "        print(f\"[ADVERTENCIA] No se encontr\u00f3 etiqueta para: {file_name}\")"
      ],
      "metadata": {
        "id": "KtfHaouedz1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DVo9WYSYjZ6H",
        "outputId": "e9d2f07a-aff2-4b42-c328-4d5b7b9f4a4d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Asegurar formato correcto: vector promedio por archivo\n",
        "train_embeddings_avg = [np.mean(embed, axis=0) for embed in train_embeddings]\n",
        "train_embeddings_avg = np.array(train_embeddings_avg)\n",
        "\n",
        "# PCA sobre vectores promedio\n",
        "pca = PCA(n_components=2)\n",
        "pca_embeddings = pca.fit_transform(train_embeddings_avg)\n",
        "\n",
        "# Crear DataFrame con coordenadas PCA y etiquetas\n",
        "df = pd.DataFrame(pca_embeddings, columns=[\"x\", \"y\"])\n",
        "df[\"label\"] = train_labels  # Aseg\u00farate de que train_labels est\u00e9 alineado con train_embeddings\n",
        "\n",
        "# Mapa de colores por clase\n",
        "label_colors = {\n",
        "    \"vocal\": \"tab:blue\",\n",
        "    \"lung\": \"tab:red\"\n",
        "}\n",
        "\n",
        "# Dibujar puntos por clase\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, group in df.groupby(\"label\"):\n",
        "    plt.scatter(group[\"x\"], group[\"y\"], color=label_colors.get(label, \"gray\"), label=label, alpha=0.4)\n",
        "\n",
        "# Calcular y dibujar centroides por clase\n",
        "centroids = df.groupby(\"label\")[[\"x\", \"y\"]].mean()\n",
        "for label, row in centroids.iterrows():\n",
        "    plt.scatter(row[\"x\"], row[\"y\"], marker=\"*\", s=400,\n",
        "                color=label_colors.get(label, \"gray\"),\n",
        "                edgecolors=\"black\", linewidths=1.5, label=f\"{label} (centroide)\")\n",
        "\n",
        "# Formato del gr\u00e1fico\n",
        "plt.xlabel(\"PCA Dimension 1\")\n",
        "plt.ylabel(\"PCA Dimension 2\")\n",
        "plt.title(\"Distribuci\u00f3n de embeddings por tipo de tos\")\n",
        "plt.legend(title=\"Clase\", loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX7_A3Kln47d",
        "outputId": "b4496b43-7bc3-4496-9643-002d59dc19e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udd04 Entrenando: Support Vector Machine (linear)\n",
            "\u2705 Finished training and saved: Support Vector Machine (linear)\n",
            "\ud83d\udd04 Entrenando: Logistic Regression\n",
            "\u2705 Finished training and saved: Logistic Regression\n",
            "\ud83d\udd04 Entrenando: Gradient Boosting\n",
            "\u2705 Finished training and saved: Gradient Boosting\n",
            "\ud83d\udd04 Entrenando: Random Forest\n",
            "\u2705 Finished training and saved: Random Forest\n",
            "\ud83d\udd04 Entrenando: MLP Classifier\n",
            "\u2705 Finished training and saved: MLP Classifier\n",
            "CPU times: user 55.9 s, sys: 170 ms, total: 56.1 s\n",
            "Wall time: 45.7 s\n"
          ]
        }
      ],
      "source": [
        "# @title Train and Save Multi-class Cough Type Classifiers (\"lung\", \"vocal\")\n",
        "%%time\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Convert categorical cough labels\n",
        "cough_labels = []\n",
        "valid_files = []\n",
        "\n",
        "# Match training files with their corresponding labels\n",
        "for file_name in train_file_names:\n",
        "    if file_name in file_cough_labels:\n",
        "        label = file_cough_labels[file_name]\n",
        "        cough_labels.append(label)\n",
        "        valid_files.append(file_name)\n",
        "    else:\n",
        "        print(f\"Warning: No label found for '{file_name}'. Skipping.\")\n",
        "\n",
        "# Filter embeddings that match valid labeled files\n",
        "filtered_embeddings = [train_embeddings[train_file_names.index(f)] for f in valid_files]\n",
        "\n",
        "# \u2705 Convertir a vectores promedio por archivo\n",
        "filtered_embeddings_avg = [np.mean(embed, axis=0) for embed in filtered_embeddings]\n",
        "filtered_embeddings_avg = np.array(filtered_embeddings_avg)\n",
        "\n",
        "# Create output directory to save models\n",
        "os.makedirs(\"results/saved_models_multiclass\", exist_ok=True)\n",
        "\n",
        "# \u2705 Define models to train (con probabilidad donde aplica)\n",
        "models = {\n",
        "    \"Support Vector Machine (linear)\": SVC(kernel='linear', probability=True),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),  # ya da probabilidad\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=128),  # ya da\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=128),  # ya da\n",
        "    \"MLP Classifier\": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=1000),  # ya da\n",
        "}\n",
        "\n",
        "# Train and save models\n",
        "cough_models = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\ud83d\udd04 Entrenando: {name}\")\n",
        "    model.fit(filtered_embeddings_avg, cough_labels)\n",
        "    cough_models[name] = model\n",
        "\n",
        "    # Save model to disk\n",
        "    safe_name = name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
        "    joblib.dump(model, f\"results/saved_models_multiclass/{safe_name}.joblib\")\n",
        "\n",
        "    print(f\"\u2705 Finished training and saved: {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total de archivos en test_file_names: {len(test_file_names)}\")\n",
        "print(test_file_names[:5])  # muestra los primeros 5"
      ],
      "metadata": {
        "id": "LYBHkfw5CWsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5102c80-d998-4b52-c03b-4670a8ff5efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de archivos en test_file_names: 1296\n",
            "['20220125112846_DAKP%20fe_vocal.webm', '20220125112846_DAKP%20fe_vocal.webm', '20220125112846_DAKP%20fe_vocal.webm', '20220125112846_DAKP%20fe_vocal.webm', '20230420094226_GCH%20fe-1_lungback.webm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIjuNLyp0NPK",
        "outputId": "6b1a62cf-115e-4bd6-d50b-8ab3e67cbf75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83c\udfaf Clasificando 4 embeddings del archivo: 20220125112846_DAKP%20fe_vocal.webm usando 5 modelos...\n",
            "\n",
            "\ud83d\udd0e Modelo: Support Vector Machine (linear)\n",
            "  \u2022 vocal: 4 segmento(s)\n",
            "  \u2705 Dominante: vocal (4/4)\n",
            "  \ud83d\udcca Confianza promedio para 'vocal': 0.99\n",
            "--------------------------------------------------\n",
            "\ud83d\udd0e Modelo: Logistic Regression\n",
            "  \u2022 vocal: 4 segmento(s)\n",
            "  \u2705 Dominante: vocal (4/4)\n",
            "  \ud83d\udcca Confianza promedio para 'vocal': 1.00\n",
            "--------------------------------------------------\n",
            "\ud83d\udd0e Modelo: Gradient Boosting\n",
            "  \u2022 vocal: 4 segmento(s)\n",
            "  \u2705 Dominante: vocal (4/4)\n",
            "  \ud83d\udcca Confianza promedio para 'vocal': 1.00\n",
            "--------------------------------------------------\n",
            "\ud83d\udd0e Modelo: Random Forest\n",
            "  \u2022 vocal: 4 segmento(s)\n",
            "  \u2705 Dominante: vocal (4/4)\n",
            "  \ud83d\udcca Confianza promedio para 'vocal': 0.91\n",
            "--------------------------------------------------\n",
            "\ud83d\udd0e Modelo: MLP Classifier\n",
            "  \u2022 vocal: 4 segmento(s)\n",
            "  \u2705 Dominante: vocal (4/4)\n",
            "  \ud83d\udcca Confianza promedio para 'vocal': 1.00\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Seleccionar archivo de prueba\n",
        "target_file = '20220125112846_DAKP%20fe_vocal.webm'\n",
        "assert target_file in test_file_names, f\"'{target_file}' no est\u00e1 en test_file_names.\"\n",
        "\n",
        "# Agrupar los embeddings por archivo\n",
        "file_to_embeddings = {}\n",
        "for embedding, name in zip(test_embeddings, test_file_names):\n",
        "    file_to_embeddings.setdefault(name, []).append(embedding)\n",
        "\n",
        "# Convertir embeddings del archivo objetivo\n",
        "target_embeddings = np.array(file_to_embeddings[target_file])\n",
        "print(f\"\\n\ud83c\udfaf Clasificando {len(target_embeddings)} embeddings del archivo: {target_file} usando {len(cough_models)} modelos...\\n\")\n",
        "\n",
        "# Clasificaci\u00f3n con cada modelo\n",
        "for model_name, model in cough_models.items():\n",
        "    print(f\"\ud83d\udd0e Modelo: {model_name}\")\n",
        "\n",
        "    # Predicciones por clip\n",
        "    predictions = model.predict(target_embeddings)\n",
        "    label_counts = Counter(predictions)\n",
        "    most_common_label, count = label_counts.most_common(1)[0]\n",
        "\n",
        "    for label, c in label_counts.items():\n",
        "        print(f\"  \u2022 {label}: {c} segmento(s)\")\n",
        "\n",
        "    print(f\"  \u2705 Dominante: {most_common_label} ({count}/{len(predictions)})\")\n",
        "\n",
        "    # Mostrar probabilidades si es posible\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        class_idx = list(model.classes_).index(most_common_label)\n",
        "        probs = model.predict_proba(target_embeddings)[:, class_idx]\n",
        "        mean_prob = np.mean(probs)\n",
        "        print(f\"  \ud83d\udcca Confianza promedio para '{most_common_label}': {mean_prob:.2f}\")\n",
        "    else:\n",
        "        print(\"  \u26a0\ufe0f Este modelo no soporta predict_proba()\")\n",
        "\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate calibrated multi-class classifiers on the test set using majority vote\n",
        "For each test audio file:\n",
        "- Group its segment-level embeddings\n",
        "- Predict labels using each model for every segment\n",
        "- Assign a final label via majority vote\n",
        "- Compare predictions to ground-truth labels\n",
        "\n",
        "Outputs include:\n",
        "- Classification report (precision, recall, f1-score)\n",
        "- Confusion matrix\n",
        "- Sensitivity, specificity, and accuracy (per class and overall)\n",
        "- Misclassified file list for error analysis"
      ],
      "metadata": {
        "id": "sM5lyAYVLp5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "from sklearn.metrics import (confusion_matrix, classification_report,\n",
        "                             accuracy_score)\n",
        "import numpy as np\n",
        "\n",
        "# Agrupar embeddings por archivo\n",
        "file_to_embeddings = defaultdict(list)\n",
        "for embedding, name in zip(test_embeddings, test_file_names):\n",
        "    file_to_embeddings[name].append(embedding)\n",
        "\n",
        "file_to_label = {fname: file_cough_labels[fname] for fname in test_file_names}\n",
        "\n",
        "true_labels = []\n",
        "model_predictions = defaultdict(list)\n",
        "\n",
        "print(f\"Evaluando {len(file_to_embeddings)} archivos de test con {len(cough_models)} modelos...\\n\")\n",
        "\n",
        "# Clasificaci\u00f3n por archivo (mayor\u00eda de votos)\n",
        "for file_name, embeddings in file_to_embeddings.items():\n",
        "    X = np.array(embeddings)\n",
        "    true_label = file_to_label[file_name]\n",
        "    true_labels.append(true_label)\n",
        "\n",
        "    for model_name, cough_model in cough_models.items():\n",
        "        preds = cough_model.predict(X)\n",
        "        majority = Counter(preds).most_common(1)[0][0]\n",
        "        model_predictions[model_name].append(majority)\n",
        "\n",
        "# M\u00e9tricas y errores\n",
        "for model_name, predictions in model_predictions.items():\n",
        "    print(f\"\\n=== Reporte para {model_name} ===\")\n",
        "    print(classification_report(true_labels, predictions, zero_division=0))\n",
        "\n",
        "    labels = sorted(set(true_labels + predictions))\n",
        "    cm = confusion_matrix(true_labels, predictions, labels=labels)\n",
        "\n",
        "    # Sensibilidad, especificidad y accuracy\n",
        "    TP = np.diag(cm)\n",
        "    FN = np.sum(cm, axis=1) - TP\n",
        "    FP = np.sum(cm, axis=0) - TP\n",
        "    TN = np.sum(cm) - (FP + FN + TP)\n",
        "\n",
        "    sensitivity = TP / (TP + FN + 1e-10)\n",
        "    specificity = TN / (TN + FP + 1e-10)\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    print(\"\\nMetrics per class:\")\n",
        "    for i, label in enumerate(labels):\n",
        "        print(f\"  Clase '{label}': Sensitivity (Recall): {sensitivity[i]:.2f}, Specificity: {specificity[i]:.2f}\")\n",
        "    print(f\"  Overall Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    # Guardar misclassifications\n",
        "    print(f\"[Errores - {model_name}]\")\n",
        "    for fname, y_true, y_pred in zip(file_to_embeddings.keys(), true_labels, predictions):\n",
        "        if y_true != y_pred:\n",
        "            print(f\"  {fname} | real: {y_true} \u2192 pred: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9yJOznGwqa3",
        "outputId": "3972556d-cca2-455a-ee1d-174815d7fe13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluando 211 archivos de test con 5 modelos...\n",
            "\n",
            "\n",
            "=== Reporte para Support Vector Machine (linear) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        lung       0.99      0.99      0.99       134\n",
            "       vocal       0.97      0.99      0.98        77\n",
            "\n",
            "    accuracy                           0.99       211\n",
            "   macro avg       0.98      0.99      0.98       211\n",
            "weighted avg       0.99      0.99      0.99       211\n",
            "\n",
            "\n",
            "Metrics per class:\n",
            "  Clase 'lung': Sensitivity (Recall): 0.99, Specificity: 0.99\n",
            "  Clase 'vocal': Sensitivity (Recall): 0.99, Specificity: 0.99\n",
            "  Overall Accuracy: 0.99\n",
            "[Errores - Support Vector Machine (linear)]\n",
            "  20220111120259_RARN_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220108152718_PMAD_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220107134757_OCAD_vocal.webm | real: vocal \u2192 pred: lung\n",
            "\n",
            "=== Reporte para Logistic Regression ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        lung       0.99      0.99      0.99       134\n",
            "       vocal       0.97      0.99      0.98        77\n",
            "\n",
            "    accuracy                           0.99       211\n",
            "   macro avg       0.98      0.99      0.98       211\n",
            "weighted avg       0.99      0.99      0.99       211\n",
            "\n",
            "\n",
            "Metrics per class:\n",
            "  Clase 'lung': Sensitivity (Recall): 0.99, Specificity: 0.99\n",
            "  Clase 'vocal': Sensitivity (Recall): 0.99, Specificity: 0.99\n",
            "  Overall Accuracy: 0.99\n",
            "[Errores - Logistic Regression]\n",
            "  20220111120259_RARN_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220108152718_PMAD_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220302053604_MLQ%20fe%202-2_vocal.webm | real: vocal \u2192 pred: lung\n",
            "\n",
            "=== Reporte para Gradient Boosting ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        lung       0.96      0.99      0.97       134\n",
            "       vocal       0.97      0.92      0.95        77\n",
            "\n",
            "    accuracy                           0.96       211\n",
            "   macro avg       0.96      0.95      0.96       211\n",
            "weighted avg       0.96      0.96      0.96       211\n",
            "\n",
            "\n",
            "Metrics per class:\n",
            "  Clase 'lung': Sensitivity (Recall): 0.99, Specificity: 0.92\n",
            "  Clase 'vocal': Sensitivity (Recall): 0.92, Specificity: 0.99\n",
            "  Overall Accuracy: 0.96\n",
            "[Errores - Gradient Boosting]\n",
            "  20220111120259_RARN_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220125155955_MMLJ%20es_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220125162729_MCEE%20es_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20211216131859_JSR-scp_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220124133907_GMK%20es_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220212065052_ATC%2017-1_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220108152718_PMAD_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220302053604_MLQ%20fe%202-2_vocal.webm | real: vocal \u2192 pred: lung\n",
            "\n",
            "=== Reporte para Random Forest ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        lung       0.96      0.97      0.96       134\n",
            "       vocal       0.95      0.92      0.93        77\n",
            "\n",
            "    accuracy                           0.95       211\n",
            "   macro avg       0.95      0.95      0.95       211\n",
            "weighted avg       0.95      0.95      0.95       211\n",
            "\n",
            "\n",
            "Metrics per class:\n",
            "  Clase 'lung': Sensitivity (Recall): 0.97, Specificity: 0.92\n",
            "  Clase 'vocal': Sensitivity (Recall): 0.92, Specificity: 0.97\n",
            "  Overall Accuracy: 0.95\n",
            "[Errores - Random Forest]\n",
            "  20220111120259_RARN_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220125155955_MMLJ%20es_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220115111646_EMPV_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220125162729_MCEE%20es_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20211216131859_JSR-scp_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220120143633_SBDS_lungback.webm | real: lung \u2192 pred: vocal\n",
            "  20220212064149_Rgh%2016-1_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220212065052_ATC%2017-1_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220108152718_PMAD_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220302053604_MLQ%20fe%202-2_vocal.webm | real: vocal \u2192 pred: lung\n",
            "\n",
            "=== Reporte para MLP Classifier ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        lung       0.94      0.98      0.96       134\n",
            "       vocal       0.96      0.90      0.93        77\n",
            "\n",
            "    accuracy                           0.95       211\n",
            "   macro avg       0.95      0.94      0.94       211\n",
            "weighted avg       0.95      0.95      0.95       211\n",
            "\n",
            "\n",
            "Metrics per class:\n",
            "  Clase 'lung': Sensitivity (Recall): 0.98, Specificity: 0.90\n",
            "  Clase 'vocal': Sensitivity (Recall): 0.90, Specificity: 0.98\n",
            "  Overall Accuracy: 0.95\n",
            "[Errores - MLP Classifier]\n",
            "  20220111120259_RARN_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220212065239_ATC%2017-2_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220125155955_MMLJ%20es_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220525090247_Pt_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220125162729_MCEE%20es_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20211216131859_JSR-scp_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220105133643_YE_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220124133907_GMK%20es_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220108152718_PMAD_lungfront.webm | real: lung \u2192 pred: vocal\n",
            "  20220302053604_MLQ%20fe%202-2_vocal.webm | real: vocal \u2192 pred: lung\n",
            "  20220107134757_OCAD_vocal.webm | real: vocal \u2192 pred: lung\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Crear tabla de m\u00e9tricas\n",
        "rows = []\n",
        "for model_name, predictions in model_predictions.items():\n",
        "    labels = sorted(set(true_labels + predictions))\n",
        "    cm = confusion_matrix(true_labels, predictions, labels=labels)\n",
        "\n",
        "    TP = np.diag(cm)\n",
        "    FN = np.sum(cm, axis=1) - TP\n",
        "    FP = np.sum(cm, axis=0) - TP\n",
        "    TN = np.sum(cm) - (FP + FN + TP)\n",
        "\n",
        "    sensitivity = TP / (TP + FN + 1e-10)\n",
        "    specificity = TN / (TN + FP + 1e-10)\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    for i, label in enumerate(labels):\n",
        "        rows.append({\n",
        "            \"Modelo\": model_name,\n",
        "            \"Clase\": label,\n",
        "            \"Recall (Sensibilidad)\": round(sensitivity[i], 2),\n",
        "            \"Specificity\": round(specificity[i], 2),\n",
        "            \"Accuracy Global\": round(accuracy, 2)\n",
        "        })\n",
        "\n",
        "# Mostrar como tabla con estilo (funciona en Colab)\n",
        "df_metrics = pd.DataFrame(rows)\n",
        "df_metrics.style.background_gradient(\n",
        "    subset=[\"Recall (Sensibilidad)\", \"Specificity\", \"Accuracy Global\"],\n",
        "    cmap=\"YlGn\"\n",
        ").format(precision=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AMrFMzJvw-DF",
        "outputId": "a32c6284-e214-4b1a-8cda-88851d6269dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7a1370a63cd0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_10949_row0_col2, #T_10949_row0_col3, #T_10949_row0_col4, #T_10949_row1_col2, #T_10949_row1_col3, #T_10949_row1_col4, #T_10949_row2_col2, #T_10949_row2_col3, #T_10949_row2_col4, #T_10949_row3_col2, #T_10949_row3_col3, #T_10949_row3_col4, #T_10949_row4_col2, #T_10949_row5_col3 {\n",
              "  background-color: #004529;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_10949_row4_col3, #T_10949_row5_col2, #T_10949_row6_col3, #T_10949_row7_col2 {\n",
              "  background-color: #e0f3a8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_10949_row4_col4, #T_10949_row5_col4 {\n",
              "  background-color: #d9f0a3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_10949_row6_col2, #T_10949_row7_col3 {\n",
              "  background-color: #1a7d40;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_10949_row6_col4, #T_10949_row7_col4, #T_10949_row8_col3, #T_10949_row8_col4, #T_10949_row9_col2, #T_10949_row9_col4 {\n",
              "  background-color: #ffffe5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_10949_row8_col2, #T_10949_row9_col3 {\n",
              "  background-color: #006435;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_10949\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_10949_level0_col0\" class=\"col_heading level0 col0\" >Modelo</th>\n",
              "      <th id=\"T_10949_level0_col1\" class=\"col_heading level0 col1\" >Clase</th>\n",
              "      <th id=\"T_10949_level0_col2\" class=\"col_heading level0 col2\" >Recall (Sensibilidad)</th>\n",
              "      <th id=\"T_10949_level0_col3\" class=\"col_heading level0 col3\" >Specificity</th>\n",
              "      <th id=\"T_10949_level0_col4\" class=\"col_heading level0 col4\" >Accuracy Global</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_10949_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_10949_row0_col0\" class=\"data row0 col0\" >Support Vector Machine (linear)</td>\n",
              "      <td id=\"T_10949_row0_col1\" class=\"data row0 col1\" >lung</td>\n",
              "      <td id=\"T_10949_row0_col2\" class=\"data row0 col2\" >0.99</td>\n",
              "      <td id=\"T_10949_row0_col3\" class=\"data row0 col3\" >0.99</td>\n",
              "      <td id=\"T_10949_row0_col4\" class=\"data row0 col4\" >0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_10949_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_10949_row1_col0\" class=\"data row1 col0\" >Support Vector Machine (linear)</td>\n",
              "      <td id=\"T_10949_row1_col1\" class=\"data row1 col1\" >vocal</td>\n",
              "      <td id=\"T_10949_row1_col2\" class=\"data row1 col2\" >0.99</td>\n",
              "      <td id=\"T_10949_row1_col3\" class=\"data row1 col3\" >0.99</td>\n",
              "      <td id=\"T_10949_row1_col4\" class=\"data row1 col4\" >0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_10949_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_10949_row2_col0\" class=\"data row2 col0\" >Logistic Regression</td>\n",
              "      <td id=\"T_10949_row2_col1\" class=\"data row2 col1\" >lung</td>\n",
              "      <td id=\"T_10949_row2_col2\" class=\"data row2 col2\" >0.99</td>\n",
              "      <td id=\"T_10949_row2_col3\" class=\"data row2 col3\" >0.99</td>\n",
              "      <td id=\"T_10949_row2_col4\" class=\"data row2 col4\" >0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_10949_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_10949_row3_col0\" class=\"data row3 col0\" >Logistic Regression</td>\n",
              "      <td id=\"T_10949_row3_col1\" class=\"data row3 col1\" >vocal</td>\n",
              "      <td id=\"T_10949_row3_col2\" class=\"data row3 col2\" >0.99</td>\n",
              "      <td id=\"T_10949_row3_col3\" class=\"data row3 col3\" >0.99</td>\n",
              "      <td id=\"T_10949_row3_col4\" class=\"data row3 col4\" >0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_10949_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_10949_row4_col0\" class=\"data row4 col0\" >Gradient Boosting</td>\n",
              "      <td id=\"T_10949_row4_col1\" class=\"data row4 col1\" >lung</td>\n",
              "      <td id=\"T_10949_row4_col2\" class=\"data row4 col2\" >0.99</td>\n",
              "      <td id=\"T_10949_row4_col3\" class=\"data row4 col3\" >0.92</td>\n",
              "      <td id=\"T_10949_row4_col4\" class=\"data row4 col4\" >0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_10949_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_10949_row5_col0\" class=\"data row5 col0\" >Gradient Boosting</td>\n",
              "      <td id=\"T_10949_row5_col1\" class=\"data row5 col1\" >vocal</td>\n",
              "      <td id=\"T_10949_row5_col2\" class=\"data row5 col2\" >0.92</td>\n",
              "      <td id=\"T_10949_row5_col3\" class=\"data row5 col3\" >0.99</td>\n",
              "      <td id=\"T_10949_row5_col4\" class=\"data row5 col4\" >0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_10949_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_10949_row6_col0\" class=\"data row6 col0\" >Random Forest</td>\n",
              "      <td id=\"T_10949_row6_col1\" class=\"data row6 col1\" >lung</td>\n",
              "      <td id=\"T_10949_row6_col2\" class=\"data row6 col2\" >0.97</td>\n",
              "      <td id=\"T_10949_row6_col3\" class=\"data row6 col3\" >0.92</td>\n",
              "      <td id=\"T_10949_row6_col4\" class=\"data row6 col4\" >0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_10949_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_10949_row7_col0\" class=\"data row7 col0\" >Random Forest</td>\n",
              "      <td id=\"T_10949_row7_col1\" class=\"data row7 col1\" >vocal</td>\n",
              "      <td id=\"T_10949_row7_col2\" class=\"data row7 col2\" >0.92</td>\n",
              "      <td id=\"T_10949_row7_col3\" class=\"data row7 col3\" >0.97</td>\n",
              "      <td id=\"T_10949_row7_col4\" class=\"data row7 col4\" >0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_10949_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_10949_row8_col0\" class=\"data row8 col0\" >MLP Classifier</td>\n",
              "      <td id=\"T_10949_row8_col1\" class=\"data row8 col1\" >lung</td>\n",
              "      <td id=\"T_10949_row8_col2\" class=\"data row8 col2\" >0.98</td>\n",
              "      <td id=\"T_10949_row8_col3\" class=\"data row8 col3\" >0.90</td>\n",
              "      <td id=\"T_10949_row8_col4\" class=\"data row8 col4\" >0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_10949_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_10949_row9_col0\" class=\"data row9 col0\" >MLP Classifier</td>\n",
              "      <td id=\"T_10949_row9_col1\" class=\"data row9 col1\" >vocal</td>\n",
              "      <td id=\"T_10949_row9_col2\" class=\"data row9 col2\" >0.90</td>\n",
              "      <td id=\"T_10949_row9_col3\" class=\"data row9 col3\" >0.98</td>\n",
              "      <td id=\"T_10949_row9_col4\" class=\"data row9 col4\" >0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar valor de true_labels\n",
        "print(len( ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehgJNripYXe5",
        "outputId": "de1166ac-e3e1-4453-acdb-cead1d76f2fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "for model_name, predictions in model_predictions.items():\n",
        "    model = cough_models[model_name]  # \u2705 Access the trained model\n",
        "    labels = sorted(set(true_labels + predictions))\n",
        "    cm = confusion_matrix(true_labels, predictions, labels=labels)\n",
        "\n",
        "    # Skip if not binary classification\n",
        "    if len(labels) != 2:\n",
        "        print(f\"\ud83d\udd36 {model_name}: solo matriz de confusi\u00f3n (no binario)\")\n",
        "        fig, ax = plt.subplots(figsize=(5, 4))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, ax=ax)\n",
        "        ax.set_title(f\"Matriz de Confusi\u00f3n\\n{model_name}\")\n",
        "        ax.set_xlabel(\"Predicted\")\n",
        "        ax.set_ylabel(\"True\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        continue\n",
        "\n",
        "    # Binarize ground truth\n",
        "    y_true_bin = label_binarize(true_labels, classes=labels).ravel()\n",
        "\n",
        "    # Predict probabilities if available\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        probs = model.predict_proba(test_embeddings_avg)\n",
        "        class_idx = list(model.classes_).index(labels[1])  # Take index of positive class\n",
        "        y_score = probs[:, class_idx]\n",
        "    else:\n",
        "        print(f\"\u26a0\ufe0f {model_name} no soporta predict_proba, usando predicciones binarias.\")\n",
        "        y_pred_bin = label_binarize(predictions, classes=labels).ravel()\n",
        "        y_score = y_pred_bin  # Fallback (step curve)\n",
        "\n",
        "    # Compute ROC and PRC\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin, y_score)\n",
        "    precision, recall, _ = precision_recall_curve(y_true_bin, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    prc_auc = auc(recall, precision)\n",
        "\n",
        "    # Plot: Confusion Matrix + ROC + PRC\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, ax=axs[0])\n",
        "    axs[0].set_title(f\"Matriz de Confusi\u00f3n\\n{model_name}\")\n",
        "    axs[0].set_xlabel(\"Predicted\")\n",
        "    axs[0].set_ylabel(\"True\")\n",
        "\n",
        "    axs[1].plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
        "    axs[1].plot([0, 1], [0, 1], 'k--')\n",
        "    axs[1].set_title(\"ROC Curve\")\n",
        "    axs[1].set_xlabel(\"False Positive Rate\")\n",
        "    axs[1].set_ylabel(\"True Positive Rate\")\n",
        "    axs[1].legend()\n",
        "    axs[1].grid(True)\n",
        "\n",
        "    axs[2].plot(recall, precision, label=f\"AUC = {prc_auc:.2f}\")\n",
        "    axs[2].set_title(\"Precision-Recall Curve\")\n",
        "    axs[2].set_xlabel(\"Recall\")\n",
        "    axs[2].set_ylabel(\"Precision\")\n",
        "    axs[2].legend()\n",
        "    axs[2].grid(True)\n",
        "\n",
        "    plt.suptitle(f\"Evaluaci\u00f3n del modelo: {model_name}\", fontsize=14, y=1.05)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RI41is5Jz046",
        "outputId": "9b26492b-28db-47cf-d1a9-a6052f2ec41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x500 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABv4AAAISCAYAAAAEOrjCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd8jef/x/H3OdlThMRuYqutlFpF7U219t5VWqWDaq1StanWaou2KGrV3kqpahUtatQeJUZISJBx7t8ffjlfRxISEidOXs/H4zw4133d9/257zsnue77c67rMhmGYQgAAAAAAAAAAADAM81s7wAAAAAAAAAAAAAAPDkSfwAAAAAAAAAAAIADIPEHAAAAAAAAAAAAOAASfwAAAAAAAAAAAIADIPEHAAAAAAAAAAAAOAASfwAAAAAAAAAAAIADIPEHAAAAAAAAAAAAOAASfwAAAAAAAAAAAIADIPEHAAAAAAAAAAAAOAASfwAAAADi6d+/v1xcXLR+/Xp7hwIAAAAAAJKIxB8AAACQQoYOHSqTyaSff/7Z3qEk6PTp0zKZTOrYseND6y1fvlwTJ07UjBkzVLt27acT3AOSGuujVK1aVSaTKWWCshPOxdMxZ84cmUwmzZkzx6bcZDKpatWqdokJ//Pzzz/LZDJp6NCh9g4FAAAASNNI/AEAAOCZFZcQedgrODjY3mE+U06dOqVOnTpp8ODB6ty5s73DgQOJiYnR3Llz1bhxY+XIkUNubm7y8vJSgQIF1LZtWy1btkwWi8XeYaYJiSUhk7re/S+z2Sw/Pz9VrlxZs2fPTp2AUwhJVgAAAODJOds7AAAAAOBJ5c2bV23btk1wmZ+f39MNJg3LkSOHDh8+rAwZMiRaZ//+/RoxYoTefPPNpxgZHN2ZM2fUtGlT7du3T5kzZ1b16tUVFBQki8WiU6dOad26dZo3b56aNGmiZcuW2TtcG4cPH5anp6e9w0iW6tWrq1KlSpLuJVzPnTunn376SZ07d9Y///yjsWPH2jnC5CtbtqwOHz6szJkz2zsUAAAAIE0j8QcAAIBnXr58+Rj+LQlcXFxUqFChh9Zp2rTpU4oG6UV4eLhq166to0eP6v3339fQoUPl4eFhUyc6Olrz58/XypUr7RRl4h71mUmLatSooQEDBtiUnT59WkWLFtWUKVM0fPjweNcgrfP09HwmrwUAAADwtDHUJwAAANKFyMhI+fj4KG/evInWKV68uDw8PBQeHi5J+u+//zRkyBC99NJLCgwMlJubm4KDg9WrVy9dvnw5Sft92LxUic3dtnXrVnXu3FkFCxaUt7e3vL29VaZMGc2cOTPR/Zw8eVLdu3dX7ty55ebmpsDAQFWtWtVmqMCHzRV35swZdenSRTly5JCrq6ty5sypLl266OzZs/Hqxs0VFx0draFDhyo4OFhubm4qUKCApk6dmqTzEic2NlajR49Wvnz55O7urnz58mnUqFEPHfLx8uXLeuedd5QvXz65ubkpc+bMatasmQ4ePJisfT/o/vNz+PBhNWjQQH5+fsqYMaNatWqlq1evSpJ27dql6tWry9fXVxkzZlTXrl0VERGR4DZnz56tcuXKWa9juXLlEh2+0V7nIiYmRhMmTFCJEiXk4eGhDBkyqFq1aimWhBs7dqyOHj2qDh06aPTo0QkmnFxcXNShQwctWLDApvz+eTPnzJmjF154QZ6entbhIMPCwjR69GhVqVJF2bNnl6urq7Jnz6727dvrxIkTCcYTGhqqnj17KkuWLPL09NSLL7740F6GiQ0/GRUVpQkTJuiFF16Ql5eXfHx8VLlyZa1YsSJe3Y4dO8pkMunUqVP6/PPPVahQIbm5uSkoKEjDhg2zucYdO3ZUp06dJEmdOnWyGbbzSQQHB6tgwYK6e/eubt68GW/5ypUrVa1aNWXIkEEeHh4qUaKEJkyYoJiYmAS3l5z6W7duVd26dZU9e3a5ubkpS5Ysqly5svV3WtzvSUnatm2bzTHHfV4S+10aHBys4OBg3bp1S2+//bZ1H8WLF9fixYsTjP306dNq0aKF/P395e3trSpVqmj79u1pfp5WAAAAICno8QcAAIB0wdPTU82aNdO3336rX3/9VRUqVLBZ/tdff+nAgQNq0aKFfH19JUnbt2/X+PHjVb16dZUrV04uLi7at2+fpk2bpvXr12vv3r0PHTbzcY0ePVrHjx/XSy+9pKZNm+rGjRtat26devTooaNHj2r8+PE29Xfs2KH69evr5s2bql27tlq2bKnr169r3759mjx5coKJvvsdO3ZMlSpV0pUrV9SwYUMVKVJEBw8e1KxZs7Ry5Urt2LFDBQoUiLdeq1at9Pvvv6tu3bpycnLSokWL9Oabb8rFxUXdunVL0rF2795ds2bNUu7cufXmm2/qzp07mjBhgn799dcE6584cUJVq1bV+fPnVatWLTVp0kSXL1/WkiVLtH79em3evFnlypVL0r4Tc+rUKVWoUEFlypRR165dtWfPHi1YsEDnzp3TZ599plq1aqlmzZrq3r27fv75Z33zzTeyWCyaNWuWzXbeeustTZkyRTly5FCXLl0kSUuWLFGnTp2s18be58IwDL322mv66aefVKBAAb355puKiIjQwoUL1ahRI02YMEHvvPOOzTrBwcE6c+aMTp06laQ5NOPmlfv4448fWdfZOeFb1LFjx2rr1q1q3LixatWqJScnJ0n3huEcPHiwqlWrpqZNm8rLy0tHjhzR/PnztXr1au3du1dBQUHW7URGRqpq1ao6cOCAypcvrypVqujcuXNq0aKFatWq9cj44ty9e1d16tTRzz//rJIlS6pLly6Kjo7W6tWr1bhxY02ZMkW9e/eOt957772nbdu2qUGDBqpdu7aWL1+uoUOHKioqSiNHjpQkNWnSRDdu3NBPP/2kxo0bq2TJkkmO62HOnDmjo0ePKmfOnAoMDLRZNmHCBPXv31/+/v5q3bq1vLy8tGLFCvXv31+//PKLli5dapN4TE791atXq2HDhvLz81Pjxo2VLVs2XblyRX/99Ze+//57de/eXcHBwRoyZIiGDRumoKAgm99ZSTn+6Oho1apVS9evX1ezZs0UGRmpBQsWqHnz5lq3bp3Ntb1w4YIqVKigixcvqk6dOipVqpSOHj2qmjVr6pVXXnmykwwAAACkBQYAAADwjDp16pQhycibN68xZMiQBF9r16611t+0aZMhyXjjjTfibat///6GJGPVqlXWspCQEOPmzZvx6n777beGJGPEiBE25UOGDDEkGVu3brWWbd261ZBkDBkyJNH4O3ToYFN+8uTJeHWjo6ONmjVrGk5OTsaZM2es5Xfu3DFy5MhhmM1mm2ONc+7cuUfur1q1aoYkY8aMGTblX375pSHJeOWVV2zKq1SpYkgyypUrZ4SFhVnLjxw5Yjg7OxsFCxaMF0dC4s5NiRIljFu3blnLz58/b2TOnDnBWCtUqGA4OTkZ69atsyk/evSo4ePjYxQrVizBWJMi7vxIMiZNmmQtt1gsRr169QxJhp+fn7F8+XLrsqioKKN48eKGs7OzcenSJWv5tm3bDEnG888/b9y4ccNaHhoaahQoUMCQZGzfvt3u5yLuZ7lKlSrG3bt3reVnzpwxMmfObDg7OxsnTpywWScoKMiQZJw6dSqxU2mzHUlGrly5Hlk3IXGfKS8vL+Pvv/+Ot/zGjRvGtWvX4pVv2bLFMJvNRteuXRPcXrdu3WzK161bZ732s2fPtlkWd37u9+GHHxqSjI8//tiwWCzW8vDwcKNMmTKGq6urceHCBWt5hw4dDElG7ty5jf/++89afuXKFcPPz8/w8fGxOf+zZ89OMJZHiVuvevXq1t+BgwYNMjp06GBkzJjRCAwMNDZt2mSzzvHjxw1nZ2cjMDDQOHv2rLX8zp07RqVKlQxJxnfffffY9V999VVDkrF///548V69etXmfULnOk5iv0vjfh4bN25scw7jft/Xrl3bpn7btm0NScbIkSNtyr/55hvrz8D9v8MBAACAZw2JPwAAADyz7k/UJPZ6++23rfVjY2ONHDlyGJkyZTKioqJsyrNly2YEBAQY0dHRj9yvxWIxfH19japVq9qUp1TiLzFLliwxJBlz5syxli1cuNCQZLRv3/6R6ye0v7jETOHChW0SGIZx77wUKlTIkGTzgD8ugbRly5Z4+4hbFh4e/sh4OnXqZEgylixZEm/ZJ598Ei/WvXv3GpKMzp07J7i9fv36GZKMAwcOxIsnKe5PJD94Lr777jtDklGtWrV46w0fPjze+ejcubMhyVi4cGG8+vPmzYt3HPY6F6+88oohydi9e3e8bYwcOdKQZAwfPtym/Pjx48bhw4dtPkOJ2b17tzVJnJCJEyfGS9Zfv37dujzuM/XOO+88cl8PKlasmBEcHGxTljt3bsPV1dW4ePFivPrVq1dPUuIvNjbWyJgxY4I/J4ZhGCtWrDAkGVOmTLGWxSX+Zs2aFa9+3LL7E5tPmvhL6OXs7Gz07t3bCAkJsVkn7ud39OjR8ba3c+fOeMn/5NaPS/wdPXr0kfE/SeIvoS9MBAUFGf7+/tb3d+7cMdzc3IzAwEDjzp07NnUtFotRsGBBEn8AAAB45jHUJwAAAJ55tWvX1rp16x5Zz2w2q02bNhozZozWrFmjxo0bS5I2b96sixcvqk+fPvGGGly6dKlmzJihvXv36vr164qNjbUu+++//1L2QP7fzZs3NW7cOC1fvlwnTpyIN3/c/fv9/fffJSlZwxTeb//+/ZKkKlWqxJtDzGw26+WXX9aRI0e0f/9+5cqVy2Z56dKl420vZ86ckqQbN27Ix8fnofv+66+/JEmVK1eOtyyhst9++02SFBISkuCciUeOHLH+W7Ro0Yfu+2GKFy8e71xky5ZNUsLDDsYtu/+67Nu3T5ISnBuuWrVqkv537iX7nYt9+/bJ09NTZcuWTVKckh46T2ZyTZo0SWfOnLEp69ixo/z8/GzKEoovzs8//6xJkyZp9+7dunr1qs0cc66urtb/h4eH69SpUypcuLCyZs0abzuVK1fW5s2bHxnz0aNHdf36dWXPnl3Dhg2Lt/zKlSuS/ncN7veoz0xKGTVqlAYMGCBJslgsunjxopYvX67+/ftrzZo1NsMUP+xntXz58nJ3d7f5GUhu/ZYtW2rp0qV66aWX1Lp1a1WvXl2VK1dW5syZU+ZgJfn5+Sl37tzxynPmzKldu3ZZ3x89elR3795VmTJl5ObmZlPXZDKpQoUKOnr0aIrFBQAAANgDiT8AAACkK+3atdOYMWM0d+5ca+Lv+++/ty673/jx4/Xuu+8qICBAtWrVUs6cOeXh4SHpXsLi7t27KR5fVFSUqlatqr1796pUqVJq166dMmXKJGdnZ50+fVrffvutzX7DwsIkSTly5His/YWHh0uSsmTJkuDyuKRWXL37xc2FeL+4xOn9CdLEhIWFyWw2J5gASCie0NBQSffmDFu9enWi230wUZpcDzuuhy2Ljo62loWHh8tsNisgICBe/SxZsshkMtmcU3udi/Dw8HgJ3TgPu/ZJFRd7Ykny06dPW/9fp04drV+//qHbedCPP/6oFi1ayNvbW7Vr11ZwcLA8PT1lMpk0Z84cm6Ri3HE8OL/do/bxoLhzf+jQIR06dCjRegmd+yf9zDwOs9msHDly6M0339TFixc1cuRIffHFFxo0aJCkh/8OMJlMypIliy5cuGAtS279119/XcuXL9eECRM0ffp0ffnllzKZTKpWrZrGjx+fInMYJjbXqrOzsywWS7zYn/RnAAAAAEjLSPwBAAAgXSlatKhKliypVatWKSwsTC4uLlq2bJkKFiyoF1980VovJiZGn3zyibJly6b9+/fbPCg2DENjxoxJ0v7MZrN1ew+KS9rd76efftLevXvVpUsXff311zbLFixYoG+//damLK5n1P0P2pMjLhEREhKS4PJLly7Z1EtJGTJkkMVi0dWrV+MlyBKKJy6GKVOmqHfv3ikeT0ry9fWVxWLRlStX4iUZLl++LMMwbM6pvc6Fr6+vLl++nOCylLj2QUFBypEjh86dO6cTJ048dm/BB3tgxhk6dKjc3d31559/Kn/+/DbLFixYYPM+7jgSO97EPgMPittOs2bNtHjx4iStk1aUK1dOkvTHH39Yy+7/HRAUFGRT3zAMhYSE2PwMJLe+JDVu3FiNGzfWzZs3tXPnTi1dulTffPON6tSpoyNHjsTr4ZlaUupnAAAAAEjLzPYOAAAAAHja2rVrpzt37mjx4sVatmyZbt26pbZt29rUuXr1qsLCwlS+fPl4iZs9e/bo9u3bSdpXxowZJSWcmIsbMu9+J06ckCRrb8T7/fLLL/HK4oZA3LBhQ5LieVBcb5vt27fLMAybZYZhaPv27Tb1UlKJEiUkJXxcCZXFJS3uH7ovrSpVqpSke8NQPiiu7P5zaq9zUapUKUVGRlqHjH1UnI+jU6dOkqSRI0c+0XYScuLECT3//PPxkn4XL17UyZMnbcp8fX2VO3duHT9+3JrUvF9C5zkhzz//vHx9fbVnzx6bXp4pycnJSVLK9wK8fv26JNn0gnvYz+ru3bt1584dm5+B5Na/n4+Pj+rUqaOZM2eqY8eOCgkJ0e7du63LzWZzqvV8lKSCBQvKzc1Nf/75Z7we24ZhPBO/WwAAAIBHIfEHAACAdKd169ZycnLS999/r++//14mkyle4i8wMFAeHh7au3evIiMjreXXr19Xnz59kryvggULysfHRytWrLAOESjd61kyYsSIePXjetDs2LHDpnzbtm366quv4tVv1KiRcubMqblz5yY4TOKjegI+99xzqlatmg4dOqRZs2bZLJs5c6YOHz6sV155JdHhIJ9E3NCqw4cPtxkW8cKFC5o8eXK8+mXLllW5cuX0ww8/aOHChfGWWywWbdu2LcXjfBwdOnSQJA0bNizekJ5x88LF1ZHsdy7iYhg4cKBNEuvcuXOaMGGCnJ2d1aZNG5t1Tpw4oSNHjiQ56fXee++pQIECmj17tgYOHKg7d+7EqxMTE/NYQ7QGBQXp+PHjNj217ty5ozfeeCPB+Nq1a6eoqCgNHjzYpnzDhg1Jmt9Pujd85BtvvKEzZ87o3XffTXA/Bw8eTLRXWVL4+/tLuncdUsqdO3c0depUSdLLL79sLW/durWcnZ01YcIEmyFZo6Ki9MEHH0i6N+/i49bfvn17gsm8uPPj7u5uLfP399f58+ef4Cgfzs3NTa+99ppCQkI0adIkm2XfffddgvMyAgAAAM8ahvoEAADAM+/48eMaOnRoossHDBhg83A5a9asqlGjhjZs2CCz2axKlSopODjYZh2z2axevXpp/PjxKlGihBo2bKjw8HCtXbtWQUFByp49e5Jic3V1VZ8+ffTpp5/qhRdesA53t3LlSlWpUsXawy9Ow4YNFRwcrDFjxujgwYMqWrSojh49qlWrVqlp06bxhhZ0c3PTokWLVKdOHdWtW1d16tRRiRIlFB4erv379ysyMjLBnoX3mzZtmipVqqRu3bpp5cqVKly4sA4dOqQVK1YoICBA06ZNS9KxJle1atXUqVMnzZ49W8WKFVPTpk119+5dLVy4UC+99JJWrVoVb50ffvhB1apVU8uWLTVp0iS98MIL8vDw0NmzZ7Vr1y5duXIlwcTS0/byyy+rT58+mjJliooWLapmzZrJMAwtWbJE58+f11tvvWWTfLHXuWjXrp2WLl2qn376ScWLF1eDBg0UERGhhQsXKjQ0VOPHj1eePHls1qlevbrOnDmjU6dOxfvcJMTX11cbNmxQkyZN9Nlnn+nrr79WjRo1FBQUpJiYGF28eFGbN29WSEiIihYtmqxhH/v06aM+ffqoVKlSeu211xQTE6ONGzfKMAyVKFFCf/31l039999/X0uXLtVXX32lQ4cO6eWXX9a5c+e0aNEi1a9f/6HzJd5v2LBh2rt3rz7//HOtXr1aL7/8sgIDA3XhwgUdOHBAf/31l3bt2pXoXHKPUr58eXl4eGjSpEm6fv26dfjXjz76KEnrb9q0yXrtLRaLLl26pLVr1+r8+fMqWbKkevXqZa2bN29ejR49Wv3791fx4sXVvHlzeXl5aeXKlTp69KgaN25s88WI5NZ/66239N9//1l/z5pMJu3YsUO///67XnrpJVWqVMla95VXXtGiRYvUpEkTlSpVSk5OTmrUqJGKFy/+WOcxIaNGjdKmTZs0YMAAbdu2TaVKlbL+jq1Tp47WrVtnHaIZAAAAeCYZAAAAwDPq1KlThqRHvq5fvx5v3blz51qXz5gxI8HtR0VFGSNHjjTy589vuLm5Gc8995zRv39/4+bNm0ZQUJARFBRkU3/IkCGGJGPr1q025bGxscbQoUONXLlyGa6urkaBAgWMyZMnGydPnjQkGR06dLCpf/LkSaNZs2ZGQECA4enpabz44ovGggULjK1btxqSjCFDhsSL9fjx40aXLl2MnDlzGi4uLkZgYKBRtWpV47vvvot3vh7cn2EYxunTp41OnToZ2bJlM5ydnY1s2bIZnTp1Mk6fPh2vbpUqVYzEbiU6dOhgSDJOnTqV4PIHxcTEGKNGjTLy5MljuLq6Gnny5DE+/fRT4/jx44nGGhoaanz00UdG0aJFDQ8PD8Pb29vInz+/0bp1a2Pp0qVJjvVBDzs/Dzv3s2fPNiQZs2fPjrds1qxZxosvvmh4enpar+WsWbMS3L+9zkV0dLQxbtw4o1ixYoabm5vh4+NjVKlSxfjpp58SjDMoKChZ1/j+/Xz33XdGgwYNjGzZshmurq6Gp6enkTdvXqNly5bGsmXLjJiYGJt1EvtMxbFYLMb06dONIkWKGO7u7kbWrFmNLl26GJcvX070eK9du2Z0797dCAgIMNzd3Y3SpUsbS5cuTfQ6SjKqVKkSbzsxMTHGjBkzjIoVKxq+vr7W3xF16tQxpk2bZty6dcta92Gfi8SOcfXq1caLL75oeHh4WH9XPUrcMTz48vLyMkqWLGmMGDHCiIiISHDdn376yahSpYrh4+NjuLm5GcWKFTPGjx9vREdHP1H9BQsWGM2bNzfy5s1reHp6GhkyZDBKlChhjB492rh586ZN3YsXLxrNmzc3MmfObJjNZpvrkdhnMKHfxXES+xk4efKk8frrrxsZMmQwPD09jcqVKxvbtm0zevfubUgy9u3bl+D2AAAAgGeByTAemMgDAAAAAAAgnalUqZJ27dqlsLAweXt72zscAAAA4LEwfgUAAAAAAEg3Ll68GK9s7ty52rlzp2rUqEHSDwAAAM80evwBAAAAAIB0I1OmTCpVqpQKFy4sJycn7d+/Xz///LN8fHy0c+dOFStWzN4hAgAAAI+NxB8AAAAAAEg3Bg0apJUrV+rs2bOKiIhQQECAqlWrpo8//liFChWyd3gAAADAEyHxBwAAAAAAAAAAADgA5vgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwAAAAAAAAAAAMABkPgDAAAAAAAAAAAAHACJPwBIhqVLl2rcuHGKjY21dygAAAAAAAAAANgg8QfYwdChQ2UymVJ1HyaTSUOHDk3VfTxtY8eOVZ48eeTk5KSSJUum+PY7duyo4ODgRJf/+uuvatOmjQoXLiwnJ6cU3z8AAAAAAAAAAE+CxB8c2pw5c2QymWQymbRjx454yw3DUK5cuWQymdSgQYPH2senn36q5cuXP2Gkz4bY2FjNnj1bVatWlb+/v9zc3BQcHKxOnTppz549qbrvDRs26P3331fFihU1e/Zsffrpp6m6vwddu3ZNLVu21Oeff6569eo91X0DAAAAAAAAAJAUJP6QLri7u2v+/Pnxyrdt26bz58/Lzc3tsbf9OIm/jz76SLdv337sfdrD7du31aBBA3Xu3FmGYejDDz/UtGnT1L59e+3atUtly5bV+fPnU23/W7Zskdls1jfffKP27dunSvLtq6++0tGjRxNctm/fPo0YMULdunVL8f0CAAAAAAAAAJASnO0dAPA01KtXTz/++KM+//xzOTv/78d+/vz5Kl26tK5evfpU4oiIiJCXl5ecnZ1t4ngWvPfee1q3bp0mTpyovn372iwbMmSIJk6cmKr7v3z5sjw8POTq6ppq+3BxcUl0WY0aNVJtvwAAAAAAAAAApAR6/CFdaNWqla5du6aNGzday6KiorR48WK1bt06wXXGjRunChUqKFOmTPLw8FDp0qW1ePFimzomk0kRERH69ttvrUOKduzYUdL/5vH7559/1Lp1a2XMmFGVKlWyWRanY8eO1vUffD1qnr67d+/qnXfeUUBAgHx8fNSoUaNEe95duHBBnTt3VpYsWeTm5qYiRYpo1qxZjzp9On/+vGbMmKGaNWvGS/pJkpOTk959913lzJnTWrZv3z7VrVtXvr6+8vb2VvXq1fXbb7/ZrBc3FOvOnTvVr18/BQQEyMvLS02bNtWVK1es9Uwmk2bPnq2IiAjreZkzZ45Onz5t/f+DHjx3N2/eVN++fRUcHCw3NzcFBgaqZs2a2rt3r7VOQnP8RUREqH///sqVK5fc3NxUsGBBjRs3ToZhxNtf7969tXz5chUtWtR6ftetW/fI8wsAAAAAAAAAQEp4trocAY8pODhY5cuX1w8//KC6detKktauXauwsDDrvG0Pmjx5sho1aqQ2bdooKipKCxYs0Ouvv65Vq1apfv36kqTvv/9eXbt2VdmyZdW9e3dJUt68eW228/rrryt//vz69NNP4yWL4vTo0SNej7J169Zp3rx5CgwMfOixde3aVXPnzlXr1q1VoUIFbdmyxRrf/UJCQvTSSy9ZE1QBAQFau3atunTpovDw8AQTenHWrl2rmJgYtWvX7qGxxDl06JAqV64sX19fvf/++3JxcdGMGTNUtWpVbdu2TeXKlbOp36dPH2XMmFFDhgzR6dOnNWnSJPXu3VsLFy6UdO88z5w5U7///ru+/vprSVKFChWSFEucnj17avHixerdu7cKFy6sa9euaceOHTp8+LBeeOGFBNcxDEONGjXS1q1b1aVLF5UsWVLr16/Xe++9pwsXLsTr5bhjxw4tXbpUvXr1ko+Pjz7//HM1a9ZMZ8+eVaZMmZIVLwAAAAAAAAAAyUXiD+lG69atNXDgQN2+fVseHh6aN2+eqlSpouzZsydY/9ixY/Lw8LC+7927t1544QVNmDDBmlhr27atevbsqTx58qht27YJbqdEiRIJzi94v/Lly6t8+fLW98ePH1fv3r1Vs2ZN9ejRI9H1/vrrL82dO1e9evXSl19+KUl688031aZNG/399982dQcNGqTY2FgdOHDAmoTq2bOnWrVqpaFDh6pHjx42x3u/w4cPS5KKFSv20OOI89FHHyk6Olo7duxQnjx5JEnt27dXwYIF9f7772vbtm029TNlyqQNGzZYe0FaLBZ9/vnnCgsLU4YMGdS2bVtt2rRJe/futTnPp0+fTlI8krR69Wp169ZN48ePt5a9//77D11nxYoV2rJli0aMGKFBgwZJund+X3/9dU2ePFm9e/e2SfQePnxY//zzj7WsWrVqKlGihH744Qf17t07ybECAAAAAAAAAPA4GOoT6Ubz5s11+/ZtrVq1Sjdv3tSqVasSHeZTkk0S7Pr16woLC1PlypVthoZMip49eyarfkREhJo2baqMGTPqhx9+kJOTU6J116xZI0l66623bMof7L1nGIaWLFmihg0byjAMXb161fqqXbu2wsLCHnpc4eHhkiQfH59Hxh8bG6sNGzaoSZMm1qSfJGXLlk2tW7fWjh07rNuL0717d5uhTytXrqzY2FidOXPmkftLKj8/P+3evVv//fdfktdZs2aNnJyc4p3f/v37yzAMrV271qa8Ro0aNonA4sWLy9fXVydPnnyy4AEAAAAAAAAASAJ6/CHdCAgIUI0aNTR//nxFRkYqNjZWr732WqL1V61apREjRmj//v26e/eutfz+BFVS5M6dO1n1u3XrphMnTujXX3995PCQZ86ckdlsjje8aMGCBW3eX7lyRTdu3NDMmTM1c+bMBLd1+fLlRPfj6+sr6d48eY9y5coVRUZGxotBkp5//nlZLBadO3dORYoUsZY/99xzNvUyZswo6V7CNaWMGTNGHTp0UK5cuVS6dGnVq1dP7du3t0lOPujMmTPKnj17vITn888/b11+vwePQ7p3LCl5HAAAAAAAAAAAJIbEH9KV1q1bq1u3brp06ZLq1q0rPz+/BOv98ssvatSokV5++WVNnTpV2bJlk4uLi2bPnv3IYTsflNjwmQmZPHmyfvjhB82dO1clS5ZM1n4exmKxSLo3NGmHDh0SrFO8ePFE1y9UqJAk6cCBAykaV5zEejUmNidinMSSsLGxsfHKmjdvrsqVK2vZsmXasGGDxo4dq9GjR2vp0qXWeR+f1OMeBwAAAAAAAAAAKYHEH9KVpk2bqkePHvrtt9+0cOHCROstWbJE7u7uWr9+vdzc3Kzls2fPjlc3uT0AE/PLL7/o3XffVd++fdWmTZskrRMUFCSLxaITJ07Y9LA7evSoTb2AgAD5+PgoNjZWNWrUSHZsdevWlZOTk+bOnat27do9tG5AQIA8PT3jxSBJR44ckdlsVq5cuZIdQ0LiegbeuHHDpjyxIUKzZcumXr16qVevXrp8+bJeeOEFjRw5MtHEX1BQkDZt2qSbN2/a9Po7cuSIdTkAAAAAAAAAAGkFc/whXfH29ta0adM0dOhQNWzYMNF6Tk5OMplMNj3HTp8+reXLl8er6+XlFS/xlFwXL15U8+bNValSJY0dOzbJ68UlrD7//HOb8kmTJtm8d3JyUrNmzbRkyRIdPHgw3nauXLny0P3kypVL3bp104YNGzRlypR4yy0Wi8aPH6/z58/LyclJtWrV0k8//aTTp09b64SEhGj+/PmqVKmSdejQJ+Xr66vMmTNr+/btNuVTp061eR8bG6uwsDCbssDAQGXPnt1mGNcH1atXT7Gxsfriiy9syidOnCiTyZRiPQUBAAAAAAAAAEgJ9PhDupPYUJf3q1+/viZMmKA6deqodevWunz5sr788kvly5dPf//9t03d0qVLa9OmTZowYYKyZ8+u3Llzq1y5csmK6a233tKVK1f0/vvva8GCBTbLihcvnugwnCVLllSrVq00depUhYWFqUKFCtq8ebOOHz8er+5nn32mrVu3qly5curWrZsKFy6s0NBQ7d27V5s2bVJoaOhDYxw/frxOnDiht956S0uXLlWDBg2UMWNGnT17Vj/++KOOHDmili1bSpJGjBihjRs3qlKlSurVq5ecnZ01Y8YM3b17V2PGjEnWuXmUrl276rPPPlPXrl1VpkwZbd++XceOHbOpc/PmTeXMmVOvvfaaSpQoIW9vb23atEl//PGHxo8fn+i2GzZsqGrVqmnQoEE6ffq0SpQooQ0bNuinn35S3759482tCAAAAAAAAACAPZH4AxLwyiuv6JtvvtFnn32mvn37Knfu3Bo9erROnz4dL/E3YcIEde/eXR999JFu376tDh06JDvxd+XKFcXGxqpfv37xlg0ZMuSh8+/NmjVLAQEBmjdvnpYvX65XXnlFq1evjjecZpYsWfT7779r+PDhWrp0qaZOnapMmTKpSJEiGj169CNj9PT01Nq1azVnzhx9++23+uSTTxQZGans2bPrlVde0bx585QjRw5JUpEiRfTLL79o4MCBGjVqlCwWi8qVK6e5c+cm+9w8yuDBg3XlyhUtXrxYixYtUt26dbV27VoFBgbaxN6rVy9t2LBBS5culcViUb58+TR16lS98cYbiW7bbDZrxYoVGjx4sBYuXKjZs2crODhYY8eOVf/+/VP0OAAAAAAAAAAAeFImwzAMewcBAAAAAAAAAAAA4Mkwxx8AAAAAAAAAAADgAEj8AQAAAAAAAAAAAA6AxB8AAAAAAAAAAADgAEj8AQAAAAAAAAAAAA6AxB8AAAAAAAAAAADgAEj8AQAAAAAAAAAAAA6AxB+QhnTs2FHBwcE2ZSaTSUOHDrVLPI6I8wkAAAAAAPBsSujZ2aP8/PPPMplM+vnnn1Mlpmdd1apVVbVqVev706dPy2Qyac6cOXaLCcCTIfEHSDp16pR69+6tAgUKyNPTU56enipcuLDefPNN/f333/YOL9XNnz9fkyZNSnL94OBgmUwm68vd3V358+fXe++9p9DQ0NQLNInWrFlDcg8AADyT5syZY9POcnZ2Vo4cOdSxY0dduHAhwXUMw9D333+vl19+WX5+fvL09FSxYsU0fPhwRUREJLqvZcuWqW7dusqcObNcXV2VPXt2NW/eXFu2bElSrHfu3NHEiRNVrlw5ZciQQe7u7ipQoIB69+6tY8eOPdbxAwCAtOXBtsn9f+9DQkLsHV6aF5dEi3uZzWb5+/urbt262rVrl73DSxEhISF69913VahQIXl6esrLy0ulS5fWiBEjdOPGDXuHB6RLzvYOALC3VatWqUWLFnJ2dlabNm1UokQJmc1mHTlyREuXLtW0adN06tQpBQUF2SW+27dvy9k5dT+q8+fP18GDB9W3b98kr1OyZEn1799f0r2HPn/++acmTZqkbdu26ffff0+lSJNmzZo1+vLLLxNM/j2N8wkAAPCkhg8frty5c+vOnTv67bffNGfOHO3YsUMHDx6Uu7u7tV5sbKxat26tRYsWqXLlyho6dKg8PT31yy+/aNiwYfrxxx+1adMmZcmSxbqOYRjq3Lmz5syZo1KlSqlfv37KmjWrLl68qGXLlql69erauXOnKlSokGh8V69eVZ06dfTnn3+qQYMGat26tby9vXX06FEtWLBAM2fOVFRUVKqeIwAA8PTc3zbZsWOHpk2bpjVr1ujgwYPy9PR8anF89dVXslgsyVrn5Zdf1u3bt+Xq6ppKUT1aq1atVK9ePcXGxurYsWOaOnWqqlWrpj/++EPFihWzW1xP6o8//lC9evV069YttW3bVqVLl5Yk7dmzR5999pm2b9+uDRs22DlKIP3h6TfStRMnTqhly5YKCgrS5s2blS1bNpvlo0eP1tSpU2U2P7xzbEREhLy8vFIlxvsf7KQlOXLkUNu2ba3vu3btKm9vb40bN07//vuv8ufPb8foEpdWzycAAMD96tatqzJlyki6187KnDmzRo8erRUrVqh58+bWemPGjNGiRYv07rvvauzYsdby7t27q3nz5mrSpIk6duyotWvXWpeNHz9ec+bMUd++fTVhwgSZTCbrskGDBun7779/5BelOnbsqH379mnx4sVq1qyZzbJPPvlEgwYNeqLjjxMTEyOLxWLXB3UAACB+2yRTpkyaMGGCfvrpJ7Vq1SrBdVLjeZmLi0uy1zGbzXZ/HvTCCy/YPEerXLmy6tatq2nTpmnq1Kl2jOzx3bhxQ02bNpWTk5P27dunQoUK2SwfOXKkvvrqqxTZV2o+ewUcEUN9Il0bM2aMIiIiNHv27HhJP0lydnbWW2+9pVy5clnLOnbsKG9vb504cUL16tWTj4+P2rRpI0n65Zdf9Prrr+u5556Tm5ubcuXKpXfeeUe3b9+Ot+3ly5eraNGicnd3V9GiRbVs2bIEY0xoTroLFy6oc+fOypIli9zc3FSkSBHNmjXLpk7c+OWLFi3SyJEjlTNnTrm7u6t69eo6fvy4tV7VqlW1evVqnTlzxjrsQHLHSo+TNWtWSYr3oGjLli2qXLmyvLy85Ofnp8aNG+vw4cPx1t+3b5/q1q0rX19feXt7q3r16vrtt99s6kRHR2vYsGHKnz+/3N3dlSlTJlWqVEkbN26UdO/6fPnll9ZzF/eK8+D5HDp0qEwmk44fP66OHTvKz89PGTJkUKdOnRQZGWmz79u3b+utt95S5syZ5ePjo0aNGunChQvMGwgAAFJd5cqVJd374lqc27dva+zYsSpQoIBGjRoVb52GDRuqQ4cOWrdunbVNdfv2bY0aNUqFChXSuHHjbNpJcdq1a6eyZcsmGsvu3bu1evVqdenSJV7ST5Lc3Nw0btw46/sH542J8+AcPXFDYY0bN06TJk1S3rx55ebmpn379snZ2VnDhg2Lt42jR4/KZDLpiy++sJbduHFDffv2Va5cueTm5qZ8+fJp9OjRye4dAAAAEvfKK69Iujd9jvTw52UWi0WTJk1SkSJF5O7urixZsqhHjx66fv16vO2uXbtWVapUkY+Pj3x9ffXiiy9q/vz51uUJzfG3YMEClS5d2rpOsWLFNHnyZOvyxOb4+/HHH1W6dGl5eHgoc+bMatu2bbyh1eOO68KFC2rSpIm8vb0VEBCgd999V7GxsY99/hJq20lJb8dYLBZNnjxZxYoVk7u7uwICAlSnTh3t2bPHWmf27Nl65ZVXFBgYKDc3NxUuXFjTpk177JgfNGPGDF24cEETJkyIl/STpCxZsuijjz6yvk/s+VlwcLA6duxofR83vOy2bdvUq1cvBQYGKmfOnFq8eLG1PKFYTCaTDh48aC07cuSIXnvtNfn7+8vd3V1lypTRihUrnuyggWcEPf6Qrq1atUr58uVTuXLlkrVeTEyMateurUqVKmncuHHWIQ1+/PFHRUZG6o033lCmTJn0+++/a8qUKTp//rx+/PFH6/obNmxQs2bNVLhwYY0aNUrXrl1Tp06dlDNnzkfuOyQkRC+99JJMJpN69+6tgIAArV27Vl26dFF4eHi84To/++wzmc1mvfvuuwoLC9OYMWPUpk0b7d69W9K9b3WHhYXp/PnzmjhxoiTJ29v7kXFER0fr6tWrku4N9blv3z5NmDBBL7/8snLnzm2tt2nTJtWtW1d58uTR0KFDdfv2bU2ZMkUVK1bU3r17rY21Q4cOqXLlyvL19dX7778vFxcXzZgxQ1WrVtW2bdus12jo0KEaNWqUunbtqrJlyyo8PFx79uzR3r17VbNmTfXo0UP//fefNm7cqO+///6RxxGnefPmyp07t0aNGqW9e/fq66+/VmBgoEaPHm2t07FjRy1atEjt2rXTSy+9pG3btql+/fpJ3gcAAMDjOn36tCQpY8aM1rIdO3bo+vXrevvttxPtode+fXvNnj1bq1at0ksvvaQdO3YoNDRUffv2lZOT02PFEvfApF27do+1/qPMnj1bd+7cUffu3eXm5qZs2bKpSpUqWrRokYYMGWJTd+HChXJyctLrr78uSYqMjFSVKlV04cIF9ejRQ88995x+/fVXDRw4UBcvXkzWvNYAACBxcQmrTJkyWcsSe17Wo0cPzZkzR506ddJbb72lU6dO6YsvvtC+ffu0c+dOay++OXPmqHPnzipSpIgGDhwoPz8/7du3T+vWrVPr1q0TjGPjxo1q1aqVqlevbn2Gc/jwYe3cuVNvv/12ovHHxfPiiy9q1KhRCgkJ0eTJk7Vz507t27dPfn5+1rqxsbGqXbu2ypUrp3HjxmnTpk0aP3688ubNqzfeeOOxzl9CbbvktGO6dOmiOXPmqG7duuratatiYmL0yy+/6LfffrP2zJw2bZqKFCmiRo0aydnZWStXrlSvXr1ksVj05ptvPlbc91uxYoU8PDz02muvPfG2EtKrVy8FBARo8ODBioiIUP369eXt7a1FixapSpUqNnUXLlyoIkWKqGjRopLuPWesWLGicuTIoQEDBsjLy0uLFi1SkyZNtGTJEjVt2jRVYgbSDANIp8LCwgxJRpMmTeItu379unHlyhXrKzIy0rqsQ4cOhiRjwIAB8da7v16cUaNGGSaTyThz5oy1rGTJkka2bNmMGzduWMs2bNhgSDKCgoJs1pdkDBkyxPq+S5cuRrZs2YyrV6/a1GvZsqWRIUMGawxbt241JBnPP/+8cffuXWu9yZMnG5KMAwcOWMvq168fb78PExQUZEiK96pYsWK8uEqWLGkEBgYa165ds5b99ddfhtlsNtq3b28ta9KkieHq6mqcOHHCWvbff/8ZPj4+xssvv2wtK1GihFG/fv2Hxvfmm28aif16e/B8DhkyxJBkdO7c2aZe06ZNjUyZMlnf//nnn4Yko2/fvjb1OnbsGG+bAAAAj2v27NmGJGPTpk3GlStXjHPnzhmLFy82AgICDDc3N+PcuXPWupMmTTIkGcuWLUt0e6GhoYYk49VXXzUM439twYet8yhNmzY1JBnXr19PUv0qVaoYVapUiVfeoUMHmzboqVOnDEmGr6+vcfnyZZu6M2bMiNeGNQzDKFy4sPHKK69Y33/yySeGl5eXcezYMZt6AwYMMJycnIyzZ88mKWYAAHBPQm2TBQsWGJkyZTI8PDyM8+fPG4aR+POyX375xZBkzJs3z6Z83bp1NuU3btwwfHx8jHLlyhm3b9+2qWuxWKz/f7D98Pbbbxu+vr5GTExMoscQ94xs69athmEYRlRUlBEYGGgULVrUZl+rVq0yJBmDBw+22Z8kY/jw4TbbLFWqlFG6dOlE9xknrn0zbNgw48qVK8alS5eMX375xXjxxRcNScaPP/5orZvUdsyWLVsMScZbb70Vb3/3n6uEnlPWrl3byJMnj03Zg221uJhnz5790GPLmDGjUaJEiYfWuV9iz8+CgoKMDh06WN/H/cxVqlQp3nVt1aqVERgYaFN+8eJFw2w221yj6tWrG8WKFTPu3LljLbNYLEaFChWM/PnzJzlm4FnFUJ9It8LDwyUl3LutatWqCggIsL7iho68X0Lf6PHw8LD+PyIiQlevXlWFChVkGIb27dsnSbp48aL279+vDh06KEOGDNb6NWvWVOHChR8as2EYWrJkiRo2bCjDMHT16lXrq3bt2goLC9PevXtt1unUqZPNnChxQwmcPHnyoft6lHLlymnjxo3auHGjVq1apZEjR+rQoUNq1KiRdWjTuGPt2LGj/P39resWL15cNWvW1Jo1ayTd++bUhg0b1KRJE+XJk8daL1u2bGrdurV27NhhvV5+fn46dOiQ/v333yeK/0E9e/a0eV+5cmVdu3bNut9169ZJuvdto/v16dMnReMAAACQpBo1aiggIEC5cuXSa6+9Ji8vL61YscJmhIibN29Kknx8fBLdTtyyuDZN3L8PW+dRUmIbD9OsWTMFBATYlL366qtydnbWwoULrWUHDx7UP//8oxYtWljLfvzxR1WuXFkZM2a0aSvXqFFDsbGx2r59e6rEDACAo7u/bdKyZUt5e3tr2bJlypEjh029B5+X/fjjj8qQIYNq1qxp87e5dOnS8vb21tatWyXd67l38+ZNDRgwIN58fAkNTR7Hz89PERER1ilgkmLPnj26fPmyevXqZbOv+vXrq1ChQlq9enW8dRJ6bpScZ2tDhgxRQECAsmbNqsqVK+vw4cMaP368TW+5pLZjlixZIpPJFG8kBMn2XN3/nDIsLExXr15VlSpVdPLkSYWFhSU59sSEh4enWntQkrp16xZvhIoWLVro8uXLNsO2Ll68WBaLxdomDA0N1ZYtW9S8eXPdvHnTeh6vXbum2rVr699//403pCvgaBjqE+lW3B+mW7duxVs2Y8YM3bx5UyEhITYT78ZxdnZOcFjOs2fPavDgwVqxYkW8ccrj/qCeOXNGkpQ/f/546xcsWDBe4u5+V65c0Y0bNzRz5kzNnDkzwTqXL1+2ef/cc8/ZvI8bQiChcdSTI3PmzKpRo4b1ff369VWwYEG99tpr+vrrr9WnTx/rsRYsWDDe+s8//7zWr1+viIgI3bx5U5GRkYnWs1gsOnfunIoUKaLhw4ercePGKlCggIoWLao6deqoXbt2Kl68+BMdz8POk6+vr86cOSOz2WwzjKkk5cuX74n2CwAAkJAvv/xSBQoUUFhYmGbNmqXt27fLzc3Npk5cezYuAZiQB5ODvr6+j1znUe7fxv3DYKWUB9tb0r22Z/Xq1bVo0SJ98sknku4N6eTs7KxXX33VWu/ff//V33//HS9xGOfBtjIAAEiauLaJs7OzsmTJooIFC8pstu1TktDzsn///VdhYWEKDAxMcLtxf5vjhg6NG6oxqXr16qVFixapbt26ypEjh2rVqqXmzZurTp06ia7zsOdVhQoV0o4dO2zK4ubQu1/GjBltnq1duXLFZs4/b29vm84G3bt31+uvv647d+5oy5Yt+vzzz+PNEZjUdsyJEyeUPXt2my/ZJ2Tnzp0aMmSIdu3apcjISJtlYWFhNh0SHoevr+8TtSkfJaE2YZ06dZQhQwYtXLhQ1atXl3SvTViyZEkVKFBAknT8+HEZhqGPP/5YH3/8cYLbvnz5crykNeBISPwh3cqQIYOyZctmM+lrnLj55OLG236Qm5tbvMZNbGysatasqdDQUH3wwQcqVKiQvLy8dOHCBXXs2DHeJLyPI24bbdu2VYcOHRKs82ACLLG5WwzDeOJ4HhT3B3f79u2p1hPu5Zdf1okTJ/TTTz9pw4YN+vrrrzVx4kRNnz5dXbt2feztPs3zBAAA8Chly5a1zs/SpEkTVapUSa1bt9bRo0etD5Gef/55SdLff/+tJk2aJLidv//+W5KsI0sUKlRIknTgwIFE13mU+7cRN5rEw5hMpgTbVA8+7Ipz/7fT79eyZUt16tRJ+/fvV8mSJbVo0SJVr15dmTNnttaxWCyqWbOm3n///QS3EfdACAAAJM/9bZPEJPS8zGKxKDAwUPPmzUtwncSSXEkVGBio/fv3a/369Vq7dq3Wrl2r2bNnq3379vr222+faNtxkjIv8osvvmhNKEr3evgNHTrU+j5//vzWL9A3aNBATk5OGjBggKpVq2Y9rynZjjlx4oSqV6+uQoUKacKECcqVK5dcXV21Zs0aTZw4MUWeUxYqVEj79+9XVFSUzWhjyZWcNqGbm5uaNGmiZcuWaerUqQoJCdHOnTv16aefWuvEHdu7776r2rVrJ7htvsgPR0fiD+la/fr19fXXX+v3339X2bJln2hbBw4c0LFjx/Ttt9+qffv21vIHhxoICgqSpASHqjx69OhD9xEQECAfHx/Fxsba9LZ7Ug8bMiE5YmJiJP2vF2XcsSZ0XEeOHFHmzJnl5eUld3d3eXp6JlrPbDYrV65c1jJ/f3916tRJnTp10q1bt/Tyyy9r6NCh1sRfSh3P/YKCgmSxWHTq1Cmb3prHjx9P8X0BAADcz8nJSaNGjVK1atX0xRdfaMCAAZKkSpUqyc/PT/Pnz9egQYMSfCj13XffSbr3gClunYwZM+qHH37Qhx9+mKQHWQ9q2LChRo0apblz5yYp8ZcxY8YEh8K6/+FYUjRp0kQ9evSwDvd57NgxDRw40KZO3rx5devWrRRtKwMAgMeXN29ebdq0SRUrVkz0yz1x9aR7Q3knNynj6uqqhg0bqmHDhrJYLOrVq5dmzJihjz/+OMFt3f+86pVXXrFZdvToUevy5Jg3b5516htJNlPZJGTQoEH66quv9NFHH1mnl0lqOyZv3rxav369QkNDE+31t3LlSt29e1crVqywGeUqbmjVlNCwYUPt2rVLS5YsUatWrR5ZP2PGjLpx44ZNWVRUlC5evJis/bZo0ULffvutNm/erMOHD8swDJuh3+POvYuLC21CpFvM8Yd07f3335enp6c6d+6skJCQeMuT09sr7qHJ/esYhqHJkyfb1MuWLZtKliypb7/91mY87Y0bN+qff/555D6aNWumJUuWJNhT8cqVK0mO935eXl4pMrb3ypUrJUklSpSQZHus9/9hP3jwoDZs2KB69epJundctWrV0k8//WTTyzIkJETz589XpUqVrENKXbt2zWaf3t7eypcvn+7evWtzPJLiNSaeRNw3hKZOnWpTPmXKlBTbBwAAQGKqVq2qsmXLatKkSbpz544kydPTU++++66OHj2qQYMGxVtn9erVmjNnjmrXrq2XXnrJus4HH3ygw4cP64MPPkiwvTt37lz9/vvvicZSvnx51alTR19//bWWL18eb3lUVJTeffdd6/u8efPqyJEjNm3Vv/76Szt37kzy8Uv35vCpXbu2Fi1apAULFsjV1TVer8XmzZtr165dWr9+fbz1b9y4Yf2iGgAAeDqaN2+u2NhY61Dd94uJibE+u6lVq5Z8fHw0atQoa1snzsOezz34nMhsNltHw7r/WdH9ypQpo8DAQE2fPt2mztq1a3X48GHVr18/Scd2v4oVK6pGjRrW16MSf35+furRo4fWr1+v/fv3S0p6O6ZZs2YyDEPDhg2LVy/uXCX0nDIsLEyzZ89O9rElpmfPnsqWLZv69++vY8eOxVt++fJljRgxwvo+b9688eZbnjlzZqI9/hJTo0YN+fv7a+HChVq4cKHKli1rMyxoYGCgqlatqhkzZiSYVHzc56fAs4Qef0jX8ufPr/nz56tVq1YqWLCg2rRpoxIlSsgwDJ06dUrz58+X2WxOcD6/BxUqVEh58+bVu+++qwsXLsjX11dLlixJcC69UaNGqX79+qpUqZI6d+6s0NBQTZkyRUWKFElwzsH7ffbZZ9q6davKlSunbt26qXDhwgoNDdXevXu1adMmhYaGJvs8lC5dWgsXLlS/fv304osvytvbWw0bNnzoOhcuXNDcuXMl3Xu489dff2nGjBnKnDmzzTCfY8eOVd26dVW+fHl16dJFt2/f1pQpU5QhQwabIQ9GjBihjRs3qlKlSurVq5ecnZ01Y8YM3b17V2PGjLHWK1y4sKpWrarSpUvL399fe/bs0eLFi9W7d2+b45Gkt956S7Vr15aTk5NatmyZ7PPy4Dlq1qyZJk2apGvXrumll17Stm3brA2b1OhlCAAAcL/33ntPr7/+uubMmaOePXtKkgYMGKB9+/Zp9OjR2rVrl5o1ayYPDw/t2LFDc+fO1fPPPx9vmKv33ntPhw4d0vjx47V161a99tprypo1qy5duqTly5fr999/16+//vrQWL777jvVqlVLr776qho2bKjq1avLy8tL//77rxYsWKCLFy9q3LhxkqTOnTtrwoQJql27trp06aLLly9r+vTpKlKkiMLDw5N1Dlq0aKG2bdtq6tSpql27drw5Bt977z2tWLFCDRo0UMeOHVW6dGlFRETowIEDWrx4sU6fPm0zNCgAAEhdVapUUY8ePTRq1Cjt379ftWrVkouLi/7991/9+OOPmjx5sl577TX5+vpq4sSJ6tq1q1588UW1bt1aGTNm1F9//aXIyMhEh+3s2rWrQkND9corryhnzpw6c+aMpkyZopIlS1qHRX+Qi4uLRo8erU6dOqlKlSpq1aqVQkJCNHnyZAUHB+udd95JzVNi9fbbb2vSpEn67LPPtGDBgiS3Y6pVq6Z27drp888/17///qs6derIYrHol19+UbVq1dS7d2/VqlXL2hOyR48eunXrlr766isFBgYmu4ddYjJmzKhly5apXr16KlmypNq2bWt9Jrd371798MMPKl++vLV+165d1bNnTzVr1kw1a9bUX3/9pfXr1ye7bebi4qJXX31VCxYsUEREhLXNeb8vv/xSlSpVUrFixdStWzflyZNHISEh2rVrl86fP6+//vrryQ4eSOsMAMbx48eNN954w8iXL5/h7u5ueHh4GIUKFTJ69uxp7N+/36Zuhw4dDC8vrwS3888//xg1atQwvL29jcyZMxvdunUz/vrrL0OSMXv2bJu6S5YsMZ5//nnDzc3NKFy4sLF06VKjQ4cORlBQkE09ScaQIUNsykJCQow333zTyJUrl+Hi4mJkzZrVqF69ujFz5kxrna1btxqSjB9//NFm3VOnTsWL59atW0br1q0NPz8/Q1K8GB4UFBRkSLK+zGazERgYaLRq1co4fvx4vPqbNm0yKlasaHh4eBi+vr5Gw4YNjX/++Sdevb179xq1a9c2vL29DU9PT6NatWrGr7/+alNnxIgRRtmyZQ0/Pz/rdRo5cqQRFRVlrRMTE2P06dPHCAgIMEwmk3H/r7oHz+eQIUMMScaVK1ds9jN79mxDknHq1ClrWUREhPHmm28a/v7+hre3t9GkSRPj6NGjhiTjs88+e+g5AwAASIq4Nsgff/wRb1lsbKyRN29eI2/evEZMTIxN+ezZs42KFSsavr6+hru7u1GkSBFj2LBhxq1btxLd1+LFi41atWoZ/v7+hrOzs5EtWzajRYsWxs8//5ykWCMjI41x48YZL774ouHt7W24uroa+fPnN/r06ROvTTh37lwjT548hqurq1GyZElj/fr18dq+ce3UsWPHJrrP8PBww8PDw5BkzJ07N8E6N2/eNAYOHGjky5fPcHV1NTJnzmxUqFDBGDdunE2bEQAAPNrD2ib3e9jzMsMwjJkzZxqlS5c2PDw8DB8fH6NYsWLG+++/b/z333829VasWGFUqFDB+gypbNmyxg8//GCzn/vbD3HtmcDAQMPV1dV47rnnjB49ehgXL1601ol7RrZ161abfS1cuNAoVaqU4ebmZvj7+xtt2rQxzp8/n6Tjinue9CiPat907NjRcHJysradktqOiYmJMcaOHWsUKlTIcHV1NQICAoy6desaf/75p825LF68uOHu7m4EBwcbo0ePNmbNmhXveVeVKlWMKlWqxIv5wWeZifnvv/+Md955xyhQoIDh7u5ueHp6GqVLlzZGjhxphIWFWevFxsYaH3zwgZE5c2bD09PTqF27tnH8+HEjKCjI6NChg7VeUn7mNm7caEgyTCaTce7cuQTrnDhxwmjfvr2RNWtWw8XFxciRI4fRoEEDY/HixUk6LuBZZjKMZIxlCACwsX//fpUqVUpz585VmzZt7B0OAAAAAAAAACAdY44/AEii+ydpjjNp0iSZzWa9/PLLdogIAAAAAAAAAID/YY4/AEiiMWPG6M8//1S1atXk7OystWvXau3aterevbty5cpl7/AAAAAAAAAAAOkcQ30CQBJt3LhRw4YN0z///KNbt27pueeeU7t27TRo0CA5O/M9CgAAAAAAAACAfZH4AwAAAAAAAAAAABwAc/wBAAAAAAAAAAAADoDEHwAAAAAAAAAAAOAAmJQKAAAACbJYLPrvv//k4+Mjk8lk73AAAMAzxjAM3bx5U9mzZ5fZnL6/e067CgAAPInktKscMvHnUaq3vUMAHMr1P76wdwiAw3B/in95U+Lv4e19fP7Ts//++0+5cuWydxgAAOAZd+7cOeXMmdPeYdgV7SoAAJASktKucsjEHwAAkGRK39+qxpPz8fGRdK9R6evrm+Lbj46O1oYNG1SrVi25uLik+PbxaFwD++L82x/XwP64BvaV2uc/PDxcuXLlsrYp0jPaVY6N829/XAP74xrYF+ff/tJSu4rEHwAAABIUNwyVr69vqj2g8vT0lK+vLzcmdsI1sC/Ov/1xDeyPa2BfT+v8M7Ql7SpHx/m3P66B/XEN7Ivzb39pqV1F4g8AAEfFAxYAAAAAAAAgXSHxBwCAo2KoTwAAAAAAACBd4YkgAAAAAAAAAAAA4ADo8QcAgKNiqE88JbGxsYqOjk72etHR0XJ2dtadO3cUGxubCpHhUZ7kGri4uMjJySmVIgMAAACA9MdisSgqKirZ63F/bX9Peg1S8h6bxB8AAI6KoT6RygzD0KVLl3Tjxo3HXj9r1qw6d+5ckianRsp70mvg5+enrFmzcv0AAAAA4AlFRUXp1KlTslgsyV6X+2v7S4lrkFL32CT+AABwVDT0kMrikn6BgYHy9PRMdsPUYrHo1q1b8vb2ltlMotoeHvcaGIahyMhIXb58WZKULVu21AoRAAAAAByeYRi6ePGinJyclCtXrmTfI3N/bX9Pcg1S+h6bxB8AAACSLTY21pr0y5Qp02NtI24IE3d3d25M7ORJroGHh4ck6fLlywoMDGTYTwAAAAB4TDExMYqMjFT27Nnl6emZ7PW5v7a/J70GKXmPTeIPAABHxVCfSEVxc/o9zg0JHEfc9Y+OjibxBwAAAACPKW5OOFdXVztHAntKqXtsnggCAOCoTKYnfyHN2L59uxo2bKjs2bPLZDJp+fLlj1zn559/1gsvvCA3Nzfly5dPc+bMSfG4mDsgfeP6AwCeNWm1TQUAgMQ9VnqXUtefxB8AAI7KZH7yF9KMiIgIlShRQl9++WWS6p86dUr169dXtWrVtH//fvXt21ddu3bV+vXrUzlSAACAtIs2FQAAcHQM9QkAAPAMqFu3rurWrZvk+tOnT1fu3Lk1fvx4SdLzzz+vHTt2aOLEiapdu3ZqhQkAAJCm0aYCAACOjq/yAwDgqBjqM13btWuXatSoYVNWu3Zt7dq1y04RpS27du2Sk5OT6tevH2/Zzz//LJPJpBs3bsRbFhwcrEmTJtmUbd26VfXq1VOmTJnk6empwoULq3///rpw4UIqRS/duXNHb775pjJlyiRvb281a9ZMISEhD12nY8eOMplMNq8HH3yGhoaqTZs28vX1lZ+fn7p06aJbt26l2nEAAFJHxN0Yhd2OfuQr/Ha0ImOkmFiLvUNOs56FNlV0rEXht6N1J9bekQAA0qv0eI89dOhQFSpUSF5eXsqYMaNq1aqlPXv22NQJDg6Odx/+2WefpdpxxKHHHwAAjoqhOtO1S5cuKUuWLDZlWbJkUXh4uG7fvi0PD49469y9e1d37961vg8PD5d0b1Lp6Ohom7rR0dEyDEMWi0UWy+M9LDQMw/rv427jcX399dfq3bu3Zs2apfPnzyt79uzWZXGxJHZs98c7Y8YM9e7dW+3bt9ePP/6o4OBgnT17Vt9//73GjRtn7R2Q0vr27as1a9Zo4cKFypAhg9566y29+uqr+uWXXxJdxzAM1a5dW7NmzbKWxU0cH3dMrVu31qVLl7R+/XpFR0erS5cu6tatm+bNm5fgNi0WiwzDeOKJx9OruM/Vg58vPD1cA/vjGqQswzD06dqj+va3s/r/P7OJigo5obDfFitz/XcUVDRUL+bJnOLxOMJ1fZw2lZS8dtWT+uXfq+r83V7l8HRSwzrP/jl/FvG7zP64BvbHNXgyT3qPbc/7ayl93mPny5dPn3/+ufLkyaPbt29r0qRJevXVV3Xs2DEFBgZa6w0bNkxdu3a1vvfx8Un0Gj3sHjs5ny0SfwAAOCp67CGZRo0apWHDhsUr37Bhgzw9PW3KnJ2dlTVrVt26dUtRUVFPtN+bN28+0frJdevWLS1atEhbtmzRuXPnNGPGDPXv39+6PDIy0hqX2WybQLdYLLpz547Cw8N14cIF9e3bVz169NCnn35qrePv76+SJUsqLCzM+pAvJYWFhWnWrFn66quvVKZMGUnS5MmTVa5cOW3evFkvvvhiguvF3Tg8eC2le8d69OhRrV+/Xlu2bNHzzz8v6d7PRPPmzTV48GBly5Yt3npRUVG6ffu2tm/frpiYmBQ8yvRl48aN9g4h3eMa2B/XIGVsOG/S6nMP/yKGEROtG78uUPhvP0qGRWGZcun3kmZdOZLy8cT9TU2PktOuelKHb5gk3bvufJbsi/Nvf1wD++MaPJ6Uusd+2vfXUvq9x27QoIHN+yFDhmjWrFnavXu3qlSpYj0+FxcXm7/9sbGxiR7Hw+6xk9OuIvEHAADggLJmzRpvWIqQkBD5+vom+s30gQMHql+/ftb34eHhypUrl2rVqiVfX1+bunfu3NG5c+fk7e0td3d3GYah29HJG1/KMAzdunlL3j7eMj1BotrDxSlZ6y9evFiFChVS6dKl1bFjR/Xr109Dhw61biOuQe7j4xPvuM1ms9zd3eXr66tZs2YpKipKgwYNildPUoJlcerVq6cdO3YkujwoKEgHDhxIcNmePXsUHR2thg0bWvdRpkwZPffcczpw4ICqV6+e4HouLi7auXOnChQooIwZM6patWoaPny4XF1d5ePjowMHDsjPz896gyJJjRo1ktls1j///KOCBQvG2+adO3fk4eGhl19+We7u7okeDxIWHR2tjRs3qmbNmnJxcbF3OOkS18D+uAYp56f9/2n1roOSpCENCqlFmZwJ1jtx4oTKfvmTZFjUpGlTNWxYS82b1pDb//cCT0mp8XDuaXucNpWUvHbVk/L596qmH94rSXyW7ITfZfbHNbA/rsGTedJ77JS6v5a4x5aSdo99v6ioKM2cOVO+vr566aWXrNsxm82aPHmyxo0bp+eee06tWrVS37595eyccGruYffYyWlXkfgDAMBRMdRnula+fHmtWbPGpmzjxo0qX758ouu4ubnJzc0tXrmLi0u8G7fY2FiZTCaZzWaZzWZFRsWo6FD7fLPzn+G15ema9GEmZ8+erbZt28psNqtevXrq0qWLfvnlF1WtWlWSrN9AjDu2B8Ud9/Hjx+Xr66scOXIkO+ZvvvlGt2/fTnS5i4tLgvuWpMuXL8vV1VX+/v425VmyZFFISEii69WtW1fNmjVT7ty5deLECX344Ydq0KCB1q5dK5PJpMuXLyswMNBm/bj9XL58OcHtms1mmUymBH9GkHScP/vjGtgf1+DJ/Hr8qgYuPyRJ6vFyHnWqlNdmeWxsrHW4qGJFCmvy5MnKlCmTGjVqpDVr1sjN1TVVzr8jXNPHaVNJyWtXPSmn+x4e8lmyL86//XEN7I9r8Hi4x3727rEladWqVWrZsqUiIyOVLVs2LVu2TAEBAdZ13nrrLb3wwgvy9/fXr7/+qoEDB+rSpUuaMGFCgtt72D12cj5XJP4AAHBUJP4cyq1bt3T8+HHr+1OnTmn//v3y9/fXc889p4EDB+rChQv67rvvJEk9e/bUF198offff1+dO3fWli1btGjRIq1evdpeh5AmHD16VL///ruWLVsm6d5wKi1atNA333xjvSlJKsMwHvublI9zI/OkWrZsaf1/sWLFVLx4ceXNm1c7duxQw4YNn3o8AICUcfTSTfX4/k9FxxpqUDybPqhTyGb59u3b1a1bN82aNUsVK1aUJHXv3l1S+pyHiTYVAAApJz3fY0tStWrVtH//fl29elUzZ85Up06dtHv3bmXNmlWSbHr/Fy9eXK6ururRo4dGjRqV4BeEUgqJPwAAgGfAnj17VK1aNev7uMZjhw4dNGfOHF28eFFnz561Ls+dO7dWr16td955R5MnT1bOnDn19ddfq3bt2qkSn4eLk/4ZnrxtWywW3Qy/KR9fn4d+gy4p+06qb775RjExMTYTjRuGITc3N33xxRfKkCGDdUiOsLAw+fn52ax/48YNZciQQZJUoEABhYWF6eLFiwnOf/cwdevWfegk4UFBQTp06FCCy7JmzaqoqCjduHHDJr6QkBDrzUVS5MmTR5kzZ9bJkyet2718+bJNnZiYGIWGhiZruwCAp+dS2B11nP27bt6NUdlgf417vYTM5nsPzG7duqUBAwboyy+/lCQNHjxYmzdvtme4aUJab1MBACAl/x47pe6v4/adVOn9HtvLy0v58uVTvnz5VLZsWeXPn1+zZs3Shx9+mGD9cuXKKSYmRqdPn05wOo2UQuIPAABHZX6yMd2RtlStWlWGYSS6fM6cOQmus2/fvlSM6n9MJpM8XZPXtLRYLIpxdZKnq/MT35gkRUxMjL777juNHz9etWrVslnWpEkT/fDDD+rZs6fy588vs9msP//8U0FBQdY6J0+eVFhYmAoUKCBJeu211zRgwACNGTNGEydOjLe/B28a7vf1118/chiSxJQuXVouLi7avHmzmjVrJunetyzPnj37yGHH7nf+/Hldu3ZNWbJkkXRvKLMbN27ozz//VOnSpSVJW7ZskcViUbly5ZK8XQDA03Hrbow6zflDF8PuKE+Al2a2Ly33/39Qt2nTJnXt2lVnzpyRJHXr1k1jx461Z7hpRlpvUwEAICX/Hvtp319L3GMnxGKx6O7du4ku379/v8xmswIDA5O13eQi8QcAgKNiqE/AxqpVq3T9+nV16dLF+o3COM2aNdM333yjnj17ysfHR127dlX//v3l7OysYsWK6dy5c/rggw/00ksvqUKFCpKkXLlyaeLEierdu7fCw8PVvn17BQcH6/z58/ruu+/k7e2t8ePHJxjLkwxDkiFDBnXp0kX9+vWTv7+/fH191adPH5UvX14vvfSStV6hQoU0atQoNW3aVLdu3dKwYcPUrFkzZc2aVSdOnND777+vfPnyWScqf/7551WnTh1169ZN06dPV3R0tHr37q2WLVvafHsTAGB/0bEWvTH3Tx2+GK7M3m76tlNZ+Xm6KiwsTO+++66+/vprSVJwcLC++uor1ahRw84RAwAAR5Oe77EjIiI0cuRINWrUSNmyZdPVq1f1xRdf6OLFi3rttdckSbt27dLu3btVrVo1+fj4aNeuXXrnnXfUtm1bZcyY8bHjTQoSfwAAOKrHHBcdcFTffPONatSoEe+GRLp3UzJmzBj9/fffKl68uCZPnqzPPvtMH3zwgc6cOaOsWbOqZs2aGjlypM2cA7169VKBAgU0btw4NW3aVLdv31ZwcLAaNGhgM5Z/Sps4caLMZrOaNWumu3fvqnbt2po6dapNnaNHjyosLEyS5OTkpL///lvffvutbty4oezZs6tWrVoaNmyYzbwC8+bNU+/evVW9enXr9j///PNUOw4AQMIMw9DApQf055nrCS6PjIrVhRu35eHipFkdyyiXv6ckaeXKldakX58+ffTpp5/K29v7qcUNAADSj/R+j33kyBF9++23unr1qjJlyqQyZcpozZo1KlKkiCTJzc1NCxYs0NChQ3X37l3lzp1b77zzTqoeRxwSfwAAAEgXVq5cmeiysmXL2gz75e7urqFDh2ro0KGP3G6NGjWeek8Kd3d3ffnll9Z5mxJy//F4eHho/fr18epYLBaFh4db3/v7+2v+/PkpGywAINmu3orSgj/OPbSOs9mkL1qXUrEc/3vY1qZNG+3cuVOtW7dW5cqVUztMAACQjqXne2x3d3ctXbrUZvmD99cvvPCCfvvtt5QPNglI/AEA4KgY6hMAAOCZFPdgyWyS5nV9KcE6wZk9tXPjapVpO0qbN2+Wn5+fTCaTpk2b9jRDBQAAQBpD4g8AAEfFUJ8AAADPNJPJpPJ5M8Urv3Tpknp3aaclS5ZIkiZMmKDhw4c/7fAAAACQBpH4AwDAUdHjDwAAwKEYhqF58+bp7bffVmhoqJydnTVw4EANGjTI3qEBAAAgjeCJIAAASDHbt29Xw4YNlT17dplMJi1fvty6LDo6Wh988IGKFSsmLy8vZc+eXe3bt9d///1ns43Q0FC1adNGvr6+8vPzU5cuXXTr1q2nfCQAAABpy/nz59WgQQO1a9dOoaGhKlWqlP744w8NHz5cbm5u9g4PAAAAaQSJPwAAHJXJ9OSvZIqIiFCJEiUSnAw5MjJSe/fu1ccff6y9e/dq6dKlOnr0qBo1amRTr02bNjp06JA2btyoVatWafv27erevftjnwakrvsnt0b6w/UHgKdn6NChWrNmjVxdXTVy5Ejt3r1bJUuWtHdYAAAgBXGPlb6l1PVnqE8AAByVHYb6rFu3rurWrZvgsgwZMmjjxo02ZV988YXKli2rs2fP6rnnntPhw4e1bt06/fHHHypTpowkacqUKapXr57GjRun7Nmzp/oxIGlcXFwk3Uvoenh42Dka2EtkZKSk//08AABSz2effaaQkBCNHj1ahQsXtnc4AAAgBTk5OUmSoqKiuMdOx1LqHpvEHwAAjuoxeuw96O7du7p7965NmZubW4oNJxUWFiaTySQ/Pz9J0q5du+Tn52dN+klSjRo1ZDabtXv3bjVt2jRF9osn5+TkJD8/P12+fFmS5OnpKVMyf+YsFouioqJ0584dmc0MRGEPj3sNDMNQZGSkLl++LD8/P+tNKgDg8R29dFNzfzujGItFkXeiFf7nSkVfPCZjZF2ZTCZlzpxZK1eutHeYAAAgFTg7O8vT01NXrlyRi4tLsu+Rub+2vye5Bil9j03iDwAAJGrUqFEaNmyYTdmQIUM0dOjQJ972nTt39MEHH6hVq1by9fWVJF26dEmBgYE29ZydneXv769Lly498T6RsrJmzSpJ1uRfchmGodu3b8vDwyPZSUOkjCe9Bn5+ftafAwDAk/l8879afeCiokMv6Nraybp7/h9J0saNG1WrVi07RwcAAFKTyWRStmzZdOrUKZ05cybZ63N/bX8pcQ1S6h6bxB8AAI4qBYb6HDhwoPr162dTlhK9/aKjo9W8eXMZhqFp06Y98fZgH3E3JoGBgYqOjk72+tHR0dq+fbtefvllhoq0kye5Bi4uLvT0A4AUFHHnrsJ2L9HNnfMVG31Xbh5eeufDYapRo4a9QwMAAE+Bq6ur8ufPr6ioqGSvy/21/T3pNUjJe2wSfwAAOKoU+IZXSg7rGScu6XfmzBlt2bLF2ttPuteD7MHeYzExMQoNDaVXURrm5OT0WI1TJycnxcTEyN3dnRsTO+EaAEDacPDgQa0e2VU3Tt3r5VerVi3NnDlTQUFBdo4MAAA8TWazWe7u7slej3s7+0tL14DEHwAAeGrikn7//vuvtm7dqkyZMtksL1++vG7cuKE///xTpUuXliRt2bJFFotF5cqVs0fIAAAAKWbn8avae+a6TZnFYtGnXRrp6rlTMrl5qcf7wzR1WD+G6QIAAMBjIfEHAICjSoGhPpPr1q1bOn78uPX9qVOntH//fvn7+ytbtmx67bXXtHfvXq1atUqxsbHWefv8/f3l6uqq559/XnXq1FG3bt00ffp0RUdHq3fv3mrZsqWyZ8/+1I8HAAAgJfwbclMjVh/WtmNXEq5QoYs8/lwp/1q9VK9ZDZJ+AAAAeGwk/gAAcFR2SPzt2bNH1apVs76Pmx+wQ4cOGjp0qFasWCFJKlmypM16W7duVdWqVSVJ8+bNU+/evVW9enWZzWY1a9ZMn3/++VOJHwAAICVdj4jSpE3HNHf3WcVaDLk4mVSroL/2/fSNMgRkV8lar92rWPY5qXkjBXi7qvrzgfYNGgAAAM80En8AADgqO3xTvGrVqjIMI9HlD1sWx9/fX/Pnz0/JsAAAAJ6q6FiLvt91RpM2HVP4nRhJUq3CWVQ38KYG9eusw4cPy9vbW9990lsBAQF2jhYAAACOhMQfAAAAAABACtl+7IqGrjykk1ciJEmFsvro/erBWjV7kppNmiTDMJQlSxZNnTqVpB8AAABSHIk/AAAclR2G+gQAAEjPbkRGqePs32UxpExernq3dkEF3jqh7k1f0YkTJyRJ7du318SJE+Xv72/naAEAAOCISPwBAOCo7DDUJwAAQHp2806MLIbk6mTW1veqKuzKJeXJU0sxMTHKmTOnZsyYoXr16tk7TAAAADgwEn8AADgqevwBAADYhdks+bq7yDdXLr333nsKDQ3VmDFj5Ovra+/QAAAA4OBI/AEAAAAAAKSAGzeu69raz5X5pSbWspEjR8rESAwAAAB4Skj8AQDgqHjABAAA8NSsWLFC3br30K2QS4q5dlaG0VMmk4mkHwAAAJ4qEn8AADgoHjIBAACkvqtXr+qtt97SDz/8IEly9s+pgBpdaIsBAADALkj8AQDgoHjYBAAAkHoMw9CPP/6o3r1768qVKzKbzerZ5x2tcq4oDw93e4cHAACAdMps7wAAAAAAAACeNcuXL1eLFi105coVFStWTLt379aAwcNlcna1d2gAAABIx+jxBwCAo6LDHwAAQKpp1KiRKlWqpBo1amjgwIFydXXVudBIe4cFAACAdI7EHwAADoqhPgEAAFLOuXPn9Omnn2rixIlyd3eXk5OTfv75Zzk5Odk7NAAAAMCKxB8AAAAAAEAiLBaLvvrqK7333nu6efOmMmbMqE8//VSSSPoBAAAgzSHxBwCAg6LHHwAAwJM5efKkunbtqq1bt0qSypcvr3bt2sWrFx1rkWHc+xcAAACwJxJ/AAA4KBJ/AAAAjyc2NlZffPGFPvzwQ0VGRsrDw0Offvqp+vTpE6+X31fbT2rU2sOyGHYKFgAAALgPiT8AABwUiT8AAIDHM3DgQI0dO1aSVLVqVX399dfKmzdvgnW3/3slXtKvQt7MqR0iAAAAkCASfwAAAAAAAPd58803NW/ePA0ePFjdunWT2Wx+5DqjXi2m+sWzSZJ83HjcAgAAAPugJQoAgKOiwx8AAECSHDhwQGvXrtX7778vSQoKCtLJkyfl5uaW5G14uDjJ190ltUIEAAAAkoTEHwAADoqhPgEAAB4uKipKo0aN0siRIxUdHa0XXnhBNWrUkCSbpN+naw5r6d4LCW4j7HbUU4kVAAAASAoSfwAAOCgSfwAAAInbs2ePOnfurAMHDkiSmjRpoiJFiiRY94ffz+rmnZhEt2U2SXkDvFMlTgAAACA5SPwBAAAAAIB0486dOxo6dKjGjh0ri8WizJkz68svv9Trr7/+yC9OfdOhjHJk9IhX7u/lqkAf99QKGQAAAEgyEn8AADgoevwBAADYMgxDtWvX1vbt2yVJrVq10uTJkxUQEJCk9fMEeCt3Zq/UDBEAAAB4IiT+AABwUCT+AABAejft5xNae/CiTVlE3upy239IxVv0163ildVl4VFJRx+6nYi7iQ/zCQAAAKQlJP4AAHBU5P0AAEA6N2XLv7r2714ZMVHyzPuiJMkIeEGBXabrsquHLp8PS/K2XJ3N8vdyTa1QAQAAgBRB4g8AAAAAADic8PBw/bfqc4XtWyvfjJk0/Z1t8vPP/NjbyxfgowweLikYIQAAAJDySPwBAOCgGOoTAACkV2vXrlX37t0Vdv68JKlx01dVs9hz8vHxsXNkAAAAQOoi8QcAgIMi8QcAANKb0NBQ9evXT99++60kycUvq/zrvqVPx70tHx9PO0cHAAAApD4SfwAAOCgSfwAAID25fv26ihYtqosXL8pkMqlv375a6VxZ0Wbm5QMAAED6YbZ3AAAAAAAAAE8qY8aMql+/vgoVKqSdO3dqwoQJMru62zssAAAA4Kmixx8AAI6KDn8AAMCBGYahhQsXqnz58goKCpIkTZw4Uc7OznJ3J+EHAACA9InEHwAADoqhPgEAgCO4HRWrWTtP6eqtu9ay8GuXtXr6CB3dvUV5S1VU26HTE2z7RMdanmaoAAAAgN2R+AMAAAAAAGnW5iMhGrv+qKR7vfwiDm7W9c1fyXI3QjI766pXsGbvOCmT2SnB9U0mydOVxx8AAABIH2j5AgDgoOjxBwAAHEHk3VhJUhZzuG5smKqzf+6QJOUsUEyvvzNCWYMLPHT9YjkyyN/LNdXjBAAAANICEn8AADgoEn8AAMBR3L1wWHsXD1HMnUi5ubnpk08+0TvvvCNnZx5rAAAAAPejhQwAgIMi8QcAAJ62/eduaM/p0CTXj42N1eH/TLq087ScnBIeqnPfuRtyCcwjL78AFc2bU998840KFiyYUiEDAAAADoXEHwAAAAAAeGIWi6F23+zWzTsxyVzTScvPHLMpMSyxivjnZ3kVriqT2UlmFzc1+nCa5rxZW2azOeWCBgAAABwMiT8AABwVHf4AAMBTZDEMa9KvfrFscnV+dILOYrHowoULypEjhzWhF3rhpDZMH6pr/x5QYT+pdMP2cnEyqUOFYJJ+AAAAwCOQ+AMAwEEx1Kfj+fLLLzV27FhdunRJJUqU0JQpU1S2bNlE60+aNEnTpk3T2bNnlTlzZr322msaNWqU3N3dn2LUAID0aGTTovLzdH1kvejoaK1Zc0716hWTJI0bN05Thw5VVFSUfHx81Kl6MXVqUTKVo0V6RLsKAAA4qjSR+MuYMWOCDydNJpPc3d2VL18+dezYUZ06dbJDdAAAPJtI/DmWhQsXql+/fpo+fbrKlSunSZMmqXbt2jp69KgCAwPj1Z8/f74GDBigWbNmqUKFCjp27Jg6duwok8mkCRMm2OEIAACO4uCFMJ0NjYxXHmsxHnubf/31l3r06KG9e/dKkurVq6fp06crV65cj71NIDG0qwAAgCNLE4m/wYMHa+TIkapbt67121W///671q1bpzfffFOnTp3SG2+8oZiYGHXr1s3O0QIAADx9EyZMULdu3axfhJo+fbpWr16tWbNmacCAAfHq//rrr6pYsaJat24tSQoODlarVq20e/fupxo3AMCxnAuNVIMpOx5Zz2xO+heQNm3apOnTpysmJkYZM2bU5MmT1bZtW77EhFRDuwoAADiyNJH427Fjh0aMGKGePXvalM+YMUMbNmzQkiVLVLx4cX3++eck/gAASCIeljmOqKgo/fnnnxo4cKC1zGw2q0aNGtq1a1eC61SoUEFz587V77//rrJly+rkyZNas2aN2rVrl+h+7t69q7t371rfh4eHS7o3DFt0dHQKHc3/xG0zNbaNpOEa2Bfn3/64Bsn33/UISZKrs1klcmZIsE7Z4IzycEraeY2Ojlb+/PllMpnUuHFjTZkyRVmzZlVMTEyKxo2EpfZnIC1+thyxXRV73+clLZ7z9IC/J/bHNbA/roF9cf7tLy21q9JE4m/9+vUaPXp0vPLq1aurf//+ku4N85HQt64AAEAiyPs5jKtXryo2NlZZsmSxKc+SJYuOHDmS4DqtW7fW1atXValSJRmGoZiYGPXs2VMffvhhovsZNWqUhg0bFq98w4YN8vT0fLKDeIiNGzem2raRNFwD++L82x/XIOlO3ZQkZ/k6xapttisJV7p7RWvWHEt0G3fv3tWhQ4f0wgsvSJKCgoI0ceJE5ciRwzrUJ56u1PoMREbGHxLW3hyxXXX4hkmSkyR+n9kb59/+uAb2xzWwL86//aWFdlWaSPz5+/tr5cqVeuedd2zKV65cKX9/f0lSRESEfHx87BEeAADPJHr8pW8///yzPv30U02dOlXlypXT8ePH9fbbb+uTTz7Rxx9/nOA6AwcOVL9+/azvw8PDlStXLtWqVUu+vr4pHmN0dLQ2btyomjVrysXFJcW3j0fjGtgX59/+uAbJt/fsDU06+Ls8vTxVr17lZK+/c+dOde/eXSdPntTOnTtVrFgxbdy4UZ06deIa2EFqfwbierk969J6u8rn36uafvhe0pzfZ/bB3xP74xrYH9fAvjj/9peW2lVpIvH38ccf64033tDWrVutc/z98ccfWrNmjaZPny7pXpa0SpUq9gwTSVDxhbx6p30NvVD4OWULyKDm78zUyp//ti4f1KOeXq/9gnJmzaio6FjtO3xWQ79YqT8OnpEkPZfNXwO711HVFwsoSyZfXbwSph/W/KHRX69XdEysvQ4LSLO++WqGNm/coFOnTsrN3V0lS5ZS337vKjh3HnuHhnRq+/btGjt2rP78809dvHhRy5YtU5MmTazLDcPQkCFD9NVXX+nGjRuqWLGipk2bpvz581vrhIaGqk+fPlq5cqXMZrOaNWumyZMny9vb2w5HlDZkzpxZTk5OCgkJsSkPCQlR1qxZE1zn448/Vrt27dS1a1dJUrFixRQREaHu3btr0KBBMpvN8dZxc3OTm5tbvHIXF5dUvXFI7e3j0bgG9sX5tz+uQdI5O9/rVWQymZJ1zm7duqUPP/xQX3zxhQzDULZs2RQREWHdBtfAvlLr/KfFa+qI7Son5/893uOzZF+cf/vjGtgf18C+OP/2lxbaVfFbJnbQrVs3bdu2TV5eXlq6dKmWLl0qT09Pbdu2TV26dJEk9e/fXwsXLrRzpHgULw83HTh2QX1HJXytjp+5rHdG/6gyr3+q6p0m6Mx/oVo5tbcyZ7z3MLdg7iwym8zqPWKBXnhtpN4fv1RdX6uk4X0aPc3DAJ4Ze/74XS1atdH3PyzSjK9m3xtypluXNDmkDp4+k8n0xK/kioiIUIkSJfTll18muHzMmDH6/PPPNX36dO3evVteXl6qXbu27ty5Y63Tpk0bHTp0SBs3btSqVau0fft2de/e/bHPgyNwdXVV6dKltXnzZmuZxWLR5s2bVb58+QTXiYyMjPcQysnp3sNawzBSL1gAAB6wefNmFStWTFOmTJFhGOrSpYv++ecfvfLKK/YODekQ7SoAAODo0kSPP0mqWLGiKlasaO8w8IQ27PxHG3b+k+jyhev22Lz/YPxSdWpaQUXzZ9fPvx/Txl8Pa+Ovh63LT1+4pgJBger2emUNnLgs1eIGnlXTZn5j8374yM9UrXJ5Hf7nkEqXedFOUSGtsMdQn3Xr1lXdunUTXGYYhiZNmqSPPvpIjRs3liR99913ypIli5YvX66WLVvq8OHDWrdunf744w+VKVNGkjRlyhTVq1dP48aNU/bs2Z/asaQ1/fr1U4cOHVSmTBmVLVtWkyZNUkREhDp16iRJat++vXLkyKFRo0ZJkho2bKgJEyaoVKlS1iGpPv74YzVs2ND6oAoAgNTWr18/TZw4UdK9ufxmzpypWrVq2TkqpHe0qwAAgCNLM4k/i8Wi48eP6/Lly7JYLDbLXn75ZTtFhdTk4uykLq9W1I2bkTpw7EKi9Xy9PRQaTu8lIClu3bwpSfLNkMHOkQDxnTp1SpcuXVKNGjWsZRkyZFC5cuW0a9cutWzZUrt27ZKfn5816SdJNWrUkNls1u7du9W0aVN7hJ4mtGjRQleuXNHgwYN16dIllSxZUuvWrVOWLFkkSWfPnrX5JvpHH30kk8mkjz76SBcuXFBAQIAaNmyokSNH2usQAABpWKzF0LVbdx9ZLzQiOlnbzZcvnyTpzTff1KhRo+Tj4/NY8QEpiXYVAABwZGki8ffbb7+pdevWOnPmTLwhEkwmk2JjmdvNkdStXFTffdZJnu4uunQ1XA16fqFrNyISrJsnV2a90bIKvf2AJLBYLBoz+lOVLPWC8ucvYO9wkAakRI+/u3fv6u5d24eAic1X8iiXLl2SJOsDlThZsmSxLrt06ZICAwNtljs7O8vf399aJz3r3bu3evfuneCyn3/+2ea9s7OzhgwZoiFDhjyFyAAAzzKLxVCDKTt0+GL4E2/r2rVrOn/+vEqUKCFJ6tmzp8qVK6fSpUs/8baBlES7CgAAOKo0Mcdfz549VaZMGR08eFChoaG6fv269RUaGvrQde/evavw8HCbl2EhUZiWbfvjmMq1HKVqHSdow6//aO6Yzgr4/zn+7pc9IINWfPGmlm7ap9nLfrVDpMCz5dMRw3Ti3381ZtxEe4eCtML05K9Ro0YpQ4YMNq+4IY8AAIBjuBtjsSb9zCbJyWx66MvZbFKdolnjbWfJkiUqXLiwmjZtqlu3bt3bntlM0g8AAAB4itJEj79///1Xixcvtg4BkhyjRo3SsGHDbMqcsrwol2xlUyo8pLDIO1E6ee6qTp67qt8PnNaBnwarQ9MKGjdrg7VOtoAMWvfV2/rt75N685Mf7Bgt8Gz4dMRwbd/2s2Z9O1dZssZ/CIP0KSV6/A0cOFD9+vWzKXuc3n6SlPX/fzZDQkKULVs2a3lISIhKlixprXP58mWb9WJiYhQaGmpdHwAApJ6Dw2rL0zV5jwpCQkLUu3dvLV68WJL0/PPP6+LFi8qfP39qhAgAAADgIdJEj7+4iZEfx8CBAxUWFmbzcs7CtwmfJWaTSW4u/7uxzB6QQeu/elv7Dp9V9yFz4w3/CuB/DMPQpyOGa8vmjfpq1rfKmTOXvUOCg3Fzc5Ovr6/N63ETf7lz51bWrFm1efNma1l4eLh2796t8uXLS5LKly+vGzdu6M8//7TW2bJliywWi8qVK/dkBwMAAFKUYRiaP3++ihQposWLF8vJyUmDBg3Svn37SPoBAAAAdpImevz16dNH/fv316VLl1SsWDG5uLjYLC9evHii6yY0z5DJ7JQqceLRvDxclTdXgPV9cI5MKl4gh66HR+rajQh90LW2Vm87oEtXw5TJz1s9mr+s7IF+Wrpxr6T/T/p9/bbOXgzVwAnLbIYADbl286kfD5DWffrJMK1ds0qTpkyVl6eXrl65Ikny9vGRu7u7naODvaVEj7/kunXrls2XeU6dOqX9+/fL399fzz33nPr27asRI0Yof/78yp07tz7++GNlz55dTZo0kXSvh0CdOnXUrVs3TZ8+XdHR0erdu7datmyp7NmzP/XjAQAACbt9+7ZatGihlStXSpJKlCih2bNnq1SpUnaODAAAAEjf0kTir1mzZpKkzp07W8tMJpMMw5DJZFJsLHP2PSteKBykDV+/bX0/5t171/b7Fb+pz8gFKhicRW0bllMmPy+FhkVqz6EzqtF5og6fvCRJeuWlQsr3XKDyPReoExtG2mzbo1TCk24D6dmihfeGwu3SsZ1N+fARo9S46av2CAlpiB3yftqzZ4+qVatmfR83TGiHDh00Z84cvf/++4qIiFD37t1148YNVapUSevWrbNJVM+bN0+9e/dW9erVZTab1axZM33++edP/VgAAEDi3N3d5eTkJBcXFw0ePFgffPBBvC/xAgAAAHj60kTi79SpU/YOASnklz//fWiCruW7Xz90/bkrd2vuyt0pHRbgsP46dNTeISANs0ePv6pVqz50iGaTyaThw4dr+PDhidbx9/fX/PnzUyM8AADwBM6cOSNvb29lypRJJpNJU6dOVWhoqIoUKWLv0AAAAAD8vzSR+AsKCrJ3CAAAAAAAIAEWi0XTpk3TgAED1LhxY82dO1eSlC1bNmXLls3O0QEAAAC4X5pI/H333XcPXd6+ffunFAkAAI7DHkN9AgCAtOPrX07qu11nZCjx3viSZLEkvuzff/9Vly5d9Msvv0iSzp49q9u3b8vDwyMlQwUAAACQQtJE4u/tt9+2eR8dHa3IyEi5urrK09OTxB8AAI/BHkN9AgCAtGPe7rM6GxqZ5PrZMrjLzdlJkhQbG6tJkybpo48+0p07d+Tl5aXRo0frjTfekNlsTq2QAQAAADyhNJH4u379eryyf//9V2+88Ybee+89O0QEAMCzj7wfAADpW9y8u6NeLaZCWX0eWT9voLeczCadPn1aLVu21O7d9+Zfr1Gjhr766isFBwenZrgAAAAAUkCaSPwlJH/+/Prss8/Utm1bHTlyxN7hAAAAAADwTCqQxVulnsuY5Pp+fn46d+6cfH19NWHCBHXu3JmRBAAAAIBnRJpN/EmSs7Oz/vvvP3uHAQDAM8ls5gEdAADpyYUbtzVsxSHduB0tSboYdifJ6x47dkz58+eXyWSSn5+fFi9erOeee045cuRIrXABAAAApII0kfhbsWKFzXvDMHTx4kV98cUXqlixop2iAgDg2cYX8wEASF/WHrioDf+ExCsP9HFPdJ27d+/qk08+0WeffaZvvvlGHTp0kCSVL18+1eIEAAAAkHrSROKvSZMmNu9NJpMCAgL0yiuvaPz48fYJCgAAAACAZ0iM5d6cfuVy+6t9+WBJUlAmT+Xy90yw/u7du9W5c2f9888/kqQdO3ZYE38AAAAAnk1pIvFnsVjsHQIAAA6HuXgAAEifcvl7qn7xbIkuj4yM1ODBgzVx4kRZLBYFBgZq6tSpatas2VOMEgAAAEBqsFvir1+/fkmuO2HChFSMBAAAx0TeDwAAxzd/91n9cTpUknQs5OYj6//2229q166djh8/Lklq166dJk6cqEyZMqVqnAAAAACeDrsl/vbt25ekevRWAADg8fA3FAAAxxZxN0aDlh+QYdiWZ/R0SXSd2NhYnThxQjly5NCMGTNUv379VI4SAAAAwNNkt8Tf1q1b7bVrAAAAAACeeTGxhjXpN7BuITmZTXJzcVLDB4b5vHDhgnLkyCFJqlixon744QfVqVNHGTJkeNohAwAAAEhlaWKOPwAAkPLo8QcAQPrRuVJuuTiZbcrCwsL07rvvat68efrrr7+UP39+SVKLFi3sESIAAACAp8D86CoAAOBZZDI9+QsAADybVq1apcKFC+vrr7/W7du3tWHDBnuHBAAAAOApoMcfAAAOih5/AACkP9euXdPbb7+tefPmSZLy58+vb775RpUrV7ZzZAAAAACeBnr8AQAAAADgAJYuXarChQtr3rx5MpvNeu+99/TXX3+R9AMAAADSEXr8AQDgoOjwBwBA+nLw4EFdvnxZRYoU0axZs1S2bFl7hwQAAADgKSPxBwCAg2KoTwAAHM+NyCht+CdEUTEWRd6NUeztm3Ly8JEkDRgwQH5+furRo4fc3NzsHCkAAAAAeyDxBwCAgyLvBwCA4xm7/qjm7T6rmPCrCl3/hWJuXlWuTpNkkuTi6qq33nrL3iECAAAAsCMSfwAAAAAAPCOu3bqrm/vXKXzbbMXciZDZ2UVt88TI2cls79AAAAAApAEk/gAAcFAM9QkAgGM5deqUVo1+U6GHfpckvfTSS/rmm29UuHBhO0cGAAAAIK0g8QcAgIMi75e23LlzR+7u7vYOAwCQRly4cVvHLt1MUl2LxaLl82fp6wkjdOf2bZmc3dSq13v6bsJQOTk5pXKkAAAAAJ4lJP4AAABSicVi0ciRIzV9+nSFhITo2LFjypMnjz7++GMFBwerS5cu9g4RAGAHd6JjVWfidt28G5Ok+oZhUcj8+bp7+7bcchVVprpvqV7rWiT9AAAAAMRD4g8AAAfFUJ/2N2LECH377bcaM2aMunXrZi0vWrSoJk2aROIPANKpm3dirEm/4jkzJFjHEhsjwxIrJxc3SdKtToN09egeBVVsrEw+7qpeKMtTixcAAADAs4PEHwAADoq8n/199913mjlzpqpXr66ePXtay0uUKKEjR47YMTIAQFpgMkkreleKV37w4EF17txZFSpU0KRJk+5b0uqpxQYAAADg2WS2dwAAACB1mEymJ37hyVy4cEH58uWLV26xWBQdHW2HiAAAaVl0dLQ++eQTvfDCC/rjjz/0/fffKzQ01N5hAQAAAHiGkPgDAABIJYULF9Yvv/wSr3zx4sUqVaqUHSICAKRVe/fu1YsvvqjBgwcrOjpajRo10oEDB+Tv72/v0AAAAAA8QxjqEwAAB0WHPfsbPHiwOnTooAsXLshisWjp0qU6evSovvvuO61atcre4QEA0oA7d+7ok08+0ejRoxUbG6tMmTLpiy++UIsWLeh9DwAAACDZ6PEHAICDYqhP+2vcuLFWrlypTZs2ycvLS4MHD9bhw4e1cuVK1axZ097hAQDSgOvXr2vq1KmKjY1VixYt9M8//6hly5b8Hcb/sXff4VGUXR/Hv7vpIZWEFEIgoROqgCggKEhRfBQsWEBBUFSkCNjAQhNFRRAFBAGx82LBLiKIgoKIdOm9QwqEkJ5sdvf9IxKNSSCBbCbZ/D7PtdeTvXfKyYxZZufsObeIiIiIyCVRxZ+IiIiT0v3C8qFDhw4sX77c6DBERMQAFquNDIu1wHhiSnrez+Hh4bz99tu4ublx6623lmV4IiIiIiLihJT4ExEREXGQ2rVrs379eoKCgvKNJyUl0bJlSw4ePGhQZCIi4mgnkjLo8cZvnMuw5BvPPPoXZ36YQeD1g6hSrw0Ad955pxEhioiIiIiIE1LiT0RExEmpRZjxDh8+jNVasNIjKyuLEydOGBCRiIiUlV0nk/Ml/WxZ6Zxd9R6pm5cAcO73T/jfTTcZFZ6IiIiIiDgpJf5ERESclBJ/xvnmm2/yfv7xxx/x9/fPe261WlmxYgVRUVEGRCYiImWteQ1/BtVOYcjgJ0g9ehSABwc9xOSXXyG4aoCxwYmIiIiIiNNR4k9ERMRJKe9nnF69egG5ydf+/fvne83NzY2oqCimTp1qQGQiIlKWrJmpbP7oLW5el1vlFx0dzfz58+ncubPBkYmIiIiIiLNS4k9ERESklNlsNiD3Bu/69esJDg42OCIRESkLLy3Zxf+ty63qs9hsZJ3YRcK6JZhMJoYPH86LL75IlSpVDI5SREREREScmRJ/IiIiTkqtPo136NAho0MQEZEy9MWmEyRnZGEyuwDgXedK2t3+IK+OvJ/27dsbHJ2IiIiIiFQGSvyJiIg4KeX9yoe0tDRWrVrF0aNHyc7Ozvfa8OHDDYpKRERKm91uJ3HbSk7+9B4Lv1zClTF1cDGbqBHYQ1/GERERERGRMqPEn4iIiJPSTUbjbd68mR49epCenk5aWhpVq1bl9OnTeHt7ExISosSfiIiTOHXqFEOGDOHQl18C8P3Hc+n99kyDoxIRERERkcpIiT8RERERBxk5ciQ333wzc+bMwd/fnz/++AM3NzfuvfdeHnvsMaPDExGRv7396yG++etUidez2+2c2rCMPV/NJCcjBcwu+Le9i1HPji/9IEVERERERIpBiT8REREnpYI/423ZsoW3334bs9mMi4sLWVlZ1K5dm1dffZX+/ftz2223GR2iiIgA81cfJinDUqJ1cpITOPPjTDIPbgTAPawuQTc+hk94HWoE+TkiTBERERERkYtS4k9ERMRJmZX5M5ybmxtmsxmAkJAQjh49SqNGjfD39+fYsWMGRyciIufZ7HYAXuvdnOr+nsVaZ+bL4/i/gxtxd/fggeFPcfcDj+Lq6kqt4CpUreLuyHBFRERERESKpMSfiIiIiINcccUVrF+/nnr16nHttdcyduxYTp8+zYcffkiTJk2MDk9ERP7jipoB1KnmU+Trdrs9bw7dZtNfwZZ6hvHjx9OwYcOyClFEREREROSClPgTERFxUir4M95LL71ESkoKAC+++CL9+vVj8ODB1KtXj3feecfg6EREnEtKpoUXvttJfEpWsdex2+zEJ5hJy7ZecDmr1crMmTNZtmwZ3377LWazGR8fHxYtWnS5YYuIiIiIiJQqJf5ERESclKmMM39Wq5Xx48fz0UcfERsbS/Xq1bn//vt57rnn8mKx2+2MGzeOefPmkZSURPv27Zk9ezb16tUr01jLSuvWrfN+DgkJYenSpQZGIyLi3H7de5pPNxy/hDXNgB0Xs4lA74ItOnfv3s0DDzzA77//DsCXX37J7bfffnnBioiIiIiIOIgSfyIiIk7KXMYVf6+88gqzZ8/m/fffp3HjxmzYsIEBAwbg7+/P8OHDAXj11Vd58803ef/994mOjub555+ne/fu7Ny5E0/P4s2p5Aw2bdrE2LFj+e6774wORUTEaeTYbADUC/Hh4WvrFGsdqzWHv7b+RbPmzWhUPSDf3Hw5OTlMnTqVcePGkZWVha+vL1OmTOHWW291SPwiIiIiIiKlQYk/ERERKRW///47PXv25KabbgIgKiqK//u//+PPP/8Ecqv9pk+fznPPPUfPnj0B+OCDDwgNDeWrr77i7rvvNix2R/jxxx9Zvnw57u7uPPjgg9SuXZvdu3czevRovv32W7p37250iCIiTinUz5M7WtUo1rIWiwXPU1vpcUUEbm5ueeN//fUXAwcOZOPGjQDccMMNvP3229SsWdMhMYuIiIiIiJQWJf5EREScVFm3+mzXrh1z585l79691K9fn61bt7J69WqmTZsGwKFDh4iNjaVLly556/j7+3PVVVexdu1ap0r8vfPOOwwaNIiqVaty9uxZ5s+fz7Rp0xg2bBh33XUX27dvp1GjRiXe7qxZs5gyZQqxsbE0b96cGTNm0KZNmyKXT0pK4tlnn+WLL74gMTGRWrVqMX36dHr06HE5v56IiEP9dTyJTzccw2or2XqHT6eVyv7tdnte0i8gIIDp06fTr1+/Mv93VUQcS9dVIiIi4qyU+BMREXFSpXF/Misri6ysrHxjHh4eeHh4FFh29OjRJCcn07BhQ1xcXLBarbz44ov07dsXgNjYWABCQ0PzrRcaGpr3mrN44403eOWVV3jyySdZvHgxvXv35q233mLbtm3UqFG8KpT/+uSTTxg1ahRz5szhqquuYvr06XTv3p09e/YQEhJSYPns7Gy6du1KSEgIn3/+ORERERw5coSAgIDL/O1ERBzrlaW7WbP/zCWv7+d1eR9zTSYTb7/9NpMnT2bGjBmEh4df1vZEpPzRdZWIiIg4MyX+REREnJSJy8/8TZ48mQkTJuQbGzduHOPHjy+w7KeffsrHH3/MwoULady4MVu2bGHEiBFUr16d/v37X3YsFcmBAwfo3bs3ALfddhuurq5MmTLlkpN+ANOmTWPQoEEMGDAAgDlz5vD999+zYMECRo8eXWD5BQsWkJiYyO+//57Xvi4qKuqS9y8iUlYysq0A3NK8OnVDfEq0rquLiZubVS/ROtnZ2TzzzDMEBgbyzDPPANCqVSs+//zzEm1HRCoOXVeJiIiIM1PiT0RERIo0ZswYRo0alW+ssGo/gCeffJLRo0fntexs2rQpR44cYfLkyfTv35+wsDAA4uLi8lVPxMXF0aJFC8f8AgbJyMjA29sbyK0c8fDwuKyKkezsbDZu3MiYMWPyxsxmM126dGHt2rWFrvPNN9/Qtm1bhgwZwtdff021atXo06cPTz/9NC4uLpcci4hIWbmpWTjdG4c5dB9r165l5MiRnDhxAjc3N+677z4iIyMduk8RMZauq0RERMTZKfEnIiLipMyl0OqzqLaehUlPT8dsNucbc3FxwWbLnaQpOjqasLAwVqxYkZfoS05OZt26dQwePPjygy1n5s+fj49PbqVKTk4O7733HsHBwfmWGT58eLG2dfr0aaxWa6FtUnfv3l3oOgcPHuTnn3+mb9++LFmyhP379/Poo49isVgYN25coev8t7VrcnIyABaLBYvFUqxYS+L8Nh2xbSkenQNj6fjnys6x8dWWk5xOzQbg1LlMAKw5Vocdm7S0NMaOHcvMmTOx2+2EhYUxc+ZMwsLCKv35KGv6OzCWo49/eTyvznhdZc3Jyfu5PB7zykDvZcbTOTCezoGxdPyNV56uq5T4ExERcVKm0pjkrwRuvvlmXnzxRWrWrEnjxo3ZvHkz06ZNY+DAgXnxjBgxgkmTJlGvXj2io6N5/vnnqV69Or169SrTWB2tZs2azJs3L+95WFgYH374Yb5lTCZTsRN/l8JmsxESEsLcuXNxcXGhVatWnDhxgilTphR5g6qw1q4Ay5Yty6tgdITly5c7bNtSPDoHxqrsx3/rGRML9hasmNm2ZSOWw/ZS39+2bduYOXMmcXFxAFx//fUMGDAAV1dXlixZUur7k+Kp7H8HRnPU8U9PT3fIdstaeb+u2pVkAnLfR/W3ZCwdf+PpHBhP58BYOv7GKw/XVUr8iYiIOKkyzvsxY8YMnn/+eR599FHi4+OpXr06Dz/8MGPHjs1b5qmnniItLY2HHnqIpKQkrrnmGpYuXYqnp2fZButghw8fLtXtBQcH4+LikneT+ry4uLi8Fqr/FR4ejpubW772U40aNSI2Npbs7Gzc3d0LrPPf1q7JyclERkbSrVs3/Pz8Sum3+YfFYmH58uV07do1b74cKVs6B8bS8c+VvukE7N1BmJ8H19bPrYwO9fPk4Q7RuLuaL7J2yZw+fZp77rmHjIwMIiMjmTFjBkClPwdG0t+BsRx9/M9XuZUnznhd5bvvNHN2bQL0fmYUvZcZT+fAeDoHxtLxN155uq5S4k9ERERKha+vL9OnT2f69OlFLmMymZg4cSITJ04su8CcgLu7O61atWLFihV51ZE2m40VK1YwdOjQQtdp3749CxcuxGaz5bVg3bt3L+Hh4YXenIKiW7u6ubk59IODo7cvF6dzYKzKfvzP30hvFO7HK3e0cOi+wsPDeeGFFzhw4AAvv/wyXl5eLFmypNKfg/JA58BYjjr+5fGcOuN1lYvrP7f39LdkLB1/4+kcGE/nwFg6/sYrD9dVSvyJiIg4KXNZl/yJQ40aNYr+/fvTunVr2rRpw/Tp00lLS2PAgAEA9OvXj4iICCZPngzA4MGDmTlzJo899hjDhg1j3759vPTSSw5tLyoiUpRMi5VfdseTYbEWeG3TkbMO229iYiKPP/44gwYNol27dgA8/vjjea9rDhSRyknXVSIiIuLMlPgTERFxUsr7OZe77rqLhIQExo4dS2xsLC1atGDp0qWEhoYCcPTo0bxvoANERkby448/MnLkSJo1a0ZERASPPfYYTz/9tFG/gohUYnNWHWD6T/suuIyrS+m29fzyyy959NFHiY2N5c8//+Svv/7K16ZPRCoeq9XKe++9x4oVK4iPj8dms+V7/eeffy7WdnRdJSIiIs5MiT8RERGRCmLo0KFFtqBauXJlgbG2bdvyxx9/ODgqEZGLO52aBUCtIG9qBVUp8Lq7i4mHOtYulX3Fx8czbNgwPv30UwAaNmzI/PnzlfQTcQKPPfYY7733HjfddBNNmjTBdBnfdNN1lYiIiDgrJf5ERESc1OXcCBEREXGEW6+IYESX+g7Ztt1uZ9GiRQwbNowzZ87g4uLCU089xdixY/H09HTIPkWkbC1atIhPP/2UHj16GB2KiIiISLmlxJ+IiIiTUt6vfDhw4ADvvvsuBw4c4I033iAkJIQffviBmjVr0rhxY6PDExFxGsuXL6dPnz4ANGvWjAULFtCqVSuDoxKR0uTu7k7dunWNDkNERESkXCvdSRRERESk3DCbTJf9kMuzatUqmjZtyrp16/jiiy9ITU0FYOvWrYwbN87g6EREnEvXrl25+eabmTBhAuvXr1fST8QJPf7447zxxhvY7XajQxEREREpt1TxJyIiIuIgo0ePZtKkSYwaNQpfX9+88c6dOzNz5kwDIxMRqfiOHDnC888/z5tvvklAQAAmk4mvv/5ara5FnNjq1av55Zdf+OGHH2jcuDFubm75Xv/iiy8MikxERESk/FDiT0RExEnptqfxtm3bxsKFCwuMh4SEcPr0aQMiEhGp+Gw2G2+//TZPPfUUqampVKlShdmzZwOa31bE2QUEBHDrrbcaHYaIiIhIuabEn4iIiJPSzU/jBQQEcOrUKaKjo/ONb968mYiICIOiEhGpuPbv38+DDz7IqlWrAGjfvj0jRowwNigRKTPvvvuu0SGIiIiIlHua409ERMRJmU2X/5DLc/fdd/P0008TGxuLyWTCZrOxZs0annjiCfr162d0eCIiFYbVauX111+nWbNmrFq1Cm9vb958801+/fVXGjRoYHR4IlLGEhISWL16NatXryYhIcHocERERETKFSX+RERERBzkpZdeomHDhkRGRpKamkpMTAwdO3akXbt2PPfcc0aHJyJSYbzwwguMGjWKjIwMOnfuzLZt2xg2bBhmsz7SilQmaWlpDBw4kPDwcDp27EjHjh2pXr06DzzwAOnp6UaHJyIiIlIu6FOSiIiIkzKZTJf9kMvj7u7OvHnzOHDgAN999x0fffQRu3fv5sMPP8TFxcXo8EREKoyhQ4dSt25d5s6dy08//UTt2rWNDklEDDBq1ChWrVrFt99+S1JSEklJSXz99desWrWKxx9/3OjwRERERMoFzfEnIiLipJS3M97q1au55pprqFmzJjVr1jQ6HBGRMmW328mx2QGw2kq27tatW/nkk0948cUXMZlMBAcHs2vXLlxd9RFWpDJbvHgxn3/+Odddd13eWI8ePfDy8uLOO+9k9uzZxgUnIiIiUk7oU5OIiIiTUsWe8Tp37kxERAT33HMP9957LzExMUaHJCJSJtKzc+jxxm8cPlOy1ntZWVm8+OKLTJ48mZycHK644gp69+4NoKSfiJCenk5oaGiB8ZCQELX6FBEREfmbWn2KiIiIOMjJkyd5/PHHWbVqFU2aNKFFixZMmTKF48ePGx2aiIhDHUxIK5D0c3cx07JmYJHr/Pnnn7Rq1YoXXniBnJwcbr31Vjp06ODoUEWkAmnbti3jxo0jMzMzbywjI4MJEybQtm1bAyMTERERKT8u6SuTv/32G2+//TYHDhzg888/JyIigg8//JDo6Giuueaa0o5RRERELoFZBX+GCw4OZujQoQwdOpRDhw6xcOFC3n//fcaMGUPHjh35+eefjQ5RRMShQnw9WD7yWgDcXc14uRec3zQjI4Nx48YxdepUbDYb1apVY9asWdxxxx2qXheRfN544w26d+9OjRo1aN68OZDbGtjT05Mff/zR4OhEREREyocSV/wtXryY7t274+XlxebNm8nKygLg3LlzvPTSS6UeoIiIiFwak8l02Q8pPdHR0YwePZqXX36Zpk2bsmrVKqNDEhFxOLPJhL+3G/7eboUm/QB69erFlClTsNls9OnTh507d9K7d2/9OyQiBTRp0oR9+/YxefJkWrRoQYsWLXj55ZfZt28fjRs3Njo8ERERkXKhxBV/kyZNYs6cOfTr149Fixbljbdv355JkyaVanAiIiIizmDNmjV8/PHHfP7552RmZtKzZ08mT55sdFgiIuXCk08+yY4dO5g9ezY333yz0eGISDnn7e3NoEGDjA5DREREpNwqceJvz549dOzYscC4v78/SUlJpRGTiIiIlALVSRhvzJgxLFq0iJMnT9K1a1feeOMNevbsibe3t9GhiYgYZsWKFcTFxdGnTx8AunTpwv79+/H09DQ4MhEpj7755htuvPFG3Nzc+Oabby647C233FJGUYmIiIiUXyVO/IWFhbF//36ioqLyja9evZratWuXVlwiIiJymcxqkWa4X3/9lSeffJI777yT4OBgo8MRETHUuXPnePLJJ5k3bx4+Pj60b9+eWrVqASjpJyJF6tWrF7GxsYSEhNCrV68ilzOZTFit1rILTERERKScKnHib9CgQTz22GMsWLAAk8nEyZMnWbt2LU888QTPP/+8I2IUERGRS6C8n/HWrFljdAgiIuXC999/z8MPP8yJEycA6N+/P1WrVjU4KhGpCGw2W6E/i4iIiEjhSpz4Gz16NDabjeuvv5709HQ6duyIh4cHTzzxBMOGDXNEjCIiIiIVhtpRiYj8w5J+jvvuu4+PPvoIgLp16/LOO+8UOn2EiMilSEpKIiAgwOgwRERERMqNEif+TCYTzz77LE8++ST79+8nNTWVmJgYfHx8HBGfiIiIXCKTSv4MoXZUIiK5bNmZbJv9CJuST2M2mxk1ahQTJkzQPKcicsleeeUVoqKiuOuuuwDo3bs3ixcvJjw8nCVLltC8eXODIxQRERExXokTf+e5u7sTExNTmrGIiIhIKVLezxhqRyUiksvs7klwi+sJPL2NBQsWcNVVVxkdkohUcHPmzOHjjz8GYPny5fz0008sXbqUTz/9lCeffJJly5YZHKGIiIiI8Uqc+OvUqdMFKwh+/vnnywpIRERESodZmT/DffDBB9x11114eHjkG8/OzmbRokX069fPoMhEREqf3W7n//7v/3IrbgJqAFCjc39+G925wPugiMiliI2NJTIyEoDvvvuOO++8k27duhEVFaUvF4iIiIj8rcSJvxYtWuR7brFY2LJlC9u3b6d///6lFZeIiIhIhTdgwABuuOEGQkJC8o2npKQwYMAAJf5EpFxYtTeBT9cfw2a3X/I2UhPj+e29yRzZ/BshtRvT6ck5AJjd3JX0E5FSExgYyLFjx4iMjGTp0qVMmjQJyP3igVqoi4iIiOQqceLv9ddfL3R8/PjxpKamXnZAIiIiUjpU8Gc8u91eaKeE48eP4+/vb0BEIiIFvfbjHradOHdJ69rtdlL/Ws7ZX97BnpUGLq5kR7Rk7cFETGYXqlZxL+VoRaQyu+222+jTpw/16tXjzJkz3HjjjQBs3ryZunXrGhydiIiISPlwyXP8/de9995LmzZteO2110prkyIiInIZLtSaWxzriiuuwGQyYTKZuP7663F1/eeSy2q1cujQIW644QYDIxQR+Ud2Tu58pPe3i6JOiE+x10s4dYwFk8dwdP1qAGrHNOfBZ6dQo3Z9AExAh3rBpR6viFRer7/+OlFRURw7doxXX30VH5/c96xTp07x6KOPGhxd+fTt1pOkZ+dw15U1jQ5FREREykipJf7Wrl2Lp6dnaW3ussSvfdPoEEScyqOfbzM6BBGnseDupmW2L3OZ7Un+q1evXgBs2bKF7t27592UAnB3dycqKorbb7/doOhERArXNSaU9nWLl6jbvHkzHe67gbS0NDw9PZk0aRIjRozAxcXFwVGKSGXm5ubGE088UWB85MiRBkRT/lltdh7/bCsWq40bm4bj5+lmdEgiIiJSBkqc+LvtttvyPbfb7Zw6dYoNGzbw/PPPl1pgIiIiIhXVuHHjAIiKiuKuu+4qN1+OEhEBSM3K4b01hzibbgEgPiWzxNto2rQpMTExeHp68s4771CvXr3SDlNEBIBvvvmGG2+8ETc3N7755psLLnvLLbeUUVQVQ6bFmlfVbfn7/0VERMT5lTjx99/5aMxmMw0aNGDixIl069at1AITERGRy6NWn8br37+/0SGIiBSw5K9TvLZsb4FxH4+iPx5arVbeeecd+vXrh6enJ66urnz//fcEBQVhNqvGXEQcp1evXsTGxhISEpLXVaEwJpMJq9VadoFVABkWHQ8REZHKqESJP6vVyoABA2jatCmBgYGOiklERERKgVl5P0NUrVqVvXv3EhwcTGBg4AUTsImJiWUYmYhIrrTsHADqVKtCt8ZhANQI9KJZDf9Cl9+xYwcDBw7kzz//5NChQ0yePBmAatWqlU3AIlKp2Wy2Qn+Wi8vIVuJPRESkMipR4s/FxYVu3bqxa9cuJf5ERERECvH666/j6+ub97MqL0WkvGoU7sfTNzQs8nWLxcKrr77KxIkTyc7Oxs/Pj/r165dhhCIicjkyVfEnIiJSKZW41WeTJk04ePAg0dHRjohHRERESokq/ozx7/ae999/v3GBiIhchs2bNzNw4EC2bNkCwP/+9z/mzJlDRESEsYGJSKU2fPhw6taty/Dhw/ONz5w5k/379zN9+nRjAiun1OpTRESkcirxZAyTJk3iiSee4LvvvuPUqVMkJyfne4iIiEj5YDKZLvshl2fTpk1s27Yt7/nXX39Nr169eOaZZ8jOzjYwMhGRon300UdceeWVbNmyhapVq/Lxxx/zzTffKOknIoZbvHgx7du3LzDerl07Pv/8cwMiKt/S1epTRESkUip24m/ixImkpaXRo0cPtm7dyi233EKNGjUIDAwkMDCQgIAAtf8UEREpR8ymy3/I5Xn44YfZu3cvAAcPHuSuu+7C29ubzz77jKeeesrg6ERECtehQwe8vLzo3bs3O3fupE+fPvoyiIiUC2fOnMHfv+B8pH5+fpw+fdqAiMo3VfyJiIhUTsVu9TlhwgQeeeQRfvnlF0fGIyIiIuI09u7dS4sWLQD47LPPuPbaa1m4cCFr1qzh7rvvVjsqESkX0tPT+f777+nduzcAtWrVYtu2bURFRRkbmIjIf9StW5elS5cydOjQfOM//PADtWvXNiiq8itTFX8iIiKVUrETf3a7HYBrr73WYcGIiIhI6VFxhvHsdjs2mw2An376if/9738AREZG6lvpIlJiNpudPw6d4Vy65bK2s/PkP1M0/PrrrzzwwAPs37+f5cuX06VLFwAl/USkXBo1ahRDhw4lISGBzp07A7BixQqmTp2qL1QVQhV/IiIilVOxE3+A2ruIiIhUIGb9u2241q1bM2nSJLp06cKqVauYPXs2AIcOHSI0NNTg6ESkovn2r5M8tmhLqWzLlpXOb++/wqxlnwJo/j4RqRAGDhxIVlYWL774Ii+88AKQ+0WF2bNn069fP4OjK3+U+BMREamcSpT4q1+//kWTf4mJiZcVkIiIiJSOYk/kKw4zffp0+vbty1dffcWzzz5L3bp1Afj8889p166dwdGJSEUTl5wJQLCPO7WDfS59O7v+ZOPHL3PsTCwAgwYNYsqUKYXOmyUiUt4MHjyYwYMHk5CQgJeXFz4+l/5+6Owy1OpTRESkUipR4m/ChAn6MCgiIiJSTM2aNWPbtm0FxqdMmYKLi4sBEYmIM+hYvxrT7mxxSes+9dRTfPbmFCC3SmbevHl57T1FRCqCnJwcVq5cyYEDB+jTpw8AJ0+exM/PT0nA/8hUxZ+IiEilVKLE3913301ISIijYhEREZFSpE6f5cfGjRvZtWsXADExMbRs2dLgiESkPIlLzuR0etpFlzuZlHnZ+2rVqhUAw4YN46WXXtJNchGpUI4cOcINN9zA0aNHycrKomvXrvj6+vLKK6+QlZXFnDlzjA6xXFGrTxERkcqp2Ik/ze8nIiJSsWiOP+PFx8dz1113sWrVKgICAgBISkqiU6dOLFq0iGrVqhkboIgY7nQmXDv1N6w2e7HXMVH89/czZ86wd+9e2rZtC8Cdd95J48aNadKkSYljFREx2mOPPUbr1q3ZunUrQUFBeeO33norgwYNMjCy8ildrT5FREQqpWJP/2O3F/+DqIiIiBjPZLr8R0mdOHGCe++9l6CgILy8vGjatCkbNmzIe91utzN27FjCw8Px8vKiS5cu7Nu3rxR/6/Jl2LBhpKamsmPHDhITE0lMTGT79u0kJyczfPhwo8MTkXLgdKYJq82Oq9lERIDXRR91qlWhZ4vqxdr2559/TkxMDD179uT06dNA7hc6lfQTkYrqt99+47nnnsPd3T3feFRUFCdOnDAoqvJLrT5FREQqp2JX/NlsNkfGISIiIhXc2bNnad++PZ06deKHH36gWrVq7Nu3j8DAwLxlXn31Vd58803ef/99oqOjef755+nevTs7d+7E09PTwOgdY+nSpfz00080atQobywmJoZZs2bRrVs3AyMTkfKmbogPS0d0LJVtxcbGMnToUBYvXgxA48aNOX36NMHBwaWyfRERo9hsNqzWgsms48eP4+vra0BE5VuGKv5EREQqpWJX/ImIiEjFYjZd/qMkXnnlFSIjI3n33Xdp06YN0dHRdOvWjTp16gC51X7Tp0/nueeeo2fPnjRr1owPPviAkydP8tVXX5X+ASgHbDYbbm5uBcbd3Nz0pSoRKXV2u52PPvqIxo0bs3jxYlxdXRk7diwbN26kYcOGRocnInLZunXrxvTp0/Oem0wmUlNTGTduHD169DAusHJKc/yJiIhUTkr8iYiIOCmzyXTZj6ysLJKTk/M9srKyCt3fN998Q+vWrenduzchISFcccUVzJs3L+/1Q4cOERsbS5cuXfLG/P39ueqqq1i7dq3Dj4cROnfuzGOPPcbJkyfzxk6cOMHIkSO5/vrrDYxMRJyNxWLhlltu4b777iMxMZErrriCDRs2MGHCBDw8PIwOT0SkVLz22musWbOGmJgYMjMz6dOnT16bz1deecXo8MqdDIu+aCYiIlIZKfEnIiLipEpjjr/Jkyfj7++f7zF58uRC93fw4EFmz55NvXr1+PHHHxk8eDDDhw/n/fffB3JbzwGEhobmWy80NDTvNWczc+ZMkpOTiYqKok6dOtSpU4fo6GiSk5OZMWOG0eGJiBNxc3MjNDQUd3d3XnrpJdatW0fz5s2NDktEpFRFRkaydetWnn32WUaOHMkVV1zByy+/zObNmwkJCTE6vHInU60+RUREKqViz/EnIiIilc+YMWMYNWpUvrGiKkdsNhutW7fmpZdeAuCKK65g+/btzJkzh/79+zs81vIoMjKSTZs2sWLFCnbt2gVAo0aN8lU9iohcqkOHDuHm5kaNGjWA3EqYUaNGERMTY3BkIiKlz2Kx0LBhQ7777jv69u1L3759jQ6p3FOrTxERkcpJiT8REREnVdI5+grj4eFR7BZx4eHhBW42N2rUiMWLFwMQFhYGQFxcHOHh4XnLxMXF0aJFi8sPtpz55JNP+Oabb8jOzub6669n2LBhRockIk7CZrMxa9YsRo8eTYcOHfjhhx8wmUwEBAQQEBBgdHgiIg7h5uZGZmam0WFUKOnZOUaHICIiIgZQ4k9ERMRJmSiFzF8JtG/fnj179uQb27t3L7Vq1QIgOjqasLAwVqxYkZfoS05OZt26dQwePLhMY3W02bNnM2TIEOrVq4eXlxdffPEFBw4cYMqUKUaHJiJlwGaz03f+OjYcSbzoslZryWZf2Lt3LwMHDmTNmjUAZGZmkpycjL+//yXFKiJSkQwZMoRXXnmF+fPn4+qqW1oXk6k5/kRERColXSWJiIhIqRg5ciTt2rXjpZde4s477+TPP/9k7ty5zJ07FwCTycSIESOYNGkS9erVIzo6mueff57q1avTq1cvY4MvZTNnzmTcuHGMGzcOgI8++oiHH35YiT+RSiIxPZu1B88Uc+ncL2m0rBV4waVycnJ4/fXXGTt2LJmZmfj4+PDqq6/y8MMPYzZr6nYRqRzWr1/PihUrWLZsGU2bNqVKlSr5Xv/iiy8Miqx8UqtPERGRykmJPxERESdVGq0+S+LKK6/kyy+/ZMyYMUycOJHo6GimT5+eb/6Vp556irS0NB566CGSkpK45pprWLp0KZ6enmUbrIMdPHgw37yGffr04YEHHuDUqVP52pyKiPP7Y8z1Rb5mybHw84qf6dLleqoHVilyuePHj3Pbbbexfv16ALp168bcuXPzKqpFRCqLgIAAbr/9dqPDqDAyspX4ExERqYyU+BMREXFSZZ34A/jf//7H//73vyJfN5lMTJw4kYkTJ5ZhVGUvKysr3zfQzWYz7u7uZGRkGBiViBghzL/oLzZYLC4EeECIrwcmU9Fv2kFBQZw7dw5/f39ef/117r///gsuLyLibGw2G1OmTGHv3r1kZ2fTuXNnxo8fj5eXl9GhlVt2u10VfyIiIpWUEn8iIiJOSjeFjfX888/j7e2d9zw7O5sXX3wx3zxc06ZNMyI0EXGAH3fE8urS3Visdqw2+2Vvb/v27TRq1AgXFxe8vLz47LPPCA4Opnr16qUQrYhIxfLiiy8yfvx4unTpgpeXF2+++SYJCQksWLDA6NDKrawcze8nIiJSWSnxJyIiIlLKOnbsyJ49e/KNtWvXjoMHD+Y9V2JWxLks3nicAwlp+caigryLWLpomZmZvPDCC7zyyiu88sorPP744wA0a9asVOIUEamIPvjgA9566y0efvhhAH766Sduuukm5s+fr3lOi6A2nyIiIpWXEn8iIiJOyohWn5Jr5cqVDtnurFmzmDJlCrGxsTRv3pwZM2bQpk2bi663aNEi7rnnHnr27MlXX33lkNhEKrvzNX6Dr6tD15hQAOqH+pZoG3/88QcDBw5k165dQG7Vn4iIwNGjR+nRo0fe8y5dumAymTh58iQ1atS4pG06+3VVutp8ioiIVFr6WpSIiIiTMpku/yHlxyeffMKoUaMYN24cmzZtonnz5nTv3p34+PgLrnf48GGeeOIJOnToUEaRilRuNat607JmIC1rBuLjUbzvWaanpzNq1CjatWvHrl27CA0N5YsvvuDdd991cLQiIhVDTk4Onp7550x1c3PDYrFc0vYqw3WVKv5EREQqL1X8iYiIOCmzMndOZdq0aQwaNIgBAwYAMGfOHL7//nsWLFjA6NGjC13HarXSt29fJkyYwG+//UZSUlIZRiwixbF3714ef/xxDhw4AED//v2ZNm0aVatWNTgyEZHyw263c//99+Ph4ZE3lpmZySOPPEKVKlXyxr744otiba8yXFdlquJPRESk0lLiT0RERKScy87OZuPGjYwZMyZvzGw206VLF9auXVvkehMnTiQkJIQHHniA33777aL7ycrKIisrK+95cnIyABaL5ZK/UX8h57fpiG1L8egclB67zQbk3hgu7vG0WCx4eHhw9OhRatSowVtvvcUNN9yQ95o4nv4GjKdzYCxHH//S2m7//v0LjN17772XtC1nvK6y5uTk/Xx+2ykZWfmWseTkYLGo8Zej6L3MeDoHxtM5MJaOv/HK03WVEn8iIiJOSnP8OY/Tp09jtVoJDQ3NNx4aGsru3bsLXWf16tW88847bNmypdj7mTx5MhMmTCgwvmzZMry9vUsUc0ksX77cYduW4tE5uHxxcWbAzLZt2/CN/+uCy546dYrw8HAAatWqxdNPP01MTAw2m40lS5aUQbTyX/obMJ7OgbEcdfzT09NLZTul2frYGa+rdiWZABfgn3O5+19jACt++gkft1LdrRRC72XG0zkwns6BsXT8jVcerquU+BMREXFS6vRZeaWkpHDfffcxb948goODi73emDFjGDVqVN7z5ORkIiMj6datG35+fqUep8ViYfny5XTt2hU3N92JMoLOQen59uxmtp1NoGnTpvRoXaPQZc6ePcuTTz7Jxx9/zJo1a2jatCnLly9nzJgxOv4G0d+A8XQOjOXo43++yq0iqwjXVb77TjNn1yaAvHPptjMedm3JW+b6Ll0IquJeqvuVf+i9zHglPQc2m50/D59l2a542tepyvUNQy64vN1uZ8fJFL796xSHz6Qz8ZZGhPp5XnAdZ5OSmYOHqxl318Krh/97DtKycjh8Jp26IT54FLGOlB69DxmvPF1XKfEnIiLipMwo81ce/Pbbb7z99tscOHCAzz//nIiICD788EOio6O55pprirWN4OBgXFxciIuLyzceFxdHWFhYgeUPHDjA4cOHufnmm/PGbH+3IXR1dWXPnj3UqVOnwHoeHh755s45z83NzaEfHBy9fbk4nYPLZzLn3sxwcXEp9Fh+/fXXPPLII8TGxmIymfj9999p2bIloONfHugcGE/nwFiOOv7l8Zw643WVi+s/t/fOb99i/89+XV3L5flwNnovM95/z8HRM+l8tvEYfxw8w+gbGxLo7c4Xm07w5eYTnEjKAGD94bPc0DSi0O0dTEjlm60n+WbLSQ6eTssbv+FgOHdeGenYX8ZgOVYbW48n8eve0/y6L4Gtx5II8vHgt6c64enmQlaOlU1Hkliz/zRJGdkMvTaafedM7Fl1hHWHz7L1WBI5NjsPX1ubMTc2MvrXqTT0PmS88nBdpcSfiIiIiIMsXryY++67j759+7J58+a8eV7OnTvHSy+9VOyWfu7u7rRq1YoVK1bQq1cvIPeG04oVKxg6dGiB5Rs2bMi2bdvyjT333HOkpKTwxhtvEBnp3B9QRcqThIQEhg8fzqJFiwCoX78+CxYsoH379pp/Q0TEAJXluioj22p0CCKGybRY+WH7KT5Zf4w/Dibmjd8+O/88nq5mEzk2OxarLd94XHIm3249yTdbT/LX8XN5455uZtxdzCRn5mCz52bX7XY7u06l8P22k/xxMJEhnerQuWH+VsIVybHEdH7dl8CvexP4ff8ZUrJy8r2ekJLFtOV72XUqmfWHE8m0/HPsPvrjKLkthg/mW+fI6dJp+ywixafEn4iIiJNSq0/jTZo0iTlz5tCvX7+8m/4A7du3Z9KkSSXa1qhRo+jfvz+tW7emTZs2TJ8+nbS0NAYMGABAv379iIiIYPLkyXh6etKkSZN86wcEBAAUGBcRx/niiy945JFHSEhIwGw28+STTzJu3Di8vLyMDk1EpFKrDNdV6Ur8iRPIzrHh5mLCVIwPt3a7naOpMPabnXy3LZaUzNyElckE9n9VwLqYTXSsF8xtLWvg5+VG/wV/AnAuw8KP22P5assJ1h48k7eOi9lEh3rB9GxRna4xYYxYtJmfdsVz6Ewa05bt4bttpziY8E8l4OJNJy478RefnMm++FSurh2Ei9mxH+xTs3JYe+AMv/2d7Dt8Jn+SLsDbjfZ1g+lYL5jnv95Bdo6Nub/+k9gL9vHgdGpW3nM/NzvXNarONfWqcTQxnZm/7M+3r/WHE/njwBk2HT3LdQ1CGNKprkN/P5HKSok/ERERJ+XgzwdSDHv27KFjx44Fxv39/UlKSirRtu666y4SEhIYO3YssbGxtGjRgqVLlxIamvuh8ujRo5jNmjdBpDw5deoUCQkJNGnShAULFnDllVcaHZKIiFA5rqsyLEr8ScVkt9tZdyiRD9Ye5scdcQzqUJvRNzYscvnEtGy+2nyCT9YfZU+cK3AcgBqBXtzZOpI7WtUgw2Jl6rI9XBEZSM8rqhPimzs337qDZwA4lpjBlZN+IvtflX+tagXSs0V1bmoaTpBPwba9b6/6J/nl7mom3N+TI2fSwV5g0UKdTMpg+c44LFYbA9tHsz8hleU741i2M46tx5IAeOnWpvS5qmbxNlgE+98ZzPPJU6vNzvYT53ITfftOs+nIWXJs/wTtajbRsmYgHeoF07F+NZpE+OclH9fsP8PKPfG0ia5KuzrBXFMvmHohPpxNt/DHwTPUDvJi95+ruOmmpri5ufHhH0cA2HbiHD1nrWH7iXNY/7Wv3adSlPgTcRAl/kREREQcJCwsjP379xMVFZVvfPXq1dSuXbvE2xs6dGihLagAVq5cecF133vvvRLvT6SyO5dhYdGfR/O+MX4h++NTsdvtJJ2JB3Jv0AwePBgPDw/69euHu7u7g6MVEZGScPbrqkwl/qSCScvK4astJ/jg9yPsiUvJG99y7GyBZa02O7/tS+DTDcf+Tp7lJpNcTXZubBrOPW1qcXXtIMz/+jbsW31bFdiOq0vu6+cTfvVDfejZIoJbmlcnsqp3oXEGeude07m7mOlYvxo3Nw+nc8MQvth0gnHf7Ljg73gwIZWlO2L5ccc/yT2ASd/vKnT5M/+qpCuJ1KwcVu87zco98fyyJ5645CxGda3P3rgU1uw/zdn0/O3mo4K86VCvGh3rV+Pq2lXx9Sx8HrE377mi0PGqVdzp0TQci8XCnn99Adnl72TjiaSMvPkUa1b1pmGYL8t2xuW1SwXIyrHy1/Fz/HkoES83Fwa0jypWpWdFEpecydZjSRxNTOfGpuFEBBTdBSQtK4edp5LZdvwc206cw8fDlfG3NC60AjTHauPg6TS2Hk3k+8NmPn5nPYfPpPNQx9o82KE2SenZ7DyZzI6Tyew6lUyTCH8GXhPtyF9VygEl/kRERJyU2ckukiuiQYMG8dhjj7FgwQJMJhMnT55k7dq1PPHEEzz//PNGhyciF/Hp+mNM/mF3sZbNSU7gzI8zmfBxAv327KRKlSqYzWYefPBBB0cpIiJSkOb4c7yNR87y5GdbaR0VyIs9Yxy2n8S0bFxMJvy9C0/GVHSHTqfx4dojfLbxWN6XrbzcXGgQ5suWfyXHAE6dy+DT9cf5ZP1RTp7LzBtvEuHHHVdUxyNuO3fc0gw3t+IdqyYR/tx3dS18PF3p2aI6DcP8LrrO8zfHcGPTMFpHVcWviATZeXa7nR0nk1m2I5alO2LZG5ea99p/W5C6u5hpXzeIrjFh/LYvgR+2xxbrdzi/n4On0/hld26i789DiXnJ0POmLd+b97Ovhyvt6gblJvvqVaNmUOFJzsvVNSaUX/bEE+DlxtW1g7i6ThARAV4cOZPGsp1xWGx2Xl++l3WHzrD5aBJZOf9UXLatE0Sj8Iufj5I6m5bNpqNnsdrsdI0JveTkos2We8y3Hksi1M+T1lGB7DyVzF/Hkth6/BxbjyVx8HQaPVtUJz3byl/Hk4hL/ieRuzs2hdd6NwcgPTuHHSdzk3zbT5zjrxPnOJCQmu+/D4DbWkYQU92PfXGpbD9xju0nz7H9RDK7Y5P/NdeiGchNlk/6fhfvrjmcl3Q978stJ7i7TSTe7koNOTOdXRERESelvJ/xRo8ejc1m4/rrryc9PZ2OHTvi4eHBE088wbBhw4wOT0QuIiUr9+ZTwzBfrq4dVOgydpuNjcs+Z/l7U8nOSMPu4cHatWvp0qVLWYYqIiKSj1p9OtYn64/y/Fc7yLbaOJdhcUjiLzvHxpxVB5j5835C/Dz47alOTlMBZbPZWbk3nvd/P8KqvQl541FB3tzXNoo7WtXgt30JDF24GZsNVuyK4//+PMrPu+M53ynS38uNW6+IoHfrGjSu7o/FYmHJku0lisPD1YUXepVsrk4/T7cLzuFns9vZcDiRpdtzk33Hz/6TdHE1m2hXN5jujUPpGhPK2gNn+OPgmbxqOx+P3Fv1206cu2gcmRYrfxw8w8o9Cfy8O56jifnn5qsV5E2nBiFsOnqWv46fo0VkAB3rV+Pa+sE0rxGAq4vj2xlX8/VgXr/WRb6enWPjjRX78p4H+7iTnJFDttVW7HlK07NzOBCfRt0QH7zcXfK9ZrPZOZCQysYjZ3MfR8/mm4/x80fa0jqqarH2k5CSxdZjSWz5+7H1eFKxuoJ8veVk3s9mU+5/t2fTLWw6epZRn2xh299JPlshLWLD/DxpEuHPukNnSMnMYdj/bSYuObNAUhfA292FmHBfvLMSCQqvwZebc/f770rLBmG+LN8Zh91OvparkisxLZv98ansj0/lQELu/5tNMP3uK/D3+ifJn2O1kZKZw7kMC8mZltz/z8h9fi49C9IusJMypMSfiIiIk1LFn/FMJhPPPvssTz75JPv37yc1NZWYmBh8fHyMDk1ESqBNdFXG39K4wPjBgwd58MEH+eWXXwBo27YtCxYsoGHDouehERERKQtK/DmGxWpj0nc7eX/tEYfuZ8PhRMZ8sY198bkVYsfPZmC3V/wvd55Lt/DphmN8+MeRvESVyQSdGoTQr20tOtarlq89J8CfhxP583Bi3vM20VXpe1VNujcOw9Mtf6KnPPhhe2y+aj1PNzPX1q/GDU3C6NwgNF/lZs8WEfRsEVHsbZ9Iysit6tsdz5oDp/9V5ZVbMXhV7apc1yCEzg1DiA6ukvea1WYvtEWkUSICvGhVK5BTSRlcGV2Vq6KDaBNdlTrVqnDtlJX5kpiZFitbjyWx4chZElKyuKNVDY4mprPh8Fk2HEnkr+O5SdLbWkYwsWcTth5Lykv0bT56luRCknMuZhNWm53TqdnAP9V7W44lcTIpg1uaVychNTfRt/lYEluOJhWomoPcc/vvcxBUxZ3mkQE0rxHA2fRsft2XQJPq/jSr4U/zyABiwv34dutJRn+xjYMJafmSkKF+HjSN8KdpRABNa/jRJMI/by7Km2esZtuJc3lJ5ABvNxpX96NJdX8aR/jTuLof0UFVsFpzWLJkCTfc0JjmNQKwAzHhfjSq7oefpxtZOVYaPLc0b5+pWTnsPpXMzlO5LUABxt3c+KJ/VzabnaOJ6Rw8nUqT6v6E+HlecPnSYLXZOZaYzt64FPbFp7I3LoXTqVm4uZhxdzHj5mrGw8WMu6uZwCruPHBNNMF/z82ZlJ6b0DuRlEGb6KrkWO3sT0jlwH+SfP9tgXte8wnLaBjmS3KGheTMHFKzLpzwDfd2oTz0fFHiT0RERMTB3N3diYlxXPsfESlbdrudN998k2eeeYb09HS8vLyYPHkyQ4cOxcWl/N2AEhGRykdz/JW+M6lZDFm4iT8O5iahbrsigi82nyh02QMJqZxOyeKqIjoGFCU508IrP+zm43VHAfD1dC1WVVF5tz8+hXdWH+bLzcfzEiV+nq7cdWUk915di1pBVQqs4+H6zzVVgLcbd7Sswd1talI3pHx+ifLf1Wa+nq50aRRK98ZhXFu/WoFKtOKy2OysO3iGn/fEs3J3Qr65DyG3IqxTw2p0ahBC+7rBVPEo/FZ/eUr6Abi6mFk8uN0Fl3l3zSEmL9nFX8fP5c3BCPDe74cLXf7brSf5avOJApVzXm4uNI/0p1WtQFrVCuSKyEAGfbCBDUfO8sWm4yz88yhb/pMg/Hdb1PNMJqgX4kOLyACaRwbQIjKABqG+nEzKZHdsMjHV/YgI8LpoVW6nhiG0qxOEt7sLTSL8/072XTh59tKtTfl1XwJ1qvnQJKLo/Vj/fts3m03c3/7Cc/jdMP23QpOZnRvmVqOedy7dwu7YZHbHprA7Npldp1LYG5eSV5HZqlbgRc9lSdhsdo6fzWBvXAp741PYF5eb5Nsfn5qvFezFzF55gLa1g9gXn8rpEsyVGRHgRd0QH+qG+PDO6kN547tjUwosW8XdBT8vN/w83fD3csOOnfWHz5JRTt6ylfgTERFxUhX926DOoFOnC7fj+fnnn8swGhEpTb/88gvp6el06tSJefPmUadOHaNDEhERyVPcNnlSPDtOnuOhDzZyIimDKu4uvH5XC6KCqxRI/NntdhasPsTkH3Zhsdr5fXRnqgd4FWsfS7efYuzXO4hPyb1JfWfrGgy+ri6dXltZ2r9Ooex2e7FaiZ5IymDerwf57q+TjL6xEXe0qlHk9n4/cIb5vx3klz3/tPNsFO5H/7a16Nki4oIJsQ71gnmiW30iq3qX2+q+f7u5WXXSs3KIruZD29pBuLtefivNN1fs481/tcI0m3ITLeer+hqG+TpN+9fzzv863/11Km+smq8HCSn/JG8ahfvRulYgraMCAXhs0Za89pfnqwnPPxqG+RZoa3p+H8t2xuWNebia8yWWQnw9aBEZQIuaAbSoEUDTGv74FjKnY80g7xLNkRjq58nCQVcXe3mApjX8aVrDv0TrFMbFZKKKuwtp2da8pF+Ynycx1f3YduIcCSlZ/LYvgS3HzrLrVAq7TyXnm0vz38wmsNkh9j+vJ2da2BeXQlAVD6KC8yf0U7NyyLJYCfLxwGazcyIpg33xKez9O7m3Ly638q6oinV3VzN1q/lQP9SHeqG+RAR4YbHayLbayM7Jffx7fva1B88Uvh0XM1HB3rkJvmo+1AnxoU613Me/35MeubYOK/fE4+Xukpfc8/PK/X9fT1fc/vPf1fYT5/jfjNVFHP2yp8SfiIiIk3J8x365mBYtWuR7brFY2LJlC9u3b6d///7GBCUilyQnJ4eMjAx8fXNvsMyePZsePXrw4IMPYjbrHVdERMqXDCX+Ss0P204x8tMtZFpsRAV5M69fa+qF+rL3P9VX6Tkw5P+2snxXfN7Y2fTsiyb+ElKyGPv19rz2kNHBVXjx1ia0qxPM2bTsIteLS87kZFIGV9QMvOTfLcdq48vNJ5j5y35czCZ+HNEx72Z2do6NLzYdZ+epZB7v2oCE1ExmrzzI11tOkPN3WdWqvQkFEn9ZOVa+3XqK+b8dzKuSMZmgW0woA9tH0ya6arGSVZ5uLgztXO+Sf7ey5uXuctEqq+IK/Fc70KpV3Lm2fjU6NQyhY71gArzdS2Uf5dW9V9Xiy80naBrhT+uoQNpEV6VmVW9sdtgfn0p4gCd+/0rAnU9Yu5pNtKwZSJj/xdtO3n1lTTIsVuqH+HJFzQCuqBlIgzBfzCYTu04lU7WKO+H+nk6XVHV1MTOvf2t2nUqhUZgvjcL9CKyS+9/TnW+vJSEliw8KaWMcEeBFo3BfGob50fDv/z+XYeH22b+TmpXDyz/sZk9sMnvjUvNVEY6/OYbY5Cz2xqWwJzYl32vnE5CFcXcxU7taFeqH+uYl+eqH+lKzqvdFq1dvaBLGnFUH8Pdyp97flXt1Qnzw8XDl+Nl0LFY7kYFexZrjspqvB71bR150ufNqBXmzoH9LNq//s9jrOJISfyIiIk7K2S5SK6LXX3+90PHx48eTmppaxtGIyKWKO7yXq6++n4YNG/LRRx8BEB4ezkMPPWRwZCIiIoVTq88LK051m91uZ/aqA7y6dA8AHetXY8bdV+Sbo+28LceSmPKXC4lZ8bi7mLFjz6tAutD2v9l6kvHf7OBsugVXs4lHrq3D0M51L1jdlmmxMvfXg7y1cj+ZFhvfDbuGJhG51UDnMizM/HkfS7bF8tJtTbm2frVCt2Gz2flheyzTlu/hwL/mGTuTmk1gFTc+3XCc2b/sz6v2+WDtEUwmsP/9KwX7uOfNj3be2bRsPl53hPfXHsmrzvJ2d+HO1pHc3y6qQPWPFG1Qh9pEBVWhbqgPzWsElLtWnY40qGNtBnWsXWDcxQQNwnwLjJtMJm5pXr1E+7i9VQ1uL6JS9fzfkrNqVyeYdnWCC4zf2CSMgwlp1KzqRcNwPxqF+dIw3I/6ob74exV8z/vreBKQ+54zZ9WBQvc1/tudRcaRlm3FzcVE7WAf6oX65Evy1arqXazEXGFqBVVh8m3NCn2tRmDxKzMvha+nGx3qBpNSsFOsIZT4ExERESlj9957L23atOG1114zOhQRuYAcSzZJqxcyf92n2HJyOHDgACdPnqR69ZLdXBARESlrRbVKq+zOpGYx+KNNZFttfDG4HeYiEirZOTae+2obn244DsD97aJ47qZGhd6MTsqwcM/89eTYTEQGevFW31Y8+MF64pKLnlcqPjmTZ77czk+7clsNxoT7MaV3MxpXLzrpYAeW7Yjlhe93cizxn8qZ06lZWKw2Fq47yvSf9nI23QLAr3sTCiT+7HY7K/cm8NqPe9hxMhnInT8v6e91Pl53hM82HCc2uWB7P7sdujcO5dHr6rLxyFkmfpd7U/9AQioLVh9i8aZ/5u8L9fPg/nbR9GlTs9BEqVxYYBV37ryy+JVGIpdrQPtoBpSgYrVRuB/dYkI5m55NgzBfGoT50SDUlwahvkxZtpul22OpXc2HBqG+1A/LHff3cuP3A6cJ9fOkfqgPtYKqFGiXKaVHiT8REREnVXm+E1jxrF27Fk/Pi7cgERHjbNiwgelD+3LuUO5XNnv16sVbb71FeHi4wZGJiIhcnBJ/BZ1OzaLvvHXs+btF5+m0LEJ8C16Tn0u38MhHG1l78AxmE4y7uTH920UVuV3r320vWwTZWPDI1VT1LbqqxG63s3jTCSZ+u4PkzBzcXEwM61yPwdfVuegN8AHvrefXvblz5YX5eZJttZGYls1v+04z8budHPy7cs/FbMqL6d/WHTzDlB/3sOHIWSC31d4DHWrzYIdoWk5cTo7Nzoyf9+dtf/B1dUhIyWLOqgPc0rw6j1xXh/qhuRVXG//exi+74/l268m8fTSu7segDrXp0TS8VOa4E5Hyyc3FzNx+rQt9bVKvpkzq1bTQ1wqr2hTHUOJPRETESZnV6tNwt912W77ndrudU6dOsWHDBp5//nmDohKRC8nMzGT8+PFMmTIFm82G2cuPXkOe5/NXH1cLZRERqTAysm1Gh2C47BxbXvIpISWLPvP+YF/8hdvtHz6dxsD31nPwdBpV3F2Y2aclnRqGFLpsgLcbJhO4mc0806MBAQnb8PUsurotPiWTMYu3sWJ37hyAzWr48+odzWgY5les3+fXvQm4u5h5sEM0QzrV5a65a0lMy+ad1YcACKrizsiu9TmamM7cXw/mrffX8SSm/LiH3/adBsDD1Uy/trUYfF1dqv49v1cVD1fOZViICPDi0U51uKNVDTxcc9uNjuhSr0Cl4/lLotSsHEwmuL5hKA92iOaqYs7fJyIijqXEn4iIiJPSxy3j+fvnb9VjNptp0KABEydOpFu3bgZFJSIXkpmZyQcffIDNZuOKTv8jock9NL6mmW5iiYhIhVLZ5/j7bV8Cj368iVuaV+exLvXoM28d++NTCfPzLLSNJcD6w4k89MEGzqZbqO7vyTv3X0mj8KKTciG+nnz5aHsCvd2o7ufOkiXbilx2ybZTPPvlNs6mW3B3MTOya30GdYi+6DxWnm4uuLuYybba6NSgGmNvbkz033Pluf+9rrurmQeuiWbwdXXw83TjlaW7ATiamM4jH25k6Y5YAFzNJu66MpJhnesR5p+/0nFev9bEJWfSvXFYgUq9wmLsUC+YphH+NI/0Z2D7aGpX87ng7yEiImVLiT8RERERB7BarQwYMICmTZsSGBhodDgicgEZGRl4enpiMpkICAjg3XffJTMzkwPejXhzxT6jwxMRESkRu91OenaO0WEYZuORszz0wUYyLFZ+2R3PHwfPcCAhjXB/T/5v0NV0mroS+386YS7dHsvwRZvJzrHRNMKfd/q3JsTv4q35W0QGAGCxWAp9/VyGhRGLNvPVltx2mI2r+zHtzhbFbnfn5e7CBw+0wW6HtnWC8r32RLcGrNqbwL1X1yKyasH2ost35s4faDLBrS0iGNGlPjWDCm9D2ia6arHiOa9uiC/fDrumROuIiEjZUeJPRETESak4xVguLi5069aNXbt2KfEnUo798ssvPPjgg4wdO5b+/fsD0L17dwCmLd9rZGgiIiKXJNtqo5Ap3iqFXaeSGfDun3lzHJ48l1vdV93fk/976GpqBVUpsM5Hfxxh7NfbsdmhS6MQ3rznCrzdS+eW6aD3N5CWbcVsgiGd6jKsc70Sz313de2gQsfb1Q2mXd3gAuOef7foBLihcRijutXPm5tPREQqByX+REREnJTa0hmvSZMmHDx4kOjoaKNDEZH/SE5O5umnn2bOnDkAvP7669x3332YzSW7GSciIlLeZFbQ+f1yrDZe+G4nIX6eDOlUt8TrHz6dxn3v/ElyZg5Vq7iTmJYNQESAF4seurpgVZwdpi3bw5s/7wfg7isjmdSryUXbb5ZEWraV6OAqTL2zOS1rls2XAe+5KhKb3U7nhiE0/7siUUREKhd9qhURERFxkEmTJvHEE0/w3XffcerUKZKTk/M9RMQYP/zwA02aNMlL+g0ePJhff/1VST8REXEK56vdXMwV64uAs1ce4P21Ry6p4v7UuQz6zl/H6dQsGoX78U7/1gDUCCwi6Qc8//X2vKTfY9fXY/JtTUst6Rfm7wVA/7a1WDK8Q5kl/SB37sGRXesr6SciUomp4k9ERMRJ6fa1cSZOnMjjjz9Ojx49ALjlllvyVWDa7XZMJhNWq9WoEEUqpcTEREaNGsX7778PQFR0bWbNeZsOHa8FICUz//w82TkVs2JCREQqt/OJP283F1KyKsZcf9tPnOONv+fVtZawT2liWjb3vfMnJ5IyiA6uwgcD21DN14MVj19LmJ8nVTwKv/354444zCZ4oVcT+l5V67J/h397f8CVJKZlU7uaT6luV0REpDiU+BMREXFSavVpnAkTJvDII4/wyy+/GB2KiPzLrl27+OCDDwATvq1vwdrhPh79OQt+XmZ0aCIiIqUmIzs38efpXjESf1k5Vh7/dCs5lzAxYUqmhf4L/mR/fCrh/p58+EBu0g+gzkWSbh6uZt685wq6Nw67pLgvJMDbnQBv91LfroiISHEo8SciIuKklPYzjt2ee9Pi2muvNTgSEbFYLLi5uQHQvn17Bo58lu/j/fGIaFSs9d1dzbStHeTIEEVERErV+Yo/LzcXgyMpnmnL97InLgVvdxfSs4vfESM7x8YjH21k24lzVK3izocPXEWNwIItPf+rcXU/TiZl8vZ9rbgyqurlhC4iIlIuKfEnIiIi4gCquBQxlt1uZ9GiRTz99NOsWLGCevXqAXDHgEf56aNNtKwZwMJBV190Oy5mE26lNN+PiIhIWcgs54m/7SfO8ejHmxjUIZqY6n7M/fUgAM/dFMMzX24r1jbsdjujv/iLNfvP4O3uwvsD2lA3pHhtNb8Y3B6b3Y5nOT0+IiIil0uJPxERESelxJOx6tevf9FzkJiYWEbRiFQuJ0+eZPDgwXzzzTcATJkyhblz5+Zbxmwy6YafiIg4pfNVc17u5e/fuRyrjacX/8XRxHS+3nKS+asPYbfDbS0j6NY4tNiJv9eX7+WLTSdwMZuY1bclTWv4FzsGd1d9oUdERJybEn8iIiJOSh9njTVhwgT8/Yt/A0JELp/dbue9995j5MiRnDt3Djc3N5577jlymtxC0/E/AmCx2gyOUkRExLHKc6vPj/44wo6TyQBsOHIWgHB/T8bd3PiC/0bvjUth67Ek7mhVg083HOPNn/cD8GKvJnRqEOL4wEVERCoQJf5ERESclCr+jHX33XcTEqKbECJl5ciRIzz00EMsW7YMgCuvvJIFCxbQpEkTWkxcRkpmTr7lG1f3MyJMERERh8sspxV/8cmZTF22t8D4lDua4+/lxunUrELXO5CQyu1v/U5KVg6nzmXyxop9AAzrXJe729R0aMwiIiIVkRJ/IiIiIqVMSVeRsvfhhx+ybNkyPDw8eOGFFxg5ciSurvk/7rw74EqigqrgajZRI9DLoEhFREQcq7xW/E36fhcpWTm4mE1YbXYA+rWtxTX1gotcJyXTwkMfbCAlK/cLPNOW5yYOb7siglFd6zs+aBERkQpIiT8REREnpdSTcex2u9EhiFQKNpsNszm3sfFTTz3FkSNHeOKJJ2jQoEGhy0cGehEdXKUsQxQRESlz5xN/Rs9la7fbOZGUQUSAF78fOMM3W09iNsGI6+sxdfleooK8GX1jwyLXt9nsjPxkKwcS0vKNt6sTxMu3N9OX7URERIqgxJ+IiIiT0udg49hsmkNMxJGsVitvvvkmn332GStXrsTNzY0xX+3iaMx9DF8SB0vi8i2fnGExKFIREZGyl5HX6tPYWb/Hf7OD99ceYc69LXn1xz0A3Hd1LQZfV4eaQd5cXTsIb/eib02+sWIfP+2Kw93VTBV3F86mW2gQ6suc+1rh7qoZzUVERIqixJ+IiIiTMqvmT0Sc0K5duxg4cCB//PEHAAsXLuT6W+5k8abjF1zP3dVMNR/PsghRRETEUJll3Orz1LkMEtOyaVzdP29sX1wKH/5xBICJ3+7k5LlMgn08GNWtAa4uZnq2iLjgNpftiM2by+/FXk2w2uz8uCOWSbc2xc/TzXG/jIiIiBNQ4k9ERERERMo9i8XCa6+9xvjx48nOzsbPz4/XXnuN/v37czQxHQAPVzML7r+y0PWjgqvg760bhSIi4vzSs8su8ZeVY+X2t34nITWL30dfTzVfDwBe/XEPf0/jx8lzmQA8d1Mj/L2K92/xyE+2AHB/uyh6t44E4O42NUs3eBERESelxJ+IiIiTUqtPEXEWW7duZeDAgWzatAmAHj168Pbbb1OjRo18y7maTbSvG2xEiCIiIuXG+Tn+vC7QRrO0fL35ZF5i70xaFtV8PdhwOJHlO/O33b66dlV6tqhe7O2mZVu5Kroqz97UqFTjFRERqQyU+BMREXFSJrX6FBEnMWrUKDZt2kRgYCBvvvkmffv2xaRvN4iIiBQqL/Hn5th58Ox2O/NXHyww9srS3fnGXM0mJvVqUqJ/uyMCvHirb0vcXDSXn4iISEnpX08RERFxiJdffhmTycSIESPyxjIzMxkyZAhBQUH4+Phw++23ExcXV/RGRKTSstvteT/Pnj2be+65h507d3Lvvfcq6SciInIBmedbfbo7ttXnqr0J7I1LzTe2Ylc86w+fxcPVTK+/K/we6libuiG+F91eFXdXvN1d8HA18/Z9rQjy8XBI3CIiIs5OFX8iIiJOysj74uvXr+ftt9+mWbNm+cZHjhzJ999/z2effYa/vz9Dhw7ltttuY82aNQZFKiLlTUZGBuPGjcNms/Haa68BUL9+fRYuXGhwZCIiIhXD+Yo/TwfP8Tf/t0P5nlttdl79Mbfab0D7aIZ2rsudrSO5unZQsbbn5e7C4sHt8HA1U7uaT6nHKyIiUlko8SciIuKkzAa1+kxNTaVv377MmzePSZMm5Y2fO3eOd955h4ULF9K5c2cA3n33XRo1asQff/zB1VdfbUi8IlJ+rF69moEDB7Jv3z5MJhODBg2iQYMGRoclIiJSofzT6tNxib+dJ5NZvf80ZhO4upjJzrHx5aYT7I1Lxd/LjcHX1sHHw5V2JZx7t1G4n4MiFhERqTyU+BMREXFSRlX8DRkyhJtuuokuXbrkS/xt3LgRi8VCly5d8sYaNmxIzZo1Wbt2rRJ/IpVYamoqzzzzDDNnzsRut1O9enXmzJnDSXsgH3y57aLrp2TmlEGUIiIiFUNGGbT6fGd1brXfjU3CWXcokdOpWXzwxxEAHr2uDv7ebg7bt4iIiFyYIYm/UaNGFXvZadOmOTASERERuZCsrCyysrLyjXl4eODhUfh8G4sWLWLTpk2sX7++wGuxsbG4u7sTEBCQbzw0NJTY2NhSi1lEKpaffvqJQYMGcfjwYQAeeOABXnvtNQICAmg9aTmnU7OLvS0/L91kFBERcXTFX1xyJt9sPQHAgx2iWXcoEYDsHBvh/p70bxflkP2KiIhI8RiS+Nu8eXOxljMZOTmRiIhIBVca/4xOnjyZCRMm5BsbN24c48ePL7DssWPHeOyxx1i+fDmenp6Xv3MRcXrJycnceeednD17llq1ajF37ly6deuW9/r5ioUB7aMI8HK/6PY61i9ZOzERERFn5IiKP5vNztu/HqReiA+bjp7FYrXTulYgV9QMzLfcyK71HT63oIiIiFyYIYm/X375xYjdioiIVCqmUpjjb8yYMQUq9Yuq9tu4cSPx8fG0bNkyb8xqtfLrr78yc+ZMfvzxR7Kzs0lKSspX9RcXF0dYWNhlxyoiFY+fnx+vv/4669evZ/Lkyfj6+ha63IB20dQM8i7j6ERERComR1T8fbzuCK8s3Q2A/98V9g92qJ1vmXohPtzeskap7VNEREQujeb4ExERcVLmUqj4u1Bbz/+6/vrr2bYt/1xcAwYMoGHDhjz99NNERkbi5ubGihUruP322wHYs2cPR48epW3btpcfrIiUe2fOnGHEiBHcfffd3HTTTQBUv/IGGtVszwcb4oC4fMtnW20GRCkiIlKxZVpKv+Jv3m+H8n4+l2GhVpA3XWNCAfDzdOV0ahZPdm+AS2l8CBEREZHLUi4Sfxs2bODTTz/l6NGjZGfnn8Pjiy++MCgqERERKQlfX1+aNGmSb6xKlSoEBQXljT/wwAOMGjWKqlWr4ufnx7Bhw2jbti1XX321ESGLSBlavHgxjz76KPHx8fz666/s27ePs5k2Bn2w4aLrerqZyyBCERGRis9itWGx2oHSq/g7k5rF0cT0fGMPXBOdl+R7/a4WnEjKyEsEioiIiLEMT/wtWrSIfv360b17d5YtW0a3bt3Yu3cvcXFx3HrrrUaHJyIiUmGVRqvP0vb6669jNpu5/fbbycrKonv37rz11ltGhyUiDhQXF8fQoUP5/PPPAYiJiWHBggW4u7uTkpQCgLuLmVuviCh0/SY1/Anx07yhIiIixZFp+adavrTm2vtqy8l8z/293Lij1T8tPZtHBtA8MqBU9iUiIiKXz/DE30svvcTrr7/OkCFD8PX15Y033iA6OpqHH36Y8PBwo8MTERGpsEzlIO+3cuXKfM89PT2ZNWsWs2bNMiYgESkzdrudhQsXMnz4cBITE3FxcWHMmDE899xzBVoIV/Fw4ZU7mhkUqYiIiPM43+bTbMr9Yk1RzqRmsf1kMh3qBmO+QHtOu93OZxuO5Ru79+qaeLsbfktRREREimD4v9IHDhzIm9/D3d2dtLQ0TCYTI0eOpHPnzkyYMMHgCEVERCqm8ljxJyLOKdNiZeWeBDIsOXlju7du4JkB9wIQVT+GoeOnUrthE5bsTMhbJvZcVpnHKiIi4swyzs/v5+ZywS8CPvvldpbuiOWDgW3oWL9akcvtOJnM7tiUvOfuLmb6t40qrXBFRETEAQxP/AUGBpKSknsBERERwfbt22natClJSUmkp6dfZG0RERERETHa3F8PMm353v+MulGlyfW4BoZju+oOZmy1wtatha7veoGKBBERESm+jOy/E38XqcjbcOQsAIlp2Rdc7vONxwG4qVk4DUJ9qV2tilpwi4iIlHOGJ/46duzI8uXLadq0Kb179+axxx7j559/Zvny5Vx//fVGhyciIlJhXaBjj4hIqUpIySLnXBxZa96nY/+n8A4IBsD+2CRMxeg7fEvz6o4OUUREpFLIq/hzL/pLNQkpWZxOvXjVfVaOla+2nACgd6saXNcgpHSCFBEREYcyPPE3c+ZMMjMzAXj22Wdxc3Pj999/5/bbb+e5554zODpxhPi4OGZMn8rva34lMzOTGpE1GTfxJWIaNzE6NJFy7dWbGxBcxb3A+M/7zvDRxpNcWyeQq2oFUCvQCy83F4Ys3kHGvyZ2l8pHrT5FpCzYbDY2LPk/Tr43DbslE7f14Xy4aJHRYYmIiFRKmX9/BvRycylymV2nkou1rRW74klKtxDm50mHekW3AxUREZHyxfDEX9WqVfN+NpvNjB492sBoxNGSk8/xwP19aN36Kt6YNZfAwKocO3oEPz8/o0MTKfdeWLY/X9VEDX8PnuhUm/XHzgG5cy1sP5XK9lOp3NE8zKgwpRwpRpGNiMhl2bdvHw888AC//fYbALWbtGbixIkGRyUiIlJ5/XuOv6LsLGbi77MNxwC4rWUELmonIiIiUmEYnvhbsmQJLi4udO/ePd/4smXLsFqt3HjjjQZFJo7w/oL5hIaGM+6Fl/LGImrUMDAikYojJcua73nzRtWIS8liT3waAMv3ngGgQUiVMo9NREQqF6vVyvTp03nuuefIzMzEzdML3w79Gfz4Y9SvX9/o8ERERCqtzL8Tf56XWfEXn5zJqr0JANzRSvdtREREKpKiG36XkdGjR2O1WguM22w2Vf85oV9X/UKjxo15+okRdL2uPX3uvI0vF39qdFgiFY6L2cTVUQGsPnTW6FCkHDOVwkNEpDDTpk3jiSeeIDMzky5duvDwG1/i2/J/mM2Gf7wQERGp1P6Z4+/yEn9fbD6BzQ6tagVSu5pPqcUnIiIijmf4J/N9+/YRExNTYLxhw4bs37/fgIjEkU4cP8biTxdRs2YtZsyexx133s1rr7zEd998ZXRoIhVKywg/vN1cWHNQiT8pmtlkuuyHiEhhBg8eTIsWLZg/fz7Lli0jICTC6JBEREQE8uZ5L6rVZ6bFyoGEtAtuw26357X57K1qPxERkQrH8Faf/v7+HDx4kKioqHzj+/fvp0qVi7ery8rKIisrK99Ytt0NDw+P0gxTSonNZiemcWOGDB8JQMNGMRzYv4/Fny3if7f0MjY4kQqkQ+1Atp1KISkzx+hQRESkEti8eTPz5s1j5syZmM1mfHx82Lhxoyr8REREypmM7AvP8bcvLhWrzX7BbWw+lsSBhDQ83czc1Cy81GMUERERxzL8k3rPnj0ZMWIEBw4cyBvbv38/jz/+OLfccstF1588eTL+/v75HlOnvOzIkOUyBFcLJrp2nXxj0bVrE3vqlEERiVQ8Qd5uxIT68OvBRKNDkXJOrT5F5HJlZWXx3HPPceWVVzJ79mzmz5+f95qSfiIiIuXPxVp9FqfN5+cbjwPQo0k4vp5upReciIiIlAnDK/5effVVbrjhBho2bEiNGrntA44fP06HDh147bXXLrr+mDFjGDVqVL6xbLsuSsqr5i1acuTw4XxjR44cJrx6dWMCEqmArqkdSHJWDn+dTDE6FCnvlLkTkcuwbt06BgwYwK5duwDo3bs3PXv2NDgqERERuZBMy4Ur/nZeJPGXabHy7daTANyhNp8iIiIVkuGJP39/f37//XeWL1/O1q1b8fLyolmzZnTs2LFY63t4eBRo65mSaXNEqFIK+tzbn4H9+7Bg/tt07XYDO7Zv48vPP+PZsROMDk2kQjAB7aMD+f3QWf7bncXP0xV/T1dCfNwBqBHgSabFRmK6hbS/271I5WJS5k9ELkF6ejpjx47l9ddfx2azERISwltvvcXtt99udGgiIiJyEXlz/BVR8XexxN+PO2JJycyhRqAXV9cOKvX4RERExPHKRX8ek8lEt27dePLJJxk6dGixk35S8TRu0pTXpr3Jjz98z12338L8ubN5/KnR3HjTzUaHJlIhxIT5EFzFnd8OnS3wWqe6VZlwQz0GtMn9VuaY6+sw4YZ6tIjwLeswRcRBZs2aRVRUFJ6enlx11VX8+eefRS47b948OnToQGBgIIGBgXTp0uWCy4uc16dPX6ZOnYrNZuPee+9j2/Yd9Lr1Nqw2e5EPm/3CcwWJiIiUN856XXW+4s+zkIo/u92e1+ozqIp7oet//1fuVCy3XhGB2awvEoqIiFREhlf8AaxatYrXXnstr41QTEwMTz75JB06dDA4MnGEDtd2osO1nYwOQ6RC2hGbysBF2wp97evt8Xy9Pb6MI5LyzKTP6U7lk08+YdSoUcyZM4errrqK6dOn0717d/bs2UNISEiB5VeuXMk999xDu3bt8PT05JVXXqFbt27s2LGDiIgIA34DqQgeeG896/yvxcXvd6p2G8xvEVfSZuo6o8MSEREpVc58XZWRXXSrzxNJGaRk5uDmYqJOiA9nDuWfNz41K4eVexMA6NE03PHBioiIiEMYXvH30Ucf0aVLF7y9vRk+fDjDhw/Hy8uL66+/noULFxodnoiISIVlKoWHlB/Tpk1j0KBBDBgwgJiYGObMmYO3tzcLFiwodPmPP/6YRx99lBYtWtCwYUPmz5+PzWZjxYoVZRy5lHdbtmzh7bffBmDF7ng8wusR8dBcvOtcWaLtuLuYaVkzwAERioiIlC5nvq7Km+OvkFafO0/mVvvVDfHF3aXgLcFfdseTnWMjOrgKDcPUOUZERKSiMrzi78UXX+TVV19l5MiReWPDhw9n2rRpvPDCC/Tp08fA6ERERCowZe6cRnZ2Nhs3bmTMmDF5Y2azmS5durB27dpibSM9PR2LxULVqlWLXCYrK4usrKy858nJuTeHLBYLFovlEqMv2vltOmLbcnFJSUk8+eSTvP/++7i5uXHNNdfkvbZ81LUEehfeAqwoHq5mvNxddD5LQH8DxtM5MJ7OgbEcffzL43l1xusqa05O3s9pWbk/u5nzH39LTg7bTyQB0DDMh7jkTAByrNa85b7/6yQA3WNCyPnXNuXi9F5mPJ0D4+kcGEvH33jl6brK8MTfwYMHufnmgvO73XLLLTzzzDMGRCQiIiJSvpw+fRqr1UpoaGi+8dDQUHbv3l2sbTz99NNUr16dLl26FLnM5MmTmTBhQoHxZcuW4e3tXbKgS2D58uUO27YU7s8//2TOnDkkJua2+OrWrdvf/y3lfrt//ZpV+LgZGGAlo78B4+kcGE/nwFiOOv7p6ekO2e7lcMbrql1JJiC3wi/2dCJgYte2Lbget3P+1t+Kn35i5UEzYMaeeIzTSSbAzNYtW3A7sZlsK/y8ywUw4XN2H0uW7CvVGCsLvZcZT+fAeDoHxtLxN155uK4yPPEXGRnJihUrqFu3br7xn376icjISIOiEhERqfhMKvmTv7388sssWrSIlStX4unpWeRyY8aMYdSoUXnPk5OTiYyMpFu3bvj5+ZV6XBaLheXLl9O1a1fc3JRlcpT31h5h/urD2O1gSTvH0e/fIvGvnwHwCIog4qZhxNVrybQDJiC3MuH6Ll0IqlKyij8pOf0NGE/nwHg6B8Zy9PE/X+XmTMrjdZXvvtPM2bUJAI8qvpCSSvurr+SaOkGM+CP35uP1Xbow5+11QAa3dW5D/K+H2HsukeYtWtCjeTg/7ogj+8+t1Ajw5KHeHTBpwvAS0XuZ8XQOjKdzYCwdf+OVp+sqwxN/jz/+OMOHD2fLli20a9cOgDVr1vDee+/xxhtvGBydiIhIxaXP6s4jODgYFxcX4uLi8o3HxcURFhZ2wXVfe+01Xn75ZX766SeaNWt2wWU9PDzw8PAoMO7m5ubQDw6O3n5l98XmU8QlZ2HPsXBi3qNYk+PBZMbvyl74X9MXq5sHCanZecuH+HpQ1ccLN1fDpwOvNPQ3YDydA+PpHBjLUce/PJ5TZ7yucnH95/ZelsUGgK+XR779ZFnh2NkMAJrWqIrZdAQAVxcX3NzcWLYrAYAezarj7q4v/1wqvZcZT+fAeDoHxtLxN155uK4yPPE3ePBgwsLCmDp1Kp9++ikAjRo14pNPPqFnz54GRyciIlJxKe/nPNzd3WnVqhUrVqygV69eANhsNlasWMHQoUOLXO/VV1/lxRdf5Mcff6R169ZlFK2UN3a7HYCXel/BZq+hfP3Z//HC1Fk0u6IVOTk5rF79G9dc0wHXv28a1gzyxl1JPxERcVLOfl2VYbEC4OXmkm98d2wKAOH+ngT+p6o/02Jlxa7cROiNTS6c/BQREZHyz/DE34MPPsi9997L6tWrjQ5FREREpNwaNWoU/fv3p3Xr1rRp04bp06eTlpbGgAEDAOjXrx8RERFMnjwZgFdeeYWxY8eycOFCoqKiiI2NBcDHxwcfHx/Dfg8pO3a7nY8++oikw6ngWZNaVatw17gxvPjcU3kVCBaLhUNVoFG4r74VKiIilYYzX1dl/l3x5/mfxN/Ok7ntwRqFF2wz+tu+06RlW6nu70mLyACHxygiIiKOZXjiLyEhgRtuuIFq1apxzz330LdvX5o3b250WCIiIhWfSv6cyl133UVCQgJjx44lNjaWFi1asHTpUkJDQwE4evQoZvM/VVqzZ88mOzubO+64I992xo0bx/jx48sydDHA8ePHefjhh1myZAlVQmoSdN90AFxdXfMq+0RERCorZ76uyqv4c8+f+Nt16nziz7fAOj9sOwXADU3CNbefiIiIEzD8U//XX3/N2bNn+eyzz1i4cCFTp06lYcOG9O3blz59+hAVFWV0iCIiIhWSSZk/pzN06NAiW1CtXLky3/PDhw87PiApd+x2O/Pnz+eJJ54gOTkZd3d3ql/ZnSyTWneKiIj8mzNeV9mBrJzcir//tvrcFZub+IsJ9883np1jY/nfbT57NFWbTxEREWdQLu4ABAYG8tBDD7Fy5UqOHDnC/fffz4cffkjdunWNDk1EREREpEI4dOgQXbt25aGHHiI5OZmrr76aLVu2ULvLvZhcDP++n4iIiDhYtu2fn73/U/F3LDEDKFjxt+bAaVIycwjx9aBlzUCHxygiIiKOV67uAFgsFjZs2MC6des4fPhwXosFERERKTl16RGpPHbt2kXr1q1JT0/Hy8uLF198keHDh+Pi4gI/JhgdnoiIiJSBv7t8AuDhWvC7/l5uLtQKqpJvbMWueABuaBKG2awPECIiIs6gXCT+fvnlFxYuXMjixYux2WzcdtttfPfdd3Tu3Nno0ERERCosfWwXqTwaNmxI+/btyc7OZv78+eqcISIiUgmdr/jzcnPBZDJht9vzvd4gzBeX/yT3UrNyALixSXiZxCgiIiKOZ3jiLyIigsTERG644Qbmzp3LzTffjIeHh9FhiYiIVHzK/Ik4rZycHGbPnk2/fv3w9/fHZDLx2Wef4evri9lcLrr5i4iISBnLS/z9p83neTHV/QodD6riTpvoqo4KS0RERMqY4Ym/8ePH07t3bwICAowORURERESk3Nu+fTsDBw5k/fr1bNu2jblz5wLg7+9vcGQiIiJiJKs995t/Xm6FJ/4ahRee+OveJKxAJaCIiIhUXIYn/gYNGmR0CCIiIk7JpJI/EaeSnZ3Nyy+/zKRJk7BYLPj7+9O2bVujwxIREZFyxtOt8Or/mHDfQsd7qM2niIiIUzE88SciIiKOYVLeT8RpbNy4kYEDB/LXX38B0PWGHrS572lO+AUz6budF1w3PiWrLEIUERGRcqKwVp8mEzQIK1jxF+jtxlW11eZTRETEmSjxJyIi4qSU9xNxDp9++il9+vTBarUSFBTEjBkz2O7ZmI/WHQNSir2dKh6Ft/0SERER51JYq89aVb3x8Sh4G7BbTBhuLpofWERExJko8SciIiIiUo516tSJqlWr0qlTJ2bMmEFISAijPtkCwNW1q9IiMvCi26gR6EWLyADHBioiIiLlgpd7wdt9/53fr16oD78fOM2dV9Yoq7BERESkjCjxJyIi4qxU8idSIaWnp/PJJ58wYMAAAKpVq8bWrVsJDy84/07nhiE81LFOWYcoIiIi5ZhXIXP8xfwn8ff8TTEM61yPqlXcyyosERERKSNK/ImIiDgpkzJ/IhXOL7/8woMPPsjBgwfx9fXljjvuACA8PJyfdsZxJDEdgH3xqUaGKSIiIuVYYa0+/1vxZzablPQTERFxUkr8iYiIOCmT8n4iFUZycjJPP/00c+bMAaBGjRr4+/vnvb4vLoUHP9hQYD0PV83bJyIiIvl5uf9zfeDuYibbaiOmut8F1hARERFnosSfiIiIiIiBli5dykMPPcSxY8cAePjhh3n11Vfx8/vnBt3ZdAsAVdxduL5RKAAB3m78r1nB9p8iIiJSuXn+XfFnMpmYdGsTsixWqgd4GRyViIiIlBUl/kRERJyUCv5Eyr9nn32Wl156CYDatWszf/58OnXqVOTyoX6evHnPFWUVnoiIiFRA/271eWfrSAMjERERESMUnO1XREREnIOpFB4i4lDXXXcdZrOZESNG8Ndff10w6SciIiJSHIXN8SciIiKVhyr+RERERETKSEJCAlu3bqVLly4AdO3alb1791KnTh2DIxMRERFn8e85/kRERKTyUcWfiIiIkzKVwv9EpHTY7XY++eQTYmJiuPXWWzl69Gjea0r6iYiISGlS4k9ERKRyU8WfiIiIkzIpbydSLpw6dYohQ4bw5ZdfAtC0aVNSUlIMjkpERESclVp9ioiIVG5K/ImIiDgp5f1EjGW32/nggw8YMWIESUlJuLq68uyzz/LMM8/g7u5+0fUtVht7YlOw2e0cSEgtg4hFRETEGSjxJyIiUrkp8SciIiIiUspsNhs9e/bku+++A6Bly5a8++67NGvWrNjbePTjTSzfGZd/UBl9ERERuQhPtfoUERGp1DTHn4iIiLMylcKjBCZPnsyVV16Jr68vISEh9OrViz179uRbJjMzkyFDhhAUFISPjw+33347cXFxRWxRpOIym83ExMTg4eHB5MmTWbduXYmSfgAH/67yC/ZxJyLAixqBXvRpU9MR4YqIiIgTUcWfiIhI5aaKPxERESdlKuPSoFWrVjFkyBCuvPJKcnJyeOaZZ+jWrRs7d+6kSpUqAIwcOZLvv/+ezz77DH9/f4YOHcptt93GmjVryjRWEUc4cOAANpuNevXqATB+/HgGDhxIgwYNLmu7s/q05KraQaURooiIiFQCSvyJiIhUbkr8iYiIOClTGbcEXLp0ab7n7733HiEhIWzcuJGOHTty7tw53nnnHRYuXEjnzp0BePfdd2nUqBF//PEHV199ddkGLFJKrFYrM2bM4JlnnqFZs2asWbMGFxcXvLy8aNCgAZkWKymZOSXfrs3ugGhFRETE2Xmr1aeIiEilpsSfiIiIFCkrK4usrKx8Yx4eHnh4eFx03XPnzgFQtWpVADZu3IjFYqFLly55yzRs2JCaNWuydu1aJf6kQtq9ezcDBw5k7dq1AHh7e5OUlERQUG6FXnxyJl2mrSL5EhJ/IiIiIpfCUxV/IiIilZrm+BMREXFSpTHF3+TJk/H398/3mDx58kX3bbPZGDFiBO3bt6dJkyYAxMbG4u7uTkBAQL5lQ0NDiY2NLYXfWKTs5OTk8PLLL9OiRQvWrl2Lr68vc+bM4aeffspL+gHsi0+9rKRfrSBvGob7lUbIIiIiUkl4qeJPRESkUlPFn4iIiLMqhVafY8aMYdSoUfnGilPtN2TIELZv387q1asvPwiRcubUqVPcfPPNbNy4EYAbb7yRt99+m8jIyCLXaRjmy9IRHcsqRBEREanENMefiIhI5abEn4iIiJMylULmr7htPf9t6NChfPfdd/z666/UqFEjbzwsLIzs7GySkpLyVf3FxcURFhZ22bGKlJVq1aphMpkICAjgjTfe4L777sNU1pNqioiIiBRBrT5FREQqNyX+REREpFTY7XaGDRvGl19+ycqVK4mOjs73eqtWrXBzc2PFihXcfvvtAOzZs4ejR4/Stm1bI0IWKbbNmzfTqFEjPD09cXV15f/+7/+oUqUK4eHhBZad/MMu3l1zGOxgs9vLPlgRERGptNxdzbiY9YUkERGRykxz/ImIiDgpk+nyHyUxZMgQPvroIxYuXIivry+xsbHExsaSkZEBgL+/Pw888ACjRo3il19+YePGjQwYMIC2bdty9dVXO+AIiFy+jIwMRo8eTevWrZk4cWLeeN26dQtN+gEs2XaK7Bwb2VYbObbcxF+LyICyCFdEREQqOS833eoTERGp7FTxJyIi4qTK+nu+s2fPBuC6667LN/7uu+9y//33A/D6669jNpu5/fbbycrKonv37rz11ltlHKlI8axZs4YHHniAPXv2AHD8+HHsdnux23rO79eaxhF+mE0mQnxL1jJXRERE5FJofj8RERFR4k9ERERKhb0YLQ09PT2ZNWsWs2bNKoOIRC5NWloazz77LG+++SZ2u53w8HBmz55Nz549S7SdIB93wv29HBSliIiISEFK/ImIiIgSfyIiIs5KU3uIlNiGDRu48847OXToEAADBgxg6tSpBAYGFrnOvrgUHv9sK+cyLACcTMosk1hFRERE/stTiT8REZFKT4k/ERERJ2VS5k+kxIKDg4mPjycyMpJ58+bRvXv3i66zfFccfx0/l2/MzcVERICq/URERKRsebkr8SciIlLZKfEnIiLipIo5DZlIpbdjxw4aN24MQFRUFN999x0tW7bEz8+vWOuf73J7fcMQHu1UB4Aagd6E+Hk6JF4RERGRoni6mY0OQURERAymqwERERERqZQSExPp378/TZo04eeff84bv+6664qd9Pu3YB8PWtWqSqtaVQlV0k9EREQMoDn+RERERBV/IiIiTkoFfyJF+/LLLxk8eDBxcXGYTCY2bNhA586di1z+z0OJzPxlP5YcW4HXjielOzJUERERkWLTHH8iIiKixJ+IiIiTUqtPkYLi4+MZNmwYn376KQANGzZkwYIFtG3b9oLrvff7IX7dm3DBZUL9PEotThEREZFLoYo/ERERUeJPRETEaSnzJ/JvX3zxBQ899BBnzpzBxcWFp59+mueffx5Pz4u35cyx5k7kd/eVkbSvG1zgdU83FzrUKzguIiIiUpa83JX4ExERqeyU+BMRERGRSiE7O5szZ87QrFkz3n33XVq2bFnibTSt4c/Nzas7IDoRERGRy+flZjY6BBERETGYEn8iIiJOSq0+pbKz2+0cOXKEqKgoAO666y7sdju333477u7uF1zXYrUxY8U+TiRlArD9xDlHhysiIiJy2TTHn4iIiCjxJyIi4qSU95PK7MiRIwwaNIitW7eyc+dOgoKCMJlM3HPPPcVaf/3hRN78eX+B8QCvCycMRURERIykOf5EREREiT8REREnpYo/qYxsNhtz5szh6aefJjU1FU9PT9atW0ePHj1KtJ0siw2AMD9PBrSPAqBqFXe6xoSWdsgiIiIipUatPkVERESJPxERERFxCvv37+fBBx9k1apVAFxzzTW888471K9f/5K3Wc3Xg4evrVNaIYqIiIg4lFp9ioiIiL4GJCIi4qRMpfA/kYrAbrfz+uuv06xZM1atWkWVKlWYMWMGq1atuqykn4iIiEhFo1afIiIiooo/ERERZ6W8nVQSJpOJ7du3k5GRQefOnZk/fz7R0dFGhyUiIiJS5rzclfgTERGp7JT4ExERcVLK+4kzs1gspKSkULVqVQCmTp3KNddcw/33349JE1yKiIhIJaWKPxEREVGrTxERERGpULZs2cJVV13Fvffei91uByAgIIABAwYo6SciIiKVmqebbvWJiIhUdqr4ExERcVLKf4izycrK4sUXX2Ty5Mnk5OQQGBjIoUOHqF27dt4ydrudlXsTiD2XeVn72hObcrnhioiIiJQ5VfyJiIiIEn8iIiJOyqRmn+JE/vzzTwYOHMiOHTsAuO2225g1axZhYWH5ltt45CwD3l1favt1c9HfkYiIiFQcnprjT0REpNJT4k9EREREyq3MzEzGjh3L1KlTsdlsVKtWjbfeeos77rij0OXPpGUD4O/lRpvoqpe1bxeTib5X17ysbYiIiIiUJVX8iYiIiBJ/IiIizkqFSuIE7HY7X331FTabjb59+zJ9+nSCg4Mvul7dEB/m9WtdBhGKiIiIlB9emuNPRESk0lPiT0RExEkp7ycVza5TycQlZ5KRloa7pycuLrnfWH9s4uucO5tIu87d2X7GBmfii9zGjhPnyipcERERkXLHUxV/IiIilZ4SfyIiIk7KpMyf05k1axZTpkwhNjaW5s2bM2PGDNq0aVPk8p999hnPP/88hw8fpl69erzyyiv06NGjDCMuvk1Hz3LbW7+TcXgLZ5bOwK/l//Brc+u/lqjK3BLM3eeiPwARERG5AGe8rnIx2XFzUcWfiIhIZaerAREREZEK4JNPPmHUqFGMGzeOTZs20bx5c7p37058fOHVb7///jv33HMPDzzwAJs3b6ZXr1706tWL7du3l3HkxbP3aBxnls4g/pPnsJ6Lw7LzJxqFetO4ul+JH81q+HN/+yijfyUREREpp5z1uspdd/lEREQEVfyJiIg4LZOafTqVadOmMWjQIAYMGADAnDlz+P7771mwYAGjR48usPwbb7zBDTfcwJNPPgnACy+8wPLly5k5cyZz5swp09gvZsmSJQx96BFS42MBGDp0KJMnT8bHx8fgyERERMQZOet1lab3ExEREVDFn4iIiNMymS7/IeVDdnY2GzdupEuXLnljZrOZLl26sHbt2kLXWbt2bb7lAbp3717k8kbYuPc4k1+bTq9evTgTH4trYDidHp/FjBkzlPQTERERh3DW6ypQxZ+IiIjkUsWfiIiISDl3+vRprFYroaGh+cZDQ0PZvXt3oevExsYWunxsbGyR+8nKyiIrKyvveXJyMgAWiwWLxXKp4Rfp3hlLOfD7ajCZ8buyF/7X9KFavXCH7EsKd/5Y65gbQ8ffeDoHxtM5MJajj395PK/OeF1lzckBwM2lfB7zykDvZcbTOTCezoGxdPyNV56uq5T4ExEREREAJk+ezIQJEwqML1u2DG9v71Lfn39oJOHdH8YjNBrviAa4mCDadJolS5aU+r7kwpYvX250CJWajr/xdA6Mp3NgLEcd//T0dIdstyIoy+uq9ByoWcWFlsE2/S0ZTMffeDoHxtM5MJaOv/HKw3WVEn8iIiJOSq06nUdwcDAuLi7ExcXlG4+LiyMsLKzQdcLCwkq0PMCYMWMYNWpU3vPk5GQiIyPp1q0bfn5+l/EbFK5rVwvLl1vp2rUrbm5upb59uTiLxcLy5ct1Dgyi4288nQPj6RwYy9HH/3yVW3nirNdVPW/U35KR9F5mPJ0D4+kcGEvH33jl6bpKiT8REREnZUKZP2fh7u5Oq1atWLFiBb169QLAZrOxYsUKhg4dWug6bdu2ZcWKFYwYMSJvbPny5bRt27bI/Xh4eODh4VFg3M3NzaEfHBy9fbk4nQNj6fgbT+fAeDoHxnLU8S+P51TXVeJIOv7G0zkwns6BsXT8jVcerquU+BMREXFSqvhzLqNGjaJ///60bt2aNm3aMH36dNLS0hgwYAAA/fr1IyIigsmTJwPw2GOPce211zJ16lRuuukmFi1axIYNG5g7d66Rv4aIiIiI4XRdJSIiIs5MiT8RERGRCuCuu+4iISGBsWPHEhsbS4sWLVi6dCmhoaEAHD16FLPZnLd8u3btWLhwIc899xzPPPMM9erV46uvvqJJkyZG/QoiIiIi5YKuq0RERMSZKfEnIiLipFTw53yGDh1aZAuqlStXFhjr3bs3vXv3dnBUIiIiIhWPrqtERETEWSnxJyIi4qyU+RMREREREREREalUzBdfRERERERERERERERERETKO1X8iYiIOCmTSv5EREREREREREQqFSX+REREnJRJeT8REREREREREZFKRYk/ERERJ6W8n4iIiIiIiIiISOWiOf5EREREREREREREREREnIAq/kRERJyVSv5EREREREREREQqFSX+REREnJRJmT8REREREREREZFKRYk/ERERJ2VS3k9ERERERERERKRSUeJPRERERAplt9sBSE5Odsj2LRYL6enpJCcn4+bm5pB9yIXpHBhLx994OgfG0zkwlqOP//lriPPXFJWZrqucm46/8XQOjKdzYCwdf+OVp+sqp0z8+XqajQ5BiiErK4vJkyczZswYPDw8jA5HLmDB3U2NDkEuQn9PUhhPp/xXXspSSkoKAJGRkQZHIiIiIhVZSkoK/v7+RodhKF1XiYiISGkoznWVya6vXYlBkpOT8ff359y5c/j5+RkdjkiFpr8nEXEEm83GyZMn8fX1xeSA3rHJyclERkZy7NgxvXcZROfAWDr+xtM5MJ7OgbEcffztdjspKSlUr14ds7lyf0lb11XOTcffeDoHxtM5MJaOv/HK03WVagFEREREpFBms5kaNWo4fD9+fn76YGIwnQNj6fgbT+fAeDoHxnLk8a/slX7n6bqqctDxN57OgfF0Doyl42+88nBdVbm/biUiIiIiIiIiIiIiIiLiJJT4ExEREREREREREREREXECSvyJYTw8PBg3bhweHh5GhyJS4envSUQqIr13GU/nwFg6/sbTOTCezoGxdPydh86lsXT8jadzYDydA2Pp+BuvPJ0Dk91utxsdhIiIiIiIiIiIiIiIiIhcHlX8iYiIiIiIiIiIiIiIiDgBJf5EREREREREREREREREnIASf1IqrrvuOkaMGGF0GCJyifQ3LCIiIiIiIiIiIlLxKfEnIiIiIg4za9YsoqKi8PT05KqrruLPP/+84PKfffYZDRs2xNPTk6ZNm7JkyZIyitR5leQczJs3jw4dOhAYGEhgYCBdunS56DmTCyvp38B5ixYtwmQy0atXL8cGWAmU9BwkJSUxZMgQwsPD8fDwoH79+novugwlPf7Tp0+nQYMGeHl5ERkZyciRI8nMzCyjaJ3Pr7/+ys0330z16tUxmUx89dVXF11n5cqVtGzZEg8PD+rWrct7773n8DileHRdZSxdUxlP11XG0jWV8XRdZZyKdk2lxJ+IiIiIOMQnn3zCqFGjGDduHJs2baJ58+Z0796d+Pj4Qpf//fffueeee3jggQfYvHkzvXr1olevXmzfvr2MI3ceJT0HK1eu5J577uGXX35h7dq1REZG0q1bN06cOFHGkTuHkh7/8w4fPswTTzxBhw4dyihS51XSc5CdnU3Xrl05fPgwn3/+OXv27GHevHlERESUceTOoaTHf+HChYwePZpx48axa9cu3nnnHT755BOeeeaZMo7ceaSlpdG8eXNmzZpVrOUPHTrETTfdRKdOndiyZQsjRozgwQcf5Mcff3RwpHIxuq4ylq6pjKfrKmPpmsp4uq4yVoW7prKLlIJrr73W/thjj9ntdrsdsH/55Zf5Xvf397e/++67drvdbj906JAdsC9evNh+3XXX2b28vOzNmjWz//777/nWmTt3rr1GjRp2Ly8ve69evexTp061+/v7O/6XESljb7/9tj08PNxutVrzjd9yyy32AQMG2O12u/2tt96y165d2+7m5mavX7++/YMPPsi37NmzZ+0PPfSQPSQkxO7h4WFv3Lix/dtvv7Xb7Xb76dOn7Xfffbe9evXqdi8vL3uTJk3sCxcuzLf+v/+GRURKS5s2bexDhgzJe261Wu3Vq1e3T548udDl77zzTvtNN92Ub+yqq66yP/zwww6N05mV9Bz8V05Ojt3X19f+/vvvOypEp3Ypxz8nJ8ferl07+/z58+39+/e39+zZswwidV4lPQezZ8+2165d256dnV1WITq1kh7/IUOG2Dt37pxvbNSoUfb27ds7NM7KorDP6v/11FNP2Rs3bpxv7K677rJ3797dgZFJcei6yli6pjKerquMpWsq4+m6qvyoCNdUqvgTwzz77LM88X2Lh8oAABpSSURBVMQTbNmyhfr163PPPfeQk5MDwJo1a3jkkUd47LHH2LJlC127duXFF180OGIRx+jduzdn/r+9O4+rMf3/B/7qtJySYkIqGoSyZcn2iTHJZMQw2RlNsi8JY8+MLY11LB88xmAGpWns66eSPZ86hiFikJPQMDMxH8vYUzrv7x9+3T+HQg0dHa/n43EeD+e+r+u639d9P47z7rru6z43buDAgQPKtps3byIuLg7+/v7YunUrRo4ciTFjxuD06dMYPHgw+vbtq5TX6XRo27YtNBoNfvzxR5w9exazZ8+GqakpACAzMxMNGzZETEwMTp8+jUGDBiEgIICPGSGiNyorKwtJSUnw8fFRtqlUKvj4+ODnn3/Os87PP/+sVx4A2rRpk295erHCXINnPXjwANnZ2bCzs3tTYRqtwp7/6dOnw97eHv379y+KMI1aYa7Bjh074OnpiWHDhqF8+fKoU6cOZs6ciZycnKIK22gU5vw3a9YMSUlJSp568eJFxMbGol27dkUSM/G7+G3FvMqwmFMZHvMqw2JOZXjMq4ofQ38PmxXJUYjyMHbsWHzyyScAgNDQUNSuXRtpaWmoUaMGlixZgrZt22Ls2LEAAFdXVxw6dAjR0dGGDJnojXjvvffQtm1b/PTTT/joo48AAJs2bULZsmXh7e2NFi1aoE+fPggKCgIAjB49GocPH8a8efPg7e2NvXv34pdffkFKSgpcXV0BAC4uLkr7FSpUUD5LADB8+HDs2rULGzZsQJMmTYqwp0T0Lrl+/TpycnJQvnx5ve3ly5fHuXPn8qxz9erVPMtfvXr1jcVpzApzDZ41YcIEODk5PfcHC71cYc5/YmIiVq5cieTk5CKI0PgV5hpcvHgR+/fvh7+/P2JjY5GWloagoCBkZ2dj6tSpRRG20SjM+e/VqxeuX7+ODz74ACKCx48fY8iQIXwkVRHK77v4zp07ePjwIaysrAwU2buNeZVhMacyPOZVhsWcyvCYVxU/hs6puOKPDKZu3brKvx0dHQFAeSaxVqt9bkKCExRkzPz9/bF582Y8evQIABAVFYWePXtCpVIhJSUFzZs31yvfvHlzpKSkAACSk5NRsWJFZdLvWTk5OQgLC4O7uzvs7OxQsmRJ7Nq1C5cvX36znSIiomJt9uzZWLduHbZu3QpLS0tDh2P07t69i4CAAHz//fcoW7asocN5Z+l0Otjb22PFihVo2LAhevToga+++grLli0zdGjvhPj4eMycORNLly7F8ePHsWXLFsTExCAsLMzQoRERFRpzqqLHvMrwmFMZHvOqdxtX/NFrZ2JiAhHR25adnf1cOXNzc706wJMvBaJ3UYcOHSAiiImJQePGjZGQkICFCxe+Ut2X3SHyzTffYNGiRfj3v/8Nd3d3WFtb44svvkBWVtbrCJ2IKE9ly5aFqakprl27prf92rVrcHBwyLOOg4NDgcrTixXmGuSaN28eZs+ejb179+rdrEWvrqDn/8KFC0hPT0eHDh2Ubbm5sZmZGbRaLapWrfpmgzYyhfkMODo6wtzcXHlkOgDUrFkTV69eRVZWFiwsLN5ozMakMOd/8uTJCAgIwIABAwAA7u7uuH//PgYNGoSvvvoKKhXvXX7T8vsutrW15Wo/A2JeZVjMqQyPeZVhMacyPOZVxY+hcypeXXrtypUrh4yMDOX9+fPn8eDBgwK14ebmhqNHj+pte/Y9kTGxtLRE586dERUVhbVr18LNzQ0eHh4AniRGGo1Gr7xGo0GtWrUAPFk9+/vvvyM1NTXPtjUaDfz8/PD555+jXr16cHFxybcsEdHrYmFhgYYNG2Lfvn3KNp1Oh3379sHT0zPPOp6ennrlAWDPnj35lqcXK8w1AIC5c+ciLCwMcXFxaNSoUVGEapQKev5r1KiBX3/9FcnJycrr008/hbe3N5KTk+Hs7FyU4RuFwnwGmjdvjrS0NL0bElNTU+Ho6MgBqgIqzPl/8ODBc4NQuQOGz95cSm8Gv4vfTsyrDIs5leExrzIs5lSGx7yq+DH497AQvQZeXl4ycuRIERHp2bOn1KxZU44fPy5Hjx6VVq1aibm5uaxevVpERC5duiQA5MSJE0r9W7duCQA5cOCAiIgkJiaKSqWS+fPnS2pqqixbtkzKlCkjpUuXLtqOERWhPXv2iFqtFjc3NwkLC1O2b926VczNzWXp0qWSmpoq8+fPF1NTU+XzIiLSsmVLqVOnjuzevVsuXrwosbGxsnPnThERGTVqlDg7O4tGo5GzZ8/KgAEDxNbWVvz8/JT6T3+GiYhel3Xr1olarZbw8HA5e/asDBo0SEqXLi1Xr14VEZGAgAAJCQlRyms0GjEzM5N58+ZJSkqKTJ06VczNzeXXX381VBeKvYJeg9mzZ4uFhYVs2rRJMjIylNfdu3cN1YViraDn/1mBgYF639dUcAW9BpcvXxYbGxsJDg4WrVYr0dHRYm9vL19//bWhulCsFfT8T506VWxsbGTt2rVy8eJF2b17t1StWlW6d+9uqC4Ue3fv3pUTJ07IiRMnBIAsWLBATpw4Ib/99puIiISEhEhAQIBS/uLFi1KiRAkZN26cpKSkyLfffiumpqYSFxdnqC7Q/8O8yrCYUxke8yrDYk5leMyrDKu45VSc+KPX4ulJgz/++EM+/vhjsba2lurVq0tsbKyUKlWqQBN/IiIrVqyQChUqiJWVlXTs2FG+/vprcXBwKLpOERWxnJwccXR0FABy4cIFvX1Lly4VFxcXMTc3F1dXV1mzZo3e/hs3bkjfvn2lTJkyYmlpKXXq1JHo6Ghln5+fn5QsWVLs7e1l0qRJ0rt3b078EVGRWLJkibz//vtiYWEhTZo0kcOHDyv7vLy8JDAwUK/8hg0bxNXVVSwsLKR27doSExNTxBEbn4Jcg0qVKgmA515Tp04t+sCNREE/A0/jANXrUdBrcOjQIWnatKmo1WpxcXGRGTNmyOPHj4s4auNRkPOfnZ0t06ZNk6pVq4qlpaU4OztLUFCQ3Lp1q+gDNxIHDhzI8//13PMeGBgoXl5ez9WpX7++WFhYiIuLi/K3PBke8yrDYk5leMyrDIs5leExrzKc4pZTmYhwXScVDwMHDsS5c+eQkJBg6FCIiIiIiIiIiIiIiIjeOmaGDoAoP/PmzUPr1q1hbW2NnTt3IiIiAkuXLjV0WERERERERERERERERG8lrvijt1b37t0RHx+Pu3fvwsXFBcOHD8eQIUMMHRYREREREREREREREdFbiRN/REREREREREREREREREZAZegAiIiIiIiIiIiIiIiIiOif48QfERERERERERERERERkRHgxB8RERERERERERERERGREeDEHxEREREREREREREREZER4MQfERERERERERERERERkRHgxB8R6enTpw86duyovG/ZsiW++OKLIo8jPj4eJiYm+Pvvv4v82ERERERFJTw8HKVLlzZ0GIVmYmKCbdu2vbDMs/klEREREb0+T+dj6enpMDExQXJyskFjIiLD4sQfUTHRp08fmJiYwMTEBBYWFqhWrRqmT5+Ox48fv9HjbtmyBWFhYa9UlpN1RERE9C56Ok97+pWWlmbo0BAeHq7Eo1KpULFiRfTt2xd//fXXa2k/IyMDbdu2BZD/QNOiRYsQHh7+Wo6Xn2nTpin9NDU1hbOzMwYNGoSbN28WqB1OUhIREVFBPJ0Hmpubo0qVKhg/fjwyMzMNHRoRvcPMDB0AEb06X19frF69Go8ePUJsbCyGDRsGc3NzTJw4Ua9cVlYWLCwsXssx7ezsXks7RERERMYsN097Wrly5QwUjT5bW1totVrodDqcPHkSffv2xZ9//oldu3b947YdHBxeWqZUqVL/+Divonbt2ti7dy9ycnKQkpKCfv364fbt21i/fn2RHJ+IiIjeTbl5YHZ2NpKSkhAYGAgTExPMmTPH0KER0TuKK/6IihG1Wg0HBwdUqlQJQ4cOhY+PD3bs2KHcmTxjxgw4OTnBzc0NAHDlyhV0794dpUuXhp2dHfz8/JCenq60l5OTg9GjR6N06dIoU6YMxo8fDxHRO+azj/p89OgRJkyYAGdnZ6jValSrVg0rV65Eeno6vL29AQDvvfceTExM0KdPHwCATqfDrFmzUKVKFVhZWaFevXrYtGmT3nFiY2Ph6uoKKysreHt768VJRERE9LbLzdOefpmammLBggVwd3eHtbU1nJ2dERQUhHv37uXbzsmTJ+Ht7Q0bGxvY2tqiYcOGOHbsmLI/MTERLVq0gJWVFZydnTFixAjcv3//hbGZmJjAwcEBTk5OaNu2LUaMGIG9e/fi4cOH0Ol0mD59OipWrAi1Wo369esjLi5OqZuVlYXg4GA4OjrC0tISlSpVwqxZs/Tazn20VJUqVQAADRo0gImJCVq2bAlAfxXdihUr4OTkBJ1Opxejn58f+vXrp7zfvn07PDw8YGlpCRcXF4SGhr70SRdmZmZwcHBAhQoV4OPjg27dumHPnj3K/pycHPTv31/JSd3c3LBo0SJl/7Rp0xAREYHt27crd+7Hx8cDeHleTURERO+u3DzQ2dkZHTt2hI+Pj5KDvMqY2JkzZ9C+fXvY2trCxsYGLVq0wIULFwAAR48eRevWrVG2bFmUKlUKXl5eOH78eJH3kYiKF078ERVjVlZWyMrKAgDs27cPWq0We/bsQXR0NLKzs9GmTRvY2NggISEBGo0GJUuWhK+vr1Jn/vz5CA8Px6pVq5CYmIibN29i69atLzxm7969sXbtWixevBgpKSlYvnw5SpYsCWdnZ2zevBkAoNVqkZGRoQykzJo1C2vWrMGyZctw5swZjBo1Cp9//jkOHjwI4MlASufOndGhQwckJydjwIABCAkJeVOnjYiIiKjIqFQqLF68GGfOnEFERAT279+P8ePH51ve398fFStWxNGjR5GUlISQkBCYm5sDAC5cuABfX1906dIFp06dwvr165GYmIjg4OACxWRlZQWdTofHjx9j0aJFmD9/PubNm4dTp06hTZs2+PTTT3H+/HkAwOLFi7Fjxw5s2LABWq0WUVFRqFy5cp7t/vLLLwCAvXv3IiMjA1u2bHmuTLdu3XDjxg0cOHBA2Xbz5k3ExcXB398fAJCQkIDevXtj5MiROHv2LJYvX47w8HDMmDHjlfuYnp6OXbt26T0FQ6fToWLFiti4cSPOnj2LKVOm4Msvv8SGDRsAAGPHjkX37t3h6+uLjIwMZGRkoFmzZq+UVxMREREBwOnTp3Ho0CElB3nZmNgff/yBDz/8EGq1Gvv370dSUhL69eun3PB09+5dBAYGIjExEYcPH0b16tXRrl073L1712B9JKJiQIioWAgMDBQ/Pz8REdHpdLJnzx5Rq9UyduxYCQwMlPLly8ujR4+U8pGRkeLm5iY6nU7Z9ujRI7GyspJdu3aJiIijo6PMnTtX2Z+dnS0VK1ZUjiMi4uXlJSNHjhQREa1WKwBkz549ecZ44MABASC3bt1StmVmZkqJEiXk0KFDemX79+8vn332mYiITJw4UWrVqqW3f8KECc+1RURERPQ2CgwMFFNTU7G2tlZeXbt2zbPsxo0bpUyZMsr71atXS6lSpZT3NjY2Eh4enmfd/v37y6BBg/S2JSQkiEqlkocPH+ZZ59n2U1NTxdXVVRo1aiQiIk5OTjJjxgy9Oo0bN5agoCARERk+fLi0atVKL6d8GgDZunWriIhcunRJAMiJEyf0yjydx4qI+Pn5Sb9+/ZT3y5cvFycnJ8nJyRERkY8++khmzpyp10ZkZKQ4OjrmGYOIyNSpU0WlUom1tbVYWloKAAEgCxYsyLeOiMiwYcOkS5cu+caae+yX5dVERET0bno6D1Sr1QJAVCqVbNq06ZXHxKpUqSJZWVmvdLycnByxsbGR//znP8q2V8nHiOjdwt/4IypGoqOjUbJkSWRnZ0On06FXr16YNm0ahg0bBnd3d707mk+ePIm0tDTY2NjotZGZmYkLFy7g9u3byMjIQNOmTZV9ZmZmaNSo0XOP+8yVnJwMU1NTeHl5vXLMaWlpePDgAVq3bq23PSsrCw0aNAAApKSk6MUBAJ6enq98DCIiIiJD8/b2xnfffae8t7a2BvBk9dusWbNw7tw53LlzB48fP0ZmZiYePHiAEiVKPNfO6NGjMWDAAERGRiqPq6xatSqAJ/ndqVOnEBUVpZQXEeh0Oly6dAk1a9bMM7bbt2+jZMmS0Ol0yMzMxAcffIAffvgBd+7cwZ9//onmzZvrlW/evDlOnjwJ4MljOlu3bg03Nzf4+vqiffv2+Pjjj//RufL398fAgQOxdOlSqNVqREVFoWfPnlCpVEo/NRqN3gq/nJycF543AHBzc8OOHTuQmZmJH3/8EcnJyRg+fLhemW+//RarVq3C5cuX8fDhQ2RlZaF+/fovjPdleTURERG923LzwPv372PhwoUwMzNDly5dcObMmZeOiSUnJ6NFixbKEx6ede3aNUyaNAnx8fH466+/kJOTgwcPHuDy5ctvvF9EVHxx4o+oGMlNJCwsLODk5AQzs///Ec4dXMp17949NGzYUG9gKFe5cuUKdXwrK6sC18n9DZuYmBhUqFBBb59arS5UHERERERvG2tra1SrVk1vW3p6Otq3b4+hQ4dixowZsLOzQ2JiIvr374+srKw8J7CmTZuGXr16ISYmBjt37sTUqVOxbt06dOrUCffu3cPgwYMxYsSI5+q9//77+cZmY2OD48ePQ6VSwdHRUcnp7ty589J+eXh44NKlS9i5cyf27t2L7t27w8fH57nfpimIDh06QEQQExODxo0bIyEhAQsXLlT237t3D6GhoejcufNzdS0tLfNt18LCQrkGs2fPxieffILQ0FCEhYUBANatW4exY8di/vz58PT0hI2NDb755hscOXLkhfG+ibyaiIiIjMfTeeCqVatQr149rFy5EnXq1AHw4jGxl421BQYG4saNG1i0aBEqVaoEtVoNT09PPm6ciF6IE39ExUheA0r58fDwwPr162Fvbw9bW9s8yzg6OuLIkSP48MMPAQCPHz9GUlISPDw88izv7u4OnU6HgwcPwsfH57n9uSsOc3JylG21atWCWq3G5cuX810pWLNmTezYsUNv2+HDh1/eSSIiIqK3WFJSEnQ6HebPn6+sZsv9PbkXcXV1haurK0aNGoXPPvsMq1evRqdOneDh4YGzZ8++cj6YS6VS5VnH1tYWTk5O0Gg0enmaRqNBkyZN9Mr16NEDPXr0QNeuXeHr64ubN2/Czs5Or728csG8WFpaonPnzoiKikJaWhrc3Nz08k8PDw9otdoC9/NZkyZNQqtWrTB06FCln82aNUNQUJBS5tkVexYWFs/F/yp5NRERERHwJO/68ssvMXr0aKSmpr50TKxu3bqIiIhAdnZ2nqv+NBoNli5dinbt2gEArly5guvXr7/RPhBR8acydABE9Gb4+/ujbNmy8PPzQ0JCAi5duoT4+HiMGDECv//+OwBg5MiRmD17NrZt24Zz584hKCgIf//9d75tVq5cGYGBgejXrx+2bdumtJk7gFWpUiWYmJggOjoa//vf/3Dv3j3Y2Nhg7NixGDVqFCIiInDhwgUcP34cS5YsQUREBABgyJAhOH/+PMaNGwetVouffvoJ4eHhb/oUEREREb1R1apVQ3Z2NpYsWYKLFy8iMjISy5Yty7f8w4cPERwcjPj4ePz222/QaDQ4evSo8gjPCRMm4NChQwgODkZycjLOnz+P7du3Izg4uNAxjhs3DnPmzMH69euh1WoREhKC5ORkjBw5EgCwYMECrF27FufOnUNqaio2btwIBwcHlC5d+rm27O3tYWVlhbi4OFy7dg23b9/O97j+/v6IiYnBqlWr4O/vr7dvypQpWLNmDUJDQ3HmzBmkpKRg3bp1mDRpUoH65unpibp162LmzJkAgOrVq+PYsWPYtWsXUlNTMXnyZBw9elSvTuXKlXHq1ClotVpcv34d2dnZr5RXExEREeXq1q0bTE1NsXz58peOiQUHB+POnTvo2bMnjh07hvPnzyMyMhJarRbAk/wlMjISKSkpOHLkCPz9/Qv1RC4ierdw4o/ISJUoUQL//e9/8f7776Nz586oWbMm+vfvj8zMTOVO5TFjxiAgIACBgYHK4446der0wna/++47dO3aFUFBQahRowYGDhyI+/fvAwAqVKiA0NBQhISEoHz58sogVFhYGCZPnoxZs2ahZs2a8PX1RUxMDKpUqQLgyaOpNm/ejG3btqFevXpYtmyZMkBDREREVFzVq1cPCxYswJw5c1CnTh1ERUVh1qxZ+ZY3NTXFjRs30Lt3b7i6uqJ79+5o27YtQkNDATy5I/zgwYNITU1FixYt0KBBA0yZMgVOTk6FjnHEiBEYPXo0xowZA3d3d8TFxWHHjh2oXr06gCePCZ07dy4aNWqExo0bIz09HbGxscoKxqeZmZlh8eLFWL58OZycnODn55fvcVu1agU7OztotVr06tVLb1+bNm0QHR2N3bt3o3HjxvjXv/6FhQsXolKlSgXu36hRo/DDDz/gypUrGDx4MDp37owePXqgadOmuHHjht7qPwAYOHAg3Nzc0KhRI5QrVw4ajeaV8moiIiKiXGZmZggODsbcuXMxceLEF46JlSlTBvv378e9e/fg5eWFhg0b4vvvv1dW/61cuRK3bt2Ch4cHAgICMGLECNjb2xuye0RUDJiIiBg6CCIiIiIiIiIiIiIiIiL6Z7jij4iIiIiIiIiIiIiIiMgIcOKPiIiIiIiIiIiIiIiIyAhw4o+IiIiIiIiIiIiIiIjICHDij4iIiIiIiIiIiIiIiMgIcOKPiIiIiIiIiIiIiIiIyAhw4o+IiIiIiIiIiIiIiIjICHDij4iIiIiIiIiIiIiIiMgIcOKPiIiIiIiIiIiIiIiIyAhw4o+IiIiIiIiIiIiIiIjICHDij4iIiIiIiIiIiIiIiMgIcOKPiIiIiIiIiIiIiIiIyAhw4o+IiIiIiIiIiIiIiIjICPwfbRJEcog300kAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix shows the number of correct and incorrect predictions made by the classifier.  \n",
        "- Rows represent the actual class (`True`), columns represent the predicted class.  \n",
        "- A perfect classifier would have all values on the diagonal.  \n",
        "- Misclassifications appear off-diagonal.\n",
        "\n",
        "The ROC (Receiver Operating Characteristic) curve evaluates the model's ability to distinguish between classes.  \n",
        "- It plots the True Positive Rate (Sensitivity) against the False Positive Rate.  \n",
        "- The closer the curve follows the top-left corner, the better the model.  \n",
        "- AUC (Area Under the Curve) values closer to 1 indicate stronger performance.\n",
        "\n",
        "The Precision-Recall Curve focuses on performance for the positive class.  \n",
        "- It is particularly useful for imbalanced datasets.  \n",
        "- High precision means few false positives; high recall means few false negatives.  \n",
        "- The AUC score reflects the balance between precision and recall across thresholds."
      ],
      "metadata": {
        "id": "QOC0UrcTSjB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Models**\n",
        "  ## **MLP Classifier**\n",
        "\n",
        "### 1. **Confusion Matrix**\n",
        "  * Correctly predicted: 131 lung samples, 69 vocal samples\n",
        "  * Misclassified: 3 lung \u2192 vocal, 8 vocal \u2192 lung\n",
        "  * Total accuracy appears reasonable, but some vocal misclassifications occur.\n",
        "\n",
        "### 2. **ROC Curve**\n",
        "  * AUC = 0.49\n",
        "  * The model performs nearly at random (AUC \u2248 0.5), suggesting poor probabilistic discrimination between classes.\n",
        "\n",
        "### 3. **Precision-Recall Curve**\n",
        "  * AUC = 0.36\n",
        "  * Indicates low precision across the recall spectrum. The model struggles especially in minority confidence regions.\n",
        "\n",
        "\n",
        "  ## **Random Forest**\n",
        "\n",
        "  ### 1. **Confusion Matrix**\n",
        "  * Correctly predicted: 130 lung, 71 vocal\n",
        "  * Misclassified: 4 lung \u2192 vocal, 6 vocal \u2192 lung\n",
        "  * Balanced performance, with a slight improvement on vocal class over MLP.\n",
        "\n",
        "### 2. **ROC Curve**\n",
        "  * AUC = 0.50\n",
        "  * Class probability estimates are not better than chance.\n",
        "\n",
        "### 3. **Precision-Recall Curve**\n",
        "  * AUC = 0.35\n",
        "  * Precision remains low across all recall levels, suggesting weak model confidence.\n",
        "\n",
        "\n",
        "  ## **Support Vector Machine (linear)**\n",
        "\n",
        "### **1. Confusion Matrix**\n",
        "  * Correctly predicted: 132 lung, 76 vocal\n",
        "  * Misclassified: 2 lung \u2192 vocal, 1 vocal \u2192 lung\n",
        "  * This is the strongest confusion matrix, with near-perfect predictions.\n",
        "\n",
        "### **2. ROC Curve**\n",
        "  * AUC = 0.48\n",
        "  * However, the low AUC shows poor calibration of predicted probabilities.\n",
        "\n",
        "### **3. Precision-Recall Curve**\n",
        "  * AUC = 0.34\n",
        "  * Despite the matrix, confidence levels are not reliable; the model predicts sharply but does not assign probabilities well.\n",
        "\n",
        "\n",
        "  ## **Logistic Regression**\n",
        "  \n",
        "  ### **1. Confusion Matrix**\n",
        "  * Same prediction as SVM: 132 lung, 76 vocal,\n",
        "  * Misclassified: 2 lung \u2192 vocal, 1 vocal \u2192 lung\n",
        "  * High classification accuracy, consistent with SVM.\n",
        "\n",
        "### **2. ROC Curve**\n",
        "  * AUC = 0.48\n",
        "  * Poor discrimination in probability space.\n",
        "\n",
        "### **3. Precision-Recall Curve**\n",
        "  * AUC = 0.34\n",
        "  * Confidence distributions mirror those of SVM: accurate predictions but low probability quality.\n",
        "\n",
        "\n",
        "  ## **Gradient Boosting**\n",
        "\n",
        "### **1. Confusion Matrix**\n",
        "  * Correctly predicted: 132 lung, 71 vocal\n",
        "  * Misclassified: 2 lung \u2192 vocal, 6 vocal \u2192 lung\n",
        "  * Slightly underperforms compared to SVM/LR in vocal class recall.\n",
        "\n",
        "### **2. ROC Curve**\n",
        "  * AUC = 0.50\n",
        "  * No probabilistic advantage, suggesting poor generalization from boosting.\n",
        "\n",
        "### **3. Precision-Recall Curve**\n",
        "  * AUC = 0.35\n",
        "  * Shows the same trend: low confidence spread, though classification itself remains solid."
      ],
      "metadata": {
        "id": "TmLOCf0GSjtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**  \n",
        "This notebook trains, evaluates, and compares multiple classifiers on pulmonary sound embeddings, distinguishing between `lung` and `vocal` coughs. The pipeline includes data loading, train/test split, model training, prediction, and performance analysis using confusion matrices, ROC and PRC curves, and per-class metrics.  \n",
        "\n",
        "Probability calibration was explored but deliberately excluded from this version. It is recommended as a next step to fine-tune decision thresholds and improve model interpretability for deployment scenarios."
      ],
      "metadata": {
        "id": "ZFGUoLmVSGGB"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "TmLOCf0GSjtn"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab695cfe824d4d04bec3432ad38e94cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c1925c3178b49c386a9e91562444a23",
              "IPY_MODEL_58fa6b71479f43a9804333d2d09af993",
              "IPY_MODEL_fe4eba1fa0cc48219f53bdd6410d603f"
            ],
            "layout": "IPY_MODEL_f7052d36cb054a11b8f6f03a544e0f97"
          }
        },
        "3c1925c3178b49c386a9e91562444a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aad741741c74a8c9f19d787cd5d53e0",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_2f54d0c750f7485dac6a9a10b77cadac",
            "value": "Fetching\u200724\u2007files:\u2007100%"
          }
        },
        "58fa6b71479f43a9804333d2d09af993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_273964d2c9cd479a867fdddd4b20f6e6",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5e239cb2e1442ef8d2aca4c117465b4",
            "value": 24
          }
        },
        "fe4eba1fa0cc48219f53bdd6410d603f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f1352aeb7e4b80a77119ef3838e686",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_19ba2fc5dcaa4108b3f64fa073f434cf",
            "value": "\u200724/24\u2007[00:08&lt;00:00,\u200725.31it/s]"
          }
        },
        "f7052d36cb054a11b8f6f03a544e0f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aad741741c74a8c9f19d787cd5d53e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f54d0c750f7485dac6a9a10b77cadac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "273964d2c9cd479a867fdddd4b20f6e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e239cb2e1442ef8d2aca4c117465b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07f1352aeb7e4b80a77119ef3838e686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19ba2fc5dcaa4108b3f64fa073f434cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d30a35955ef04f799c5ae7bfbf9aed80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd98606f7a5d42d98bf270055de670dd",
              "IPY_MODEL_773dce5f1d444da8bace8b113e9c1b24",
              "IPY_MODEL_49364e28a6b14926b9d29968cfc64ad5"
            ],
            "layout": "IPY_MODEL_dd5d15f3261e4604b46d6b9e585e280a"
          }
        },
        "fd98606f7a5d42d98bf270055de670dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d51ad0da6ad474ca4d2551e8a7e27f7",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_1c3ed3cfe946461bb6f7e7c6a31cb23c",
            "value": "README.md:\u2007100%"
          }
        },
        "773dce5f1d444da8bace8b113e9c1b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cac1914373d4cc78eb616981bf1369e",
            "max": 3241,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ebafed421fa4ee8a6e821038fe06072",
            "value": 3241
          }
        },
        "49364e28a6b14926b9d29968cfc64ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3ab2c414d714aa5a062f973b767e78c",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_b0e8118516e04f04af10f50ac00f01f1",
            "value": "\u20073.24k/3.24k\u2007[00:00&lt;00:00,\u200760.9kB/s]"
          }
        },
        "dd5d15f3261e4604b46d6b9e585e280a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d51ad0da6ad474ca4d2551e8a7e27f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c3ed3cfe946461bb6f7e7c6a31cb23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cac1914373d4cc78eb616981bf1369e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ebafed421fa4ee8a6e821038fe06072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3ab2c414d714aa5a062f973b767e78c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e8118516e04f04af10f50ac00f01f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b049f4d777741f3af6da3c299b29587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b27ddcd654ee441cab1caf96712c0e83",
              "IPY_MODEL_7ef5b2665e8046258df498be234fb9e7",
              "IPY_MODEL_d15e1d5738ef4b8c98575a39066c480b"
            ],
            "layout": "IPY_MODEL_1b8c248e87f248569448bbbbbd3d8971"
          }
        },
        "b27ddcd654ee441cab1caf96712c0e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c901bf4ad95b475a95d2318fead3c077",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_87cc323a06f44dacabfb1c2db16316dd",
            "value": ".DS_Store:\u2007100%"
          }
        },
        "7ef5b2665e8046258df498be234fb9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f13de01183d49dd96d8a0d13f2cbafc",
            "max": 6148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1be3fd11334b473b82a7be98f4530f11",
            "value": 6148
          }
        },
        "d15e1d5738ef4b8c98575a39066c480b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af5aa28a3c60471987897765ac675dee",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_3b366a2f82334470a6aa6b1e6772895f",
            "value": "\u20076.15k/6.15k\u2007[00:00&lt;00:00,\u200789.5kB/s]"
          }
        },
        "1b8c248e87f248569448bbbbbd3d8971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c901bf4ad95b475a95d2318fead3c077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cc323a06f44dacabfb1c2db16316dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f13de01183d49dd96d8a0d13f2cbafc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1be3fd11334b473b82a7be98f4530f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af5aa28a3c60471987897765ac675dee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b366a2f82334470a6aa6b1e6772895f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de6d9a4cce0b45a99caa0f5db76e077a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33888d210e8845499bf7217da6f5cada",
              "IPY_MODEL_c26161317b8847d1852289395b07221e",
              "IPY_MODEL_0c65e9526ae44299b68b0c45da37723b"
            ],
            "layout": "IPY_MODEL_da49ae7443f342008cd0e154e0c3fdb3"
          }
        },
        "33888d210e8845499bf7217da6f5cada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ac92b9e726544b59e5ee3cfa0e85aed",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_a9588ceb41634c51b492db47dd7c108b",
            "value": "README.md:\u2007100%"
          }
        },
        "c26161317b8847d1852289395b07221e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1189db934b9d4130b7a6f7cc442bf00e",
            "max": 11895,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c22d7bb2e6364809ba2c3e491050b0be",
            "value": 11895
          }
        },
        "0c65e9526ae44299b68b0c45da37723b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02fdf1ede0bb4efeae143fb13e5c3f10",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_11343b63a94e40e481f34cea6e3d1197",
            "value": "\u200711.9k/11.9k\u2007[00:00&lt;00:00,\u2007108kB/s]"
          }
        },
        "da49ae7443f342008cd0e154e0c3fdb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac92b9e726544b59e5ee3cfa0e85aed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9588ceb41634c51b492db47dd7c108b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1189db934b9d4130b7a6f7cc442bf00e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c22d7bb2e6364809ba2c3e491050b0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02fdf1ede0bb4efeae143fb13e5c3f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11343b63a94e40e481f34cea6e3d1197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21db9c1399b6413f8f2d13af9ab2464f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7aa902cd514249beb1782a4ce7dd5252",
              "IPY_MODEL_29e8891cde284149aae9fc6ebd647f06",
              "IPY_MODEL_c559b75e6a284504b2810459afdd7d56"
            ],
            "layout": "IPY_MODEL_e4007d30fc48404abe169e596dc7b12a"
          }
        },
        "7aa902cd514249beb1782a4ce7dd5252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3e87eb7195541a4998d0c787c906b0a",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_c93f766fc4594a44bb43d0c1135a9e00",
            "value": ".gitattributes:\u2007100%"
          }
        },
        "29e8891cde284149aae9fc6ebd647f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0d43177f0944f32a122f36dbf8c280d",
            "max": 1819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73bbe9aa071b4b62b6b78b2ffcdca6d9",
            "value": 1819
          }
        },
        "c559b75e6a284504b2810459afdd7d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_511fc5a03f614319b0f0900a381a79e9",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_04a8e2a9428a4759b91e9f3e0b46bdb6",
            "value": "\u20071.82k/1.82k\u2007[00:00&lt;00:00,\u200718.1kB/s]"
          }
        },
        "e4007d30fc48404abe169e596dc7b12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3e87eb7195541a4998d0c787c906b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93f766fc4594a44bb43d0c1135a9e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0d43177f0944f32a122f36dbf8c280d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73bbe9aa071b4b62b6b78b2ffcdca6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "511fc5a03f614319b0f0900a381a79e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04a8e2a9428a4759b91e9f3e0b46bdb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1270b2c941b44deaa820aa0f7111b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cc90383582143948b6bfba9978c1244",
              "IPY_MODEL_be1c924ca9e5407db5c90c699a55be36",
              "IPY_MODEL_eae88f12d78d44f0a01a411c804fba95"
            ],
            "layout": "IPY_MODEL_f1676a5f3f824e5e979ef0ad4db7bb77"
          }
        },
        "1cc90383582143948b6bfba9978c1244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc878f7061ea44c8bd028011a8976b63",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_92a1a5a2e160497ab03a7ea6935c41aa",
            "value": "keras_metadata.pb:\u2007100%"
          }
        },
        "be1c924ca9e5407db5c90c699a55be36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58338466d9f14a2fa8f7bdfe0f9babe9",
            "max": 759941,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b48ef212898f481c86ef25a66cc95065",
            "value": 759941
          }
        },
        "eae88f12d78d44f0a01a411c804fba95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f05b1c7fce0b49c4aaa485d460c44847",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_e30f9a035b6d45f79431635f72aa4887",
            "value": "\u2007760k/760k\u2007[00:00&lt;00:00,\u20074.48MB/s]"
          }
        },
        "f1676a5f3f824e5e979ef0ad4db7bb77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc878f7061ea44c8bd028011a8976b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a1a5a2e160497ab03a7ea6935c41aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58338466d9f14a2fa8f7bdfe0f9babe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b48ef212898f481c86ef25a66cc95065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f05b1c7fce0b49c4aaa485d460c44847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30f9a035b6d45f79431635f72aa4887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d6d0288108f492da5f3cc53d61dc7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcbde5ee597141d0b54e5c8bb0d86724",
              "IPY_MODEL_c18ecc3ac43d44f4a91be07f3485de71",
              "IPY_MODEL_4985f42ccc444d89b738421312d25c57"
            ],
            "layout": "IPY_MODEL_ff1c40dec64845f9ae79d5f4d5fa6f27"
          }
        },
        "dcbde5ee597141d0b54e5c8bb0d86724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb21f36da3c34ee3b5c5cf14e72ff701",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_3028f13533c24c02b1d2a720d2a54dd5",
            "value": "variables.data-00000-of-00001:\u2007100%"
          }
        },
        "c18ecc3ac43d44f4a91be07f3485de71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb26a0a37e274aa0921839545c4d431e",
            "max": 12221821,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_231c8367e7a84e3b96495d370f55378d",
            "value": 12221821
          }
        },
        "4985f42ccc444d89b738421312d25c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7893235e20184659891373e41891b092",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_7808aa11eada4688844ff50e115a2865",
            "value": "\u200712.2M/12.2M\u2007[00:00&lt;00:00,\u200717.8MB/s]"
          }
        },
        "ff1c40dec64845f9ae79d5f4d5fa6f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb21f36da3c34ee3b5c5cf14e72ff701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3028f13533c24c02b1d2a720d2a54dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb26a0a37e274aa0921839545c4d431e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "231c8367e7a84e3b96495d370f55378d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7893235e20184659891373e41891b092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7808aa11eada4688844ff50e115a2865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f065d63063c84705bf351c8e769c86e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acca8d2b877146aaab7eb599398e6789",
              "IPY_MODEL_03ac67467a9a4896897c3ed2845c7bd1",
              "IPY_MODEL_fcd6fc69473549b98532618efc132700"
            ],
            "layout": "IPY_MODEL_49cdeb33a5df4df498de694400f36980"
          }
        },
        "acca8d2b877146aaab7eb599398e6789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d835b1976e1848d58523f9bbc3f8d6c5",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_53ccafb250d34741aeecd1bd2c06fa28",
            "value": "fingerprint.pb:\u2007100%"
          }
        },
        "03ac67467a9a4896897c3ed2845c7bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_778a3de09d6d45fea2f9a46dda7f05fd",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79c7488af1df41e49145b1940669deb0",
            "value": 79
          }
        },
        "fcd6fc69473549b98532618efc132700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c69eecb4130d4f7d8e06b38a5f6befb1",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_b286ad0be802488aab09337efbcd5a8a",
            "value": "\u200779.0/79.0\u2007[00:00&lt;00:00,\u2007457B/s]"
          }
        },
        "49cdeb33a5df4df498de694400f36980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d835b1976e1848d58523f9bbc3f8d6c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ccafb250d34741aeecd1bd2c06fa28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "778a3de09d6d45fea2f9a46dda7f05fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79c7488af1df41e49145b1940669deb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c69eecb4130d4f7d8e06b38a5f6befb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b286ad0be802488aab09337efbcd5a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "374276840bfd4bb292e27009ab475dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec46411b2b0c4cd9bd435b8e0b03164f",
              "IPY_MODEL_d8ac94ce6c7845108596f49e872766c5",
              "IPY_MODEL_10a68c316d8943d7836961fb88cb2d61"
            ],
            "layout": "IPY_MODEL_38488f0de8cf4fd1a6a554c917dae116"
          }
        },
        "ec46411b2b0c4cd9bd435b8e0b03164f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8da6338646f548da90f33adccd2533eb",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_d4b04f6bda4a4c68a04694c90f8fe45d",
            "value": "variables.index:\u2007100%"
          }
        },
        "d8ac94ce6c7845108596f49e872766c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_054c102a800d493f86b0a5afdc9c1cbc",
            "max": 5075,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1108865724c04b8c834f92386b456feb",
            "value": 5075
          }
        },
        "10a68c316d8943d7836961fb88cb2d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80c63421baa941c38250073c626f4ef2",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_ddc62a1fef27471d8aae810849fda7bf",
            "value": "\u20075.08k/5.08k\u2007[00:00&lt;00:00,\u200736.7kB/s]"
          }
        },
        "38488f0de8cf4fd1a6a554c917dae116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da6338646f548da90f33adccd2533eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4b04f6bda4a4c68a04694c90f8fe45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "054c102a800d493f86b0a5afdc9c1cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1108865724c04b8c834f92386b456feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80c63421baa941c38250073c626f4ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc62a1fef27471d8aae810849fda7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b12a212b9df543d7abc75aa45646786c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a94bc687be1f467c8e3a51ea4dc7bbe4",
              "IPY_MODEL_430d26806a7c43aeabdef89d556dc0e9",
              "IPY_MODEL_1195daf85aeb4a45b0215c44cf17b667"
            ],
            "layout": "IPY_MODEL_08d747a647da465a99984d93982d8408"
          }
        },
        "a94bc687be1f467c8e3a51ea4dc7bbe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3d0dcd2ec894e8d9dcbd6a7193afe66",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_784f5f8f2aa04c0db590125a5f3e1bfb",
            "value": "saved_model.pb:\u2007100%"
          }
        },
        "430d26806a7c43aeabdef89d556dc0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d7d2fab2cf146b9bfae42b28fb231c0",
            "max": 4890569,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecdf50ef6cb745c192de565a2a3e60ed",
            "value": 4890569
          }
        },
        "1195daf85aeb4a45b0215c44cf17b667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cfc79467a8e4403a8d39bcf5acff201",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_d988899649214898924547ef25e66db2",
            "value": "\u20074.89M/4.89M\u2007[00:00&lt;00:00,\u200714.6MB/s]"
          }
        },
        "08d747a647da465a99984d93982d8408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3d0dcd2ec894e8d9dcbd6a7193afe66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "784f5f8f2aa04c0db590125a5f3e1bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d7d2fab2cf146b9bfae42b28fb231c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecdf50ef6cb745c192de565a2a3e60ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cfc79467a8e4403a8d39bcf5acff201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d988899649214898924547ef25e66db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46cfb63b29c04ed6bb797c7a0b1ae095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_079090b4ab714e73b1003437595e9e35",
              "IPY_MODEL_2e8d26274854481894d6c4ba6c517943",
              "IPY_MODEL_8c03a8e385bb4c23ae3a51e473badf3a"
            ],
            "layout": "IPY_MODEL_989fd4145aab45b7ab36ab62f35a8ed3"
          }
        },
        "079090b4ab714e73b1003437595e9e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_796282f1dc3a46eaae9d1dd2cb161f1c",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_0f0fc2e3829942c18e7b776752b52671",
            "value": "fingerprint.pb:\u2007100%"
          }
        },
        "2e8d26274854481894d6c4ba6c517943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cea2a10d6fd4359ad7e26b551b99644",
            "max": 76,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_503e9de35caa48f38078bf9af90e1679",
            "value": 76
          }
        },
        "8c03a8e385bb4c23ae3a51e473badf3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baff46c75dac4c808f5ebd3df43830e3",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_921d3b5649174d238e8e48dc819b5e7e",
            "value": "\u200776.0/76.0\u2007[00:00&lt;00:00,\u2007459B/s]"
          }
        },
        "989fd4145aab45b7ab36ab62f35a8ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796282f1dc3a46eaae9d1dd2cb161f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0fc2e3829942c18e7b776752b52671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cea2a10d6fd4359ad7e26b551b99644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "503e9de35caa48f38078bf9af90e1679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baff46c75dac4c808f5ebd3df43830e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "921d3b5649174d238e8e48dc819b5e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "244c5f7ec52d4da6a3270d55e041bcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6596a56a44ba4fdd8da1d4d6ea6a8555",
              "IPY_MODEL_08298afaedde4c899d6c672a8058bacf",
              "IPY_MODEL_8f78409880e244e2b3cab04b5a52ef46"
            ],
            "layout": "IPY_MODEL_dab6cd16332a484c821c457cca06e082"
          }
        },
        "6596a56a44ba4fdd8da1d4d6ea6a8555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf7d9e9c57cd4371a4fbd0b39f24e613",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_ac11fd3d2f604f79944312a36fb8feb6",
            "value": "saved_model.pb:\u2007100%"
          }
        },
        "08298afaedde4c899d6c672a8058bacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_536384fb91d6480d87a07bacc840f0ac",
            "max": 4005218,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_728e66d11466489fa7523de34a38c0ca",
            "value": 4005218
          }
        },
        "8f78409880e244e2b3cab04b5a52ef46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a32c4d7602024cc8ae197ce3966aeb8e",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_9d5cb1902508431eb1ba9c5462943d63",
            "value": "\u20074.01M/4.01M\u2007[00:00&lt;00:00,\u200711.1MB/s]"
          }
        },
        "dab6cd16332a484c821c457cca06e082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7d9e9c57cd4371a4fbd0b39f24e613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac11fd3d2f604f79944312a36fb8feb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "536384fb91d6480d87a07bacc840f0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "728e66d11466489fa7523de34a38c0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a32c4d7602024cc8ae197ce3966aeb8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5cb1902508431eb1ba9c5462943d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "620297496a4b4e22b1fcb9466c3f4a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3b709b9c7774378ba12aa53cfb315f3",
              "IPY_MODEL_1e813d4163bd46cdb5ffb960745c3a0b",
              "IPY_MODEL_0334d213a70a4eceb61e60a999f986f0"
            ],
            "layout": "IPY_MODEL_2a90e013cc244a90bad715e1b3ca1888"
          }
        },
        "a3b709b9c7774378ba12aa53cfb315f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31944190f90e420eaac43ab473860a85",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_d3edb541b0924fa1868095895034ffc2",
            "value": "keras_metadata.pb:\u2007100%"
          }
        },
        "1e813d4163bd46cdb5ffb960745c3a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2bdd2dd13b646c7ab6061607daca5cd",
            "max": 643662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53717466d8564974833edf549e154ac0",
            "value": 643662
          }
        },
        "0334d213a70a4eceb61e60a999f986f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e33e2d289954ec5afb98d4908f78e23",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_b10e403fdaf14a6fb6c64bb96b6ed053",
            "value": "\u2007644k/644k\u2007[00:00&lt;00:00,\u20073.34MB/s]"
          }
        },
        "2a90e013cc244a90bad715e1b3ca1888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31944190f90e420eaac43ab473860a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3edb541b0924fa1868095895034ffc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2bdd2dd13b646c7ab6061607daca5cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53717466d8564974833edf549e154ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e33e2d289954ec5afb98d4908f78e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b10e403fdaf14a6fb6c64bb96b6ed053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e28f4a8c4884514911499d0171900ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24b09c61b99548778c19a4b6b1ae8ea2",
              "IPY_MODEL_6cfdd1b614e14b41a8b98e30ca482343",
              "IPY_MODEL_a41cf648c3c649638f42c3251147557f"
            ],
            "layout": "IPY_MODEL_82aff41d867847f6b62d85107eea62ab"
          }
        },
        "24b09c61b99548778c19a4b6b1ae8ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_522b8b827b414700a22a72006d393b1a",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_f857c66330b042aeaa1e486cabac0536",
            "value": "variables.index:\u2007100%"
          }
        },
        "6cfdd1b614e14b41a8b98e30ca482343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e0e4deb1dd44853b73254f12b3232ca",
            "max": 4209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f5b3c4550ee4812bf7925dbdac516f0",
            "value": 4209
          }
        },
        "a41cf648c3c649638f42c3251147557f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d430e4cd0c4c0abc1ad24048254df2",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_ee3ee8ab8b6646b884859f4b45e13bdf",
            "value": "\u20074.21k/4.21k\u2007[00:00&lt;00:00,\u200741.2kB/s]"
          }
        },
        "82aff41d867847f6b62d85107eea62ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522b8b827b414700a22a72006d393b1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f857c66330b042aeaa1e486cabac0536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e0e4deb1dd44853b73254f12b3232ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f5b3c4550ee4812bf7925dbdac516f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90d430e4cd0c4c0abc1ad24048254df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee3ee8ab8b6646b884859f4b45e13bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdfd92829542415c9d8be746fba57dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1a925678bc249a1869db6d249f391e4",
              "IPY_MODEL_2311b4ef0da0498ebf3af8d8782d0b93",
              "IPY_MODEL_807dc11257824eceb8870210679c605e"
            ],
            "layout": "IPY_MODEL_d601a3cfada04e02b8893f3b50419c2e"
          }
        },
        "e1a925678bc249a1869db6d249f391e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88d8d64ce4f2442486a513af60ee5a5f",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_7d4ee1b6c44044528980aa59f93f0af1",
            "value": "variables.data-00000-of-00001:\u2007100%"
          }
        },
        "2311b4ef0da0498ebf3af8d8782d0b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcdb7cbf4a514f5cae347942d43a489a",
            "max": 3949791,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a57145c9ffb48f49e2fb9ffebf1a92b",
            "value": 3949791
          }
        },
        "807dc11257824eceb8870210679c605e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2bab728d9c34fd68bdf581ee462bde1",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_75c8a37a99a648aea32a344d434f4606",
            "value": "\u20073.95M/3.95M\u2007[00:00&lt;00:00,\u200714.2MB/s]"
          }
        },
        "d601a3cfada04e02b8893f3b50419c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d8d64ce4f2442486a513af60ee5a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4ee1b6c44044528980aa59f93f0af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcdb7cbf4a514f5cae347942d43a489a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a57145c9ffb48f49e2fb9ffebf1a92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2bab728d9c34fd68bdf581ee462bde1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c8a37a99a648aea32a344d434f4606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62e1308372074f5cbf5855938f8141dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7af77e029c4e4f44b54e6cfbb0b92bc0",
              "IPY_MODEL_28c16c00500e457ebc8788a895a4a476",
              "IPY_MODEL_fc7b350a4fa741d7b19b9cacb84f9c2d"
            ],
            "layout": "IPY_MODEL_2c0c3e778b384071aedcf69d22e5ac94"
          }
        },
        "7af77e029c4e4f44b54e6cfbb0b92bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0336c993df014f599ec290aca45bd725",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_f3d02494c2c0474a916d5147b2598cde",
            "value": "fingerprint.pb:\u2007100%"
          }
        },
        "28c16c00500e457ebc8788a895a4a476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d68bc38125744bb9bae0133ef329cab8",
            "max": 55,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e13f57cda9584a95949cdce9dbfffa17",
            "value": 55
          }
        },
        "fc7b350a4fa741d7b19b9cacb84f9c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc7d625e86c44913a1c58ea224057294",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_b6db9489c3c94a57b0eb33e6ba481401",
            "value": "\u200755.0/55.0\u2007[00:00&lt;00:00,\u2007341B/s]"
          }
        },
        "2c0c3e778b384071aedcf69d22e5ac94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0336c993df014f599ec290aca45bd725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d02494c2c0474a916d5147b2598cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d68bc38125744bb9bae0133ef329cab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e13f57cda9584a95949cdce9dbfffa17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc7d625e86c44913a1c58ea224057294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6db9489c3c94a57b0eb33e6ba481401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a5e6591650246d4a55bbf736e1ad370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_546dec9cea2246c1a4da104b5b977b67",
              "IPY_MODEL_9e329f9614c74681a9a8528f00992a66",
              "IPY_MODEL_81dda9f63abd4de798e125694476cb79"
            ],
            "layout": "IPY_MODEL_a2ba2edf90294db1aa1120ec9f180c89"
          }
        },
        "546dec9cea2246c1a4da104b5b977b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d134fb8c906436abb1ed8752e59e321",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_c9012cc225bd436ebb2ff49518533483",
            "value": "keras_metadata.pb:\u2007100%"
          }
        },
        "9e329f9614c74681a9a8528f00992a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27a51bd918fe42dfbfae2e604a6386e8",
            "max": 10684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47628522e1d2419db3b284b80c6bd267",
            "value": 10684
          }
        },
        "81dda9f63abd4de798e125694476cb79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86656895db9743ed9d453c35015292cd",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_4d32a7659ac74e3aa8278cd80890c91a",
            "value": "\u200710.7k/10.7k\u2007[00:00&lt;00:00,\u200766.9kB/s]"
          }
        },
        "a2ba2edf90294db1aa1120ec9f180c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d134fb8c906436abb1ed8752e59e321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9012cc225bd436ebb2ff49518533483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27a51bd918fe42dfbfae2e604a6386e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47628522e1d2419db3b284b80c6bd267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86656895db9743ed9d453c35015292cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d32a7659ac74e3aa8278cd80890c91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3764145e75d48c8b912dd4322215fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edfea30ac45e49edb18327a61d201e9a",
              "IPY_MODEL_6b9b6047ee3940158395359725956f39",
              "IPY_MODEL_d43eed7b1c91490793f00fd2ac6b11b0"
            ],
            "layout": "IPY_MODEL_933b7788b5214f87971a9f8945232426"
          }
        },
        "edfea30ac45e49edb18327a61d201e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3b3aed10c834b05b5910c0c7e8b2958",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_0d7f44d10bd24958ac76ac47c40023dd",
            "value": "saved_model.pb:\u2007100%"
          }
        },
        "6b9b6047ee3940158395359725956f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ff648091f54cbd855a0facc378f54b",
            "max": 339865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec31296836424ee197b328fcd605f22b",
            "value": 339865
          }
        },
        "d43eed7b1c91490793f00fd2ac6b11b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7367330f59444327bd1276835734de10",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_a6657b92c2884897b9fc2cad9e620aac",
            "value": "\u2007340k/340k\u2007[00:00&lt;00:00,\u20071.73MB/s]"
          }
        },
        "933b7788b5214f87971a9f8945232426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3b3aed10c834b05b5910c0c7e8b2958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7f44d10bd24958ac76ac47c40023dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76ff648091f54cbd855a0facc378f54b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec31296836424ee197b328fcd605f22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7367330f59444327bd1276835734de10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6657b92c2884897b9fc2cad9e620aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1ea45401a6b4aa4a4a7ab7840485a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82824dac5c3b45e38b0cd8e86287dac9",
              "IPY_MODEL_b6ae42f6abe34a249218b2eb5e7f6388",
              "IPY_MODEL_eea641039c464f1daad44a65546de35e"
            ],
            "layout": "IPY_MODEL_c1064cd4a9bd47eabac1f8e751c27a05"
          }
        },
        "82824dac5c3b45e38b0cd8e86287dac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ffc1a56174d442f9b991b76455ca2eb",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_3e8857f6696c4ca7814f1be3d0324f01",
            "value": "variables.index:\u2007100%"
          }
        },
        "b6ae42f6abe34a249218b2eb5e7f6388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca60d69b2a5349f7b50779f0803d363d",
            "max": 286,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a157a0db04bd4bcc9d695ba6ec218331",
            "value": 286
          }
        },
        "eea641039c464f1daad44a65546de35e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97f85bdae8af46afbf2e44e0f5991e1c",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_ebed5106957c4af98b0d663d27e1eae1",
            "value": "\u2007286/286\u2007[00:00&lt;00:00,\u20073.50kB/s]"
          }
        },
        "c1064cd4a9bd47eabac1f8e751c27a05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ffc1a56174d442f9b991b76455ca2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e8857f6696c4ca7814f1be3d0324f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca60d69b2a5349f7b50779f0803d363d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a157a0db04bd4bcc9d695ba6ec218331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97f85bdae8af46afbf2e44e0f5991e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebed5106957c4af98b0d663d27e1eae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e57af1620bcd48968398de6ea2b76efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3a2a9f2af7342979d3475fc45347d8c",
              "IPY_MODEL_8f7a2cc5ab96416f9be039900a7b3449",
              "IPY_MODEL_ee1376af2c164e20ac907a6606eedcfb"
            ],
            "layout": "IPY_MODEL_95a72cdfea0f4913951b76c9cb73bfbc"
          }
        },
        "d3a2a9f2af7342979d3475fc45347d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d92c48d215b74a72a3d77b6ad719c3d1",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_90ed9af1dcac4892a0db9140e4d8290c",
            "value": "variables.data-00000-of-00001:\u2007100%"
          }
        },
        "8f7a2cc5ab96416f9be039900a7b3449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37d0262b8e6d43818f9bdebc62b592ad",
            "max": 24138,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_443483054efd41f1800518c9401aac25",
            "value": 24138
          }
        },
        "ee1376af2c164e20ac907a6606eedcfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69a6bb0be1274682868dfebb96f96162",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_58c1a386c643417bb48010443b4a695d",
            "value": "\u200724.1k/24.1k\u2007[00:00&lt;00:00,\u2007221kB/s]"
          }
        },
        "95a72cdfea0f4913951b76c9cb73bfbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d92c48d215b74a72a3d77b6ad719c3d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ed9af1dcac4892a0db9140e4d8290c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37d0262b8e6d43818f9bdebc62b592ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443483054efd41f1800518c9401aac25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69a6bb0be1274682868dfebb96f96162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c1a386c643417bb48010443b4a695d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6b997fb009d4c28a1702f07ca25a7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c8f37e6e06b45f480d1917d5fdefb66",
              "IPY_MODEL_da376135967f46fb9ee80c4fdd54a0b3",
              "IPY_MODEL_8251af94e711495dab257714a3814246"
            ],
            "layout": "IPY_MODEL_4cd6d58567dc4350b22a6ce3171b0350"
          }
        },
        "8c8f37e6e06b45f480d1917d5fdefb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54adb39b27d44028bf439945cc6a8f94",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_13dc4a6027144c18bd9875a02d56d056",
            "value": "gitattributes:\u2007100%"
          }
        },
        "da376135967f46fb9ee80c4fdd54a0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_957704fa6edc434695f31e53a37711e7",
            "max": 1595,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ea805cf5a6a4277a28f64d9ba2baab9",
            "value": 1595
          }
        },
        "8251af94e711495dab257714a3814246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e95069e882f34a1cb20ced4c2ef7e756",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_eee136ae6e76464390c67b1f5a9eca67",
            "value": "\u20071.59k/1.59k\u2007[00:00&lt;00:00,\u200714.7kB/s]"
          }
        },
        "4cd6d58567dc4350b22a6ce3171b0350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54adb39b27d44028bf439945cc6a8f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13dc4a6027144c18bd9875a02d56d056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "957704fa6edc434695f31e53a37711e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ea805cf5a6a4277a28f64d9ba2baab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e95069e882f34a1cb20ced4c2ef7e756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee136ae6e76464390c67b1f5a9eca67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21ef6cd7f93140f8ad670f3a9c82ad5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb03faa60b614131804e934970a461c7",
              "IPY_MODEL_2ef7b7af0dd44d379ab2dd62916284f7",
              "IPY_MODEL_3e3e3ec3adca42bfb32073a3d7623de3"
            ],
            "layout": "IPY_MODEL_51e0981338f24b4b838a10ea4d40ed52"
          }
        },
        "bb03faa60b614131804e934970a461c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3092e4a9003a4c09b0a4dfe2349294c3",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_04d02374695347efabee14e878dba819",
            "value": "variables.data-00000-of-00001:\u2007100%"
          }
        },
        "2ef7b7af0dd44d379ab2dd62916284f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1965ab7c3b4a40318b75c982442d28ed",
            "max": 1212568566,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b70c8c8aff7466591076a9d2a7c3f47",
            "value": 1212568566
          }
        },
        "3e3e3ec3adca42bfb32073a3d7623de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d309dd317b24fc8a78a048a08ceaae7",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_5b06cd6d5d0b4a89a0e5fabc38aab9ab",
            "value": "\u20071.21G/1.21G\u2007[00:07&lt;00:00,\u2007246MB/s]"
          }
        },
        "51e0981338f24b4b838a10ea4d40ed52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3092e4a9003a4c09b0a4dfe2349294c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d02374695347efabee14e878dba819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1965ab7c3b4a40318b75c982442d28ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b70c8c8aff7466591076a9d2a7c3f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d309dd317b24fc8a78a048a08ceaae7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b06cd6d5d0b4a89a0e5fabc38aab9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e30ba9794aab48ac8ea3a0064776cfbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_059daa9e2bfa4b2b994eced5566faa4e",
              "IPY_MODEL_9c612675c5164f3dae01ec523ff5c00b",
              "IPY_MODEL_ebfc982da3fc4528a881e89a714c5336"
            ],
            "layout": "IPY_MODEL_36691816838f4e0ba70b04a0ba72c0bc"
          }
        },
        "059daa9e2bfa4b2b994eced5566faa4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b44273e928548c8b064cc41224ce723",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_3a3f5181ff0143159de1acd38de73687",
            "value": "fingerprint.pb:\u2007100%"
          }
        },
        "9c612675c5164f3dae01ec523ff5c00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c96b25bf6db4b788ca839a603a76ab8",
            "max": 78,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_445d9d629b384cda8b03244d658188cd",
            "value": 78
          }
        },
        "ebfc982da3fc4528a881e89a714c5336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_206711a2d59043cbb4fcc5ca0efcda28",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_43592f9c567441f7b1cd0664efc80843",
            "value": "\u200778.0/78.0\u2007[00:00&lt;00:00,\u2007933B/s]"
          }
        },
        "36691816838f4e0ba70b04a0ba72c0bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b44273e928548c8b064cc41224ce723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a3f5181ff0143159de1acd38de73687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c96b25bf6db4b788ca839a603a76ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "445d9d629b384cda8b03244d658188cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "206711a2d59043cbb4fcc5ca0efcda28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43592f9c567441f7b1cd0664efc80843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02539085db3144be9aeeda9e2fdb4e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_937867b94c8f438589b91bacf9d64ab8",
              "IPY_MODEL_e8e0ecbacf92433294edc61e133315fd",
              "IPY_MODEL_94f40dd5f4894675b321809e119911d9"
            ],
            "layout": "IPY_MODEL_72ed8a28185c4174b841d84a2e9d82b8"
          }
        },
        "937867b94c8f438589b91bacf9d64ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdaee05f761947a1b4b82bce7e54709c",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_26f8805829f64a4ab1780df56a23930a",
            "value": "saved_model.pb:\u2007100%"
          }
        },
        "e8e0ecbacf92433294edc61e133315fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df705a88008e49359ed7408f954073bd",
            "max": 3981322,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37424a3582df4b9787c6badb6fa99d27",
            "value": 3981322
          }
        },
        "94f40dd5f4894675b321809e119911d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81de07af82514444a2849d45414e708c",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_f80dbd298ef64149974f30a42856dd25",
            "value": "\u20073.98M/3.98M\u2007[00:00&lt;00:00,\u200723.5MB/s]"
          }
        },
        "72ed8a28185c4174b841d84a2e9d82b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdaee05f761947a1b4b82bce7e54709c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26f8805829f64a4ab1780df56a23930a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df705a88008e49359ed7408f954073bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37424a3582df4b9787c6badb6fa99d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81de07af82514444a2849d45414e708c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f80dbd298ef64149974f30a42856dd25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26363c2ee1c44957b028d761fa229826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbbe889b153c4633b06f48494bdfb917",
              "IPY_MODEL_5b05ce5f6c594c478b1bada9cc505cb6",
              "IPY_MODEL_677b5a6bb97f445badd6590fe78567ca"
            ],
            "layout": "IPY_MODEL_379431e85f4e4341b85889419f4c48a3"
          }
        },
        "fbbe889b153c4633b06f48494bdfb917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eec7f3957366496c902555183610cb46",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_d7a0a70165b0447db35f44d2aaed2c02",
            "value": "variables.index:\u2007100%"
          }
        },
        "5b05ce5f6c594c478b1bada9cc505cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aca8f687720f412a82e413f773805438",
            "max": 6571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a61f84e75ade45e09e465cef16601d59",
            "value": 6571
          }
        },
        "677b5a6bb97f445badd6590fe78567ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e85518f2415480e8a8c0c8fdec343aa",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_2c91ee3110e741d5bd2735f2b710259c",
            "value": "\u20076.57k/6.57k\u2007[00:00&lt;00:00,\u2007143kB/s]"
          }
        },
        "379431e85f4e4341b85889419f4c48a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eec7f3957366496c902555183610cb46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7a0a70165b0447db35f44d2aaed2c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aca8f687720f412a82e413f773805438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a61f84e75ade45e09e465cef16601d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e85518f2415480e8a8c0c8fdec343aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c91ee3110e741d5bd2735f2b710259c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}