{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UCSF Embedding Validation\n",
        "\n",
        "This notebook validates the generated UCSF embeddings against the original CSV data.\n",
        "It compares patient-wise and file-wise statistics to ensure data integrity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette('husl')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Original CSV Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original CSV shape: (19798, 4)\n",
            "Columns: ['patientID', 'filename', 'path', 'label']\n",
            "\n",
            "First few rows:\n",
            "   patientID                                           filename  \\\n",
            "0  R2D202272  Lung-LeftLateralInfraScapularPosterior-N1vSYj_...   \n",
            "1  R2D202272  Lung-RightInterScapularPosterior-N1vS8Fc0_Icuz...   \n",
            "2  R2D202272  Lung-RightLateralInfraScapularPosterior-N1vSeD...   \n",
            "3  R2D202272  Lung-RightInfraClavicularAnterior-N1vRFB6Dy_0y...   \n",
            "4  R2D202272  Lung-LeftInfraScapularPosterior-N1vSM75j9I3s6e...   \n",
            "\n",
            "                                                path        label  \n",
            "0  ../../../../../../../../../../../../data/Audiu...  TB Negative  \n",
            "1  ../../../../../../../../../../../../data/Audiu...  TB Negative  \n",
            "2  ../../../../../../../../../../../../data/Audiu...  TB Negative  \n",
            "3  ../../../../../../../../../../../../data/Audiu...  TB Negative  \n",
            "4  ../../../../../../../../../../../../data/Audiu...  TB Negative  \n"
          ]
        }
      ],
      "source": [
        "# Load original CSV data\n",
        "csv_path = \"../r2d2_audio_index_with_labels.csv\"\n",
        "original_df = pd.read_csv(csv_path)\n",
        "\n",
        "print(f\"Original CSV shape: {original_df.shape}\")\n",
        "print(f\"Columns: {list(original_df.columns)}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(original_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Embeddings Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available keys in audium_UCSF_embeddings.npz: 19484 keys\n",
            "First 5 keys: ['R2D202272/Lung-LeftLateralInfraScapularPosterior-N1vSYj_jSBZ6TbbOOSE.wav', 'R2D202272/Lung-RightInterScapularPosterior-N1vS8Fc0_IcuzBHHJIO.wav', 'R2D202272/Lung-RightLateralInfraScapularPosterior-N1vSeDnv1QVQAVfVvRu.wav', 'R2D202272/Lung-RightInfraClavicularAnterior-N1vRFB6Dy_0yYnGvC8V.wav', 'R2D202272/Lung-LeftInfraScapularPosterior-N1vSM75j9I3s6eprIEO.wav']\n",
            "First embedding shape: (11, 1024)\n",
            "Successfully matched 19484 embeddings with labels\n",
            "Embeddings DataFrame shape: (19484, 6)\n",
            "Embedding dimension: (11, 1024)\n",
            "\n",
            "First few rows:\n",
            "                                                 key  patientID  \\\n",
            "0  R2D202272/Lung-LeftLateralInfraScapularPosteri...  R2D202272   \n",
            "1  R2D202272/Lung-RightInterScapularPosterior-N1v...  R2D202272   \n",
            "2  R2D202272/Lung-RightLateralInfraScapularPoster...  R2D202272   \n",
            "3  R2D202272/Lung-RightInfraClavicularAnterior-N1...  R2D202272   \n",
            "4  R2D202272/Lung-LeftInfraScapularPosterior-N1vS...  R2D202272   \n",
            "\n",
            "                                            filename    label_str  \n",
            "0  Lung-LeftLateralInfraScapularPosterior-N1vSYj_...  TB Negative  \n",
            "1  Lung-RightInterScapularPosterior-N1vS8Fc0_Icuz...  TB Negative  \n",
            "2  Lung-RightLateralInfraScapularPosterior-N1vSeD...  TB Negative  \n",
            "3  Lung-RightInfraClavicularAnterior-N1vRFB6Dy_0y...  TB Negative  \n",
            "4  Lung-LeftInfraScapularPosterior-N1vSM75j9I3s6e...  TB Negative  \n",
            "\n",
            "Label distribution:\n",
            "label_str\n",
            "TB Negative      16818\n",
            "TB Positive       2505\n",
            "Indeterminate      161\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def load_embeddings_with_labels(embedding_path, metadata_path, max_rows=None):\n",
        "    \"\"\"Load embeddings and match with labels from CSV.\"\"\"\n",
        "    # Load embeddings\n",
        "    embeddings_data = np.load(embedding_path)\n",
        "    \n",
        "    # Check what keys are available in the .npz file\n",
        "    print(f\"Available keys in {embedding_path}: {len(list(embeddings_data.keys()))} keys\")\n",
        "    print(f\"First 5 keys: {list(embeddings_data.keys())[:5]}\")\n",
        "    \n",
        "    # This .npz file structure has each file as a separate key\n",
        "    # Extract embeddings and keys from the structure\n",
        "    keys = list(embeddings_data.keys())\n",
        "    \n",
        "    # Check embedding shapes first\n",
        "    first_embedding = embeddings_data[keys[0]]\n",
        "    print(f\"First embedding shape: {first_embedding.shape}\")\n",
        "    \n",
        "    # Load metadata\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    if max_rows:\n",
        "        metadata = metadata.head(max_rows)\n",
        "    \n",
        "    # Create full key for matching\n",
        "    metadata['full_key'] = metadata['patientID'] + '/' + metadata['filename']\n",
        "    \n",
        "    # Create label mapping\n",
        "    label_map = {\"TB Positive\": 1, \"TB Negative\": 0}\n",
        "    \n",
        "    # Match embeddings with labels\n",
        "    matched_data = []\n",
        "    unmatched_count = 0\n",
        "    for key in keys:\n",
        "        key_str = key.decode('utf-8') if isinstance(key, bytes) else str(key)\n",
        "        matching_row = metadata[metadata['full_key'] == key_str]\n",
        "        \n",
        "        if len(matching_row) > 0:\n",
        "            label_str = matching_row.iloc[0]['label']\n",
        "            label = label_map.get(label_str, -1)\n",
        "            patient_id = matching_row.iloc[0]['patientID']\n",
        "            filename = matching_row.iloc[0]['filename']\n",
        "            \n",
        "            matched_data.append({\n",
        "                'key': key_str,\n",
        "                'patientID': patient_id,\n",
        "                'filename': filename,\n",
        "                'label': label,\n",
        "                'label_str': label_str,\n",
        "                'embedding': embeddings_data[key]  # Store individual embedding\n",
        "            })\n",
        "        else:\n",
        "            unmatched_count += 1\n",
        "            if unmatched_count <= 5:  # Show first 5 unmatched\n",
        "                print(f\"No match found for key: {key_str}\")\n",
        "    \n",
        "    if unmatched_count > 5:\n",
        "        print(f\"... and {unmatched_count - 5} more unmatched keys\")\n",
        "    \n",
        "    print(f\"Successfully matched {len(matched_data)} embeddings with labels\")\n",
        "    return pd.DataFrame(matched_data)\n",
        "\n",
        "# Load embeddings\n",
        "embedding_path = \"../01_data_processing/data/audium_UCSF_embeddings.npz\"\n",
        "embeddings_df = load_embeddings_with_labels(embedding_path, csv_path)\n",
        "\n",
        "print(f\"Embeddings DataFrame shape: {embeddings_df.shape}\")\n",
        "if len(embeddings_df) > 0:\n",
        "    print(f\"Embedding dimension: {embeddings_df['embedding'].iloc[0].shape}\")\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(embeddings_df[['key', 'patientID', 'filename', 'label_str']].head())\n",
        "    \n",
        "    # Check label distribution\n",
        "    print(\"\\nLabel distribution:\")\n",
        "    print(embeddings_df['label_str'].value_counts())\n",
        "else:\n",
        "    print(\"No embeddings were successfully matched!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## File-wise Statistics Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FILE-WISE STATISTICS COMPARISON\n",
            "==================================================\n",
            "Original CSV total files: 19798\n",
            "Embeddings total files: 19484\n",
            "Files matched: 98.41%\n",
            "\n",
            "TB Positive files:\n",
            "  Original: 0 (0.00%)\n",
            "  Embeddings: 2505 (12.86%)\n",
            "\n",
            "TB Negative files:\n",
            "  Original: 0 (0.00%)\n",
            "  Embeddings: 16818 (86.32%)\n",
            "\n",
            "DEBUG INFO:\n",
            "Embeddings DataFrame columns: ['key', 'patientID', 'filename', 'label', 'label_str', 'embedding']\n",
            "Embeddings DataFrame shape: (19484, 6)\n"
          ]
        }
      ],
      "source": [
        "def calculate_file_stats(df, label_col='label', name_prefix=''):\n",
        "    \"\"\"Calculate file-wise statistics.\"\"\"\n",
        "    stats = {}\n",
        "    \n",
        "    # Total files\n",
        "    stats[f'{name_prefix}total_files'] = len(df)\n",
        "    \n",
        "    # Check if the DataFrame is empty or missing the label column\n",
        "    if len(df) == 0:\n",
        "        stats[f'{name_prefix}positive_files'] = 0\n",
        "        stats[f'{name_prefix}negative_files'] = 0\n",
        "        stats[f'{name_prefix}positive_ratio'] = 0\n",
        "        stats[f'{name_prefix}negative_ratio'] = 0\n",
        "        return stats\n",
        "    \n",
        "    if label_col not in df.columns:\n",
        "        print(f\"Warning: Column '{label_col}' not found in DataFrame. Available columns: {list(df.columns)}\")\n",
        "        stats[f'{name_prefix}positive_files'] = 0\n",
        "        stats[f'{name_prefix}negative_files'] = 0\n",
        "        stats[f'{name_prefix}positive_ratio'] = 0\n",
        "        stats[f'{name_prefix}negative_ratio'] = 0\n",
        "        return stats\n",
        "    \n",
        "    # Label distribution\n",
        "    if label_col == 'label':\n",
        "        # For embeddings (numeric labels)\n",
        "        positive_files = (df[label_col] == 1).sum()\n",
        "        negative_files = (df[label_col] == 0).sum()\n",
        "    else:\n",
        "        # For original CSV (string labels)\n",
        "        positive_files = (df[label_col] == 'TB Positive').sum()\n",
        "        negative_files = (df[label_col] == 'TB Negative').sum()\n",
        "    \n",
        "    stats[f'{name_prefix}positive_files'] = positive_files\n",
        "    stats[f'{name_prefix}negative_files'] = negative_files\n",
        "    stats[f'{name_prefix}positive_ratio'] = positive_files / len(df) if len(df) > 0 else 0\n",
        "    stats[f'{name_prefix}negative_ratio'] = negative_files / len(df) if len(df) > 0 else 0\n",
        "    \n",
        "    return stats\n",
        "\n",
        "# Calculate file-wise stats\n",
        "original_file_stats = calculate_file_stats(original_df, 'label', 'original_')\n",
        "embeddings_file_stats = calculate_file_stats(embeddings_df, 'label', 'embeddings_')\n",
        "\n",
        "print(\"FILE-WISE STATISTICS COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Original CSV total files: {original_file_stats['original_total_files']}\")\n",
        "print(f\"Embeddings total files: {embeddings_file_stats['embeddings_total_files']}\")\n",
        "\n",
        "if original_file_stats['original_total_files'] > 0:\n",
        "    print(f\"Files matched: {embeddings_file_stats['embeddings_total_files'] / original_file_stats['original_total_files']:.2%}\")\n",
        "else:\n",
        "    print(\"Files matched: N/A (no original files)\")\n",
        "\n",
        "print()\n",
        "print(\"TB Positive files:\")\n",
        "print(f\"  Original: {original_file_stats['original_positive_files']} ({original_file_stats['original_positive_ratio']:.2%})\")\n",
        "print(f\"  Embeddings: {embeddings_file_stats['embeddings_positive_files']} ({embeddings_file_stats['embeddings_positive_ratio']:.2%})\")\n",
        "print()\n",
        "print(\"TB Negative files:\")\n",
        "print(f\"  Original: {original_file_stats['original_negative_files']} ({original_file_stats['original_negative_ratio']:.2%})\")\n",
        "print(f\"  Embeddings: {embeddings_file_stats['embeddings_negative_files']} ({embeddings_file_stats['embeddings_negative_ratio']:.2%})\")\n",
        "\n",
        "# Debug information\n",
        "print(\"\\nDEBUG INFO:\")\n",
        "print(f\"Embeddings DataFrame columns: {list(embeddings_df.columns) if len(embeddings_df) > 0 else 'DataFrame is empty'}\")\n",
        "print(f\"Embeddings DataFrame shape: {embeddings_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Patient-wise Statistics Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PATIENT-WISE STATISTICS COMPARISON\n",
            "==================================================\n",
            "Original CSV total patients: 551\n",
            "Embeddings total patients: 550\n",
            "Patients matched: 99.82%\n",
            "\n",
            "TB Positive patients:\n",
            "  Original: 0 (0.00%)\n",
            "  Embeddings: 128 (23.27%)\n",
            "\n",
            "TB Negative patients:\n",
            "  Original: 551 (100.00%)\n",
            "  Embeddings: 422 (76.73%)\n",
            "\n",
            "Files per patient:\n",
            "  Original - Avg: 35.9, Min: 1, Max: 8975\n",
            "  Embeddings - Avg: 35.4, Min: 1, Max: 8798\n",
            "\n",
            "DEBUG INFO:\n",
            "Embeddings DataFrame columns: ['key', 'patientID', 'filename', 'label', 'label_str', 'embedding']\n",
            "Embeddings DataFrame shape: (19484, 6)\n"
          ]
        }
      ],
      "source": [
        "def calculate_patient_stats(df, label_col='label', name_prefix=''):\n",
        "    \"\"\"Calculate patient-wise statistics.\"\"\"\n",
        "    stats = {}\n",
        "    \n",
        "    # Check if DataFrame is empty\n",
        "    if len(df) == 0:\n",
        "        stats[f'{name_prefix}total_patients'] = 0\n",
        "        stats[f'{name_prefix}positive_patients'] = 0\n",
        "        stats[f'{name_prefix}negative_patients'] = 0\n",
        "        stats[f'{name_prefix}positive_patient_ratio'] = 0\n",
        "        stats[f'{name_prefix}negative_patient_ratio'] = 0\n",
        "        stats[f'{name_prefix}avg_files_per_patient'] = 0\n",
        "        stats[f'{name_prefix}min_files_per_patient'] = 0\n",
        "        stats[f'{name_prefix}max_files_per_patient'] = 0\n",
        "        return stats, []\n",
        "    \n",
        "    # Check if label column exists\n",
        "    if label_col not in df.columns:\n",
        "        print(f\"Warning: Column '{label_col}' not found in DataFrame. Available columns: {list(df.columns)}\")\n",
        "        stats[f'{name_prefix}total_patients'] = 0\n",
        "        stats[f'{name_prefix}positive_patients'] = 0\n",
        "        stats[f'{name_prefix}negative_patients'] = 0\n",
        "        stats[f'{name_prefix}positive_patient_ratio'] = 0\n",
        "        stats[f'{name_prefix}negative_patient_ratio'] = 0\n",
        "        stats[f'{name_prefix}avg_files_per_patient'] = 0\n",
        "        stats[f'{name_prefix}min_files_per_patient'] = 0\n",
        "        stats[f'{name_prefix}max_files_per_patient'] = 0\n",
        "        return stats, []\n",
        "    \n",
        "    # Group by patient\n",
        "    patient_groups = df.groupby('patientID')\n",
        "    \n",
        "    # Total patients\n",
        "    stats[f'{name_prefix}total_patients'] = len(patient_groups)\n",
        "    \n",
        "    # Patient label determination (any positive file makes patient positive)\n",
        "    patient_labels = []\n",
        "    for patient_id, group in patient_groups:\n",
        "        if label_col == 'label':\n",
        "            # For embeddings (numeric labels)\n",
        "            has_positive = (group[label_col] == 1).any()\n",
        "        else:\n",
        "            # For original CSV (string labels)\n",
        "            has_positive = (group[label_col] == 'TB Positive').any()\n",
        "        \n",
        "        patient_labels.append(1 if has_positive else 0)\n",
        "    \n",
        "    positive_patients = sum(patient_labels)\n",
        "    negative_patients = len(patient_labels) - positive_patients\n",
        "    \n",
        "    stats[f'{name_prefix}positive_patients'] = positive_patients\n",
        "    stats[f'{name_prefix}negative_patients'] = negative_patients\n",
        "    stats[f'{name_prefix}positive_patient_ratio'] = positive_patients / len(patient_labels) if len(patient_labels) > 0 else 0\n",
        "    stats[f'{name_prefix}negative_patient_ratio'] = negative_patients / len(patient_labels) if len(patient_labels) > 0 else 0\n",
        "    \n",
        "    # Files per patient statistics\n",
        "    files_per_patient = patient_groups.size()\n",
        "    stats[f'{name_prefix}avg_files_per_patient'] = files_per_patient.mean()\n",
        "    stats[f'{name_prefix}min_files_per_patient'] = files_per_patient.min()\n",
        "    stats[f'{name_prefix}max_files_per_patient'] = files_per_patient.max()\n",
        "    \n",
        "    return stats, patient_labels\n",
        "\n",
        "# Calculate patient-wise stats\n",
        "original_patient_stats, original_patient_labels = calculate_patient_stats(original_df, 'label', 'original_')\n",
        "embeddings_patient_stats, embeddings_patient_labels = calculate_patient_stats(embeddings_df, 'label', 'embeddings_')\n",
        "\n",
        "print(\"PATIENT-WISE STATISTICS COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Original CSV total patients: {original_patient_stats['original_total_patients']}\")\n",
        "print(f\"Embeddings total patients: {embeddings_patient_stats['embeddings_total_patients']}\")\n",
        "\n",
        "if original_patient_stats['original_total_patients'] > 0:\n",
        "    print(f\"Patients matched: {embeddings_patient_stats['embeddings_total_patients'] / original_patient_stats['original_total_patients']:.2%}\")\n",
        "else:\n",
        "    print(\"Patients matched: N/A (no original patients)\")\n",
        "\n",
        "print()\n",
        "print(\"TB Positive patients:\")\n",
        "print(f\"  Original: {original_patient_stats['original_positive_patients']} ({original_patient_stats['original_positive_patient_ratio']:.2%})\")\n",
        "print(f\"  Embeddings: {embeddings_patient_stats['embeddings_positive_patients']} ({embeddings_patient_stats['embeddings_positive_patient_ratio']:.2%})\")\n",
        "print()\n",
        "print(\"TB Negative patients:\")\n",
        "print(f\"  Original: {original_patient_stats['original_negative_patients']} ({original_patient_stats['original_negative_patient_ratio']:.2%})\")\n",
        "print(f\"  Embeddings: {embeddings_patient_stats['embeddings_negative_patients']} ({embeddings_patient_stats['embeddings_negative_patient_ratio']:.2%})\")\n",
        "print()\n",
        "print(\"Files per patient:\")\n",
        "print(f\"  Original - Avg: {original_patient_stats['original_avg_files_per_patient']:.1f}, Min: {original_patient_stats['original_min_files_per_patient']}, Max: {original_patient_stats['original_max_files_per_patient']}\")\n",
        "print(f\"  Embeddings - Avg: {embeddings_patient_stats['embeddings_avg_files_per_patient']:.1f}, Min: {embeddings_patient_stats['embeddings_min_files_per_patient']}, Max: {embeddings_patient_stats['embeddings_max_files_per_patient']}\")\n",
        "\n",
        "# Debug information\n",
        "print(\"\\nDEBUG INFO:\")\n",
        "print(f\"Embeddings DataFrame columns: {list(embeddings_df.columns) if len(embeddings_df) > 0 else 'DataFrame is empty'}\")\n",
        "print(f\"Embeddings DataFrame shape: {embeddings_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Integrity Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA INTEGRITY CHECKS\n",
            "==================================================\n",
            "\u2713 Files in original CSV: 19798\n",
            "\u2713 Files in embeddings: 19484\n",
            "\u2713 Missing from embeddings: 314\n",
            "\u2713 Extra in embeddings: 0\n",
            "\n",
            "\u26a0\ufe0f  Sample missing files:\n",
            "  1. R2D204247/-MlslEvUEPBdW_B6NT9O.wav\n",
            "  2. R2D204247/-MlsktUJhiKqHKBEBeF6.wav\n",
            "  3. R2D201001/-MzDtZ5Gl6aiB5Qf-98d.wav\n",
            "  4. R2D201001/-Mj3t5IcxzF53K43T4kN.wav\n",
            "  5. R2D201294/-MyuyN3pkcop4NF73sPu.wav\n",
            "  ... and 309 more\n",
            "\n",
            "\u2713 Label consistency check (sample of 100): 100/100 matches\n",
            "\n",
            "\u2713 Embedding quality:\n",
            "  Shape: (11, 1024)\n",
            "  Data type: float32\n",
            "  Mean: -0.0156\n",
            "  Std: 1.0074\n",
            "  Min/Max: -3.7064 / 3.8234\n",
            "  NaN values: 0\n",
            "  Infinite values: 0\n"
          ]
        }
      ],
      "source": [
        "def perform_integrity_checks(original_df, embeddings_df):\n",
        "    \"\"\"Perform comprehensive data integrity checks.\"\"\"\n",
        "    print(\"DATA INTEGRITY CHECKS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Check 1: Missing files\n",
        "    original_keys = set(original_df['patientID'] + '/' + original_df['filename'])\n",
        "    embedding_keys = set(embeddings_df['key']) if len(embeddings_df) > 0 else set()\n",
        "    \n",
        "    missing_in_embeddings = original_keys - embedding_keys\n",
        "    extra_in_embeddings = embedding_keys - original_keys\n",
        "    \n",
        "    print(f\"\u2713 Files in original CSV: {len(original_keys)}\")\n",
        "    print(f\"\u2713 Files in embeddings: {len(embedding_keys)}\")\n",
        "    print(f\"\u2713 Missing from embeddings: {len(missing_in_embeddings)}\")\n",
        "    print(f\"\u2713 Extra in embeddings: {len(extra_in_embeddings)}\")\n",
        "    \n",
        "    if missing_in_embeddings:\n",
        "        print(\"\\n\u26a0\ufe0f  Sample missing files:\")\n",
        "        for i, missing_file in enumerate(list(missing_in_embeddings)[:5]):\n",
        "            print(f\"  {i+1}. {missing_file}\")\n",
        "        if len(missing_in_embeddings) > 5:\n",
        "            print(f\"  ... and {len(missing_in_embeddings) - 5} more\")\n",
        "    \n",
        "    # Check 2: Label consistency (sample check)\n",
        "    common_keys = original_keys & embedding_keys\n",
        "    label_mismatches = 0\n",
        "    \n",
        "    if len(common_keys) > 0:\n",
        "        sample_size = min(100, len(common_keys))\n",
        "        sample_keys = list(common_keys)[:sample_size]\n",
        "        \n",
        "        for key in sample_keys:\n",
        "            original_label = original_df[original_df['patientID'] + '/' + original_df['filename'] == key]['label'].iloc[0]\n",
        "            embedding_label = embeddings_df[embeddings_df['key'] == key]['label_str'].iloc[0]\n",
        "            \n",
        "            if original_label != embedding_label:\n",
        "                label_mismatches += 1\n",
        "        \n",
        "        print(f\"\\n\u2713 Label consistency check (sample of {sample_size}): {sample_size - label_mismatches}/{sample_size} matches\")\n",
        "        if label_mismatches > 0:\n",
        "            print(f\"\u26a0\ufe0f  Label mismatches found: {label_mismatches}\")\n",
        "    \n",
        "    # Check 3: Embedding quality\n",
        "    if len(embeddings_df) > 0:\n",
        "        sample_embedding = embeddings_df['embedding'].iloc[0]\n",
        "        \n",
        "        # Check for NaN or infinite values\n",
        "        nan_count = np.isnan(sample_embedding).sum()\n",
        "        inf_count = np.isinf(sample_embedding).sum()\n",
        "        \n",
        "        print(f\"\\n\u2713 Embedding quality:\")\n",
        "        print(f\"  Shape: {sample_embedding.shape}\")\n",
        "        print(f\"  Data type: {sample_embedding.dtype}\")\n",
        "        print(f\"  Mean: {sample_embedding.mean():.4f}\")\n",
        "        print(f\"  Std: {sample_embedding.std():.4f}\")\n",
        "        print(f\"  Min/Max: {sample_embedding.min():.4f} / {sample_embedding.max():.4f}\")\n",
        "        print(f\"  NaN values: {nan_count}\")\n",
        "        print(f\"  Infinite values: {inf_count}\")\n",
        "    \n",
        "    return {\n",
        "        'missing_files': len(missing_in_embeddings),\n",
        "        'extra_files': len(extra_in_embeddings),\n",
        "        'label_mismatches': label_mismatches,\n",
        "        'common_files': len(common_keys)\n",
        "    }\n",
        "\n",
        "integrity_results = perform_integrity_checks(original_df, embeddings_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/abelvillcaroque/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/axes/_axes.py:3365: RuntimeWarning: invalid value encountered in divide\n",
            "  x = x / sx\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "cannot convert float NaN to integer",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    114\u001b[39m     plt.tight_layout()\n\u001b[32m    115\u001b[39m     plt.show()\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[43mcreate_validation_dashboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_file_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_file_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m                           \u001b[49m\u001b[43moriginal_patient_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_patient_stats\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mcreate_validation_dashboard\u001b[39m\u001b[34m(original_df, embeddings_df, original_file_stats, embeddings_file_stats, original_patient_stats, embeddings_patient_stats)\u001b[39m\n\u001b[32m     50\u001b[39m original_labels = [\u001b[33m'\u001b[39m\u001b[33mTB Positive\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTB Negative\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     51\u001b[39m original_sizes = [original_file_stats[\u001b[33m'\u001b[39m\u001b[33moriginal_positive_files\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m     52\u001b[39m                  original_file_stats[\u001b[33m'\u001b[39m\u001b[33moriginal_negative_files\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpie\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43moriginal_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautopct\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m%1.1f\u001b[39;49;00m\u001b[38;5;132;43;01m%%\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartangle\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m90\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m axes[\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m].set_title(\u001b[33m'\u001b[39m\u001b[33mOriginal CSV\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLabel Distribution\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# 4. Files per patient distribution\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/_api/deprecation.py:453\u001b[39m, in \u001b[36mmake_keyword_only.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > name_idx:\n\u001b[32m    448\u001b[39m     warn_deprecated(\n\u001b[32m    449\u001b[39m         since, message=\u001b[33m\"\u001b[39m\u001b[33mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[33m; the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mparameter will become keyword-only in \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    452\u001b[39m         name=name, obj_type=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/__init__.py:1521\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1518\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1526\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1527\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1528\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/axes/_axes.py:3409\u001b[39m, in \u001b[36mAxes.pie\u001b[39m\u001b[34m(self, x, explode, labels, colors, autopct, pctdistance, shadow, labeldistance, startangle, radius, counterclock, wedgeprops, textprops, center, frame, rotatelabels, normalize, hatch)\u001b[39m\n\u001b[32m   3406\u001b[39m x += expl * math.cos(thetam)\n\u001b[32m   3407\u001b[39m y += expl * math.sin(thetam)\n\u001b[32m-> \u001b[39m\u001b[32m3409\u001b[39m w = \u001b[43mmpatches\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWedge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m360.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtheta1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3410\u001b[39m \u001b[43m                   \u001b[49m\u001b[32;43m360.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtheta1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3411\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_next_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3412\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhatch_cycle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3413\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mclip_on\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3414\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3415\u001b[39m w.set(**wedgeprops)\n\u001b[32m   3416\u001b[39m slices.append(w)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/patches.py:1252\u001b[39m, in \u001b[36mWedge.__init__\u001b[39m\u001b[34m(self, center, r, theta1, theta2, width, **kwargs)\u001b[39m\n\u001b[32m   1250\u001b[39m \u001b[38;5;28mself\u001b[39m.theta1, \u001b[38;5;28mself\u001b[39m.theta2 = theta1, theta2\n\u001b[32m   1251\u001b[39m \u001b[38;5;28mself\u001b[39m._patch_transform = transforms.IdentityTransform()\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recompute_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/patches.py:1264\u001b[39m, in \u001b[36mWedge._recompute_path\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1261\u001b[39m     connector = Path.LINETO\n\u001b[32m   1263\u001b[39m \u001b[38;5;66;03m# Form the outer ring\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m arc = \u001b[43mPath\u001b[49m\u001b[43m.\u001b[49m\u001b[43marc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# Partial annulus needs to draw the outer ring\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# followed by a reversed and scaled inner ring\u001b[39;00m\n\u001b[32m   1269\u001b[39m     v1 = arc.vertices\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/path.py:982\u001b[39m, in \u001b[36mPath.arc\u001b[39m\u001b[34m(cls, theta1, theta2, n, is_wedge)\u001b[39m\n\u001b[32m    980\u001b[39m \u001b[38;5;66;03m# number of curve segments to make\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     n = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mceil\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43meta2\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43meta1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalfpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[32m1\u001b[39m:\n\u001b[32m    984\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mn must be >= 1 or None\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mValueError\u001b[39m: cannot convert float NaN to integer"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "need at least one array to concatenate",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/IPython/core/formatters.py:402\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[32m    404\u001b[39m method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/IPython/core/pylabtools.py:170\u001b[39m, in \u001b[36mprint_figure\u001b[39m\u001b[34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[32m    168\u001b[39m     FigureCanvasBase(fig)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m data = bytes_io.getvalue()\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fmt == \u001b[33m'\u001b[39m\u001b[33msvg\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/backend_bases.py:2158\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[32m   2157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches == \u001b[33m\"\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2158\u001b[39m         bbox_inches = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2159\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2160\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(layout_engine, ConstrainedLayoutEngine) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   2161\u001b[39m                 pad_inches == \u001b[33m\"\u001b[39m\u001b[33mlayout\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2162\u001b[39m             h_pad = layout_engine.get()[\u001b[33m\"\u001b[39m\u001b[33mh_pad\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/figure.py:1848\u001b[39m, in \u001b[36mFigureBase.get_tightbbox\u001b[39m\u001b[34m(self, renderer, bbox_extra_artists)\u001b[39m\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ax.get_visible():\n\u001b[32m   1845\u001b[39m     \u001b[38;5;66;03m# some Axes don't take the bbox_extra_artists kwarg so we\u001b[39;00m\n\u001b[32m   1846\u001b[39m     \u001b[38;5;66;03m# need this conditional....\u001b[39;00m\n\u001b[32m   1847\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1848\u001b[39m         bbox = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1849\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1851\u001b[39m         bbox = ax.get_tightbbox(renderer)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/axes/_base.py:4577\u001b[39m, in \u001b[36m_AxesBase.get_tightbbox\u001b[39m\u001b[34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[39m\n\u001b[32m   4574\u001b[39m     bbox_artists = \u001b[38;5;28mself\u001b[39m.get_default_bbox_extra_artists()\n\u001b[32m   4576\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m bbox_artists:\n\u001b[32m-> \u001b[39m\u001b[32m4577\u001b[39m     bbox = \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4578\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4579\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[32m0\u001b[39m < bbox.width < np.inf\n\u001b[32m   4580\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[32m0\u001b[39m < bbox.height < np.inf):\n\u001b[32m   4581\u001b[39m         bb.append(bbox)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/artist.py:364\u001b[39m, in \u001b[36mArtist.get_tightbbox\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_tightbbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    349\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    350\u001b[39m \u001b[33;03m    Like `.Artist.get_window_extent`, but includes any clipping.\u001b[39;00m\n\u001b[32m    351\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    362\u001b[39m \u001b[33;03m        Returns None if clipping results in no intersection.\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     bbox = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_clip_on():\n\u001b[32m    366\u001b[39m         clip_box = \u001b[38;5;28mself\u001b[39m.get_clip_box()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/patches.py:655\u001b[39m, in \u001b[36mPatch.get_window_extent\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_window_extent\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_extents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/python/venvs/v_audium_hear/lib/python3.12/site-packages/matplotlib/path.py:642\u001b[39m, in \u001b[36mPath.get_extents\u001b[39m\u001b[34m(self, transform, **kwargs)\u001b[39m\n\u001b[32m    640\u001b[39m         \u001b[38;5;66;03m# as can the ends of the curve\u001b[39;00m\n\u001b[32m    641\u001b[39m         xys.append(curve([\u001b[32m0\u001b[39m, *dzeros, \u001b[32m1\u001b[39m]))\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     xys = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xys):\n\u001b[32m    644\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Bbox([xys.min(axis=\u001b[32m0\u001b[39m), xys.max(axis=\u001b[32m0\u001b[39m)])\n",
            "\u001b[31mValueError\u001b[39m: need at least one array to concatenate"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1800x1200 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def create_validation_dashboard(original_df, embeddings_df, original_file_stats, embeddings_file_stats, \n",
        "                               original_patient_stats, embeddings_patient_stats):\n",
        "    \"\"\"Create a comprehensive validation dashboard.\"\"\"\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('UCSF Embedding Validation Dashboard', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. File count comparison\n",
        "    categories = ['Total Files', 'TB Positive', 'TB Negative']\n",
        "    original_counts = [original_file_stats['original_total_files'], \n",
        "                      original_file_stats['original_positive_files'],\n",
        "                      original_file_stats['original_negative_files']]\n",
        "    embedding_counts = [embeddings_file_stats['embeddings_total_files'],\n",
        "                       embeddings_file_stats['embeddings_positive_files'],\n",
        "                       embeddings_file_stats['embeddings_negative_files']]\n",
        "    \n",
        "    x = np.arange(len(categories))\n",
        "    width = 0.35\n",
        "    \n",
        "    axes[0, 0].bar(x - width/2, original_counts, width, label='Original CSV', alpha=0.8)\n",
        "    axes[0, 0].bar(x + width/2, embedding_counts, width, label='Embeddings', alpha=0.8)\n",
        "    axes[0, 0].set_title('File Count Comparison')\n",
        "    axes[0, 0].set_xlabel('Category')\n",
        "    axes[0, 0].set_ylabel('Count')\n",
        "    axes[0, 0].set_xticks(x)\n",
        "    axes[0, 0].set_xticklabels(categories)\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Patient count comparison\n",
        "    patient_categories = ['Total Patients', 'TB Positive', 'TB Negative']\n",
        "    original_patient_counts = [original_patient_stats['original_total_patients'],\n",
        "                              original_patient_stats['original_positive_patients'],\n",
        "                              original_patient_stats['original_negative_patients']]\n",
        "    embedding_patient_counts = [embeddings_patient_stats['embeddings_total_patients'],\n",
        "                               embeddings_patient_stats['embeddings_positive_patients'],\n",
        "                               embeddings_patient_stats['embeddings_negative_patients']]\n",
        "    \n",
        "    axes[0, 1].bar(x - width/2, original_patient_counts, width, label='Original CSV', alpha=0.8)\n",
        "    axes[0, 1].bar(x + width/2, embedding_patient_counts, width, label='Embeddings', alpha=0.8)\n",
        "    axes[0, 1].set_title('Patient Count Comparison')\n",
        "    axes[0, 1].set_xlabel('Category')\n",
        "    axes[0, 1].set_ylabel('Count')\n",
        "    axes[0, 1].set_xticks(x)\n",
        "    axes[0, 1].set_xticklabels(patient_categories)\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Label distribution pie charts\n",
        "    original_labels = ['TB Positive', 'TB Negative']\n",
        "    original_sizes = [original_file_stats['original_positive_files'], \n",
        "                     original_file_stats['original_negative_files']]\n",
        "    \n",
        "    axes[0, 2].pie(original_sizes, labels=original_labels, autopct='%1.1f%%', startangle=90)\n",
        "    axes[0, 2].set_title('Original CSV\\nLabel Distribution')\n",
        "    \n",
        "    # 4. Files per patient distribution\n",
        "    original_files_per_patient = original_df.groupby('patientID').size()\n",
        "    embeddings_files_per_patient = embeddings_df.groupby('patientID').size()\n",
        "    \n",
        "    axes[1, 0].hist(original_files_per_patient, bins=20, alpha=0.7, label='Original CSV', density=True)\n",
        "    axes[1, 0].hist(embeddings_files_per_patient, bins=20, alpha=0.7, label='Embeddings', density=True)\n",
        "    axes[1, 0].set_title('Files per Patient Distribution')\n",
        "    axes[1, 0].set_xlabel('Files per Patient')\n",
        "    axes[1, 0].set_ylabel('Density')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 5. Embedding quality metrics\n",
        "    if len(embeddings_df) > 0:\n",
        "        embedding_matrix = np.stack(embeddings_df['embedding'].values)\n",
        "        norms = np.linalg.norm(embedding_matrix, axis=1)\n",
        "        \n",
        "        axes[1, 1].hist(norms, bins=30, alpha=0.7, color='green')\n",
        "        axes[1, 1].set_title('Embedding Magnitude Distribution')\n",
        "        axes[1, 1].set_xlabel('L2 Norm')\n",
        "        axes[1, 1].set_ylabel('Frequency')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add statistics text\n",
        "        mean_norm = np.mean(norms)\n",
        "        std_norm = np.std(norms)\n",
        "        axes[1, 1].axvline(mean_norm, color='red', linestyle='--', label=f'Mean: {mean_norm:.3f}')\n",
        "        axes[1, 1].legend()\n",
        "    \n",
        "    # 6. Data integrity summary\n",
        "    axes[1, 2].axis('off')\n",
        "    \n",
        "    # Create summary text\n",
        "    summary_text = f\"\"\"DATA INTEGRITY SUMMARY\n",
        "\n",
        "File Coverage:\n",
        "\u2022 Original: {original_file_stats['original_total_files']} files\n",
        "\u2022 Embeddings: {embeddings_file_stats['embeddings_total_files']} files\n",
        "\u2022 Coverage: {embeddings_file_stats['embeddings_total_files']/original_file_stats['original_total_files']:.1%}\n",
        "\n",
        "Patient Coverage:\n",
        "\u2022 Original: {original_patient_stats['original_total_patients']} patients\n",
        "\u2022 Embeddings: {embeddings_patient_stats['embeddings_total_patients']} patients\n",
        "\u2022 Coverage: {embeddings_patient_stats['embeddings_total_patients']/original_patient_stats['original_total_patients']:.1%}\n",
        "\n",
        "Label Balance (File-wise):\n",
        "\u2022 TB Positive: {original_file_stats['original_positive_ratio']:.1%} \u2192 {embeddings_file_stats['embeddings_positive_ratio']:.1%}\n",
        "\u2022 TB Negative: {original_file_stats['original_negative_ratio']:.1%} \u2192 {embeddings_file_stats['embeddings_negative_ratio']:.1%}\n",
        "\n",
        "Label Balance (Patient-wise):\n",
        "\u2022 TB Positive: {original_patient_stats['original_positive_patient_ratio']:.1%} \u2192 {embeddings_patient_stats['embeddings_positive_patient_ratio']:.1%}\n",
        "\u2022 TB Negative: {original_patient_stats['original_negative_patient_ratio']:.1%} \u2192 {embeddings_patient_stats['embeddings_negative_patient_ratio']:.1%}\"\"\"\n",
        "    \n",
        "    axes[1, 2].text(0.05, 0.95, summary_text, transform=axes[1, 2].transAxes, \n",
        "                   fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
        "                   bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "create_validation_dashboard(original_df, embeddings_df, original_file_stats, embeddings_file_stats,\n",
        "                           original_patient_stats, embeddings_patient_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Validation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_validation_report(original_df, embeddings_df, original_file_stats, embeddings_file_stats,\n",
        "                              original_patient_stats, embeddings_patient_stats, integrity_results):\n",
        "    \"\"\"Generate a comprehensive validation report.\"\"\"\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"UCSF EMBEDDING VALIDATION REPORT\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    print(\"\\n\ud83d\udcca SUMMARY\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Original CSV: {original_file_stats['original_total_files']} files from {original_patient_stats['original_total_patients']} patients\")\n",
        "    print(f\"Generated embeddings: {embeddings_file_stats['embeddings_total_files']} files from {embeddings_patient_stats['embeddings_total_patients']} patients\")\n",
        "    print(f\"Coverage: {embeddings_file_stats['embeddings_total_files']/original_file_stats['original_total_files']:.1%} files, {embeddings_patient_stats['embeddings_total_patients']/original_patient_stats['original_total_patients']:.1%} patients\")\n",
        "    \n",
        "    print(\"\\n\ud83d\udcc8 FILE-WISE STATISTICS\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"TB Positive files: {original_file_stats['original_positive_files']} \u2192 {embeddings_file_stats['embeddings_positive_files']} ({original_file_stats['original_positive_ratio']:.1%} \u2192 {embeddings_file_stats['embeddings_positive_ratio']:.1%})\")\n",
        "    print(f\"TB Negative files: {original_file_stats['original_negative_files']} \u2192 {embeddings_file_stats['embeddings_negative_files']} ({original_file_stats['original_negative_ratio']:.1%} \u2192 {embeddings_file_stats['embeddings_negative_ratio']:.1%})\")\n",
        "    \n",
        "    print(\"\\n\ud83d\udc65 PATIENT-WISE STATISTICS\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"TB Positive patients: {original_patient_stats['original_positive_patients']} \u2192 {embeddings_patient_stats['embeddings_positive_patients']} ({original_patient_stats['original_positive_patient_ratio']:.1%} \u2192 {embeddings_patient_stats['embeddings_positive_patient_ratio']:.1%})\")\n",
        "    print(f\"TB Negative patients: {original_patient_stats['original_negative_patients']} \u2192 {embeddings_patient_stats['embeddings_negative_patients']} ({original_patient_stats['original_negative_patient_ratio']:.1%} \u2192 {embeddings_patient_stats['embeddings_negative_patient_ratio']:.1%})\")\n",
        "    print(f\"Avg files per patient: {original_patient_stats['original_avg_files_per_patient']:.1f} \u2192 {embeddings_patient_stats['embeddings_avg_files_per_patient']:.1f}\")\n",
        "    \n",
        "    print(\"\\n\ud83d\udd0d DATA INTEGRITY\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Files successfully processed: {integrity_results['common_files']}/{original_file_stats['original_total_files']} ({integrity_results['common_files']/original_file_stats['original_total_files']:.1%})\")\n",
        "    print(f\"Missing files: {integrity_results['missing_files']}\")\n",
        "    print(f\"Extra files: {integrity_results['extra_files']}\")\n",
        "    print(f\"Label mismatches: {integrity_results['label_mismatches']}\")\n",
        "    \n",
        "    if len(embeddings_df) > 0:\n",
        "        embedding_matrix = np.stack(embeddings_df['embedding'].values)\n",
        "        print(\"\\n\ud83c\udfaf EMBEDDING QUALITY\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"Embedding shape: {embedding_matrix.shape}\")\n",
        "        print(f\"Data type: {embedding_matrix.dtype}\")\n",
        "        print(f\"Mean magnitude: {np.mean(np.linalg.norm(embedding_matrix, axis=1)):.4f}\")\n",
        "        print(f\"Std magnitude: {np.std(np.linalg.norm(embedding_matrix, axis=1)):.4f}\")\n",
        "        print(f\"Min/Max values: {embedding_matrix.min():.4f} / {embedding_matrix.max():.4f}\")\n",
        "        \n",
        "        # Check for problematic values\n",
        "        nan_count = np.isnan(embedding_matrix).sum()\n",
        "        inf_count = np.isinf(embedding_matrix).sum()\n",
        "        if nan_count > 0 or inf_count > 0:\n",
        "            print(f\"\u26a0\ufe0f  Issues found: {nan_count} NaN values, {inf_count} infinite values\")\n",
        "        else:\n",
        "            print(\"\u2705 No NaN or infinite values found\")\n",
        "    \n",
        "    print(\"\\n\u2705 VALIDATION CONCLUSION\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Determine overall validation status\n",
        "    issues = []\n",
        "    if integrity_results['missing_files'] > 0:\n",
        "        issues.append(f\"{integrity_results['missing_files']} missing files\")\n",
        "    if integrity_results['label_mismatches'] > 0:\n",
        "        issues.append(f\"{integrity_results['label_mismatches']} label mismatches\")\n",
        "    if len(embeddings_df) > 0:\n",
        "        embedding_matrix = np.stack(embeddings_df['embedding'].values)\n",
        "        if np.isnan(embedding_matrix).sum() > 0 or np.isinf(embedding_matrix).sum() > 0:\n",
        "            issues.append(\"problematic embedding values\")\n",
        "    \n",
        "    if not issues:\n",
        "        print(\"\ud83c\udf89 VALIDATION PASSED: Embeddings are consistent with original data\")\n",
        "        print(\"   \u2022 All files processed successfully\")\n",
        "        print(\"   \u2022 Label distributions match\")\n",
        "        print(\"   \u2022 Embedding quality is good\")\n",
        "    else:\n",
        "        print(\"\u26a0\ufe0f  VALIDATION ISSUES FOUND:\")\n",
        "        for issue in issues:\n",
        "            print(f\"   \u2022 {issue}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# Generate final report\n",
        "generate_validation_report(original_df, embeddings_df, original_file_stats, embeddings_file_stats,\n",
        "                          original_patient_stats, embeddings_patient_stats, integrity_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}